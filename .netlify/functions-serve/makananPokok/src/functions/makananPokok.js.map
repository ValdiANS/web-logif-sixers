{
  "version": 3,
  "sources": ["../../src/constants.ts", "../../src/logging.ts", "../../src/metadata.ts", "../../src/call-credentials.ts", "../../src/stream-decoder.ts", "../../src/call-stream.ts", "../../src/tls-helpers.ts", "../../src/channel-credentials.ts", "../../src/load-balancer.ts", "../../src/service-config.ts", "../../src/connectivity-state.ts", "../../src/uri-parser.ts", "../../src/resolver.ts", "../../src/picker.ts", "../../src/backoff-timeout.ts", "../../src/load-balancer-child-handler.ts", "../../src/resolving-load-balancer.ts", "../../src/channel-options.ts", "../../src/subchannel-address.ts", "../../src/http_proxy.ts", "../../src/admin.ts", "../../src/call.ts", "../../src/client-interceptors.ts", "../../src/client.ts", "../../src/make-client.ts", "node_modules/lodash.camelcase/index.js", "node_modules/@protobufjs/aspromise/index.js", "node_modules/@protobufjs/base64/index.js", "node_modules/@protobufjs/eventemitter/index.js", "node_modules/@protobufjs/float/index.js", "node_modules/@protobufjs/inquire/index.js", "node_modules/@protobufjs/utf8/index.js", "node_modules/@protobufjs/pool/index.js", "node_modules/protobufjs/src/util/longbits.js", "node_modules/protobufjs/src/util/minimal.js", "node_modules/protobufjs/src/writer.js", "node_modules/protobufjs/src/writer_buffer.js", "node_modules/protobufjs/src/reader.js", "node_modules/protobufjs/src/reader_buffer.js", "node_modules/protobufjs/src/rpc/service.js", "node_modules/protobufjs/src/rpc.js", "node_modules/protobufjs/src/roots.js", "node_modules/protobufjs/src/index-minimal.js", "node_modules/@protobufjs/codegen/index.js", "node_modules/@protobufjs/fetch/index.js", "node_modules/@protobufjs/path/index.js", "node_modules/protobufjs/src/types.js", "node_modules/protobufjs/src/field.js", "node_modules/protobufjs/src/oneof.js", "node_modules/protobufjs/src/namespace.js", "node_modules/protobufjs/src/mapfield.js", "node_modules/protobufjs/src/method.js", "node_modules/protobufjs/src/service.js", "node_modules/protobufjs/src/message.js", "node_modules/protobufjs/src/decoder.js", "node_modules/protobufjs/src/verifier.js", "node_modules/protobufjs/src/converter.js", "node_modules/protobufjs/src/wrappers.js", "node_modules/protobufjs/src/type.js", "node_modules/protobufjs/src/root.js", "node_modules/protobufjs/src/util.js", "node_modules/protobufjs/src/object.js", "node_modules/protobufjs/src/enum.js", "node_modules/protobufjs/src/encoder.js", "node_modules/protobufjs/src/index-light.js", "node_modules/protobufjs/src/tokenize.js", "node_modules/protobufjs/src/parse.js", "node_modules/protobufjs/src/common.js", "node_modules/protobufjs/src/index.js", "node_modules/protobufjs/index.js", "node_modules/protobufjs/ext/descriptor/index.js", "node_modules/@grpc/proto-loader/build/src/util.js", "node_modules/@grpc/proto-loader/build/src/index.js", "../../src/channelz.ts", "../../src/subchannel.ts", "../../src/subchannel-pool.ts", "../../src/filter-stack.ts", "../../src/filter.ts", "../../src/call-credentials-filter.ts", "../../src/deadline-filter.ts", "../../src/compression-filter.ts", "../../src/max-message-size-filter.ts", "../../src/channel.ts", "../../src/server-call.ts", "../../src/server-credentials.ts", "../../src/server.ts", "../../src/status-builder.ts", "../../src/experimental.ts", "../../src/resolver-dns.ts", "../../src/resolver-uds.ts", "../../src/resolver-ip.ts", "../../src/load-balancer-pick-first.ts", "../../src/load-balancer-round-robin.ts", "../../src/index.ts", "../../src/constants.ts", "../../src/assert.ts", "../../src/crypt.ts", "../../src/deepCopy.ts", "../../src/deferred.ts", "../../src/emulator.ts", "../../src/environment.ts", "../../src/errors.ts", "../../src/json.ts", "../../src/jwt.ts", "../../src/obj.ts", "../../src/query.ts", "../../src/sha1.ts", "../../src/subscribe.ts", "../../src/validation.ts", "../../src/utf8.ts", "../../src/exponential_backoff.ts", "../../src/formatters.ts", "../../src/compat.ts", "../../index.node.ts", "../../src/component.ts", "../../src/constants.ts", "../../src/provider.ts", "../../src/component_container.ts", "../../src/logger.ts", "../../src/platformLoggerService.ts", "../../src/logger.ts", "../../src/constants.ts", "../../src/internal.ts", "../../src/errors.ts", "../../src/firebaseApp.ts", "../../src/api.ts", "../../src/registerCoreComponents.ts", "../../src/index.ts", "../index.ts", "index.node.mjs", "functions/firebase.config.js", "functions/makananPokok.js"],
  "sourceRoot": "C:/Users/Valdi/AppData/Local/Temp/tmp-15668-HYRpzMZ07SL5",
  "sourcesContent": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, "/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/** `Object#toString` result references. */\nvar symbolTag = '[object Symbol]';\n\n/** Used to match words composed of alphanumeric characters. */\nvar reAsciiWord = /[^\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\x7f]+/g;\n\n/** Used to match Latin Unicode letters (excluding mathematical operators). */\nvar reLatin = /[\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\xff\\u0100-\\u017f]/g;\n\n/** Used to compose unicode character classes. */\nvar rsAstralRange = '\\\\ud800-\\\\udfff',\n    rsComboMarksRange = '\\\\u0300-\\\\u036f\\\\ufe20-\\\\ufe23',\n    rsComboSymbolsRange = '\\\\u20d0-\\\\u20f0',\n    rsDingbatRange = '\\\\u2700-\\\\u27bf',\n    rsLowerRange = 'a-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xff',\n    rsMathOpRange = '\\\\xac\\\\xb1\\\\xd7\\\\xf7',\n    rsNonCharRange = '\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf',\n    rsPunctuationRange = '\\\\u2000-\\\\u206f',\n    rsSpaceRange = ' \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000',\n    rsUpperRange = 'A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde',\n    rsVarRange = '\\\\ufe0e\\\\ufe0f',\n    rsBreakRange = rsMathOpRange + rsNonCharRange + rsPunctuationRange + rsSpaceRange;\n\n/** Used to compose unicode capture groups. */\nvar rsApos = \"['\\u2019]\",\n    rsAstral = '[' + rsAstralRange + ']',\n    rsBreak = '[' + rsBreakRange + ']',\n    rsCombo = '[' + rsComboMarksRange + rsComboSymbolsRange + ']',\n    rsDigits = '\\\\d+',\n    rsDingbat = '[' + rsDingbatRange + ']',\n    rsLower = '[' + rsLowerRange + ']',\n    rsMisc = '[^' + rsAstralRange + rsBreakRange + rsDigits + rsDingbatRange + rsLowerRange + rsUpperRange + ']',\n    rsFitz = '\\\\ud83c[\\\\udffb-\\\\udfff]',\n    rsModifier = '(?:' + rsCombo + '|' + rsFitz + ')',\n    rsNonAstral = '[^' + rsAstralRange + ']',\n    rsRegional = '(?:\\\\ud83c[\\\\udde6-\\\\uddff]){2}',\n    rsSurrPair = '[\\\\ud800-\\\\udbff][\\\\udc00-\\\\udfff]',\n    rsUpper = '[' + rsUpperRange + ']',\n    rsZWJ = '\\\\u200d';\n\n/** Used to compose unicode regexes. */\nvar rsLowerMisc = '(?:' + rsLower + '|' + rsMisc + ')',\n    rsUpperMisc = '(?:' + rsUpper + '|' + rsMisc + ')',\n    rsOptLowerContr = '(?:' + rsApos + '(?:d|ll|m|re|s|t|ve))?',\n    rsOptUpperContr = '(?:' + rsApos + '(?:D|LL|M|RE|S|T|VE))?',\n    reOptMod = rsModifier + '?',\n    rsOptVar = '[' + rsVarRange + ']?',\n    rsOptJoin = '(?:' + rsZWJ + '(?:' + [rsNonAstral, rsRegional, rsSurrPair].join('|') + ')' + rsOptVar + reOptMod + ')*',\n    rsSeq = rsOptVar + reOptMod + rsOptJoin,\n    rsEmoji = '(?:' + [rsDingbat, rsRegional, rsSurrPair].join('|') + ')' + rsSeq,\n    rsSymbol = '(?:' + [rsNonAstral + rsCombo + '?', rsCombo, rsRegional, rsSurrPair, rsAstral].join('|') + ')';\n\n/** Used to match apostrophes. */\nvar reApos = RegExp(rsApos, 'g');\n\n/**\n * Used to match [combining diacritical marks](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks) and\n * [combining diacritical marks for symbols](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks_for_Symbols).\n */\nvar reComboMark = RegExp(rsCombo, 'g');\n\n/** Used to match [string symbols](https://mathiasbynens.be/notes/javascript-unicode). */\nvar reUnicode = RegExp(rsFitz + '(?=' + rsFitz + ')|' + rsSymbol + rsSeq, 'g');\n\n/** Used to match complex or compound words. */\nvar reUnicodeWord = RegExp([\n  rsUpper + '?' + rsLower + '+' + rsOptLowerContr + '(?=' + [rsBreak, rsUpper, '$'].join('|') + ')',\n  rsUpperMisc + '+' + rsOptUpperContr + '(?=' + [rsBreak, rsUpper + rsLowerMisc, '$'].join('|') + ')',\n  rsUpper + '?' + rsLowerMisc + '+' + rsOptLowerContr,\n  rsUpper + '+' + rsOptUpperContr,\n  rsDigits,\n  rsEmoji\n].join('|'), 'g');\n\n/** Used to detect strings with [zero-width joiners or code points from the astral planes](http://eev.ee/blog/2015/09/12/dark-corners-of-unicode/). */\nvar reHasUnicode = RegExp('[' + rsZWJ + rsAstralRange  + rsComboMarksRange + rsComboSymbolsRange + rsVarRange + ']');\n\n/** Used to detect strings that need a more robust regexp to match words. */\nvar reHasUnicodeWord = /[a-z][A-Z]|[A-Z]{2,}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/;\n\n/** Used to map Latin Unicode letters to basic Latin letters. */\nvar deburredLetters = {\n  // Latin-1 Supplement block.\n  '\\xc0': 'A',  '\\xc1': 'A', '\\xc2': 'A', '\\xc3': 'A', '\\xc4': 'A', '\\xc5': 'A',\n  '\\xe0': 'a',  '\\xe1': 'a', '\\xe2': 'a', '\\xe3': 'a', '\\xe4': 'a', '\\xe5': 'a',\n  '\\xc7': 'C',  '\\xe7': 'c',\n  '\\xd0': 'D',  '\\xf0': 'd',\n  '\\xc8': 'E',  '\\xc9': 'E', '\\xca': 'E', '\\xcb': 'E',\n  '\\xe8': 'e',  '\\xe9': 'e', '\\xea': 'e', '\\xeb': 'e',\n  '\\xcc': 'I',  '\\xcd': 'I', '\\xce': 'I', '\\xcf': 'I',\n  '\\xec': 'i',  '\\xed': 'i', '\\xee': 'i', '\\xef': 'i',\n  '\\xd1': 'N',  '\\xf1': 'n',\n  '\\xd2': 'O',  '\\xd3': 'O', '\\xd4': 'O', '\\xd5': 'O', '\\xd6': 'O', '\\xd8': 'O',\n  '\\xf2': 'o',  '\\xf3': 'o', '\\xf4': 'o', '\\xf5': 'o', '\\xf6': 'o', '\\xf8': 'o',\n  '\\xd9': 'U',  '\\xda': 'U', '\\xdb': 'U', '\\xdc': 'U',\n  '\\xf9': 'u',  '\\xfa': 'u', '\\xfb': 'u', '\\xfc': 'u',\n  '\\xdd': 'Y',  '\\xfd': 'y', '\\xff': 'y',\n  '\\xc6': 'Ae', '\\xe6': 'ae',\n  '\\xde': 'Th', '\\xfe': 'th',\n  '\\xdf': 'ss',\n  // Latin Extended-A block.\n  '\\u0100': 'A',  '\\u0102': 'A', '\\u0104': 'A',\n  '\\u0101': 'a',  '\\u0103': 'a', '\\u0105': 'a',\n  '\\u0106': 'C',  '\\u0108': 'C', '\\u010a': 'C', '\\u010c': 'C',\n  '\\u0107': 'c',  '\\u0109': 'c', '\\u010b': 'c', '\\u010d': 'c',\n  '\\u010e': 'D',  '\\u0110': 'D', '\\u010f': 'd', '\\u0111': 'd',\n  '\\u0112': 'E',  '\\u0114': 'E', '\\u0116': 'E', '\\u0118': 'E', '\\u011a': 'E',\n  '\\u0113': 'e',  '\\u0115': 'e', '\\u0117': 'e', '\\u0119': 'e', '\\u011b': 'e',\n  '\\u011c': 'G',  '\\u011e': 'G', '\\u0120': 'G', '\\u0122': 'G',\n  '\\u011d': 'g',  '\\u011f': 'g', '\\u0121': 'g', '\\u0123': 'g',\n  '\\u0124': 'H',  '\\u0126': 'H', '\\u0125': 'h', '\\u0127': 'h',\n  '\\u0128': 'I',  '\\u012a': 'I', '\\u012c': 'I', '\\u012e': 'I', '\\u0130': 'I',\n  '\\u0129': 'i',  '\\u012b': 'i', '\\u012d': 'i', '\\u012f': 'i', '\\u0131': 'i',\n  '\\u0134': 'J',  '\\u0135': 'j',\n  '\\u0136': 'K',  '\\u0137': 'k', '\\u0138': 'k',\n  '\\u0139': 'L',  '\\u013b': 'L', '\\u013d': 'L', '\\u013f': 'L', '\\u0141': 'L',\n  '\\u013a': 'l',  '\\u013c': 'l', '\\u013e': 'l', '\\u0140': 'l', '\\u0142': 'l',\n  '\\u0143': 'N',  '\\u0145': 'N', '\\u0147': 'N', '\\u014a': 'N',\n  '\\u0144': 'n',  '\\u0146': 'n', '\\u0148': 'n', '\\u014b': 'n',\n  '\\u014c': 'O',  '\\u014e': 'O', '\\u0150': 'O',\n  '\\u014d': 'o',  '\\u014f': 'o', '\\u0151': 'o',\n  '\\u0154': 'R',  '\\u0156': 'R', '\\u0158': 'R',\n  '\\u0155': 'r',  '\\u0157': 'r', '\\u0159': 'r',\n  '\\u015a': 'S',  '\\u015c': 'S', '\\u015e': 'S', '\\u0160': 'S',\n  '\\u015b': 's',  '\\u015d': 's', '\\u015f': 's', '\\u0161': 's',\n  '\\u0162': 'T',  '\\u0164': 'T', '\\u0166': 'T',\n  '\\u0163': 't',  '\\u0165': 't', '\\u0167': 't',\n  '\\u0168': 'U',  '\\u016a': 'U', '\\u016c': 'U', '\\u016e': 'U', '\\u0170': 'U', '\\u0172': 'U',\n  '\\u0169': 'u',  '\\u016b': 'u', '\\u016d': 'u', '\\u016f': 'u', '\\u0171': 'u', '\\u0173': 'u',\n  '\\u0174': 'W',  '\\u0175': 'w',\n  '\\u0176': 'Y',  '\\u0177': 'y', '\\u0178': 'Y',\n  '\\u0179': 'Z',  '\\u017b': 'Z', '\\u017d': 'Z',\n  '\\u017a': 'z',  '\\u017c': 'z', '\\u017e': 'z',\n  '\\u0132': 'IJ', '\\u0133': 'ij',\n  '\\u0152': 'Oe', '\\u0153': 'oe',\n  '\\u0149': \"'n\", '\\u017f': 'ss'\n};\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/**\n * A specialized version of `_.reduce` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {*} [accumulator] The initial value.\n * @param {boolean} [initAccum] Specify using the first element of `array` as\n *  the initial value.\n * @returns {*} Returns the accumulated value.\n */\nfunction arrayReduce(array, iteratee, accumulator, initAccum) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  if (initAccum && length) {\n    accumulator = array[++index];\n  }\n  while (++index < length) {\n    accumulator = iteratee(accumulator, array[index], index, array);\n  }\n  return accumulator;\n}\n\n/**\n * Converts an ASCII `string` to an array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the converted array.\n */\nfunction asciiToArray(string) {\n  return string.split('');\n}\n\n/**\n * Splits an ASCII `string` into an array of its words.\n *\n * @private\n * @param {string} The string to inspect.\n * @returns {Array} Returns the words of `string`.\n */\nfunction asciiWords(string) {\n  return string.match(reAsciiWord) || [];\n}\n\n/**\n * The base implementation of `_.propertyOf` without support for deep paths.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Function} Returns the new accessor function.\n */\nfunction basePropertyOf(object) {\n  return function(key) {\n    return object == null ? undefined : object[key];\n  };\n}\n\n/**\n * Used by `_.deburr` to convert Latin-1 Supplement and Latin Extended-A\n * letters to basic Latin letters.\n *\n * @private\n * @param {string} letter The matched letter to deburr.\n * @returns {string} Returns the deburred letter.\n */\nvar deburrLetter = basePropertyOf(deburredLetters);\n\n/**\n * Checks if `string` contains Unicode symbols.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {boolean} Returns `true` if a symbol is found, else `false`.\n */\nfunction hasUnicode(string) {\n  return reHasUnicode.test(string);\n}\n\n/**\n * Checks if `string` contains a word composed of Unicode symbols.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {boolean} Returns `true` if a word is found, else `false`.\n */\nfunction hasUnicodeWord(string) {\n  return reHasUnicodeWord.test(string);\n}\n\n/**\n * Converts `string` to an array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the converted array.\n */\nfunction stringToArray(string) {\n  return hasUnicode(string)\n    ? unicodeToArray(string)\n    : asciiToArray(string);\n}\n\n/**\n * Converts a Unicode `string` to an array.\n *\n * @private\n * @param {string} string The string to convert.\n * @returns {Array} Returns the converted array.\n */\nfunction unicodeToArray(string) {\n  return string.match(reUnicode) || [];\n}\n\n/**\n * Splits a Unicode `string` into an array of its words.\n *\n * @private\n * @param {string} The string to inspect.\n * @returns {Array} Returns the words of `string`.\n */\nfunction unicodeWords(string) {\n  return string.match(reUnicodeWord) || [];\n}\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar Symbol = root.Symbol;\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolToString = symbolProto ? symbolProto.toString : undefined;\n\n/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.toString` which doesn't convert nullish\n * values to empty strings.\n *\n * @private\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n */\nfunction baseToString(value) {\n  // Exit early for strings to avoid a performance hit in some environments.\n  if (typeof value == 'string') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return symbolToString ? symbolToString.call(value) : '';\n  }\n  var result = (value + '');\n  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;\n}\n\n/**\n * Casts `array` to a slice if it's needed.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {number} start The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the cast slice.\n */\nfunction castSlice(array, start, end) {\n  var length = array.length;\n  end = end === undefined ? length : end;\n  return (!start && end >= length) ? array : baseSlice(array, start, end);\n}\n\n/**\n * Creates a function like `_.lowerFirst`.\n *\n * @private\n * @param {string} methodName The name of the `String` case method to use.\n * @returns {Function} Returns the new case function.\n */\nfunction createCaseFirst(methodName) {\n  return function(string) {\n    string = toString(string);\n\n    var strSymbols = hasUnicode(string)\n      ? stringToArray(string)\n      : undefined;\n\n    var chr = strSymbols\n      ? strSymbols[0]\n      : string.charAt(0);\n\n    var trailing = strSymbols\n      ? castSlice(strSymbols, 1).join('')\n      : string.slice(1);\n\n    return chr[methodName]() + trailing;\n  };\n}\n\n/**\n * Creates a function like `_.camelCase`.\n *\n * @private\n * @param {Function} callback The function to combine each word.\n * @returns {Function} Returns the new compounder function.\n */\nfunction createCompounder(callback) {\n  return function(string) {\n    return arrayReduce(words(deburr(string).replace(reApos, '')), callback, '');\n  };\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\n/**\n * Checks if `value` is classified as a `Symbol` primitive or object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.\n * @example\n *\n * _.isSymbol(Symbol.iterator);\n * // => true\n *\n * _.isSymbol('abc');\n * // => false\n */\nfunction isSymbol(value) {\n  return typeof value == 'symbol' ||\n    (isObjectLike(value) && objectToString.call(value) == symbolTag);\n}\n\n/**\n * Converts `value` to a string. An empty string is returned for `null`\n * and `undefined` values. The sign of `-0` is preserved.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n * @example\n *\n * _.toString(null);\n * // => ''\n *\n * _.toString(-0);\n * // => '-0'\n *\n * _.toString([1, 2, 3]);\n * // => '1,2,3'\n */\nfunction toString(value) {\n  return value == null ? '' : baseToString(value);\n}\n\n/**\n * Converts `string` to [camel case](https://en.wikipedia.org/wiki/CamelCase).\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to convert.\n * @returns {string} Returns the camel cased string.\n * @example\n *\n * _.camelCase('Foo Bar');\n * // => 'fooBar'\n *\n * _.camelCase('--foo-bar--');\n * // => 'fooBar'\n *\n * _.camelCase('__FOO_BAR__');\n * // => 'fooBar'\n */\nvar camelCase = createCompounder(function(result, word, index) {\n  word = word.toLowerCase();\n  return result + (index ? capitalize(word) : word);\n});\n\n/**\n * Converts the first character of `string` to upper case and the remaining\n * to lower case.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to capitalize.\n * @returns {string} Returns the capitalized string.\n * @example\n *\n * _.capitalize('FRED');\n * // => 'Fred'\n */\nfunction capitalize(string) {\n  return upperFirst(toString(string).toLowerCase());\n}\n\n/**\n * Deburrs `string` by converting\n * [Latin-1 Supplement](https://en.wikipedia.org/wiki/Latin-1_Supplement_(Unicode_block)#Character_table)\n * and [Latin Extended-A](https://en.wikipedia.org/wiki/Latin_Extended-A)\n * letters to basic Latin letters and removing\n * [combining diacritical marks](https://en.wikipedia.org/wiki/Combining_Diacritical_Marks).\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to deburr.\n * @returns {string} Returns the deburred string.\n * @example\n *\n * _.deburr('d\u00E9j\u00E0 vu');\n * // => 'deja vu'\n */\nfunction deburr(string) {\n  string = toString(string);\n  return string && string.replace(reLatin, deburrLetter).replace(reComboMark, '');\n}\n\n/**\n * Converts the first character of `string` to upper case.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category String\n * @param {string} [string=''] The string to convert.\n * @returns {string} Returns the converted string.\n * @example\n *\n * _.upperFirst('fred');\n * // => 'Fred'\n *\n * _.upperFirst('FRED');\n * // => 'FRED'\n */\nvar upperFirst = createCaseFirst('toUpperCase');\n\n/**\n * Splits `string` into an array of its words.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to inspect.\n * @param {RegExp|string} [pattern] The pattern to match words.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the words of `string`.\n * @example\n *\n * _.words('fred, barney, & pebbles');\n * // => ['fred', 'barney', 'pebbles']\n *\n * _.words('fred, barney, & pebbles', /[^, ]+/g);\n * // => ['fred', 'barney', '&', 'pebbles']\n */\nfunction words(string, pattern, guard) {\n  string = toString(string);\n  pattern = guard ? undefined : pattern;\n\n  if (pattern === undefined) {\n    return hasUnicodeWord(string) ? unicodeWords(string) : asciiWords(string);\n  }\n  return string.match(pattern) || [];\n}\n\nmodule.exports = camelCase;\n", "\"use strict\";\r\nmodule.exports = asPromise;\r\n\r\n/**\r\n * Callback as used by {@link util.asPromise}.\r\n * @typedef asPromiseCallback\r\n * @type {function}\r\n * @param {Error|null} error Error, if any\r\n * @param {...*} params Additional arguments\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Returns a promise from a node-style callback function.\r\n * @memberof util\r\n * @param {asPromiseCallback} fn Function to call\r\n * @param {*} ctx Function context\r\n * @param {...*} params Function arguments\r\n * @returns {Promise<*>} Promisified function\r\n */\r\nfunction asPromise(fn, ctx/*, varargs */) {\r\n    var params  = new Array(arguments.length - 1),\r\n        offset  = 0,\r\n        index   = 2,\r\n        pending = true;\r\n    while (index < arguments.length)\r\n        params[offset++] = arguments[index++];\r\n    return new Promise(function executor(resolve, reject) {\r\n        params[offset] = function callback(err/*, varargs */) {\r\n            if (pending) {\r\n                pending = false;\r\n                if (err)\r\n                    reject(err);\r\n                else {\r\n                    var params = new Array(arguments.length - 1),\r\n                        offset = 0;\r\n                    while (offset < params.length)\r\n                        params[offset++] = arguments[offset];\r\n                    resolve.apply(null, params);\r\n                }\r\n            }\r\n        };\r\n        try {\r\n            fn.apply(ctx || null, params);\r\n        } catch (err) {\r\n            if (pending) {\r\n                pending = false;\r\n                reject(err);\r\n            }\r\n        }\r\n    });\r\n}\r\n", "\"use strict\";\r\n\r\n/**\r\n * A minimal base64 implementation for number arrays.\r\n * @memberof util\r\n * @namespace\r\n */\r\nvar base64 = exports;\r\n\r\n/**\r\n * Calculates the byte length of a base64 encoded string.\r\n * @param {string} string Base64 encoded string\r\n * @returns {number} Byte length\r\n */\r\nbase64.length = function length(string) {\r\n    var p = string.length;\r\n    if (!p)\r\n        return 0;\r\n    var n = 0;\r\n    while (--p % 4 > 1 && string.charAt(p) === \"=\")\r\n        ++n;\r\n    return Math.ceil(string.length * 3) / 4 - n;\r\n};\r\n\r\n// Base64 encoding table\r\nvar b64 = new Array(64);\r\n\r\n// Base64 decoding table\r\nvar s64 = new Array(123);\r\n\r\n// 65..90, 97..122, 48..57, 43, 47\r\nfor (var i = 0; i < 64;)\r\n    s64[b64[i] = i < 26 ? i + 65 : i < 52 ? i + 71 : i < 62 ? i - 4 : i - 59 | 43] = i++;\r\n\r\n/**\r\n * Encodes a buffer to a base64 encoded string.\r\n * @param {Uint8Array} buffer Source buffer\r\n * @param {number} start Source start\r\n * @param {number} end Source end\r\n * @returns {string} Base64 encoded string\r\n */\r\nbase64.encode = function encode(buffer, start, end) {\r\n    var parts = null,\r\n        chunk = [];\r\n    var i = 0, // output index\r\n        j = 0, // goto index\r\n        t;     // temporary\r\n    while (start < end) {\r\n        var b = buffer[start++];\r\n        switch (j) {\r\n            case 0:\r\n                chunk[i++] = b64[b >> 2];\r\n                t = (b & 3) << 4;\r\n                j = 1;\r\n                break;\r\n            case 1:\r\n                chunk[i++] = b64[t | b >> 4];\r\n                t = (b & 15) << 2;\r\n                j = 2;\r\n                break;\r\n            case 2:\r\n                chunk[i++] = b64[t | b >> 6];\r\n                chunk[i++] = b64[b & 63];\r\n                j = 0;\r\n                break;\r\n        }\r\n        if (i > 8191) {\r\n            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));\r\n            i = 0;\r\n        }\r\n    }\r\n    if (j) {\r\n        chunk[i++] = b64[t];\r\n        chunk[i++] = 61;\r\n        if (j === 1)\r\n            chunk[i++] = 61;\r\n    }\r\n    if (parts) {\r\n        if (i)\r\n            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));\r\n        return parts.join(\"\");\r\n    }\r\n    return String.fromCharCode.apply(String, chunk.slice(0, i));\r\n};\r\n\r\nvar invalidEncoding = \"invalid encoding\";\r\n\r\n/**\r\n * Decodes a base64 encoded string to a buffer.\r\n * @param {string} string Source string\r\n * @param {Uint8Array} buffer Destination buffer\r\n * @param {number} offset Destination offset\r\n * @returns {number} Number of bytes written\r\n * @throws {Error} If encoding is invalid\r\n */\r\nbase64.decode = function decode(string, buffer, offset) {\r\n    var start = offset;\r\n    var j = 0, // goto index\r\n        t;     // temporary\r\n    for (var i = 0; i < string.length;) {\r\n        var c = string.charCodeAt(i++);\r\n        if (c === 61 && j > 1)\r\n            break;\r\n        if ((c = s64[c]) === undefined)\r\n            throw Error(invalidEncoding);\r\n        switch (j) {\r\n            case 0:\r\n                t = c;\r\n                j = 1;\r\n                break;\r\n            case 1:\r\n                buffer[offset++] = t << 2 | (c & 48) >> 4;\r\n                t = c;\r\n                j = 2;\r\n                break;\r\n            case 2:\r\n                buffer[offset++] = (t & 15) << 4 | (c & 60) >> 2;\r\n                t = c;\r\n                j = 3;\r\n                break;\r\n            case 3:\r\n                buffer[offset++] = (t & 3) << 6 | c;\r\n                j = 0;\r\n                break;\r\n        }\r\n    }\r\n    if (j === 1)\r\n        throw Error(invalidEncoding);\r\n    return offset - start;\r\n};\r\n\r\n/**\r\n * Tests if the specified string appears to be base64 encoded.\r\n * @param {string} string String to test\r\n * @returns {boolean} `true` if probably base64 encoded, otherwise false\r\n */\r\nbase64.test = function test(string) {\r\n    return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(string);\r\n};\r\n", "\"use strict\";\r\nmodule.exports = EventEmitter;\r\n\r\n/**\r\n * Constructs a new event emitter instance.\r\n * @classdesc A minimal event emitter.\r\n * @memberof util\r\n * @constructor\r\n */\r\nfunction EventEmitter() {\r\n\r\n    /**\r\n     * Registered listeners.\r\n     * @type {Object.<string,*>}\r\n     * @private\r\n     */\r\n    this._listeners = {};\r\n}\r\n\r\n/**\r\n * Registers an event listener.\r\n * @param {string} evt Event name\r\n * @param {function} fn Listener\r\n * @param {*} [ctx] Listener context\r\n * @returns {util.EventEmitter} `this`\r\n */\r\nEventEmitter.prototype.on = function on(evt, fn, ctx) {\r\n    (this._listeners[evt] || (this._listeners[evt] = [])).push({\r\n        fn  : fn,\r\n        ctx : ctx || this\r\n    });\r\n    return this;\r\n};\r\n\r\n/**\r\n * Removes an event listener or any matching listeners if arguments are omitted.\r\n * @param {string} [evt] Event name. Removes all listeners if omitted.\r\n * @param {function} [fn] Listener to remove. Removes all listeners of `evt` if omitted.\r\n * @returns {util.EventEmitter} `this`\r\n */\r\nEventEmitter.prototype.off = function off(evt, fn) {\r\n    if (evt === undefined)\r\n        this._listeners = {};\r\n    else {\r\n        if (fn === undefined)\r\n            this._listeners[evt] = [];\r\n        else {\r\n            var listeners = this._listeners[evt];\r\n            for (var i = 0; i < listeners.length;)\r\n                if (listeners[i].fn === fn)\r\n                    listeners.splice(i, 1);\r\n                else\r\n                    ++i;\r\n        }\r\n    }\r\n    return this;\r\n};\r\n\r\n/**\r\n * Emits an event by calling its listeners with the specified arguments.\r\n * @param {string} evt Event name\r\n * @param {...*} args Arguments\r\n * @returns {util.EventEmitter} `this`\r\n */\r\nEventEmitter.prototype.emit = function emit(evt) {\r\n    var listeners = this._listeners[evt];\r\n    if (listeners) {\r\n        var args = [],\r\n            i = 1;\r\n        for (; i < arguments.length;)\r\n            args.push(arguments[i++]);\r\n        for (i = 0; i < listeners.length;)\r\n            listeners[i].fn.apply(listeners[i++].ctx, args);\r\n    }\r\n    return this;\r\n};\r\n", "\"use strict\";\r\n\r\nmodule.exports = factory(factory);\r\n\r\n/**\r\n * Reads / writes floats / doubles from / to buffers.\r\n * @name util.float\r\n * @namespace\r\n */\r\n\r\n/**\r\n * Writes a 32 bit float to a buffer using little endian byte order.\r\n * @name util.float.writeFloatLE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Writes a 32 bit float to a buffer using big endian byte order.\r\n * @name util.float.writeFloatBE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Reads a 32 bit float from a buffer using little endian byte order.\r\n * @name util.float.readFloatLE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n/**\r\n * Reads a 32 bit float from a buffer using big endian byte order.\r\n * @name util.float.readFloatBE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n/**\r\n * Writes a 64 bit double to a buffer using little endian byte order.\r\n * @name util.float.writeDoubleLE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Writes a 64 bit double to a buffer using big endian byte order.\r\n * @name util.float.writeDoubleBE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Reads a 64 bit double from a buffer using little endian byte order.\r\n * @name util.float.readDoubleLE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n/**\r\n * Reads a 64 bit double from a buffer using big endian byte order.\r\n * @name util.float.readDoubleBE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n// Factory function for the purpose of node-based testing in modified global environments\r\nfunction factory(exports) {\r\n\r\n    // float: typed array\r\n    if (typeof Float32Array !== \"undefined\") (function() {\r\n\r\n        var f32 = new Float32Array([ -0 ]),\r\n            f8b = new Uint8Array(f32.buffer),\r\n            le  = f8b[3] === 128;\r\n\r\n        function writeFloat_f32_cpy(val, buf, pos) {\r\n            f32[0] = val;\r\n            buf[pos    ] = f8b[0];\r\n            buf[pos + 1] = f8b[1];\r\n            buf[pos + 2] = f8b[2];\r\n            buf[pos + 3] = f8b[3];\r\n        }\r\n\r\n        function writeFloat_f32_rev(val, buf, pos) {\r\n            f32[0] = val;\r\n            buf[pos    ] = f8b[3];\r\n            buf[pos + 1] = f8b[2];\r\n            buf[pos + 2] = f8b[1];\r\n            buf[pos + 3] = f8b[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.writeFloatLE = le ? writeFloat_f32_cpy : writeFloat_f32_rev;\r\n        /* istanbul ignore next */\r\n        exports.writeFloatBE = le ? writeFloat_f32_rev : writeFloat_f32_cpy;\r\n\r\n        function readFloat_f32_cpy(buf, pos) {\r\n            f8b[0] = buf[pos    ];\r\n            f8b[1] = buf[pos + 1];\r\n            f8b[2] = buf[pos + 2];\r\n            f8b[3] = buf[pos + 3];\r\n            return f32[0];\r\n        }\r\n\r\n        function readFloat_f32_rev(buf, pos) {\r\n            f8b[3] = buf[pos    ];\r\n            f8b[2] = buf[pos + 1];\r\n            f8b[1] = buf[pos + 2];\r\n            f8b[0] = buf[pos + 3];\r\n            return f32[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.readFloatLE = le ? readFloat_f32_cpy : readFloat_f32_rev;\r\n        /* istanbul ignore next */\r\n        exports.readFloatBE = le ? readFloat_f32_rev : readFloat_f32_cpy;\r\n\r\n    // float: ieee754\r\n    })(); else (function() {\r\n\r\n        function writeFloat_ieee754(writeUint, val, buf, pos) {\r\n            var sign = val < 0 ? 1 : 0;\r\n            if (sign)\r\n                val = -val;\r\n            if (val === 0)\r\n                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos);\r\n            else if (isNaN(val))\r\n                writeUint(2143289344, buf, pos);\r\n            else if (val > 3.4028234663852886e+38) // +-Infinity\r\n                writeUint((sign << 31 | 2139095040) >>> 0, buf, pos);\r\n            else if (val < 1.1754943508222875e-38) // denormal\r\n                writeUint((sign << 31 | Math.round(val / 1.401298464324817e-45)) >>> 0, buf, pos);\r\n            else {\r\n                var exponent = Math.floor(Math.log(val) / Math.LN2),\r\n                    mantissa = Math.round(val * Math.pow(2, -exponent) * 8388608) & 8388607;\r\n                writeUint((sign << 31 | exponent + 127 << 23 | mantissa) >>> 0, buf, pos);\r\n            }\r\n        }\r\n\r\n        exports.writeFloatLE = writeFloat_ieee754.bind(null, writeUintLE);\r\n        exports.writeFloatBE = writeFloat_ieee754.bind(null, writeUintBE);\r\n\r\n        function readFloat_ieee754(readUint, buf, pos) {\r\n            var uint = readUint(buf, pos),\r\n                sign = (uint >> 31) * 2 + 1,\r\n                exponent = uint >>> 23 & 255,\r\n                mantissa = uint & 8388607;\r\n            return exponent === 255\r\n                ? mantissa\r\n                ? NaN\r\n                : sign * Infinity\r\n                : exponent === 0 // denormal\r\n                ? sign * 1.401298464324817e-45 * mantissa\r\n                : sign * Math.pow(2, exponent - 150) * (mantissa + 8388608);\r\n        }\r\n\r\n        exports.readFloatLE = readFloat_ieee754.bind(null, readUintLE);\r\n        exports.readFloatBE = readFloat_ieee754.bind(null, readUintBE);\r\n\r\n    })();\r\n\r\n    // double: typed array\r\n    if (typeof Float64Array !== \"undefined\") (function() {\r\n\r\n        var f64 = new Float64Array([-0]),\r\n            f8b = new Uint8Array(f64.buffer),\r\n            le  = f8b[7] === 128;\r\n\r\n        function writeDouble_f64_cpy(val, buf, pos) {\r\n            f64[0] = val;\r\n            buf[pos    ] = f8b[0];\r\n            buf[pos + 1] = f8b[1];\r\n            buf[pos + 2] = f8b[2];\r\n            buf[pos + 3] = f8b[3];\r\n            buf[pos + 4] = f8b[4];\r\n            buf[pos + 5] = f8b[5];\r\n            buf[pos + 6] = f8b[6];\r\n            buf[pos + 7] = f8b[7];\r\n        }\r\n\r\n        function writeDouble_f64_rev(val, buf, pos) {\r\n            f64[0] = val;\r\n            buf[pos    ] = f8b[7];\r\n            buf[pos + 1] = f8b[6];\r\n            buf[pos + 2] = f8b[5];\r\n            buf[pos + 3] = f8b[4];\r\n            buf[pos + 4] = f8b[3];\r\n            buf[pos + 5] = f8b[2];\r\n            buf[pos + 6] = f8b[1];\r\n            buf[pos + 7] = f8b[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.writeDoubleLE = le ? writeDouble_f64_cpy : writeDouble_f64_rev;\r\n        /* istanbul ignore next */\r\n        exports.writeDoubleBE = le ? writeDouble_f64_rev : writeDouble_f64_cpy;\r\n\r\n        function readDouble_f64_cpy(buf, pos) {\r\n            f8b[0] = buf[pos    ];\r\n            f8b[1] = buf[pos + 1];\r\n            f8b[2] = buf[pos + 2];\r\n            f8b[3] = buf[pos + 3];\r\n            f8b[4] = buf[pos + 4];\r\n            f8b[5] = buf[pos + 5];\r\n            f8b[6] = buf[pos + 6];\r\n            f8b[7] = buf[pos + 7];\r\n            return f64[0];\r\n        }\r\n\r\n        function readDouble_f64_rev(buf, pos) {\r\n            f8b[7] = buf[pos    ];\r\n            f8b[6] = buf[pos + 1];\r\n            f8b[5] = buf[pos + 2];\r\n            f8b[4] = buf[pos + 3];\r\n            f8b[3] = buf[pos + 4];\r\n            f8b[2] = buf[pos + 5];\r\n            f8b[1] = buf[pos + 6];\r\n            f8b[0] = buf[pos + 7];\r\n            return f64[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.readDoubleLE = le ? readDouble_f64_cpy : readDouble_f64_rev;\r\n        /* istanbul ignore next */\r\n        exports.readDoubleBE = le ? readDouble_f64_rev : readDouble_f64_cpy;\r\n\r\n    // double: ieee754\r\n    })(); else (function() {\r\n\r\n        function writeDouble_ieee754(writeUint, off0, off1, val, buf, pos) {\r\n            var sign = val < 0 ? 1 : 0;\r\n            if (sign)\r\n                val = -val;\r\n            if (val === 0) {\r\n                writeUint(0, buf, pos + off0);\r\n                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos + off1);\r\n            } else if (isNaN(val)) {\r\n                writeUint(0, buf, pos + off0);\r\n                writeUint(2146959360, buf, pos + off1);\r\n            } else if (val > 1.7976931348623157e+308) { // +-Infinity\r\n                writeUint(0, buf, pos + off0);\r\n                writeUint((sign << 31 | 2146435072) >>> 0, buf, pos + off1);\r\n            } else {\r\n                var mantissa;\r\n                if (val < 2.2250738585072014e-308) { // denormal\r\n                    mantissa = val / 5e-324;\r\n                    writeUint(mantissa >>> 0, buf, pos + off0);\r\n                    writeUint((sign << 31 | mantissa / 4294967296) >>> 0, buf, pos + off1);\r\n                } else {\r\n                    var exponent = Math.floor(Math.log(val) / Math.LN2);\r\n                    if (exponent === 1024)\r\n                        exponent = 1023;\r\n                    mantissa = val * Math.pow(2, -exponent);\r\n                    writeUint(mantissa * 4503599627370496 >>> 0, buf, pos + off0);\r\n                    writeUint((sign << 31 | exponent + 1023 << 20 | mantissa * 1048576 & 1048575) >>> 0, buf, pos + off1);\r\n                }\r\n            }\r\n        }\r\n\r\n        exports.writeDoubleLE = writeDouble_ieee754.bind(null, writeUintLE, 0, 4);\r\n        exports.writeDoubleBE = writeDouble_ieee754.bind(null, writeUintBE, 4, 0);\r\n\r\n        function readDouble_ieee754(readUint, off0, off1, buf, pos) {\r\n            var lo = readUint(buf, pos + off0),\r\n                hi = readUint(buf, pos + off1);\r\n            var sign = (hi >> 31) * 2 + 1,\r\n                exponent = hi >>> 20 & 2047,\r\n                mantissa = 4294967296 * (hi & 1048575) + lo;\r\n            return exponent === 2047\r\n                ? mantissa\r\n                ? NaN\r\n                : sign * Infinity\r\n                : exponent === 0 // denormal\r\n                ? sign * 5e-324 * mantissa\r\n                : sign * Math.pow(2, exponent - 1075) * (mantissa + 4503599627370496);\r\n        }\r\n\r\n        exports.readDoubleLE = readDouble_ieee754.bind(null, readUintLE, 0, 4);\r\n        exports.readDoubleBE = readDouble_ieee754.bind(null, readUintBE, 4, 0);\r\n\r\n    })();\r\n\r\n    return exports;\r\n}\r\n\r\n// uint helpers\r\n\r\nfunction writeUintLE(val, buf, pos) {\r\n    buf[pos    ] =  val        & 255;\r\n    buf[pos + 1] =  val >>> 8  & 255;\r\n    buf[pos + 2] =  val >>> 16 & 255;\r\n    buf[pos + 3] =  val >>> 24;\r\n}\r\n\r\nfunction writeUintBE(val, buf, pos) {\r\n    buf[pos    ] =  val >>> 24;\r\n    buf[pos + 1] =  val >>> 16 & 255;\r\n    buf[pos + 2] =  val >>> 8  & 255;\r\n    buf[pos + 3] =  val        & 255;\r\n}\r\n\r\nfunction readUintLE(buf, pos) {\r\n    return (buf[pos    ]\r\n          | buf[pos + 1] << 8\r\n          | buf[pos + 2] << 16\r\n          | buf[pos + 3] << 24) >>> 0;\r\n}\r\n\r\nfunction readUintBE(buf, pos) {\r\n    return (buf[pos    ] << 24\r\n          | buf[pos + 1] << 16\r\n          | buf[pos + 2] << 8\r\n          | buf[pos + 3]) >>> 0;\r\n}\r\n", "\"use strict\";\r\nmodule.exports = inquire;\r\n\r\n/**\r\n * Requires a module only if available.\r\n * @memberof util\r\n * @param {string} moduleName Module to require\r\n * @returns {?Object} Required module if available and not empty, otherwise `null`\r\n */\r\nfunction inquire(moduleName) {\r\n    try {\r\n        var mod = eval(\"quire\".replace(/^/,\"re\"))(moduleName); // eslint-disable-line no-eval\r\n        if (mod && (mod.length || Object.keys(mod).length))\r\n            return mod;\r\n    } catch (e) {} // eslint-disable-line no-empty\r\n    return null;\r\n}\r\n", "\"use strict\";\r\n\r\n/**\r\n * A minimal UTF8 implementation for number arrays.\r\n * @memberof util\r\n * @namespace\r\n */\r\nvar utf8 = exports;\r\n\r\n/**\r\n * Calculates the UTF8 byte length of a string.\r\n * @param {string} string String\r\n * @returns {number} Byte length\r\n */\r\nutf8.length = function utf8_length(string) {\r\n    var len = 0,\r\n        c = 0;\r\n    for (var i = 0; i < string.length; ++i) {\r\n        c = string.charCodeAt(i);\r\n        if (c < 128)\r\n            len += 1;\r\n        else if (c < 2048)\r\n            len += 2;\r\n        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {\r\n            ++i;\r\n            len += 4;\r\n        } else\r\n            len += 3;\r\n    }\r\n    return len;\r\n};\r\n\r\n/**\r\n * Reads UTF8 bytes as a string.\r\n * @param {Uint8Array} buffer Source buffer\r\n * @param {number} start Source start\r\n * @param {number} end Source end\r\n * @returns {string} String read\r\n */\r\nutf8.read = function utf8_read(buffer, start, end) {\r\n    var len = end - start;\r\n    if (len < 1)\r\n        return \"\";\r\n    var parts = null,\r\n        chunk = [],\r\n        i = 0, // char offset\r\n        t;     // temporary\r\n    while (start < end) {\r\n        t = buffer[start++];\r\n        if (t < 128)\r\n            chunk[i++] = t;\r\n        else if (t > 191 && t < 224)\r\n            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;\r\n        else if (t > 239 && t < 365) {\r\n            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;\r\n            chunk[i++] = 0xD800 + (t >> 10);\r\n            chunk[i++] = 0xDC00 + (t & 1023);\r\n        } else\r\n            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;\r\n        if (i > 8191) {\r\n            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));\r\n            i = 0;\r\n        }\r\n    }\r\n    if (parts) {\r\n        if (i)\r\n            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));\r\n        return parts.join(\"\");\r\n    }\r\n    return String.fromCharCode.apply(String, chunk.slice(0, i));\r\n};\r\n\r\n/**\r\n * Writes a string as UTF8 bytes.\r\n * @param {string} string Source string\r\n * @param {Uint8Array} buffer Destination buffer\r\n * @param {number} offset Destination offset\r\n * @returns {number} Bytes written\r\n */\r\nutf8.write = function utf8_write(string, buffer, offset) {\r\n    var start = offset,\r\n        c1, // character 1\r\n        c2; // character 2\r\n    for (var i = 0; i < string.length; ++i) {\r\n        c1 = string.charCodeAt(i);\r\n        if (c1 < 128) {\r\n            buffer[offset++] = c1;\r\n        } else if (c1 < 2048) {\r\n            buffer[offset++] = c1 >> 6       | 192;\r\n            buffer[offset++] = c1       & 63 | 128;\r\n        } else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {\r\n            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);\r\n            ++i;\r\n            buffer[offset++] = c1 >> 18      | 240;\r\n            buffer[offset++] = c1 >> 12 & 63 | 128;\r\n            buffer[offset++] = c1 >> 6  & 63 | 128;\r\n            buffer[offset++] = c1       & 63 | 128;\r\n        } else {\r\n            buffer[offset++] = c1 >> 12      | 224;\r\n            buffer[offset++] = c1 >> 6  & 63 | 128;\r\n            buffer[offset++] = c1       & 63 | 128;\r\n        }\r\n    }\r\n    return offset - start;\r\n};\r\n", "\"use strict\";\r\nmodule.exports = pool;\r\n\r\n/**\r\n * An allocator as used by {@link util.pool}.\r\n * @typedef PoolAllocator\r\n * @type {function}\r\n * @param {number} size Buffer size\r\n * @returns {Uint8Array} Buffer\r\n */\r\n\r\n/**\r\n * A slicer as used by {@link util.pool}.\r\n * @typedef PoolSlicer\r\n * @type {function}\r\n * @param {number} start Start offset\r\n * @param {number} end End offset\r\n * @returns {Uint8Array} Buffer slice\r\n * @this {Uint8Array}\r\n */\r\n\r\n/**\r\n * A general purpose buffer pool.\r\n * @memberof util\r\n * @function\r\n * @param {PoolAllocator} alloc Allocator\r\n * @param {PoolSlicer} slice Slicer\r\n * @param {number} [size=8192] Slab size\r\n * @returns {PoolAllocator} Pooled allocator\r\n */\r\nfunction pool(alloc, slice, size) {\r\n    var SIZE   = size || 8192;\r\n    var MAX    = SIZE >>> 1;\r\n    var slab   = null;\r\n    var offset = SIZE;\r\n    return function pool_alloc(size) {\r\n        if (size < 1 || size > MAX)\r\n            return alloc(size);\r\n        if (offset + size > SIZE) {\r\n            slab = alloc(SIZE);\r\n            offset = 0;\r\n        }\r\n        var buf = slice.call(slab, offset, offset += size);\r\n        if (offset & 7) // align to 32 bit\r\n            offset = (offset | 7) + 1;\r\n        return buf;\r\n    };\r\n}\r\n", "\"use strict\";\nmodule.exports = LongBits;\n\nvar util = require(\"../util/minimal\");\n\n/**\n * Constructs new long bits.\n * @classdesc Helper class for working with the low and high bits of a 64 bit value.\n * @memberof util\n * @constructor\n * @param {number} lo Low 32 bits, unsigned\n * @param {number} hi High 32 bits, unsigned\n */\nfunction LongBits(lo, hi) {\n\n    // note that the casts below are theoretically unnecessary as of today, but older statically\n    // generated converter code might still call the ctor with signed 32bits. kept for compat.\n\n    /**\n     * Low bits.\n     * @type {number}\n     */\n    this.lo = lo >>> 0;\n\n    /**\n     * High bits.\n     * @type {number}\n     */\n    this.hi = hi >>> 0;\n}\n\n/**\n * Zero bits.\n * @memberof util.LongBits\n * @type {util.LongBits}\n */\nvar zero = LongBits.zero = new LongBits(0, 0);\n\nzero.toNumber = function() { return 0; };\nzero.zzEncode = zero.zzDecode = function() { return this; };\nzero.length = function() { return 1; };\n\n/**\n * Zero hash.\n * @memberof util.LongBits\n * @type {string}\n */\nvar zeroHash = LongBits.zeroHash = \"\\0\\0\\0\\0\\0\\0\\0\\0\";\n\n/**\n * Constructs new long bits from the specified number.\n * @param {number} value Value\n * @returns {util.LongBits} Instance\n */\nLongBits.fromNumber = function fromNumber(value) {\n    if (value === 0)\n        return zero;\n    var sign = value < 0;\n    if (sign)\n        value = -value;\n    var lo = value >>> 0,\n        hi = (value - lo) / 4294967296 >>> 0;\n    if (sign) {\n        hi = ~hi >>> 0;\n        lo = ~lo >>> 0;\n        if (++lo > 4294967295) {\n            lo = 0;\n            if (++hi > 4294967295)\n                hi = 0;\n        }\n    }\n    return new LongBits(lo, hi);\n};\n\n/**\n * Constructs new long bits from a number, long or string.\n * @param {Long|number|string} value Value\n * @returns {util.LongBits} Instance\n */\nLongBits.from = function from(value) {\n    if (typeof value === \"number\")\n        return LongBits.fromNumber(value);\n    if (util.isString(value)) {\n        /* istanbul ignore else */\n        if (util.Long)\n            value = util.Long.fromString(value);\n        else\n            return LongBits.fromNumber(parseInt(value, 10));\n    }\n    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;\n};\n\n/**\n * Converts this long bits to a possibly unsafe JavaScript number.\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {number} Possibly unsafe number\n */\nLongBits.prototype.toNumber = function toNumber(unsigned) {\n    if (!unsigned && this.hi >>> 31) {\n        var lo = ~this.lo + 1 >>> 0,\n            hi = ~this.hi     >>> 0;\n        if (!lo)\n            hi = hi + 1 >>> 0;\n        return -(lo + hi * 4294967296);\n    }\n    return this.lo + this.hi * 4294967296;\n};\n\n/**\n * Converts this long bits to a long.\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {Long} Long\n */\nLongBits.prototype.toLong = function toLong(unsigned) {\n    return util.Long\n        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))\n        /* istanbul ignore next */\n        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };\n};\n\nvar charCodeAt = String.prototype.charCodeAt;\n\n/**\n * Constructs new long bits from the specified 8 characters long hash.\n * @param {string} hash Hash\n * @returns {util.LongBits} Bits\n */\nLongBits.fromHash = function fromHash(hash) {\n    if (hash === zeroHash)\n        return zero;\n    return new LongBits(\n        ( charCodeAt.call(hash, 0)\n        | charCodeAt.call(hash, 1) << 8\n        | charCodeAt.call(hash, 2) << 16\n        | charCodeAt.call(hash, 3) << 24) >>> 0\n    ,\n        ( charCodeAt.call(hash, 4)\n        | charCodeAt.call(hash, 5) << 8\n        | charCodeAt.call(hash, 6) << 16\n        | charCodeAt.call(hash, 7) << 24) >>> 0\n    );\n};\n\n/**\n * Converts this long bits to a 8 characters long hash.\n * @returns {string} Hash\n */\nLongBits.prototype.toHash = function toHash() {\n    return String.fromCharCode(\n        this.lo        & 255,\n        this.lo >>> 8  & 255,\n        this.lo >>> 16 & 255,\n        this.lo >>> 24      ,\n        this.hi        & 255,\n        this.hi >>> 8  & 255,\n        this.hi >>> 16 & 255,\n        this.hi >>> 24\n    );\n};\n\n/**\n * Zig-zag encodes this long bits.\n * @returns {util.LongBits} `this`\n */\nLongBits.prototype.zzEncode = function zzEncode() {\n    var mask =   this.hi >> 31;\n    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;\n    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;\n    return this;\n};\n\n/**\n * Zig-zag decodes this long bits.\n * @returns {util.LongBits} `this`\n */\nLongBits.prototype.zzDecode = function zzDecode() {\n    var mask = -(this.lo & 1);\n    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;\n    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;\n    return this;\n};\n\n/**\n * Calculates the length of this longbits when encoded as a varint.\n * @returns {number} Length\n */\nLongBits.prototype.length = function length() {\n    var part0 =  this.lo,\n        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,\n        part2 =  this.hi >>> 24;\n    return part2 === 0\n         ? part1 === 0\n           ? part0 < 16384\n             ? part0 < 128 ? 1 : 2\n             : part0 < 2097152 ? 3 : 4\n           : part1 < 16384\n             ? part1 < 128 ? 5 : 6\n             : part1 < 2097152 ? 7 : 8\n         : part2 < 128 ? 9 : 10;\n};\n", "\"use strict\";\nvar util = exports;\n\n// used to return a Promise where callback is omitted\nutil.asPromise = require(\"@protobufjs/aspromise\");\n\n// converts to / from base64 encoded strings\nutil.base64 = require(\"@protobufjs/base64\");\n\n// base class of rpc.Service\nutil.EventEmitter = require(\"@protobufjs/eventemitter\");\n\n// float handling accross browsers\nutil.float = require(\"@protobufjs/float\");\n\n// requires modules optionally and hides the call from bundlers\nutil.inquire = require(\"@protobufjs/inquire\");\n\n// converts to / from utf8 encoded strings\nutil.utf8 = require(\"@protobufjs/utf8\");\n\n// provides a node-like buffer pool in the browser\nutil.pool = require(\"@protobufjs/pool\");\n\n// utility to work with the low and high bits of a 64 bit value\nutil.LongBits = require(\"./longbits\");\n\n/**\n * Whether running within node or not.\n * @memberof util\n * @type {boolean}\n */\nutil.isNode = Boolean(typeof global !== \"undefined\"\n                   && global\n                   && global.process\n                   && global.process.versions\n                   && global.process.versions.node);\n\n/**\n * Global object reference.\n * @memberof util\n * @type {Object}\n */\nutil.global = util.isNode && global\n           || typeof window !== \"undefined\" && window\n           || typeof self   !== \"undefined\" && self\n           || this; // eslint-disable-line no-invalid-this\n\n/**\n * An immuable empty array.\n * @memberof util\n * @type {Array.<*>}\n * @const\n */\nutil.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes\n\n/**\n * An immutable empty object.\n * @type {Object}\n * @const\n */\nutil.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes\n\n/**\n * Tests if the specified value is an integer.\n * @function\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is an integer\n */\nutil.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {\n    return typeof value === \"number\" && isFinite(value) && Math.floor(value) === value;\n};\n\n/**\n * Tests if the specified value is a string.\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is a string\n */\nutil.isString = function isString(value) {\n    return typeof value === \"string\" || value instanceof String;\n};\n\n/**\n * Tests if the specified value is a non-null object.\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is a non-null object\n */\nutil.isObject = function isObject(value) {\n    return value && typeof value === \"object\";\n};\n\n/**\n * Checks if a property on a message is considered to be present.\n * This is an alias of {@link util.isSet}.\n * @function\n * @param {Object} obj Plain object or message instance\n * @param {string} prop Property name\n * @returns {boolean} `true` if considered to be present, otherwise `false`\n */\nutil.isset =\n\n/**\n * Checks if a property on a message is considered to be present.\n * @param {Object} obj Plain object or message instance\n * @param {string} prop Property name\n * @returns {boolean} `true` if considered to be present, otherwise `false`\n */\nutil.isSet = function isSet(obj, prop) {\n    var value = obj[prop];\n    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins\n        return typeof value !== \"object\" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;\n    return false;\n};\n\n/**\n * Any compatible Buffer instance.\n * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.\n * @interface Buffer\n * @extends Uint8Array\n */\n\n/**\n * Node's Buffer class if available.\n * @type {Constructor<Buffer>}\n */\nutil.Buffer = (function() {\n    try {\n        var Buffer = util.inquire(\"buffer\").Buffer;\n        // refuse to use non-node buffers if not explicitly assigned (perf reasons):\n        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;\n    } catch (e) {\n        /* istanbul ignore next */\n        return null;\n    }\n})();\n\n// Internal alias of or polyfull for Buffer.from.\nutil._Buffer_from = null;\n\n// Internal alias of or polyfill for Buffer.allocUnsafe.\nutil._Buffer_allocUnsafe = null;\n\n/**\n * Creates a new buffer of whatever type supported by the environment.\n * @param {number|number[]} [sizeOrArray=0] Buffer size or number array\n * @returns {Uint8Array|Buffer} Buffer\n */\nutil.newBuffer = function newBuffer(sizeOrArray) {\n    /* istanbul ignore next */\n    return typeof sizeOrArray === \"number\"\n        ? util.Buffer\n            ? util._Buffer_allocUnsafe(sizeOrArray)\n            : new util.Array(sizeOrArray)\n        : util.Buffer\n            ? util._Buffer_from(sizeOrArray)\n            : typeof Uint8Array === \"undefined\"\n                ? sizeOrArray\n                : new Uint8Array(sizeOrArray);\n};\n\n/**\n * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.\n * @type {Constructor<Uint8Array>}\n */\nutil.Array = typeof Uint8Array !== \"undefined\" ? Uint8Array /* istanbul ignore next */ : Array;\n\n/**\n * Any compatible Long instance.\n * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.\n * @interface Long\n * @property {number} low Low bits\n * @property {number} high High bits\n * @property {boolean} unsigned Whether unsigned or not\n */\n\n/**\n * Long.js's Long class if available.\n * @type {Constructor<Long>}\n */\nutil.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long\n         || /* istanbul ignore next */ util.global.Long\n         || util.inquire(\"long\");\n\n/**\n * Regular expression used to verify 2 bit (`bool`) map keys.\n * @type {RegExp}\n * @const\n */\nutil.key2Re = /^true|false|0|1$/;\n\n/**\n * Regular expression used to verify 32 bit (`int32` etc.) map keys.\n * @type {RegExp}\n * @const\n */\nutil.key32Re = /^-?(?:0|[1-9][0-9]*)$/;\n\n/**\n * Regular expression used to verify 64 bit (`int64` etc.) map keys.\n * @type {RegExp}\n * @const\n */\nutil.key64Re = /^(?:[\\\\x00-\\\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;\n\n/**\n * Converts a number or long to an 8 characters long hash string.\n * @param {Long|number} value Value to convert\n * @returns {string} Hash\n */\nutil.longToHash = function longToHash(value) {\n    return value\n        ? util.LongBits.from(value).toHash()\n        : util.LongBits.zeroHash;\n};\n\n/**\n * Converts an 8 characters long hash string to a long or number.\n * @param {string} hash Hash\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {Long|number} Original value\n */\nutil.longFromHash = function longFromHash(hash, unsigned) {\n    var bits = util.LongBits.fromHash(hash);\n    if (util.Long)\n        return util.Long.fromBits(bits.lo, bits.hi, unsigned);\n    return bits.toNumber(Boolean(unsigned));\n};\n\n/**\n * Merges the properties of the source object into the destination object.\n * @memberof util\n * @param {Object.<string,*>} dst Destination object\n * @param {Object.<string,*>} src Source object\n * @param {boolean} [ifNotSet=false] Merges only if the key is not already set\n * @returns {Object.<string,*>} Destination object\n */\nfunction merge(dst, src, ifNotSet) { // used by converters\n    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)\n        if (dst[keys[i]] === undefined || !ifNotSet)\n            dst[keys[i]] = src[keys[i]];\n    return dst;\n}\n\nutil.merge = merge;\n\n/**\n * Converts the first character of a string to lower case.\n * @param {string} str String to convert\n * @returns {string} Converted string\n */\nutil.lcFirst = function lcFirst(str) {\n    return str.charAt(0).toLowerCase() + str.substring(1);\n};\n\n/**\n * Creates a custom error constructor.\n * @memberof util\n * @param {string} name Error name\n * @returns {Constructor<Error>} Custom error constructor\n */\nfunction newError(name) {\n\n    function CustomError(message, properties) {\n\n        if (!(this instanceof CustomError))\n            return new CustomError(message, properties);\n\n        // Error.call(this, message);\n        // ^ just returns a new error instance because the ctor can be called as a function\n\n        Object.defineProperty(this, \"message\", { get: function() { return message; } });\n\n        /* istanbul ignore next */\n        if (Error.captureStackTrace) // node\n            Error.captureStackTrace(this, CustomError);\n        else\n            Object.defineProperty(this, \"stack\", { value: new Error().stack || \"\" });\n\n        if (properties)\n            merge(this, properties);\n    }\n\n    (CustomError.prototype = Object.create(Error.prototype)).constructor = CustomError;\n\n    Object.defineProperty(CustomError.prototype, \"name\", { get: function() { return name; } });\n\n    CustomError.prototype.toString = function toString() {\n        return this.name + \": \" + this.message;\n    };\n\n    return CustomError;\n}\n\nutil.newError = newError;\n\n/**\n * Constructs a new protocol error.\n * @classdesc Error subclass indicating a protocol specifc error.\n * @memberof util\n * @extends Error\n * @template T extends Message<T>\n * @constructor\n * @param {string} message Error message\n * @param {Object.<string,*>} [properties] Additional properties\n * @example\n * try {\n *     MyMessage.decode(someBuffer); // throws if required fields are missing\n * } catch (e) {\n *     if (e instanceof ProtocolError && e.instance)\n *         console.log(\"decoded so far: \" + JSON.stringify(e.instance));\n * }\n */\nutil.ProtocolError = newError(\"ProtocolError\");\n\n/**\n * So far decoded message instance.\n * @name util.ProtocolError#instance\n * @type {Message<T>}\n */\n\n/**\n * A OneOf getter as returned by {@link util.oneOfGetter}.\n * @typedef OneOfGetter\n * @type {function}\n * @returns {string|undefined} Set field name, if any\n */\n\n/**\n * Builds a getter for a oneof's present field name.\n * @param {string[]} fieldNames Field names\n * @returns {OneOfGetter} Unbound getter\n */\nutil.oneOfGetter = function getOneOf(fieldNames) {\n    var fieldMap = {};\n    for (var i = 0; i < fieldNames.length; ++i)\n        fieldMap[fieldNames[i]] = 1;\n\n    /**\n     * @returns {string|undefined} Set field name, if any\n     * @this Object\n     * @ignore\n     */\n    return function() { // eslint-disable-line consistent-return\n        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)\n            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)\n                return keys[i];\n    };\n};\n\n/**\n * A OneOf setter as returned by {@link util.oneOfSetter}.\n * @typedef OneOfSetter\n * @type {function}\n * @param {string|undefined} value Field name\n * @returns {undefined}\n */\n\n/**\n * Builds a setter for a oneof's present field name.\n * @param {string[]} fieldNames Field names\n * @returns {OneOfSetter} Unbound setter\n */\nutil.oneOfSetter = function setOneOf(fieldNames) {\n\n    /**\n     * @param {string} name Field name\n     * @returns {undefined}\n     * @this Object\n     * @ignore\n     */\n    return function(name) {\n        for (var i = 0; i < fieldNames.length; ++i)\n            if (fieldNames[i] !== name)\n                delete this[fieldNames[i]];\n    };\n};\n\n/**\n * Default conversion options used for {@link Message#toJSON} implementations.\n *\n * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:\n *\n * - Longs become strings\n * - Enums become string keys\n * - Bytes become base64 encoded strings\n * - (Sub-)Messages become plain objects\n * - Maps become plain objects with all string keys\n * - Repeated fields become arrays\n * - NaN and Infinity for float and double fields become strings\n *\n * @type {IConversionOptions}\n * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json\n */\nutil.toJSONOptions = {\n    longs: String,\n    enums: String,\n    bytes: String,\n    json: true\n};\n\n// Sets up buffer utility according to the environment (called in index-minimal)\nutil._configure = function() {\n    var Buffer = util.Buffer;\n    /* istanbul ignore if */\n    if (!Buffer) {\n        util._Buffer_from = util._Buffer_allocUnsafe = null;\n        return;\n    }\n    // because node 4.x buffers are incompatible & immutable\n    // see: https://github.com/dcodeIO/protobuf.js/pull/665\n    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||\n        /* istanbul ignore next */\n        function Buffer_from(value, encoding) {\n            return new Buffer(value, encoding);\n        };\n    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||\n        /* istanbul ignore next */\n        function Buffer_allocUnsafe(size) {\n            return new Buffer(size);\n        };\n};\n", "\"use strict\";\nmodule.exports = Writer;\n\nvar util      = require(\"./util/minimal\");\n\nvar BufferWriter; // cyclic\n\nvar LongBits  = util.LongBits,\n    base64    = util.base64,\n    utf8      = util.utf8;\n\n/**\n * Constructs a new writer operation instance.\n * @classdesc Scheduled writer operation.\n * @constructor\n * @param {function(*, Uint8Array, number)} fn Function to call\n * @param {number} len Value byte length\n * @param {*} val Value to write\n * @ignore\n */\nfunction Op(fn, len, val) {\n\n    /**\n     * Function to call.\n     * @type {function(Uint8Array, number, *)}\n     */\n    this.fn = fn;\n\n    /**\n     * Value byte length.\n     * @type {number}\n     */\n    this.len = len;\n\n    /**\n     * Next operation.\n     * @type {Writer.Op|undefined}\n     */\n    this.next = undefined;\n\n    /**\n     * Value to write.\n     * @type {*}\n     */\n    this.val = val; // type varies\n}\n\n/* istanbul ignore next */\nfunction noop() {} // eslint-disable-line no-empty-function\n\n/**\n * Constructs a new writer state instance.\n * @classdesc Copied writer state.\n * @memberof Writer\n * @constructor\n * @param {Writer} writer Writer to copy state from\n * @ignore\n */\nfunction State(writer) {\n\n    /**\n     * Current head.\n     * @type {Writer.Op}\n     */\n    this.head = writer.head;\n\n    /**\n     * Current tail.\n     * @type {Writer.Op}\n     */\n    this.tail = writer.tail;\n\n    /**\n     * Current buffer length.\n     * @type {number}\n     */\n    this.len = writer.len;\n\n    /**\n     * Next state.\n     * @type {State|null}\n     */\n    this.next = writer.states;\n}\n\n/**\n * Constructs a new writer instance.\n * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.\n * @constructor\n */\nfunction Writer() {\n\n    /**\n     * Current length.\n     * @type {number}\n     */\n    this.len = 0;\n\n    /**\n     * Operations head.\n     * @type {Object}\n     */\n    this.head = new Op(noop, 0, 0);\n\n    /**\n     * Operations tail\n     * @type {Object}\n     */\n    this.tail = this.head;\n\n    /**\n     * Linked forked states.\n     * @type {Object|null}\n     */\n    this.states = null;\n\n    // When a value is written, the writer calculates its byte length and puts it into a linked\n    // list of operations to perform when finish() is called. This both allows us to allocate\n    // buffers of the exact required size and reduces the amount of work we have to do compared\n    // to first calculating over objects and then encoding over objects. In our case, the encoding\n    // part is just a linked list walk calling operations with already prepared values.\n}\n\nvar create = function create() {\n    return util.Buffer\n        ? function create_buffer_setup() {\n            return (Writer.create = function create_buffer() {\n                return new BufferWriter();\n            })();\n        }\n        /* istanbul ignore next */\n        : function create_array() {\n            return new Writer();\n        };\n};\n\n/**\n * Creates a new writer.\n * @function\n * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}\n */\nWriter.create = create();\n\n/**\n * Allocates a buffer of the specified size.\n * @param {number} size Buffer size\n * @returns {Uint8Array} Buffer\n */\nWriter.alloc = function alloc(size) {\n    return new util.Array(size);\n};\n\n// Use Uint8Array buffer pool in the browser, just like node does with buffers\n/* istanbul ignore else */\nif (util.Array !== Array)\n    Writer.alloc = util.pool(Writer.alloc, util.Array.prototype.subarray);\n\n/**\n * Pushes a new operation to the queue.\n * @param {function(Uint8Array, number, *)} fn Function to call\n * @param {number} len Value byte length\n * @param {number} val Value to write\n * @returns {Writer} `this`\n * @private\n */\nWriter.prototype._push = function push(fn, len, val) {\n    this.tail = this.tail.next = new Op(fn, len, val);\n    this.len += len;\n    return this;\n};\n\nfunction writeByte(val, buf, pos) {\n    buf[pos] = val & 255;\n}\n\nfunction writeVarint32(val, buf, pos) {\n    while (val > 127) {\n        buf[pos++] = val & 127 | 128;\n        val >>>= 7;\n    }\n    buf[pos] = val;\n}\n\n/**\n * Constructs a new varint writer operation instance.\n * @classdesc Scheduled varint writer operation.\n * @extends Op\n * @constructor\n * @param {number} len Value byte length\n * @param {number} val Value to write\n * @ignore\n */\nfunction VarintOp(len, val) {\n    this.len = len;\n    this.next = undefined;\n    this.val = val;\n}\n\nVarintOp.prototype = Object.create(Op.prototype);\nVarintOp.prototype.fn = writeVarint32;\n\n/**\n * Writes an unsigned 32 bit value as a varint.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.uint32 = function write_uint32(value) {\n    // here, the call to this.push has been inlined and a varint specific Op subclass is used.\n    // uint32 is by far the most frequently used operation and benefits significantly from this.\n    this.len += (this.tail = this.tail.next = new VarintOp(\n        (value = value >>> 0)\n                < 128       ? 1\n        : value < 16384     ? 2\n        : value < 2097152   ? 3\n        : value < 268435456 ? 4\n        :                     5,\n    value)).len;\n    return this;\n};\n\n/**\n * Writes a signed 32 bit value as a varint.\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.int32 = function write_int32(value) {\n    return value < 0\n        ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec\n        : this.uint32(value);\n};\n\n/**\n * Writes a 32 bit value as a varint, zig-zag encoded.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.sint32 = function write_sint32(value) {\n    return this.uint32((value << 1 ^ value >> 31) >>> 0);\n};\n\nfunction writeVarint64(val, buf, pos) {\n    while (val.hi) {\n        buf[pos++] = val.lo & 127 | 128;\n        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;\n        val.hi >>>= 7;\n    }\n    while (val.lo > 127) {\n        buf[pos++] = val.lo & 127 | 128;\n        val.lo = val.lo >>> 7;\n    }\n    buf[pos++] = val.lo;\n}\n\n/**\n * Writes an unsigned 64 bit value as a varint.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.uint64 = function write_uint64(value) {\n    var bits = LongBits.from(value);\n    return this._push(writeVarint64, bits.length(), bits);\n};\n\n/**\n * Writes a signed 64 bit value as a varint.\n * @function\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.int64 = Writer.prototype.uint64;\n\n/**\n * Writes a signed 64 bit value as a varint, zig-zag encoded.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.sint64 = function write_sint64(value) {\n    var bits = LongBits.from(value).zzEncode();\n    return this._push(writeVarint64, bits.length(), bits);\n};\n\n/**\n * Writes a boolish value as a varint.\n * @param {boolean} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.bool = function write_bool(value) {\n    return this._push(writeByte, 1, value ? 1 : 0);\n};\n\nfunction writeFixed32(val, buf, pos) {\n    buf[pos    ] =  val         & 255;\n    buf[pos + 1] =  val >>> 8   & 255;\n    buf[pos + 2] =  val >>> 16  & 255;\n    buf[pos + 3] =  val >>> 24;\n}\n\n/**\n * Writes an unsigned 32 bit value as fixed 32 bits.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.fixed32 = function write_fixed32(value) {\n    return this._push(writeFixed32, 4, value >>> 0);\n};\n\n/**\n * Writes a signed 32 bit value as fixed 32 bits.\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.sfixed32 = Writer.prototype.fixed32;\n\n/**\n * Writes an unsigned 64 bit value as fixed 64 bits.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.fixed64 = function write_fixed64(value) {\n    var bits = LongBits.from(value);\n    return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);\n};\n\n/**\n * Writes a signed 64 bit value as fixed 64 bits.\n * @function\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.sfixed64 = Writer.prototype.fixed64;\n\n/**\n * Writes a float (32 bit).\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.float = function write_float(value) {\n    return this._push(util.float.writeFloatLE, 4, value);\n};\n\n/**\n * Writes a double (64 bit float).\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.double = function write_double(value) {\n    return this._push(util.float.writeDoubleLE, 8, value);\n};\n\nvar writeBytes = util.Array.prototype.set\n    ? function writeBytes_set(val, buf, pos) {\n        buf.set(val, pos); // also works for plain array values\n    }\n    /* istanbul ignore next */\n    : function writeBytes_for(val, buf, pos) {\n        for (var i = 0; i < val.length; ++i)\n            buf[pos + i] = val[i];\n    };\n\n/**\n * Writes a sequence of bytes.\n * @param {Uint8Array|string} value Buffer or base64 encoded string to write\n * @returns {Writer} `this`\n */\nWriter.prototype.bytes = function write_bytes(value) {\n    var len = value.length >>> 0;\n    if (!len)\n        return this._push(writeByte, 1, 0);\n    if (util.isString(value)) {\n        var buf = Writer.alloc(len = base64.length(value));\n        base64.decode(value, buf, 0);\n        value = buf;\n    }\n    return this.uint32(len)._push(writeBytes, len, value);\n};\n\n/**\n * Writes a string.\n * @param {string} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.string = function write_string(value) {\n    var len = utf8.length(value);\n    return len\n        ? this.uint32(len)._push(utf8.write, len, value)\n        : this._push(writeByte, 1, 0);\n};\n\n/**\n * Forks this writer's state by pushing it to a stack.\n * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.\n * @returns {Writer} `this`\n */\nWriter.prototype.fork = function fork() {\n    this.states = new State(this);\n    this.head = this.tail = new Op(noop, 0, 0);\n    this.len = 0;\n    return this;\n};\n\n/**\n * Resets this instance to the last state.\n * @returns {Writer} `this`\n */\nWriter.prototype.reset = function reset() {\n    if (this.states) {\n        this.head   = this.states.head;\n        this.tail   = this.states.tail;\n        this.len    = this.states.len;\n        this.states = this.states.next;\n    } else {\n        this.head = this.tail = new Op(noop, 0, 0);\n        this.len  = 0;\n    }\n    return this;\n};\n\n/**\n * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.\n * @returns {Writer} `this`\n */\nWriter.prototype.ldelim = function ldelim() {\n    var head = this.head,\n        tail = this.tail,\n        len  = this.len;\n    this.reset().uint32(len);\n    if (len) {\n        this.tail.next = head.next; // skip noop\n        this.tail = tail;\n        this.len += len;\n    }\n    return this;\n};\n\n/**\n * Finishes the write operation.\n * @returns {Uint8Array} Finished buffer\n */\nWriter.prototype.finish = function finish() {\n    var head = this.head.next, // skip noop\n        buf  = this.constructor.alloc(this.len),\n        pos  = 0;\n    while (head) {\n        head.fn(head.val, buf, pos);\n        pos += head.len;\n        head = head.next;\n    }\n    // this.head = this.tail = null;\n    return buf;\n};\n\nWriter._configure = function(BufferWriter_) {\n    BufferWriter = BufferWriter_;\n    Writer.create = create();\n    BufferWriter._configure();\n};\n", "\"use strict\";\nmodule.exports = BufferWriter;\n\n// extends Writer\nvar Writer = require(\"./writer\");\n(BufferWriter.prototype = Object.create(Writer.prototype)).constructor = BufferWriter;\n\nvar util = require(\"./util/minimal\");\n\n/**\n * Constructs a new buffer writer instance.\n * @classdesc Wire format writer using node buffers.\n * @extends Writer\n * @constructor\n */\nfunction BufferWriter() {\n    Writer.call(this);\n}\n\nBufferWriter._configure = function () {\n    /**\n     * Allocates a buffer of the specified size.\n     * @function\n     * @param {number} size Buffer size\n     * @returns {Buffer} Buffer\n     */\n    BufferWriter.alloc = util._Buffer_allocUnsafe;\n\n    BufferWriter.writeBytesBuffer = util.Buffer && util.Buffer.prototype instanceof Uint8Array && util.Buffer.prototype.set.name === \"set\"\n        ? function writeBytesBuffer_set(val, buf, pos) {\n          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)\n          // also works for plain array values\n        }\n        /* istanbul ignore next */\n        : function writeBytesBuffer_copy(val, buf, pos) {\n          if (val.copy) // Buffer values\n            val.copy(buf, pos, 0, val.length);\n          else for (var i = 0; i < val.length;) // plain array values\n            buf[pos++] = val[i++];\n        };\n};\n\n\n/**\n * @override\n */\nBufferWriter.prototype.bytes = function write_bytes_buffer(value) {\n    if (util.isString(value))\n        value = util._Buffer_from(value, \"base64\");\n    var len = value.length >>> 0;\n    this.uint32(len);\n    if (len)\n        this._push(BufferWriter.writeBytesBuffer, len, value);\n    return this;\n};\n\nfunction writeStringBuffer(val, buf, pos) {\n    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)\n        util.utf8.write(val, buf, pos);\n    else if (buf.utf8Write)\n        buf.utf8Write(val, pos);\n    else\n        buf.write(val, pos);\n}\n\n/**\n * @override\n */\nBufferWriter.prototype.string = function write_string_buffer(value) {\n    var len = util.Buffer.byteLength(value);\n    this.uint32(len);\n    if (len)\n        this._push(writeStringBuffer, len, value);\n    return this;\n};\n\n\n/**\n * Finishes the write operation.\n * @name BufferWriter#finish\n * @function\n * @returns {Buffer} Finished buffer\n */\n\nBufferWriter._configure();\n", "\"use strict\";\nmodule.exports = Reader;\n\nvar util      = require(\"./util/minimal\");\n\nvar BufferReader; // cyclic\n\nvar LongBits  = util.LongBits,\n    utf8      = util.utf8;\n\n/* istanbul ignore next */\nfunction indexOutOfRange(reader, writeLength) {\n    return RangeError(\"index out of range: \" + reader.pos + \" + \" + (writeLength || 1) + \" > \" + reader.len);\n}\n\n/**\n * Constructs a new reader instance using the specified buffer.\n * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.\n * @constructor\n * @param {Uint8Array} buffer Buffer to read from\n */\nfunction Reader(buffer) {\n\n    /**\n     * Read buffer.\n     * @type {Uint8Array}\n     */\n    this.buf = buffer;\n\n    /**\n     * Read buffer position.\n     * @type {number}\n     */\n    this.pos = 0;\n\n    /**\n     * Read buffer length.\n     * @type {number}\n     */\n    this.len = buffer.length;\n}\n\nvar create_array = typeof Uint8Array !== \"undefined\"\n    ? function create_typed_array(buffer) {\n        if (buffer instanceof Uint8Array || Array.isArray(buffer))\n            return new Reader(buffer);\n        throw Error(\"illegal buffer\");\n    }\n    /* istanbul ignore next */\n    : function create_array(buffer) {\n        if (Array.isArray(buffer))\n            return new Reader(buffer);\n        throw Error(\"illegal buffer\");\n    };\n\nvar create = function create() {\n    return util.Buffer\n        ? function create_buffer_setup(buffer) {\n            return (Reader.create = function create_buffer(buffer) {\n                return util.Buffer.isBuffer(buffer)\n                    ? new BufferReader(buffer)\n                    /* istanbul ignore next */\n                    : create_array(buffer);\n            })(buffer);\n        }\n        /* istanbul ignore next */\n        : create_array;\n};\n\n/**\n * Creates a new reader using the specified buffer.\n * @function\n * @param {Uint8Array|Buffer} buffer Buffer to read from\n * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}\n * @throws {Error} If `buffer` is not a valid buffer\n */\nReader.create = create();\n\nReader.prototype._slice = util.Array.prototype.subarray || /* istanbul ignore next */ util.Array.prototype.slice;\n\n/**\n * Reads a varint as an unsigned 32 bit value.\n * @function\n * @returns {number} Value read\n */\nReader.prototype.uint32 = (function read_uint32_setup() {\n    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)\n    return function read_uint32() {\n        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;\n\n        /* istanbul ignore if */\n        if ((this.pos += 5) > this.len) {\n            this.pos = this.len;\n            throw indexOutOfRange(this, 10);\n        }\n        return value;\n    };\n})();\n\n/**\n * Reads a varint as a signed 32 bit value.\n * @returns {number} Value read\n */\nReader.prototype.int32 = function read_int32() {\n    return this.uint32() | 0;\n};\n\n/**\n * Reads a zig-zag encoded varint as a signed 32 bit value.\n * @returns {number} Value read\n */\nReader.prototype.sint32 = function read_sint32() {\n    var value = this.uint32();\n    return value >>> 1 ^ -(value & 1) | 0;\n};\n\n/* eslint-disable no-invalid-this */\n\nfunction readLongVarint() {\n    // tends to deopt with local vars for octet etc.\n    var bits = new LongBits(0, 0);\n    var i = 0;\n    if (this.len - this.pos > 4) { // fast route (lo)\n        for (; i < 4; ++i) {\n            // 1st..4th\n            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n        // 5th\n        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;\n        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;\n        if (this.buf[this.pos++] < 128)\n            return bits;\n        i = 0;\n    } else {\n        for (; i < 3; ++i) {\n            /* istanbul ignore if */\n            if (this.pos >= this.len)\n                throw indexOutOfRange(this);\n            // 1st..3th\n            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n        // 4th\n        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;\n        return bits;\n    }\n    if (this.len - this.pos > 4) { // fast route (hi)\n        for (; i < 5; ++i) {\n            // 6th..10th\n            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n    } else {\n        for (; i < 5; ++i) {\n            /* istanbul ignore if */\n            if (this.pos >= this.len)\n                throw indexOutOfRange(this);\n            // 6th..10th\n            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n    }\n    /* istanbul ignore next */\n    throw Error(\"invalid varint encoding\");\n}\n\n/* eslint-enable no-invalid-this */\n\n/**\n * Reads a varint as a signed 64 bit value.\n * @name Reader#int64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a varint as an unsigned 64 bit value.\n * @name Reader#uint64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a zig-zag encoded varint as a signed 64 bit value.\n * @name Reader#sint64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a varint as a boolean.\n * @returns {boolean} Value read\n */\nReader.prototype.bool = function read_bool() {\n    return this.uint32() !== 0;\n};\n\nfunction readFixed32_end(buf, end) { // note that this uses `end`, not `pos`\n    return (buf[end - 4]\n          | buf[end - 3] << 8\n          | buf[end - 2] << 16\n          | buf[end - 1] << 24) >>> 0;\n}\n\n/**\n * Reads fixed 32 bits as an unsigned 32 bit integer.\n * @returns {number} Value read\n */\nReader.prototype.fixed32 = function read_fixed32() {\n\n    /* istanbul ignore if */\n    if (this.pos + 4 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    return readFixed32_end(this.buf, this.pos += 4);\n};\n\n/**\n * Reads fixed 32 bits as a signed 32 bit integer.\n * @returns {number} Value read\n */\nReader.prototype.sfixed32 = function read_sfixed32() {\n\n    /* istanbul ignore if */\n    if (this.pos + 4 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    return readFixed32_end(this.buf, this.pos += 4) | 0;\n};\n\n/* eslint-disable no-invalid-this */\n\nfunction readFixed64(/* this: Reader */) {\n\n    /* istanbul ignore if */\n    if (this.pos + 8 > this.len)\n        throw indexOutOfRange(this, 8);\n\n    return new LongBits(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));\n}\n\n/* eslint-enable no-invalid-this */\n\n/**\n * Reads fixed 64 bits.\n * @name Reader#fixed64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads zig-zag encoded fixed 64 bits.\n * @name Reader#sfixed64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a float (32 bit) as a number.\n * @function\n * @returns {number} Value read\n */\nReader.prototype.float = function read_float() {\n\n    /* istanbul ignore if */\n    if (this.pos + 4 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    var value = util.float.readFloatLE(this.buf, this.pos);\n    this.pos += 4;\n    return value;\n};\n\n/**\n * Reads a double (64 bit float) as a number.\n * @function\n * @returns {number} Value read\n */\nReader.prototype.double = function read_double() {\n\n    /* istanbul ignore if */\n    if (this.pos + 8 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    var value = util.float.readDoubleLE(this.buf, this.pos);\n    this.pos += 8;\n    return value;\n};\n\n/**\n * Reads a sequence of bytes preceeded by its length as a varint.\n * @returns {Uint8Array} Value read\n */\nReader.prototype.bytes = function read_bytes() {\n    var length = this.uint32(),\n        start  = this.pos,\n        end    = this.pos + length;\n\n    /* istanbul ignore if */\n    if (end > this.len)\n        throw indexOutOfRange(this, length);\n\n    this.pos += length;\n    if (Array.isArray(this.buf)) // plain array\n        return this.buf.slice(start, end);\n    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1\n        ? new this.buf.constructor(0)\n        : this._slice.call(this.buf, start, end);\n};\n\n/**\n * Reads a string preceeded by its byte length as a varint.\n * @returns {string} Value read\n */\nReader.prototype.string = function read_string() {\n    var bytes = this.bytes();\n    return utf8.read(bytes, 0, bytes.length);\n};\n\n/**\n * Skips the specified number of bytes if specified, otherwise skips a varint.\n * @param {number} [length] Length if known, otherwise a varint is assumed\n * @returns {Reader} `this`\n */\nReader.prototype.skip = function skip(length) {\n    if (typeof length === \"number\") {\n        /* istanbul ignore if */\n        if (this.pos + length > this.len)\n            throw indexOutOfRange(this, length);\n        this.pos += length;\n    } else {\n        do {\n            /* istanbul ignore if */\n            if (this.pos >= this.len)\n                throw indexOutOfRange(this);\n        } while (this.buf[this.pos++] & 128);\n    }\n    return this;\n};\n\n/**\n * Skips the next element of the specified wire type.\n * @param {number} wireType Wire type received\n * @returns {Reader} `this`\n */\nReader.prototype.skipType = function(wireType) {\n    switch (wireType) {\n        case 0:\n            this.skip();\n            break;\n        case 1:\n            this.skip(8);\n            break;\n        case 2:\n            this.skip(this.uint32());\n            break;\n        case 3:\n            while ((wireType = this.uint32() & 7) !== 4) {\n                this.skipType(wireType);\n            }\n            break;\n        case 5:\n            this.skip(4);\n            break;\n\n        /* istanbul ignore next */\n        default:\n            throw Error(\"invalid wire type \" + wireType + \" at offset \" + this.pos);\n    }\n    return this;\n};\n\nReader._configure = function(BufferReader_) {\n    BufferReader = BufferReader_;\n    Reader.create = create();\n    BufferReader._configure();\n\n    var fn = util.Long ? \"toLong\" : /* istanbul ignore next */ \"toNumber\";\n    util.merge(Reader.prototype, {\n\n        int64: function read_int64() {\n            return readLongVarint.call(this)[fn](false);\n        },\n\n        uint64: function read_uint64() {\n            return readLongVarint.call(this)[fn](true);\n        },\n\n        sint64: function read_sint64() {\n            return readLongVarint.call(this).zzDecode()[fn](false);\n        },\n\n        fixed64: function read_fixed64() {\n            return readFixed64.call(this)[fn](true);\n        },\n\n        sfixed64: function read_sfixed64() {\n            return readFixed64.call(this)[fn](false);\n        }\n\n    });\n};\n", "\"use strict\";\nmodule.exports = BufferReader;\n\n// extends Reader\nvar Reader = require(\"./reader\");\n(BufferReader.prototype = Object.create(Reader.prototype)).constructor = BufferReader;\n\nvar util = require(\"./util/minimal\");\n\n/**\n * Constructs a new buffer reader instance.\n * @classdesc Wire format reader using node buffers.\n * @extends Reader\n * @constructor\n * @param {Buffer} buffer Buffer to read from\n */\nfunction BufferReader(buffer) {\n    Reader.call(this, buffer);\n\n    /**\n     * Read buffer.\n     * @name BufferReader#buf\n     * @type {Buffer}\n     */\n}\n\nBufferReader._configure = function () {\n    /* istanbul ignore else */\n    if (util.Buffer)\n        BufferReader.prototype._slice = util.Buffer.prototype.slice;\n};\n\n\n/**\n * @override\n */\nBufferReader.prototype.string = function read_string_buffer() {\n    var len = this.uint32(); // modifies pos\n    return this.buf.utf8Slice\n        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))\n        : this.buf.toString(\"utf-8\", this.pos, this.pos = Math.min(this.pos + len, this.len));\n};\n\n/**\n * Reads a sequence of bytes preceeded by its length as a varint.\n * @name BufferReader#bytes\n * @function\n * @returns {Buffer} Value read\n */\n\nBufferReader._configure();\n", "\"use strict\";\nmodule.exports = Service;\n\nvar util = require(\"../util/minimal\");\n\n// Extends EventEmitter\n(Service.prototype = Object.create(util.EventEmitter.prototype)).constructor = Service;\n\n/**\n * A service method callback as used by {@link rpc.ServiceMethod|ServiceMethod}.\n *\n * Differs from {@link RPCImplCallback} in that it is an actual callback of a service method which may not return `response = null`.\n * @typedef rpc.ServiceMethodCallback\n * @template TRes extends Message<TRes>\n * @type {function}\n * @param {Error|null} error Error, if any\n * @param {TRes} [response] Response message\n * @returns {undefined}\n */\n\n/**\n * A service method part of a {@link rpc.Service} as created by {@link Service.create}.\n * @typedef rpc.ServiceMethod\n * @template TReq extends Message<TReq>\n * @template TRes extends Message<TRes>\n * @type {function}\n * @param {TReq|Properties<TReq>} request Request message or plain object\n * @param {rpc.ServiceMethodCallback<TRes>} [callback] Node-style callback called with the error, if any, and the response message\n * @returns {Promise<Message<TRes>>} Promise if `callback` has been omitted, otherwise `undefined`\n */\n\n/**\n * Constructs a new RPC service instance.\n * @classdesc An RPC service as returned by {@link Service#create}.\n * @exports rpc.Service\n * @extends util.EventEmitter\n * @constructor\n * @param {RPCImpl} rpcImpl RPC implementation\n * @param {boolean} [requestDelimited=false] Whether requests are length-delimited\n * @param {boolean} [responseDelimited=false] Whether responses are length-delimited\n */\nfunction Service(rpcImpl, requestDelimited, responseDelimited) {\n\n    if (typeof rpcImpl !== \"function\")\n        throw TypeError(\"rpcImpl must be a function\");\n\n    util.EventEmitter.call(this);\n\n    /**\n     * RPC implementation. Becomes `null` once the service is ended.\n     * @type {RPCImpl|null}\n     */\n    this.rpcImpl = rpcImpl;\n\n    /**\n     * Whether requests are length-delimited.\n     * @type {boolean}\n     */\n    this.requestDelimited = Boolean(requestDelimited);\n\n    /**\n     * Whether responses are length-delimited.\n     * @type {boolean}\n     */\n    this.responseDelimited = Boolean(responseDelimited);\n}\n\n/**\n * Calls a service method through {@link rpc.Service#rpcImpl|rpcImpl}.\n * @param {Method|rpc.ServiceMethod<TReq,TRes>} method Reflected or static method\n * @param {Constructor<TReq>} requestCtor Request constructor\n * @param {Constructor<TRes>} responseCtor Response constructor\n * @param {TReq|Properties<TReq>} request Request message or plain object\n * @param {rpc.ServiceMethodCallback<TRes>} callback Service callback\n * @returns {undefined}\n * @template TReq extends Message<TReq>\n * @template TRes extends Message<TRes>\n */\nService.prototype.rpcCall = function rpcCall(method, requestCtor, responseCtor, request, callback) {\n\n    if (!request)\n        throw TypeError(\"request must be specified\");\n\n    var self = this;\n    if (!callback)\n        return util.asPromise(rpcCall, self, method, requestCtor, responseCtor, request);\n\n    if (!self.rpcImpl) {\n        setTimeout(function() { callback(Error(\"already ended\")); }, 0);\n        return undefined;\n    }\n\n    try {\n        return self.rpcImpl(\n            method,\n            requestCtor[self.requestDelimited ? \"encodeDelimited\" : \"encode\"](request).finish(),\n            function rpcCallback(err, response) {\n\n                if (err) {\n                    self.emit(\"error\", err, method);\n                    return callback(err);\n                }\n\n                if (response === null) {\n                    self.end(/* endedByRPC */ true);\n                    return undefined;\n                }\n\n                if (!(response instanceof responseCtor)) {\n                    try {\n                        response = responseCtor[self.responseDelimited ? \"decodeDelimited\" : \"decode\"](response);\n                    } catch (err) {\n                        self.emit(\"error\", err, method);\n                        return callback(err);\n                    }\n                }\n\n                self.emit(\"data\", response, method);\n                return callback(null, response);\n            }\n        );\n    } catch (err) {\n        self.emit(\"error\", err, method);\n        setTimeout(function() { callback(err); }, 0);\n        return undefined;\n    }\n};\n\n/**\n * Ends this service and emits the `end` event.\n * @param {boolean} [endedByRPC=false] Whether the service has been ended by the RPC implementation.\n * @returns {rpc.Service} `this`\n */\nService.prototype.end = function end(endedByRPC) {\n    if (this.rpcImpl) {\n        if (!endedByRPC) // signal end to rpcImpl\n            this.rpcImpl(null, null, null);\n        this.rpcImpl = null;\n        this.emit(\"end\").off();\n    }\n    return this;\n};\n", "\"use strict\";\n\n/**\n * Streaming RPC helpers.\n * @namespace\n */\nvar rpc = exports;\n\n/**\n * RPC implementation passed to {@link Service#create} performing a service request on network level, i.e. by utilizing http requests or websockets.\n * @typedef RPCImpl\n * @type {function}\n * @param {Method|rpc.ServiceMethod<Message<{}>,Message<{}>>} method Reflected or static method being called\n * @param {Uint8Array} requestData Request data\n * @param {RPCImplCallback} callback Callback function\n * @returns {undefined}\n * @example\n * function rpcImpl(method, requestData, callback) {\n *     if (protobuf.util.lcFirst(method.name) !== \"myMethod\") // compatible with static code\n *         throw Error(\"no such method\");\n *     asynchronouslyObtainAResponse(requestData, function(err, responseData) {\n *         callback(err, responseData);\n *     });\n * }\n */\n\n/**\n * Node-style callback as used by {@link RPCImpl}.\n * @typedef RPCImplCallback\n * @type {function}\n * @param {Error|null} error Error, if any, otherwise `null`\n * @param {Uint8Array|null} [response] Response data or `null` to signal end of stream, if there hasn't been an error\n * @returns {undefined}\n */\n\nrpc.Service = require(\"./rpc/service\");\n", "\"use strict\";\nmodule.exports = {};\n\n/**\n * Named roots.\n * This is where pbjs stores generated structures (the option `-r, --root` specifies a name).\n * Can also be used manually to make roots available accross modules.\n * @name roots\n * @type {Object.<string,Root>}\n * @example\n * // pbjs -r myroot -o compiled.js ...\n *\n * // in another module:\n * require(\"./compiled.js\");\n *\n * // in any subsequent module:\n * var root = protobuf.roots[\"myroot\"];\n */\n", "\"use strict\";\nvar protobuf = exports;\n\n/**\n * Build type, one of `\"full\"`, `\"light\"` or `\"minimal\"`.\n * @name build\n * @type {string}\n * @const\n */\nprotobuf.build = \"minimal\";\n\n// Serialization\nprotobuf.Writer       = require(\"./writer\");\nprotobuf.BufferWriter = require(\"./writer_buffer\");\nprotobuf.Reader       = require(\"./reader\");\nprotobuf.BufferReader = require(\"./reader_buffer\");\n\n// Utility\nprotobuf.util         = require(\"./util/minimal\");\nprotobuf.rpc          = require(\"./rpc\");\nprotobuf.roots        = require(\"./roots\");\nprotobuf.configure    = configure;\n\n/* istanbul ignore next */\n/**\n * Reconfigures the library according to the environment.\n * @returns {undefined}\n */\nfunction configure() {\n    protobuf.util._configure();\n    protobuf.Writer._configure(protobuf.BufferWriter);\n    protobuf.Reader._configure(protobuf.BufferReader);\n}\n\n// Set up buffer utility according to the environment\nconfigure();\n", "\"use strict\";\r\nmodule.exports = codegen;\r\n\r\n/**\r\n * Begins generating a function.\r\n * @memberof util\r\n * @param {string[]} functionParams Function parameter names\r\n * @param {string} [functionName] Function name if not anonymous\r\n * @returns {Codegen} Appender that appends code to the function's body\r\n */\r\nfunction codegen(functionParams, functionName) {\r\n\r\n    /* istanbul ignore if */\r\n    if (typeof functionParams === \"string\") {\r\n        functionName = functionParams;\r\n        functionParams = undefined;\r\n    }\r\n\r\n    var body = [];\r\n\r\n    /**\r\n     * Appends code to the function's body or finishes generation.\r\n     * @typedef Codegen\r\n     * @type {function}\r\n     * @param {string|Object.<string,*>} [formatStringOrScope] Format string or, to finish the function, an object of additional scope variables, if any\r\n     * @param {...*} [formatParams] Format parameters\r\n     * @returns {Codegen|Function} Itself or the generated function if finished\r\n     * @throws {Error} If format parameter counts do not match\r\n     */\r\n\r\n    function Codegen(formatStringOrScope) {\r\n        // note that explicit array handling below makes this ~50% faster\r\n\r\n        // finish the function\r\n        if (typeof formatStringOrScope !== \"string\") {\r\n            var source = toString();\r\n            if (codegen.verbose)\r\n                console.log(\"codegen: \" + source); // eslint-disable-line no-console\r\n            source = \"return \" + source;\r\n            if (formatStringOrScope) {\r\n                var scopeKeys   = Object.keys(formatStringOrScope),\r\n                    scopeParams = new Array(scopeKeys.length + 1),\r\n                    scopeValues = new Array(scopeKeys.length),\r\n                    scopeOffset = 0;\r\n                while (scopeOffset < scopeKeys.length) {\r\n                    scopeParams[scopeOffset] = scopeKeys[scopeOffset];\r\n                    scopeValues[scopeOffset] = formatStringOrScope[scopeKeys[scopeOffset++]];\r\n                }\r\n                scopeParams[scopeOffset] = source;\r\n                return Function.apply(null, scopeParams).apply(null, scopeValues); // eslint-disable-line no-new-func\r\n            }\r\n            return Function(source)(); // eslint-disable-line no-new-func\r\n        }\r\n\r\n        // otherwise append to body\r\n        var formatParams = new Array(arguments.length - 1),\r\n            formatOffset = 0;\r\n        while (formatOffset < formatParams.length)\r\n            formatParams[formatOffset] = arguments[++formatOffset];\r\n        formatOffset = 0;\r\n        formatStringOrScope = formatStringOrScope.replace(/%([%dfijs])/g, function replace($0, $1) {\r\n            var value = formatParams[formatOffset++];\r\n            switch ($1) {\r\n                case \"d\": case \"f\": return String(Number(value));\r\n                case \"i\": return String(Math.floor(value));\r\n                case \"j\": return JSON.stringify(value);\r\n                case \"s\": return String(value);\r\n            }\r\n            return \"%\";\r\n        });\r\n        if (formatOffset !== formatParams.length)\r\n            throw Error(\"parameter count mismatch\");\r\n        body.push(formatStringOrScope);\r\n        return Codegen;\r\n    }\r\n\r\n    function toString(functionNameOverride) {\r\n        return \"function \" + (functionNameOverride || functionName || \"\") + \"(\" + (functionParams && functionParams.join(\",\") || \"\") + \"){\\n  \" + body.join(\"\\n  \") + \"\\n}\";\r\n    }\r\n\r\n    Codegen.toString = toString;\r\n    return Codegen;\r\n}\r\n\r\n/**\r\n * Begins generating a function.\r\n * @memberof util\r\n * @function codegen\r\n * @param {string} [functionName] Function name if not anonymous\r\n * @returns {Codegen} Appender that appends code to the function's body\r\n * @variation 2\r\n */\r\n\r\n/**\r\n * When set to `true`, codegen will log generated code to console. Useful for debugging.\r\n * @name util.codegen.verbose\r\n * @type {boolean}\r\n */\r\ncodegen.verbose = false;\r\n", "\"use strict\";\r\nmodule.exports = fetch;\r\n\r\nvar asPromise = require(\"@protobufjs/aspromise\"),\r\n    inquire   = require(\"@protobufjs/inquire\");\r\n\r\nvar fs = inquire(\"fs\");\r\n\r\n/**\r\n * Node-style callback as used by {@link util.fetch}.\r\n * @typedef FetchCallback\r\n * @type {function}\r\n * @param {?Error} error Error, if any, otherwise `null`\r\n * @param {string} [contents] File contents, if there hasn't been an error\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Options as used by {@link util.fetch}.\r\n * @typedef FetchOptions\r\n * @type {Object}\r\n * @property {boolean} [binary=false] Whether expecting a binary response\r\n * @property {boolean} [xhr=false] If `true`, forces the use of XMLHttpRequest\r\n */\r\n\r\n/**\r\n * Fetches the contents of a file.\r\n * @memberof util\r\n * @param {string} filename File path or url\r\n * @param {FetchOptions} options Fetch options\r\n * @param {FetchCallback} callback Callback function\r\n * @returns {undefined}\r\n */\r\nfunction fetch(filename, options, callback) {\r\n    if (typeof options === \"function\") {\r\n        callback = options;\r\n        options = {};\r\n    } else if (!options)\r\n        options = {};\r\n\r\n    if (!callback)\r\n        return asPromise(fetch, this, filename, options); // eslint-disable-line no-invalid-this\r\n\r\n    // if a node-like filesystem is present, try it first but fall back to XHR if nothing is found.\r\n    if (!options.xhr && fs && fs.readFile)\r\n        return fs.readFile(filename, function fetchReadFileCallback(err, contents) {\r\n            return err && typeof XMLHttpRequest !== \"undefined\"\r\n                ? fetch.xhr(filename, options, callback)\r\n                : err\r\n                ? callback(err)\r\n                : callback(null, options.binary ? contents : contents.toString(\"utf8\"));\r\n        });\r\n\r\n    // use the XHR version otherwise.\r\n    return fetch.xhr(filename, options, callback);\r\n}\r\n\r\n/**\r\n * Fetches the contents of a file.\r\n * @name util.fetch\r\n * @function\r\n * @param {string} path File path or url\r\n * @param {FetchCallback} callback Callback function\r\n * @returns {undefined}\r\n * @variation 2\r\n */\r\n\r\n/**\r\n * Fetches the contents of a file.\r\n * @name util.fetch\r\n * @function\r\n * @param {string} path File path or url\r\n * @param {FetchOptions} [options] Fetch options\r\n * @returns {Promise<string|Uint8Array>} Promise\r\n * @variation 3\r\n */\r\n\r\n/**/\r\nfetch.xhr = function fetch_xhr(filename, options, callback) {\r\n    var xhr = new XMLHttpRequest();\r\n    xhr.onreadystatechange /* works everywhere */ = function fetchOnReadyStateChange() {\r\n\r\n        if (xhr.readyState !== 4)\r\n            return undefined;\r\n\r\n        // local cors security errors return status 0 / empty string, too. afaik this cannot be\r\n        // reliably distinguished from an actually empty file for security reasons. feel free\r\n        // to send a pull request if you are aware of a solution.\r\n        if (xhr.status !== 0 && xhr.status !== 200)\r\n            return callback(Error(\"status \" + xhr.status));\r\n\r\n        // if binary data is expected, make sure that some sort of array is returned, even if\r\n        // ArrayBuffers are not supported. the binary string fallback, however, is unsafe.\r\n        if (options.binary) {\r\n            var buffer = xhr.response;\r\n            if (!buffer) {\r\n                buffer = [];\r\n                for (var i = 0; i < xhr.responseText.length; ++i)\r\n                    buffer.push(xhr.responseText.charCodeAt(i) & 255);\r\n            }\r\n            return callback(null, typeof Uint8Array !== \"undefined\" ? new Uint8Array(buffer) : buffer);\r\n        }\r\n        return callback(null, xhr.responseText);\r\n    };\r\n\r\n    if (options.binary) {\r\n        // ref: https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Sending_and_Receiving_Binary_Data#Receiving_binary_data_in_older_browsers\r\n        if (\"overrideMimeType\" in xhr)\r\n            xhr.overrideMimeType(\"text/plain; charset=x-user-defined\");\r\n        xhr.responseType = \"arraybuffer\";\r\n    }\r\n\r\n    xhr.open(\"GET\", filename);\r\n    xhr.send();\r\n};\r\n", "\"use strict\";\r\n\r\n/**\r\n * A minimal path module to resolve Unix, Windows and URL paths alike.\r\n * @memberof util\r\n * @namespace\r\n */\r\nvar path = exports;\r\n\r\nvar isAbsolute =\r\n/**\r\n * Tests if the specified path is absolute.\r\n * @param {string} path Path to test\r\n * @returns {boolean} `true` if path is absolute\r\n */\r\npath.isAbsolute = function isAbsolute(path) {\r\n    return /^(?:\\/|\\w+:)/.test(path);\r\n};\r\n\r\nvar normalize =\r\n/**\r\n * Normalizes the specified path.\r\n * @param {string} path Path to normalize\r\n * @returns {string} Normalized path\r\n */\r\npath.normalize = function normalize(path) {\r\n    path = path.replace(/\\\\/g, \"/\")\r\n               .replace(/\\/{2,}/g, \"/\");\r\n    var parts    = path.split(\"/\"),\r\n        absolute = isAbsolute(path),\r\n        prefix   = \"\";\r\n    if (absolute)\r\n        prefix = parts.shift() + \"/\";\r\n    for (var i = 0; i < parts.length;) {\r\n        if (parts[i] === \"..\") {\r\n            if (i > 0 && parts[i - 1] !== \"..\")\r\n                parts.splice(--i, 2);\r\n            else if (absolute)\r\n                parts.splice(i, 1);\r\n            else\r\n                ++i;\r\n        } else if (parts[i] === \".\")\r\n            parts.splice(i, 1);\r\n        else\r\n            ++i;\r\n    }\r\n    return prefix + parts.join(\"/\");\r\n};\r\n\r\n/**\r\n * Resolves the specified include path against the specified origin path.\r\n * @param {string} originPath Path to the origin file\r\n * @param {string} includePath Include path relative to origin path\r\n * @param {boolean} [alreadyNormalized=false] `true` if both paths are already known to be normalized\r\n * @returns {string} Path to the include file\r\n */\r\npath.resolve = function resolve(originPath, includePath, alreadyNormalized) {\r\n    if (!alreadyNormalized)\r\n        includePath = normalize(includePath);\r\n    if (isAbsolute(includePath))\r\n        return includePath;\r\n    if (!alreadyNormalized)\r\n        originPath = normalize(originPath);\r\n    return (originPath = originPath.replace(/(?:\\/|^)[^/]+$/, \"\")).length ? normalize(originPath + \"/\" + includePath) : includePath;\r\n};\r\n", "\"use strict\";\n\n/**\n * Common type constants.\n * @namespace\n */\nvar types = exports;\n\nvar util = require(\"./util\");\n\nvar s = [\n    \"double\",   // 0\n    \"float\",    // 1\n    \"int32\",    // 2\n    \"uint32\",   // 3\n    \"sint32\",   // 4\n    \"fixed32\",  // 5\n    \"sfixed32\", // 6\n    \"int64\",    // 7\n    \"uint64\",   // 8\n    \"sint64\",   // 9\n    \"fixed64\",  // 10\n    \"sfixed64\", // 11\n    \"bool\",     // 12\n    \"string\",   // 13\n    \"bytes\"     // 14\n];\n\nfunction bake(values, offset) {\n    var i = 0, o = {};\n    offset |= 0;\n    while (i < values.length) o[s[i + offset]] = values[i++];\n    return o;\n}\n\n/**\n * Basic type wire types.\n * @type {Object.<string,number>}\n * @const\n * @property {number} double=1 Fixed64 wire type\n * @property {number} float=5 Fixed32 wire type\n * @property {number} int32=0 Varint wire type\n * @property {number} uint32=0 Varint wire type\n * @property {number} sint32=0 Varint wire type\n * @property {number} fixed32=5 Fixed32 wire type\n * @property {number} sfixed32=5 Fixed32 wire type\n * @property {number} int64=0 Varint wire type\n * @property {number} uint64=0 Varint wire type\n * @property {number} sint64=0 Varint wire type\n * @property {number} fixed64=1 Fixed64 wire type\n * @property {number} sfixed64=1 Fixed64 wire type\n * @property {number} bool=0 Varint wire type\n * @property {number} string=2 Ldelim wire type\n * @property {number} bytes=2 Ldelim wire type\n */\ntypes.basic = bake([\n    /* double   */ 1,\n    /* float    */ 5,\n    /* int32    */ 0,\n    /* uint32   */ 0,\n    /* sint32   */ 0,\n    /* fixed32  */ 5,\n    /* sfixed32 */ 5,\n    /* int64    */ 0,\n    /* uint64   */ 0,\n    /* sint64   */ 0,\n    /* fixed64  */ 1,\n    /* sfixed64 */ 1,\n    /* bool     */ 0,\n    /* string   */ 2,\n    /* bytes    */ 2\n]);\n\n/**\n * Basic type defaults.\n * @type {Object.<string,*>}\n * @const\n * @property {number} double=0 Double default\n * @property {number} float=0 Float default\n * @property {number} int32=0 Int32 default\n * @property {number} uint32=0 Uint32 default\n * @property {number} sint32=0 Sint32 default\n * @property {number} fixed32=0 Fixed32 default\n * @property {number} sfixed32=0 Sfixed32 default\n * @property {number} int64=0 Int64 default\n * @property {number} uint64=0 Uint64 default\n * @property {number} sint64=0 Sint32 default\n * @property {number} fixed64=0 Fixed64 default\n * @property {number} sfixed64=0 Sfixed64 default\n * @property {boolean} bool=false Bool default\n * @property {string} string=\"\" String default\n * @property {Array.<number>} bytes=Array(0) Bytes default\n * @property {null} message=null Message default\n */\ntypes.defaults = bake([\n    /* double   */ 0,\n    /* float    */ 0,\n    /* int32    */ 0,\n    /* uint32   */ 0,\n    /* sint32   */ 0,\n    /* fixed32  */ 0,\n    /* sfixed32 */ 0,\n    /* int64    */ 0,\n    /* uint64   */ 0,\n    /* sint64   */ 0,\n    /* fixed64  */ 0,\n    /* sfixed64 */ 0,\n    /* bool     */ false,\n    /* string   */ \"\",\n    /* bytes    */ util.emptyArray,\n    /* message  */ null\n]);\n\n/**\n * Basic long type wire types.\n * @type {Object.<string,number>}\n * @const\n * @property {number} int64=0 Varint wire type\n * @property {number} uint64=0 Varint wire type\n * @property {number} sint64=0 Varint wire type\n * @property {number} fixed64=1 Fixed64 wire type\n * @property {number} sfixed64=1 Fixed64 wire type\n */\ntypes.long = bake([\n    /* int64    */ 0,\n    /* uint64   */ 0,\n    /* sint64   */ 0,\n    /* fixed64  */ 1,\n    /* sfixed64 */ 1\n], 7);\n\n/**\n * Allowed types for map keys with their associated wire type.\n * @type {Object.<string,number>}\n * @const\n * @property {number} int32=0 Varint wire type\n * @property {number} uint32=0 Varint wire type\n * @property {number} sint32=0 Varint wire type\n * @property {number} fixed32=5 Fixed32 wire type\n * @property {number} sfixed32=5 Fixed32 wire type\n * @property {number} int64=0 Varint wire type\n * @property {number} uint64=0 Varint wire type\n * @property {number} sint64=0 Varint wire type\n * @property {number} fixed64=1 Fixed64 wire type\n * @property {number} sfixed64=1 Fixed64 wire type\n * @property {number} bool=0 Varint wire type\n * @property {number} string=2 Ldelim wire type\n */\ntypes.mapKey = bake([\n    /* int32    */ 0,\n    /* uint32   */ 0,\n    /* sint32   */ 0,\n    /* fixed32  */ 5,\n    /* sfixed32 */ 5,\n    /* int64    */ 0,\n    /* uint64   */ 0,\n    /* sint64   */ 0,\n    /* fixed64  */ 1,\n    /* sfixed64 */ 1,\n    /* bool     */ 0,\n    /* string   */ 2\n], 2);\n\n/**\n * Allowed types for packed repeated fields with their associated wire type.\n * @type {Object.<string,number>}\n * @const\n * @property {number} double=1 Fixed64 wire type\n * @property {number} float=5 Fixed32 wire type\n * @property {number} int32=0 Varint wire type\n * @property {number} uint32=0 Varint wire type\n * @property {number} sint32=0 Varint wire type\n * @property {number} fixed32=5 Fixed32 wire type\n * @property {number} sfixed32=5 Fixed32 wire type\n * @property {number} int64=0 Varint wire type\n * @property {number} uint64=0 Varint wire type\n * @property {number} sint64=0 Varint wire type\n * @property {number} fixed64=1 Fixed64 wire type\n * @property {number} sfixed64=1 Fixed64 wire type\n * @property {number} bool=0 Varint wire type\n */\ntypes.packed = bake([\n    /* double   */ 1,\n    /* float    */ 5,\n    /* int32    */ 0,\n    /* uint32   */ 0,\n    /* sint32   */ 0,\n    /* fixed32  */ 5,\n    /* sfixed32 */ 5,\n    /* int64    */ 0,\n    /* uint64   */ 0,\n    /* sint64   */ 0,\n    /* fixed64  */ 1,\n    /* sfixed64 */ 1,\n    /* bool     */ 0\n]);\n", "\"use strict\";\nmodule.exports = Field;\n\n// extends ReflectionObject\nvar ReflectionObject = require(\"./object\");\n((Field.prototype = Object.create(ReflectionObject.prototype)).constructor = Field).className = \"Field\";\n\nvar Enum  = require(\"./enum\"),\n    types = require(\"./types\"),\n    util  = require(\"./util\");\n\nvar Type; // cyclic\n\nvar ruleRe = /^required|optional|repeated$/;\n\n/**\n * Constructs a new message field instance. Note that {@link MapField|map fields} have their own class.\n * @name Field\n * @classdesc Reflected message field.\n * @extends FieldBase\n * @constructor\n * @param {string} name Unique name within its namespace\n * @param {number} id Unique id within its namespace\n * @param {string} type Value type\n * @param {string|Object.<string,*>} [rule=\"optional\"] Field rule\n * @param {string|Object.<string,*>} [extend] Extended type if different from parent\n * @param {Object.<string,*>} [options] Declared options\n */\n\n/**\n * Constructs a field from a field descriptor.\n * @param {string} name Field name\n * @param {IField} json Field descriptor\n * @returns {Field} Created field\n * @throws {TypeError} If arguments are invalid\n */\nField.fromJSON = function fromJSON(name, json) {\n    return new Field(name, json.id, json.type, json.rule, json.extend, json.options, json.comment);\n};\n\n/**\n * Not an actual constructor. Use {@link Field} instead.\n * @classdesc Base class of all reflected message fields. This is not an actual class but here for the sake of having consistent type definitions.\n * @exports FieldBase\n * @extends ReflectionObject\n * @constructor\n * @param {string} name Unique name within its namespace\n * @param {number} id Unique id within its namespace\n * @param {string} type Value type\n * @param {string|Object.<string,*>} [rule=\"optional\"] Field rule\n * @param {string|Object.<string,*>} [extend] Extended type if different from parent\n * @param {Object.<string,*>} [options] Declared options\n * @param {string} [comment] Comment associated with this field\n */\nfunction Field(name, id, type, rule, extend, options, comment) {\n\n    if (util.isObject(rule)) {\n        comment = extend;\n        options = rule;\n        rule = extend = undefined;\n    } else if (util.isObject(extend)) {\n        comment = options;\n        options = extend;\n        extend = undefined;\n    }\n\n    ReflectionObject.call(this, name, options);\n\n    if (!util.isInteger(id) || id < 0)\n        throw TypeError(\"id must be a non-negative integer\");\n\n    if (!util.isString(type))\n        throw TypeError(\"type must be a string\");\n\n    if (rule !== undefined && !ruleRe.test(rule = rule.toString().toLowerCase()))\n        throw TypeError(\"rule must be a string rule\");\n\n    if (extend !== undefined && !util.isString(extend))\n        throw TypeError(\"extend must be a string\");\n\n    if (rule === \"proto3_optional\") {\n        rule = \"optional\";\n    }\n    /**\n     * Field rule, if any.\n     * @type {string|undefined}\n     */\n    this.rule = rule && rule !== \"optional\" ? rule : undefined; // toJSON\n\n    /**\n     * Field type.\n     * @type {string}\n     */\n    this.type = type; // toJSON\n\n    /**\n     * Unique field id.\n     * @type {number}\n     */\n    this.id = id; // toJSON, marker\n\n    /**\n     * Extended type if different from parent.\n     * @type {string|undefined}\n     */\n    this.extend = extend || undefined; // toJSON\n\n    /**\n     * Whether this field is required.\n     * @type {boolean}\n     */\n    this.required = rule === \"required\";\n\n    /**\n     * Whether this field is optional.\n     * @type {boolean}\n     */\n    this.optional = !this.required;\n\n    /**\n     * Whether this field is repeated.\n     * @type {boolean}\n     */\n    this.repeated = rule === \"repeated\";\n\n    /**\n     * Whether this field is a map or not.\n     * @type {boolean}\n     */\n    this.map = false;\n\n    /**\n     * Message this field belongs to.\n     * @type {Type|null}\n     */\n    this.message = null;\n\n    /**\n     * OneOf this field belongs to, if any,\n     * @type {OneOf|null}\n     */\n    this.partOf = null;\n\n    /**\n     * The field type's default value.\n     * @type {*}\n     */\n    this.typeDefault = null;\n\n    /**\n     * The field's default value on prototypes.\n     * @type {*}\n     */\n    this.defaultValue = null;\n\n    /**\n     * Whether this field's value should be treated as a long.\n     * @type {boolean}\n     */\n    this.long = util.Long ? types.long[type] !== undefined : /* istanbul ignore next */ false;\n\n    /**\n     * Whether this field's value is a buffer.\n     * @type {boolean}\n     */\n    this.bytes = type === \"bytes\";\n\n    /**\n     * Resolved type if not a basic type.\n     * @type {Type|Enum|null}\n     */\n    this.resolvedType = null;\n\n    /**\n     * Sister-field within the extended type if a declaring extension field.\n     * @type {Field|null}\n     */\n    this.extensionField = null;\n\n    /**\n     * Sister-field within the declaring namespace if an extended field.\n     * @type {Field|null}\n     */\n    this.declaringField = null;\n\n    /**\n     * Internally remembers whether this field is packed.\n     * @type {boolean|null}\n     * @private\n     */\n    this._packed = null;\n\n    /**\n     * Comment for this field.\n     * @type {string|null}\n     */\n    this.comment = comment;\n}\n\n/**\n * Determines whether this field is packed. Only relevant when repeated and working with proto2.\n * @name Field#packed\n * @type {boolean}\n * @readonly\n */\nObject.defineProperty(Field.prototype, \"packed\", {\n    get: function() {\n        // defaults to packed=true if not explicity set to false\n        if (this._packed === null)\n            this._packed = this.getOption(\"packed\") !== false;\n        return this._packed;\n    }\n});\n\n/**\n * @override\n */\nField.prototype.setOption = function setOption(name, value, ifNotSet) {\n    if (name === \"packed\") // clear cached before setting\n        this._packed = null;\n    return ReflectionObject.prototype.setOption.call(this, name, value, ifNotSet);\n};\n\n/**\n * Field descriptor.\n * @interface IField\n * @property {string} [rule=\"optional\"] Field rule\n * @property {string} type Field type\n * @property {number} id Field id\n * @property {Object.<string,*>} [options] Field options\n */\n\n/**\n * Extension field descriptor.\n * @interface IExtensionField\n * @extends IField\n * @property {string} extend Extended type\n */\n\n/**\n * Converts this field to a field descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {IField} Field descriptor\n */\nField.prototype.toJSON = function toJSON(toJSONOptions) {\n    var keepComments = toJSONOptions ? Boolean(toJSONOptions.keepComments) : false;\n    return util.toObject([\n        \"rule\"    , this.rule !== \"optional\" && this.rule || undefined,\n        \"type\"    , this.type,\n        \"id\"      , this.id,\n        \"extend\"  , this.extend,\n        \"options\" , this.options,\n        \"comment\" , keepComments ? this.comment : undefined\n    ]);\n};\n\n/**\n * Resolves this field's type references.\n * @returns {Field} `this`\n * @throws {Error} If any reference cannot be resolved\n */\nField.prototype.resolve = function resolve() {\n\n    if (this.resolved)\n        return this;\n\n    if ((this.typeDefault = types.defaults[this.type]) === undefined) { // if not a basic type, resolve it\n        this.resolvedType = (this.declaringField ? this.declaringField.parent : this.parent).lookupTypeOrEnum(this.type);\n        if (this.resolvedType instanceof Type)\n            this.typeDefault = null;\n        else // instanceof Enum\n            this.typeDefault = this.resolvedType.values[Object.keys(this.resolvedType.values)[0]]; // first defined\n    }\n\n    // use explicitly set default value if present\n    if (this.options && this.options[\"default\"] != null) {\n        this.typeDefault = this.options[\"default\"];\n        if (this.resolvedType instanceof Enum && typeof this.typeDefault === \"string\")\n            this.typeDefault = this.resolvedType.values[this.typeDefault];\n    }\n\n    // remove unnecessary options\n    if (this.options) {\n        if (this.options.packed === true || this.options.packed !== undefined && this.resolvedType && !(this.resolvedType instanceof Enum))\n            delete this.options.packed;\n        if (!Object.keys(this.options).length)\n            this.options = undefined;\n    }\n\n    // convert to internal data type if necesssary\n    if (this.long) {\n        this.typeDefault = util.Long.fromNumber(this.typeDefault, this.type.charAt(0) === \"u\");\n\n        /* istanbul ignore else */\n        if (Object.freeze)\n            Object.freeze(this.typeDefault); // long instances are meant to be immutable anyway (i.e. use small int cache that even requires it)\n\n    } else if (this.bytes && typeof this.typeDefault === \"string\") {\n        var buf;\n        if (util.base64.test(this.typeDefault))\n            util.base64.decode(this.typeDefault, buf = util.newBuffer(util.base64.length(this.typeDefault)), 0);\n        else\n            util.utf8.write(this.typeDefault, buf = util.newBuffer(util.utf8.length(this.typeDefault)), 0);\n        this.typeDefault = buf;\n    }\n\n    // take special care of maps and repeated fields\n    if (this.map)\n        this.defaultValue = util.emptyObject;\n    else if (this.repeated)\n        this.defaultValue = util.emptyArray;\n    else\n        this.defaultValue = this.typeDefault;\n\n    // ensure proper value on prototype\n    if (this.parent instanceof Type)\n        this.parent.ctor.prototype[this.name] = this.defaultValue;\n\n    return ReflectionObject.prototype.resolve.call(this);\n};\n\n/**\n * Decorator function as returned by {@link Field.d} and {@link MapField.d} (TypeScript).\n * @typedef FieldDecorator\n * @type {function}\n * @param {Object} prototype Target prototype\n * @param {string} fieldName Field name\n * @returns {undefined}\n */\n\n/**\n * Field decorator (TypeScript).\n * @name Field.d\n * @function\n * @param {number} fieldId Field id\n * @param {\"double\"|\"float\"|\"int32\"|\"uint32\"|\"sint32\"|\"fixed32\"|\"sfixed32\"|\"int64\"|\"uint64\"|\"sint64\"|\"fixed64\"|\"sfixed64\"|\"string\"|\"bool\"|\"bytes\"|Object} fieldType Field type\n * @param {\"optional\"|\"required\"|\"repeated\"} [fieldRule=\"optional\"] Field rule\n * @param {T} [defaultValue] Default value\n * @returns {FieldDecorator} Decorator function\n * @template T extends number | number[] | Long | Long[] | string | string[] | boolean | boolean[] | Uint8Array | Uint8Array[] | Buffer | Buffer[]\n */\nField.d = function decorateField(fieldId, fieldType, fieldRule, defaultValue) {\n\n    // submessage: decorate the submessage and use its name as the type\n    if (typeof fieldType === \"function\")\n        fieldType = util.decorateType(fieldType).name;\n\n    // enum reference: create a reflected copy of the enum and keep reuseing it\n    else if (fieldType && typeof fieldType === \"object\")\n        fieldType = util.decorateEnum(fieldType).name;\n\n    return function fieldDecorator(prototype, fieldName) {\n        util.decorateType(prototype.constructor)\n            .add(new Field(fieldName, fieldId, fieldType, fieldRule, { \"default\": defaultValue }));\n    };\n};\n\n/**\n * Field decorator (TypeScript).\n * @name Field.d\n * @function\n * @param {number} fieldId Field id\n * @param {Constructor<T>|string} fieldType Field type\n * @param {\"optional\"|\"required\"|\"repeated\"} [fieldRule=\"optional\"] Field rule\n * @returns {FieldDecorator} Decorator function\n * @template T extends Message<T>\n * @variation 2\n */\n// like Field.d but without a default value\n\n// Sets up cyclic dependencies (called in index-light)\nField._configure = function configure(Type_) {\n    Type = Type_;\n};\n", "\"use strict\";\nmodule.exports = OneOf;\n\n// extends ReflectionObject\nvar ReflectionObject = require(\"./object\");\n((OneOf.prototype = Object.create(ReflectionObject.prototype)).constructor = OneOf).className = \"OneOf\";\n\nvar Field = require(\"./field\"),\n    util  = require(\"./util\");\n\n/**\n * Constructs a new oneof instance.\n * @classdesc Reflected oneof.\n * @extends ReflectionObject\n * @constructor\n * @param {string} name Oneof name\n * @param {string[]|Object.<string,*>} [fieldNames] Field names\n * @param {Object.<string,*>} [options] Declared options\n * @param {string} [comment] Comment associated with this field\n */\nfunction OneOf(name, fieldNames, options, comment) {\n    if (!Array.isArray(fieldNames)) {\n        options = fieldNames;\n        fieldNames = undefined;\n    }\n    ReflectionObject.call(this, name, options);\n\n    /* istanbul ignore if */\n    if (!(fieldNames === undefined || Array.isArray(fieldNames)))\n        throw TypeError(\"fieldNames must be an Array\");\n\n    /**\n     * Field names that belong to this oneof.\n     * @type {string[]}\n     */\n    this.oneof = fieldNames || []; // toJSON, marker\n\n    /**\n     * Fields that belong to this oneof as an array for iteration.\n     * @type {Field[]}\n     * @readonly\n     */\n    this.fieldsArray = []; // declared readonly for conformance, possibly not yet added to parent\n\n    /**\n     * Comment for this field.\n     * @type {string|null}\n     */\n    this.comment = comment;\n}\n\n/**\n * Oneof descriptor.\n * @interface IOneOf\n * @property {Array.<string>} oneof Oneof field names\n * @property {Object.<string,*>} [options] Oneof options\n */\n\n/**\n * Constructs a oneof from a oneof descriptor.\n * @param {string} name Oneof name\n * @param {IOneOf} json Oneof descriptor\n * @returns {OneOf} Created oneof\n * @throws {TypeError} If arguments are invalid\n */\nOneOf.fromJSON = function fromJSON(name, json) {\n    return new OneOf(name, json.oneof, json.options, json.comment);\n};\n\n/**\n * Converts this oneof to a oneof descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {IOneOf} Oneof descriptor\n */\nOneOf.prototype.toJSON = function toJSON(toJSONOptions) {\n    var keepComments = toJSONOptions ? Boolean(toJSONOptions.keepComments) : false;\n    return util.toObject([\n        \"options\" , this.options,\n        \"oneof\"   , this.oneof,\n        \"comment\" , keepComments ? this.comment : undefined\n    ]);\n};\n\n/**\n * Adds the fields of the specified oneof to the parent if not already done so.\n * @param {OneOf} oneof The oneof\n * @returns {undefined}\n * @inner\n * @ignore\n */\nfunction addFieldsToParent(oneof) {\n    if (oneof.parent)\n        for (var i = 0; i < oneof.fieldsArray.length; ++i)\n            if (!oneof.fieldsArray[i].parent)\n                oneof.parent.add(oneof.fieldsArray[i]);\n}\n\n/**\n * Adds a field to this oneof and removes it from its current parent, if any.\n * @param {Field} field Field to add\n * @returns {OneOf} `this`\n */\nOneOf.prototype.add = function add(field) {\n\n    /* istanbul ignore if */\n    if (!(field instanceof Field))\n        throw TypeError(\"field must be a Field\");\n\n    if (field.parent && field.parent !== this.parent)\n        field.parent.remove(field);\n    this.oneof.push(field.name);\n    this.fieldsArray.push(field);\n    field.partOf = this; // field.parent remains null\n    addFieldsToParent(this);\n    return this;\n};\n\n/**\n * Removes a field from this oneof and puts it back to the oneof's parent.\n * @param {Field} field Field to remove\n * @returns {OneOf} `this`\n */\nOneOf.prototype.remove = function remove(field) {\n\n    /* istanbul ignore if */\n    if (!(field instanceof Field))\n        throw TypeError(\"field must be a Field\");\n\n    var index = this.fieldsArray.indexOf(field);\n\n    /* istanbul ignore if */\n    if (index < 0)\n        throw Error(field + \" is not a member of \" + this);\n\n    this.fieldsArray.splice(index, 1);\n    index = this.oneof.indexOf(field.name);\n\n    /* istanbul ignore else */\n    if (index > -1) // theoretical\n        this.oneof.splice(index, 1);\n\n    field.partOf = null;\n    return this;\n};\n\n/**\n * @override\n */\nOneOf.prototype.onAdd = function onAdd(parent) {\n    ReflectionObject.prototype.onAdd.call(this, parent);\n    var self = this;\n    // Collect present fields\n    for (var i = 0; i < this.oneof.length; ++i) {\n        var field = parent.get(this.oneof[i]);\n        if (field && !field.partOf) {\n            field.partOf = self;\n            self.fieldsArray.push(field);\n        }\n    }\n    // Add not yet present fields\n    addFieldsToParent(this);\n};\n\n/**\n * @override\n */\nOneOf.prototype.onRemove = function onRemove(parent) {\n    for (var i = 0, field; i < this.fieldsArray.length; ++i)\n        if ((field = this.fieldsArray[i]).parent)\n            field.parent.remove(field);\n    ReflectionObject.prototype.onRemove.call(this, parent);\n};\n\n/**\n * Decorator function as returned by {@link OneOf.d} (TypeScript).\n * @typedef OneOfDecorator\n * @type {function}\n * @param {Object} prototype Target prototype\n * @param {string} oneofName OneOf name\n * @returns {undefined}\n */\n\n/**\n * OneOf decorator (TypeScript).\n * @function\n * @param {...string} fieldNames Field names\n * @returns {OneOfDecorator} Decorator function\n * @template T extends string\n */\nOneOf.d = function decorateOneOf() {\n    var fieldNames = new Array(arguments.length),\n        index = 0;\n    while (index < arguments.length)\n        fieldNames[index] = arguments[index++];\n    return function oneOfDecorator(prototype, oneofName) {\n        util.decorateType(prototype.constructor)\n            .add(new OneOf(oneofName, fieldNames));\n        Object.defineProperty(prototype, oneofName, {\n            get: util.oneOfGetter(fieldNames),\n            set: util.oneOfSetter(fieldNames)\n        });\n    };\n};\n", "\"use strict\";\nmodule.exports = Namespace;\n\n// extends ReflectionObject\nvar ReflectionObject = require(\"./object\");\n((Namespace.prototype = Object.create(ReflectionObject.prototype)).constructor = Namespace).className = \"Namespace\";\n\nvar Field    = require(\"./field\"),\n    OneOf    = require(\"./oneof\"),\n    util     = require(\"./util\");\n\nvar Type,    // cyclic\n    Service,\n    Enum;\n\n/**\n * Constructs a new namespace instance.\n * @name Namespace\n * @classdesc Reflected namespace.\n * @extends NamespaceBase\n * @constructor\n * @param {string} name Namespace name\n * @param {Object.<string,*>} [options] Declared options\n */\n\n/**\n * Constructs a namespace from JSON.\n * @memberof Namespace\n * @function\n * @param {string} name Namespace name\n * @param {Object.<string,*>} json JSON object\n * @returns {Namespace} Created namespace\n * @throws {TypeError} If arguments are invalid\n */\nNamespace.fromJSON = function fromJSON(name, json) {\n    return new Namespace(name, json.options).addJSON(json.nested);\n};\n\n/**\n * Converts an array of reflection objects to JSON.\n * @memberof Namespace\n * @param {ReflectionObject[]} array Object array\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {Object.<string,*>|undefined} JSON object or `undefined` when array is empty\n */\nfunction arrayToJSON(array, toJSONOptions) {\n    if (!(array && array.length))\n        return undefined;\n    var obj = {};\n    for (var i = 0; i < array.length; ++i)\n        obj[array[i].name] = array[i].toJSON(toJSONOptions);\n    return obj;\n}\n\nNamespace.arrayToJSON = arrayToJSON;\n\n/**\n * Tests if the specified id is reserved.\n * @param {Array.<number[]|string>|undefined} reserved Array of reserved ranges and names\n * @param {number} id Id to test\n * @returns {boolean} `true` if reserved, otherwise `false`\n */\nNamespace.isReservedId = function isReservedId(reserved, id) {\n    if (reserved)\n        for (var i = 0; i < reserved.length; ++i)\n            if (typeof reserved[i] !== \"string\" && reserved[i][0] <= id && reserved[i][1] > id)\n                return true;\n    return false;\n};\n\n/**\n * Tests if the specified name is reserved.\n * @param {Array.<number[]|string>|undefined} reserved Array of reserved ranges and names\n * @param {string} name Name to test\n * @returns {boolean} `true` if reserved, otherwise `false`\n */\nNamespace.isReservedName = function isReservedName(reserved, name) {\n    if (reserved)\n        for (var i = 0; i < reserved.length; ++i)\n            if (reserved[i] === name)\n                return true;\n    return false;\n};\n\n/**\n * Not an actual constructor. Use {@link Namespace} instead.\n * @classdesc Base class of all reflection objects containing nested objects. This is not an actual class but here for the sake of having consistent type definitions.\n * @exports NamespaceBase\n * @extends ReflectionObject\n * @abstract\n * @constructor\n * @param {string} name Namespace name\n * @param {Object.<string,*>} [options] Declared options\n * @see {@link Namespace}\n */\nfunction Namespace(name, options) {\n    ReflectionObject.call(this, name, options);\n\n    /**\n     * Nested objects by name.\n     * @type {Object.<string,ReflectionObject>|undefined}\n     */\n    this.nested = undefined; // toJSON\n\n    /**\n     * Cached nested objects as an array.\n     * @type {ReflectionObject[]|null}\n     * @private\n     */\n    this._nestedArray = null;\n}\n\nfunction clearCache(namespace) {\n    namespace._nestedArray = null;\n    return namespace;\n}\n\n/**\n * Nested objects of this namespace as an array for iteration.\n * @name NamespaceBase#nestedArray\n * @type {ReflectionObject[]}\n * @readonly\n */\nObject.defineProperty(Namespace.prototype, \"nestedArray\", {\n    get: function() {\n        return this._nestedArray || (this._nestedArray = util.toArray(this.nested));\n    }\n});\n\n/**\n * Namespace descriptor.\n * @interface INamespace\n * @property {Object.<string,*>} [options] Namespace options\n * @property {Object.<string,AnyNestedObject>} [nested] Nested object descriptors\n */\n\n/**\n * Any extension field descriptor.\n * @typedef AnyExtensionField\n * @type {IExtensionField|IExtensionMapField}\n */\n\n/**\n * Any nested object descriptor.\n * @typedef AnyNestedObject\n * @type {IEnum|IType|IService|AnyExtensionField|INamespace}\n */\n// ^ BEWARE: VSCode hangs forever when using more than 5 types (that's why AnyExtensionField exists in the first place)\n\n/**\n * Converts this namespace to a namespace descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {INamespace} Namespace descriptor\n */\nNamespace.prototype.toJSON = function toJSON(toJSONOptions) {\n    return util.toObject([\n        \"options\" , this.options,\n        \"nested\"  , arrayToJSON(this.nestedArray, toJSONOptions)\n    ]);\n};\n\n/**\n * Adds nested objects to this namespace from nested object descriptors.\n * @param {Object.<string,AnyNestedObject>} nestedJson Any nested object descriptors\n * @returns {Namespace} `this`\n */\nNamespace.prototype.addJSON = function addJSON(nestedJson) {\n    var ns = this;\n    /* istanbul ignore else */\n    if (nestedJson) {\n        for (var names = Object.keys(nestedJson), i = 0, nested; i < names.length; ++i) {\n            nested = nestedJson[names[i]];\n            ns.add( // most to least likely\n                ( nested.fields !== undefined\n                ? Type.fromJSON\n                : nested.values !== undefined\n                ? Enum.fromJSON\n                : nested.methods !== undefined\n                ? Service.fromJSON\n                : nested.id !== undefined\n                ? Field.fromJSON\n                : Namespace.fromJSON )(names[i], nested)\n            );\n        }\n    }\n    return this;\n};\n\n/**\n * Gets the nested object of the specified name.\n * @param {string} name Nested object name\n * @returns {ReflectionObject|null} The reflection object or `null` if it doesn't exist\n */\nNamespace.prototype.get = function get(name) {\n    return this.nested && this.nested[name]\n        || null;\n};\n\n/**\n * Gets the values of the nested {@link Enum|enum} of the specified name.\n * This methods differs from {@link Namespace#get|get} in that it returns an enum's values directly and throws instead of returning `null`.\n * @param {string} name Nested enum name\n * @returns {Object.<string,number>} Enum values\n * @throws {Error} If there is no such enum\n */\nNamespace.prototype.getEnum = function getEnum(name) {\n    if (this.nested && this.nested[name] instanceof Enum)\n        return this.nested[name].values;\n    throw Error(\"no such enum: \" + name);\n};\n\n/**\n * Adds a nested object to this namespace.\n * @param {ReflectionObject} object Nested object to add\n * @returns {Namespace} `this`\n * @throws {TypeError} If arguments are invalid\n * @throws {Error} If there is already a nested object with this name\n */\nNamespace.prototype.add = function add(object) {\n\n    if (!(object instanceof Field && object.extend !== undefined || object instanceof Type || object instanceof Enum || object instanceof Service || object instanceof Namespace || object instanceof OneOf))\n        throw TypeError(\"object must be a valid nested object\");\n\n    if (!this.nested)\n        this.nested = {};\n    else {\n        var prev = this.get(object.name);\n        if (prev) {\n            if (prev instanceof Namespace && object instanceof Namespace && !(prev instanceof Type || prev instanceof Service)) {\n                // replace plain namespace but keep existing nested elements and options\n                var nested = prev.nestedArray;\n                for (var i = 0; i < nested.length; ++i)\n                    object.add(nested[i]);\n                this.remove(prev);\n                if (!this.nested)\n                    this.nested = {};\n                object.setOptions(prev.options, true);\n\n            } else\n                throw Error(\"duplicate name '\" + object.name + \"' in \" + this);\n        }\n    }\n    this.nested[object.name] = object;\n    object.onAdd(this);\n    return clearCache(this);\n};\n\n/**\n * Removes a nested object from this namespace.\n * @param {ReflectionObject} object Nested object to remove\n * @returns {Namespace} `this`\n * @throws {TypeError} If arguments are invalid\n * @throws {Error} If `object` is not a member of this namespace\n */\nNamespace.prototype.remove = function remove(object) {\n\n    if (!(object instanceof ReflectionObject))\n        throw TypeError(\"object must be a ReflectionObject\");\n    if (object.parent !== this)\n        throw Error(object + \" is not a member of \" + this);\n\n    delete this.nested[object.name];\n    if (!Object.keys(this.nested).length)\n        this.nested = undefined;\n\n    object.onRemove(this);\n    return clearCache(this);\n};\n\n/**\n * Defines additial namespaces within this one if not yet existing.\n * @param {string|string[]} path Path to create\n * @param {*} [json] Nested types to create from JSON\n * @returns {Namespace} Pointer to the last namespace created or `this` if path is empty\n */\nNamespace.prototype.define = function define(path, json) {\n\n    if (util.isString(path))\n        path = path.split(\".\");\n    else if (!Array.isArray(path))\n        throw TypeError(\"illegal path\");\n    if (path && path.length && path[0] === \"\")\n        throw Error(\"path must be relative\");\n\n    var ptr = this;\n    while (path.length > 0) {\n        var part = path.shift();\n        if (ptr.nested && ptr.nested[part]) {\n            ptr = ptr.nested[part];\n            if (!(ptr instanceof Namespace))\n                throw Error(\"path conflicts with non-namespace objects\");\n        } else\n            ptr.add(ptr = new Namespace(part));\n    }\n    if (json)\n        ptr.addJSON(json);\n    return ptr;\n};\n\n/**\n * Resolves this namespace's and all its nested objects' type references. Useful to validate a reflection tree, but comes at a cost.\n * @returns {Namespace} `this`\n */\nNamespace.prototype.resolveAll = function resolveAll() {\n    var nested = this.nestedArray, i = 0;\n    while (i < nested.length)\n        if (nested[i] instanceof Namespace)\n            nested[i++].resolveAll();\n        else\n            nested[i++].resolve();\n    return this.resolve();\n};\n\n/**\n * Recursively looks up the reflection object matching the specified path in the scope of this namespace.\n * @param {string|string[]} path Path to look up\n * @param {*|Array.<*>} filterTypes Filter types, any combination of the constructors of `protobuf.Type`, `protobuf.Enum`, `protobuf.Service` etc.\n * @param {boolean} [parentAlreadyChecked=false] If known, whether the parent has already been checked\n * @returns {ReflectionObject|null} Looked up object or `null` if none could be found\n */\nNamespace.prototype.lookup = function lookup(path, filterTypes, parentAlreadyChecked) {\n\n    /* istanbul ignore next */\n    if (typeof filterTypes === \"boolean\") {\n        parentAlreadyChecked = filterTypes;\n        filterTypes = undefined;\n    } else if (filterTypes && !Array.isArray(filterTypes))\n        filterTypes = [ filterTypes ];\n\n    if (util.isString(path) && path.length) {\n        if (path === \".\")\n            return this.root;\n        path = path.split(\".\");\n    } else if (!path.length)\n        return this;\n\n    // Start at root if path is absolute\n    if (path[0] === \"\")\n        return this.root.lookup(path.slice(1), filterTypes);\n\n    // Test if the first part matches any nested object, and if so, traverse if path contains more\n    var found = this.get(path[0]);\n    if (found) {\n        if (path.length === 1) {\n            if (!filterTypes || filterTypes.indexOf(found.constructor) > -1)\n                return found;\n        } else if (found instanceof Namespace && (found = found.lookup(path.slice(1), filterTypes, true)))\n            return found;\n\n    // Otherwise try each nested namespace\n    } else\n        for (var i = 0; i < this.nestedArray.length; ++i)\n            if (this._nestedArray[i] instanceof Namespace && (found = this._nestedArray[i].lookup(path, filterTypes, true)))\n                return found;\n\n    // If there hasn't been a match, try again at the parent\n    if (this.parent === null || parentAlreadyChecked)\n        return null;\n    return this.parent.lookup(path, filterTypes);\n};\n\n/**\n * Looks up the reflection object at the specified path, relative to this namespace.\n * @name NamespaceBase#lookup\n * @function\n * @param {string|string[]} path Path to look up\n * @param {boolean} [parentAlreadyChecked=false] Whether the parent has already been checked\n * @returns {ReflectionObject|null} Looked up object or `null` if none could be found\n * @variation 2\n */\n// lookup(path: string, [parentAlreadyChecked: boolean])\n\n/**\n * Looks up the {@link Type|type} at the specified path, relative to this namespace.\n * Besides its signature, this methods differs from {@link Namespace#lookup|lookup} in that it throws instead of returning `null`.\n * @param {string|string[]} path Path to look up\n * @returns {Type} Looked up type\n * @throws {Error} If `path` does not point to a type\n */\nNamespace.prototype.lookupType = function lookupType(path) {\n    var found = this.lookup(path, [ Type ]);\n    if (!found)\n        throw Error(\"no such type: \" + path);\n    return found;\n};\n\n/**\n * Looks up the values of the {@link Enum|enum} at the specified path, relative to this namespace.\n * Besides its signature, this methods differs from {@link Namespace#lookup|lookup} in that it throws instead of returning `null`.\n * @param {string|string[]} path Path to look up\n * @returns {Enum} Looked up enum\n * @throws {Error} If `path` does not point to an enum\n */\nNamespace.prototype.lookupEnum = function lookupEnum(path) {\n    var found = this.lookup(path, [ Enum ]);\n    if (!found)\n        throw Error(\"no such Enum '\" + path + \"' in \" + this);\n    return found;\n};\n\n/**\n * Looks up the {@link Type|type} or {@link Enum|enum} at the specified path, relative to this namespace.\n * Besides its signature, this methods differs from {@link Namespace#lookup|lookup} in that it throws instead of returning `null`.\n * @param {string|string[]} path Path to look up\n * @returns {Type} Looked up type or enum\n * @throws {Error} If `path` does not point to a type or enum\n */\nNamespace.prototype.lookupTypeOrEnum = function lookupTypeOrEnum(path) {\n    var found = this.lookup(path, [ Type, Enum ]);\n    if (!found)\n        throw Error(\"no such Type or Enum '\" + path + \"' in \" + this);\n    return found;\n};\n\n/**\n * Looks up the {@link Service|service} at the specified path, relative to this namespace.\n * Besides its signature, this methods differs from {@link Namespace#lookup|lookup} in that it throws instead of returning `null`.\n * @param {string|string[]} path Path to look up\n * @returns {Service} Looked up service\n * @throws {Error} If `path` does not point to a service\n */\nNamespace.prototype.lookupService = function lookupService(path) {\n    var found = this.lookup(path, [ Service ]);\n    if (!found)\n        throw Error(\"no such Service '\" + path + \"' in \" + this);\n    return found;\n};\n\n// Sets up cyclic dependencies (called in index-light)\nNamespace._configure = function(Type_, Service_, Enum_) {\n    Type    = Type_;\n    Service = Service_;\n    Enum    = Enum_;\n};\n", "\"use strict\";\nmodule.exports = MapField;\n\n// extends Field\nvar Field = require(\"./field\");\n((MapField.prototype = Object.create(Field.prototype)).constructor = MapField).className = \"MapField\";\n\nvar types   = require(\"./types\"),\n    util    = require(\"./util\");\n\n/**\n * Constructs a new map field instance.\n * @classdesc Reflected map field.\n * @extends FieldBase\n * @constructor\n * @param {string} name Unique name within its namespace\n * @param {number} id Unique id within its namespace\n * @param {string} keyType Key type\n * @param {string} type Value type\n * @param {Object.<string,*>} [options] Declared options\n * @param {string} [comment] Comment associated with this field\n */\nfunction MapField(name, id, keyType, type, options, comment) {\n    Field.call(this, name, id, type, undefined, undefined, options, comment);\n\n    /* istanbul ignore if */\n    if (!util.isString(keyType))\n        throw TypeError(\"keyType must be a string\");\n\n    /**\n     * Key type.\n     * @type {string}\n     */\n    this.keyType = keyType; // toJSON, marker\n\n    /**\n     * Resolved key type if not a basic type.\n     * @type {ReflectionObject|null}\n     */\n    this.resolvedKeyType = null;\n\n    // Overrides Field#map\n    this.map = true;\n}\n\n/**\n * Map field descriptor.\n * @interface IMapField\n * @extends {IField}\n * @property {string} keyType Key type\n */\n\n/**\n * Extension map field descriptor.\n * @interface IExtensionMapField\n * @extends IMapField\n * @property {string} extend Extended type\n */\n\n/**\n * Constructs a map field from a map field descriptor.\n * @param {string} name Field name\n * @param {IMapField} json Map field descriptor\n * @returns {MapField} Created map field\n * @throws {TypeError} If arguments are invalid\n */\nMapField.fromJSON = function fromJSON(name, json) {\n    return new MapField(name, json.id, json.keyType, json.type, json.options, json.comment);\n};\n\n/**\n * Converts this map field to a map field descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {IMapField} Map field descriptor\n */\nMapField.prototype.toJSON = function toJSON(toJSONOptions) {\n    var keepComments = toJSONOptions ? Boolean(toJSONOptions.keepComments) : false;\n    return util.toObject([\n        \"keyType\" , this.keyType,\n        \"type\"    , this.type,\n        \"id\"      , this.id,\n        \"extend\"  , this.extend,\n        \"options\" , this.options,\n        \"comment\" , keepComments ? this.comment : undefined\n    ]);\n};\n\n/**\n * @override\n */\nMapField.prototype.resolve = function resolve() {\n    if (this.resolved)\n        return this;\n\n    // Besides a value type, map fields have a key type that may be \"any scalar type except for floating point types and bytes\"\n    if (types.mapKey[this.keyType] === undefined)\n        throw Error(\"invalid key type: \" + this.keyType);\n\n    return Field.prototype.resolve.call(this);\n};\n\n/**\n * Map field decorator (TypeScript).\n * @name MapField.d\n * @function\n * @param {number} fieldId Field id\n * @param {\"int32\"|\"uint32\"|\"sint32\"|\"fixed32\"|\"sfixed32\"|\"int64\"|\"uint64\"|\"sint64\"|\"fixed64\"|\"sfixed64\"|\"bool\"|\"string\"} fieldKeyType Field key type\n * @param {\"double\"|\"float\"|\"int32\"|\"uint32\"|\"sint32\"|\"fixed32\"|\"sfixed32\"|\"int64\"|\"uint64\"|\"sint64\"|\"fixed64\"|\"sfixed64\"|\"bool\"|\"string\"|\"bytes\"|Object|Constructor<{}>} fieldValueType Field value type\n * @returns {FieldDecorator} Decorator function\n * @template T extends { [key: string]: number | Long | string | boolean | Uint8Array | Buffer | number[] | Message<{}> }\n */\nMapField.d = function decorateMapField(fieldId, fieldKeyType, fieldValueType) {\n\n    // submessage value: decorate the submessage and use its name as the type\n    if (typeof fieldValueType === \"function\")\n        fieldValueType = util.decorateType(fieldValueType).name;\n\n    // enum reference value: create a reflected copy of the enum and keep reuseing it\n    else if (fieldValueType && typeof fieldValueType === \"object\")\n        fieldValueType = util.decorateEnum(fieldValueType).name;\n\n    return function mapFieldDecorator(prototype, fieldName) {\n        util.decorateType(prototype.constructor)\n            .add(new MapField(fieldName, fieldId, fieldKeyType, fieldValueType));\n    };\n};\n", "\"use strict\";\nmodule.exports = Method;\n\n// extends ReflectionObject\nvar ReflectionObject = require(\"./object\");\n((Method.prototype = Object.create(ReflectionObject.prototype)).constructor = Method).className = \"Method\";\n\nvar util = require(\"./util\");\n\n/**\n * Constructs a new service method instance.\n * @classdesc Reflected service method.\n * @extends ReflectionObject\n * @constructor\n * @param {string} name Method name\n * @param {string|undefined} type Method type, usually `\"rpc\"`\n * @param {string} requestType Request message type\n * @param {string} responseType Response message type\n * @param {boolean|Object.<string,*>} [requestStream] Whether the request is streamed\n * @param {boolean|Object.<string,*>} [responseStream] Whether the response is streamed\n * @param {Object.<string,*>} [options] Declared options\n * @param {string} [comment] The comment for this method\n * @param {Object.<string,*>} [parsedOptions] Declared options, properly parsed into an object\n */\nfunction Method(name, type, requestType, responseType, requestStream, responseStream, options, comment, parsedOptions) {\n\n    /* istanbul ignore next */\n    if (util.isObject(requestStream)) {\n        options = requestStream;\n        requestStream = responseStream = undefined;\n    } else if (util.isObject(responseStream)) {\n        options = responseStream;\n        responseStream = undefined;\n    }\n\n    /* istanbul ignore if */\n    if (!(type === undefined || util.isString(type)))\n        throw TypeError(\"type must be a string\");\n\n    /* istanbul ignore if */\n    if (!util.isString(requestType))\n        throw TypeError(\"requestType must be a string\");\n\n    /* istanbul ignore if */\n    if (!util.isString(responseType))\n        throw TypeError(\"responseType must be a string\");\n\n    ReflectionObject.call(this, name, options);\n\n    /**\n     * Method type.\n     * @type {string}\n     */\n    this.type = type || \"rpc\"; // toJSON\n\n    /**\n     * Request type.\n     * @type {string}\n     */\n    this.requestType = requestType; // toJSON, marker\n\n    /**\n     * Whether requests are streamed or not.\n     * @type {boolean|undefined}\n     */\n    this.requestStream = requestStream ? true : undefined; // toJSON\n\n    /**\n     * Response type.\n     * @type {string}\n     */\n    this.responseType = responseType; // toJSON\n\n    /**\n     * Whether responses are streamed or not.\n     * @type {boolean|undefined}\n     */\n    this.responseStream = responseStream ? true : undefined; // toJSON\n\n    /**\n     * Resolved request type.\n     * @type {Type|null}\n     */\n    this.resolvedRequestType = null;\n\n    /**\n     * Resolved response type.\n     * @type {Type|null}\n     */\n    this.resolvedResponseType = null;\n\n    /**\n     * Comment for this method\n     * @type {string|null}\n     */\n    this.comment = comment;\n\n    /**\n     * Options properly parsed into an object\n     */\n    this.parsedOptions = parsedOptions;\n}\n\n/**\n * Method descriptor.\n * @interface IMethod\n * @property {string} [type=\"rpc\"] Method type\n * @property {string} requestType Request type\n * @property {string} responseType Response type\n * @property {boolean} [requestStream=false] Whether requests are streamed\n * @property {boolean} [responseStream=false] Whether responses are streamed\n * @property {Object.<string,*>} [options] Method options\n * @property {string} comment Method comments\n * @property {Object.<string,*>} [parsedOptions] Method options properly parsed into an object\n */\n\n/**\n * Constructs a method from a method descriptor.\n * @param {string} name Method name\n * @param {IMethod} json Method descriptor\n * @returns {Method} Created method\n * @throws {TypeError} If arguments are invalid\n */\nMethod.fromJSON = function fromJSON(name, json) {\n    return new Method(name, json.type, json.requestType, json.responseType, json.requestStream, json.responseStream, json.options, json.comment, json.parsedOptions);\n};\n\n/**\n * Converts this method to a method descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {IMethod} Method descriptor\n */\nMethod.prototype.toJSON = function toJSON(toJSONOptions) {\n    var keepComments = toJSONOptions ? Boolean(toJSONOptions.keepComments) : false;\n    return util.toObject([\n        \"type\"           , this.type !== \"rpc\" && /* istanbul ignore next */ this.type || undefined,\n        \"requestType\"    , this.requestType,\n        \"requestStream\"  , this.requestStream,\n        \"responseType\"   , this.responseType,\n        \"responseStream\" , this.responseStream,\n        \"options\"        , this.options,\n        \"comment\"        , keepComments ? this.comment : undefined,\n        \"parsedOptions\"  , this.parsedOptions,\n    ]);\n};\n\n/**\n * @override\n */\nMethod.prototype.resolve = function resolve() {\n\n    /* istanbul ignore if */\n    if (this.resolved)\n        return this;\n\n    this.resolvedRequestType = this.parent.lookupType(this.requestType);\n    this.resolvedResponseType = this.parent.lookupType(this.responseType);\n\n    return ReflectionObject.prototype.resolve.call(this);\n};\n", "\"use strict\";\nmodule.exports = Service;\n\n// extends Namespace\nvar Namespace = require(\"./namespace\");\n((Service.prototype = Object.create(Namespace.prototype)).constructor = Service).className = \"Service\";\n\nvar Method = require(\"./method\"),\n    util   = require(\"./util\"),\n    rpc    = require(\"./rpc\");\n\n/**\n * Constructs a new service instance.\n * @classdesc Reflected service.\n * @extends NamespaceBase\n * @constructor\n * @param {string} name Service name\n * @param {Object.<string,*>} [options] Service options\n * @throws {TypeError} If arguments are invalid\n */\nfunction Service(name, options) {\n    Namespace.call(this, name, options);\n\n    /**\n     * Service methods.\n     * @type {Object.<string,Method>}\n     */\n    this.methods = {}; // toJSON, marker\n\n    /**\n     * Cached methods as an array.\n     * @type {Method[]|null}\n     * @private\n     */\n    this._methodsArray = null;\n}\n\n/**\n * Service descriptor.\n * @interface IService\n * @extends INamespace\n * @property {Object.<string,IMethod>} methods Method descriptors\n */\n\n/**\n * Constructs a service from a service descriptor.\n * @param {string} name Service name\n * @param {IService} json Service descriptor\n * @returns {Service} Created service\n * @throws {TypeError} If arguments are invalid\n */\nService.fromJSON = function fromJSON(name, json) {\n    var service = new Service(name, json.options);\n    /* istanbul ignore else */\n    if (json.methods)\n        for (var names = Object.keys(json.methods), i = 0; i < names.length; ++i)\n            service.add(Method.fromJSON(names[i], json.methods[names[i]]));\n    if (json.nested)\n        service.addJSON(json.nested);\n    service.comment = json.comment;\n    return service;\n};\n\n/**\n * Converts this service to a service descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {IService} Service descriptor\n */\nService.prototype.toJSON = function toJSON(toJSONOptions) {\n    var inherited = Namespace.prototype.toJSON.call(this, toJSONOptions);\n    var keepComments = toJSONOptions ? Boolean(toJSONOptions.keepComments) : false;\n    return util.toObject([\n        \"options\" , inherited && inherited.options || undefined,\n        \"methods\" , Namespace.arrayToJSON(this.methodsArray, toJSONOptions) || /* istanbul ignore next */ {},\n        \"nested\"  , inherited && inherited.nested || undefined,\n        \"comment\" , keepComments ? this.comment : undefined\n    ]);\n};\n\n/**\n * Methods of this service as an array for iteration.\n * @name Service#methodsArray\n * @type {Method[]}\n * @readonly\n */\nObject.defineProperty(Service.prototype, \"methodsArray\", {\n    get: function() {\n        return this._methodsArray || (this._methodsArray = util.toArray(this.methods));\n    }\n});\n\nfunction clearCache(service) {\n    service._methodsArray = null;\n    return service;\n}\n\n/**\n * @override\n */\nService.prototype.get = function get(name) {\n    return this.methods[name]\n        || Namespace.prototype.get.call(this, name);\n};\n\n/**\n * @override\n */\nService.prototype.resolveAll = function resolveAll() {\n    var methods = this.methodsArray;\n    for (var i = 0; i < methods.length; ++i)\n        methods[i].resolve();\n    return Namespace.prototype.resolve.call(this);\n};\n\n/**\n * @override\n */\nService.prototype.add = function add(object) {\n\n    /* istanbul ignore if */\n    if (this.get(object.name))\n        throw Error(\"duplicate name '\" + object.name + \"' in \" + this);\n\n    if (object instanceof Method) {\n        this.methods[object.name] = object;\n        object.parent = this;\n        return clearCache(this);\n    }\n    return Namespace.prototype.add.call(this, object);\n};\n\n/**\n * @override\n */\nService.prototype.remove = function remove(object) {\n    if (object instanceof Method) {\n\n        /* istanbul ignore if */\n        if (this.methods[object.name] !== object)\n            throw Error(object + \" is not a member of \" + this);\n\n        delete this.methods[object.name];\n        object.parent = null;\n        return clearCache(this);\n    }\n    return Namespace.prototype.remove.call(this, object);\n};\n\n/**\n * Creates a runtime service using the specified rpc implementation.\n * @param {RPCImpl} rpcImpl RPC implementation\n * @param {boolean} [requestDelimited=false] Whether requests are length-delimited\n * @param {boolean} [responseDelimited=false] Whether responses are length-delimited\n * @returns {rpc.Service} RPC service. Useful where requests and/or responses are streamed.\n */\nService.prototype.create = function create(rpcImpl, requestDelimited, responseDelimited) {\n    var rpcService = new rpc.Service(rpcImpl, requestDelimited, responseDelimited);\n    for (var i = 0, method; i < /* initializes */ this.methodsArray.length; ++i) {\n        var methodName = util.lcFirst((method = this._methodsArray[i]).resolve().name).replace(/[^$\\w_]/g, \"\");\n        rpcService[methodName] = util.codegen([\"r\",\"c\"], util.isReserved(methodName) ? methodName + \"_\" : methodName)(\"return this.rpcCall(m,q,s,r,c)\")({\n            m: method,\n            q: method.resolvedRequestType.ctor,\n            s: method.resolvedResponseType.ctor\n        });\n    }\n    return rpcService;\n};\n", "\"use strict\";\nmodule.exports = Message;\n\nvar util = require(\"./util/minimal\");\n\n/**\n * Constructs a new message instance.\n * @classdesc Abstract runtime message.\n * @constructor\n * @param {Properties<T>} [properties] Properties to set\n * @template T extends object = object\n */\nfunction Message(properties) {\n    // not used internally\n    if (properties)\n        for (var keys = Object.keys(properties), i = 0; i < keys.length; ++i)\n            this[keys[i]] = properties[keys[i]];\n}\n\n/**\n * Reference to the reflected type.\n * @name Message.$type\n * @type {Type}\n * @readonly\n */\n\n/**\n * Reference to the reflected type.\n * @name Message#$type\n * @type {Type}\n * @readonly\n */\n\n/*eslint-disable valid-jsdoc*/\n\n/**\n * Creates a new message of this type using the specified properties.\n * @param {Object.<string,*>} [properties] Properties to set\n * @returns {Message<T>} Message instance\n * @template T extends Message<T>\n * @this Constructor<T>\n */\nMessage.create = function create(properties) {\n    return this.$type.create(properties);\n};\n\n/**\n * Encodes a message of this type.\n * @param {T|Object.<string,*>} message Message to encode\n * @param {Writer} [writer] Writer to use\n * @returns {Writer} Writer\n * @template T extends Message<T>\n * @this Constructor<T>\n */\nMessage.encode = function encode(message, writer) {\n    return this.$type.encode(message, writer);\n};\n\n/**\n * Encodes a message of this type preceeded by its length as a varint.\n * @param {T|Object.<string,*>} message Message to encode\n * @param {Writer} [writer] Writer to use\n * @returns {Writer} Writer\n * @template T extends Message<T>\n * @this Constructor<T>\n */\nMessage.encodeDelimited = function encodeDelimited(message, writer) {\n    return this.$type.encodeDelimited(message, writer);\n};\n\n/**\n * Decodes a message of this type.\n * @name Message.decode\n * @function\n * @param {Reader|Uint8Array} reader Reader or buffer to decode\n * @returns {T} Decoded message\n * @template T extends Message<T>\n * @this Constructor<T>\n */\nMessage.decode = function decode(reader) {\n    return this.$type.decode(reader);\n};\n\n/**\n * Decodes a message of this type preceeded by its length as a varint.\n * @name Message.decodeDelimited\n * @function\n * @param {Reader|Uint8Array} reader Reader or buffer to decode\n * @returns {T} Decoded message\n * @template T extends Message<T>\n * @this Constructor<T>\n */\nMessage.decodeDelimited = function decodeDelimited(reader) {\n    return this.$type.decodeDelimited(reader);\n};\n\n/**\n * Verifies a message of this type.\n * @name Message.verify\n * @function\n * @param {Object.<string,*>} message Plain object to verify\n * @returns {string|null} `null` if valid, otherwise the reason why it is not\n */\nMessage.verify = function verify(message) {\n    return this.$type.verify(message);\n};\n\n/**\n * Creates a new message of this type from a plain object. Also converts values to their respective internal types.\n * @param {Object.<string,*>} object Plain object\n * @returns {T} Message instance\n * @template T extends Message<T>\n * @this Constructor<T>\n */\nMessage.fromObject = function fromObject(object) {\n    return this.$type.fromObject(object);\n};\n\n/**\n * Creates a plain object from a message of this type. Also converts values to other types if specified.\n * @param {T} message Message instance\n * @param {IConversionOptions} [options] Conversion options\n * @returns {Object.<string,*>} Plain object\n * @template T extends Message<T>\n * @this Constructor<T>\n */\nMessage.toObject = function toObject(message, options) {\n    return this.$type.toObject(message, options);\n};\n\n/**\n * Converts this message to JSON.\n * @returns {Object.<string,*>} JSON object\n */\nMessage.prototype.toJSON = function toJSON() {\n    return this.$type.toObject(this, util.toJSONOptions);\n};\n\n/*eslint-enable valid-jsdoc*/", "\"use strict\";\nmodule.exports = decoder;\n\nvar Enum    = require(\"./enum\"),\n    types   = require(\"./types\"),\n    util    = require(\"./util\");\n\nfunction missing(field) {\n    return \"missing required '\" + field.name + \"'\";\n}\n\n/**\n * Generates a decoder specific to the specified message type.\n * @param {Type} mtype Message type\n * @returns {Codegen} Codegen instance\n */\nfunction decoder(mtype) {\n    /* eslint-disable no-unexpected-multiline */\n    var gen = util.codegen([\"r\", \"l\"], mtype.name + \"$decode\")\n    (\"if(!(r instanceof Reader))\")\n        (\"r=Reader.create(r)\")\n    (\"var c=l===undefined?r.len:r.pos+l,m=new this.ctor\" + (mtype.fieldsArray.filter(function(field) { return field.map; }).length ? \",k,value\" : \"\"))\n    (\"while(r.pos<c){\")\n        (\"var t=r.uint32()\");\n    if (mtype.group) gen\n        (\"if((t&7)===4)\")\n            (\"break\");\n    gen\n        (\"switch(t>>>3){\");\n\n    var i = 0;\n    for (; i < /* initializes */ mtype.fieldsArray.length; ++i) {\n        var field = mtype._fieldsArray[i].resolve(),\n            type  = field.resolvedType instanceof Enum ? \"int32\" : field.type,\n            ref   = \"m\" + util.safeProp(field.name); gen\n            (\"case %i:\", field.id);\n\n        // Map fields\n        if (field.map) { gen\n                (\"if(%s===util.emptyObject)\", ref)\n                    (\"%s={}\", ref)\n                (\"var c2 = r.uint32()+r.pos\");\n\n            if (types.defaults[field.keyType] !== undefined) gen\n                (\"k=%j\", types.defaults[field.keyType]);\n            else gen\n                (\"k=null\");\n\n            if (types.defaults[type] !== undefined) gen\n                (\"value=%j\", types.defaults[type]);\n            else gen\n                (\"value=null\");\n\n            gen\n                (\"while(r.pos<c2){\")\n                    (\"var tag2=r.uint32()\")\n                    (\"switch(tag2>>>3){\")\n                        (\"case 1: k=r.%s(); break\", field.keyType)\n                        (\"case 2:\");\n\n            if (types.basic[type] === undefined) gen\n                            (\"value=types[%i].decode(r,r.uint32())\", i); // can't be groups\n            else gen\n                            (\"value=r.%s()\", type);\n\n            gen\n                            (\"break\")\n                        (\"default:\")\n                            (\"r.skipType(tag2&7)\")\n                            (\"break\")\n                    (\"}\")\n                (\"}\");\n\n            if (types.long[field.keyType] !== undefined) gen\n                (\"%s[typeof k===\\\"object\\\"?util.longToHash(k):k]=value\", ref);\n            else gen\n                (\"%s[k]=value\", ref);\n\n        // Repeated fields\n        } else if (field.repeated) { gen\n\n                (\"if(!(%s&&%s.length))\", ref, ref)\n                    (\"%s=[]\", ref);\n\n            // Packable (always check for forward and backward compatiblity)\n            if (types.packed[type] !== undefined) gen\n                (\"if((t&7)===2){\")\n                    (\"var c2=r.uint32()+r.pos\")\n                    (\"while(r.pos<c2)\")\n                        (\"%s.push(r.%s())\", ref, type)\n                (\"}else\");\n\n            // Non-packed\n            if (types.basic[type] === undefined) gen(field.resolvedType.group\n                    ? \"%s.push(types[%i].decode(r))\"\n                    : \"%s.push(types[%i].decode(r,r.uint32()))\", ref, i);\n            else gen\n                    (\"%s.push(r.%s())\", ref, type);\n\n        // Non-repeated\n        } else if (types.basic[type] === undefined) gen(field.resolvedType.group\n                ? \"%s=types[%i].decode(r)\"\n                : \"%s=types[%i].decode(r,r.uint32())\", ref, i);\n        else gen\n                (\"%s=r.%s()\", ref, type);\n        gen\n                (\"break\");\n    // Unknown fields\n    } gen\n            (\"default:\")\n                (\"r.skipType(t&7)\")\n                (\"break\")\n\n        (\"}\")\n    (\"}\");\n\n    // Field presence\n    for (i = 0; i < mtype._fieldsArray.length; ++i) {\n        var rfield = mtype._fieldsArray[i];\n        if (rfield.required) gen\n    (\"if(!m.hasOwnProperty(%j))\", rfield.name)\n        (\"throw util.ProtocolError(%j,{instance:m})\", missing(rfield));\n    }\n\n    return gen\n    (\"return m\");\n    /* eslint-enable no-unexpected-multiline */\n}\n", "\"use strict\";\nmodule.exports = verifier;\n\nvar Enum      = require(\"./enum\"),\n    util      = require(\"./util\");\n\nfunction invalid(field, expected) {\n    return field.name + \": \" + expected + (field.repeated && expected !== \"array\" ? \"[]\" : field.map && expected !== \"object\" ? \"{k:\"+field.keyType+\"}\" : \"\") + \" expected\";\n}\n\n/**\n * Generates a partial value verifier.\n * @param {Codegen} gen Codegen instance\n * @param {Field} field Reflected field\n * @param {number} fieldIndex Field index\n * @param {string} ref Variable reference\n * @returns {Codegen} Codegen instance\n * @ignore\n */\nfunction genVerifyValue(gen, field, fieldIndex, ref) {\n    /* eslint-disable no-unexpected-multiline */\n    if (field.resolvedType) {\n        if (field.resolvedType instanceof Enum) { gen\n            (\"switch(%s){\", ref)\n                (\"default:\")\n                    (\"return%j\", invalid(field, \"enum value\"));\n            for (var keys = Object.keys(field.resolvedType.values), j = 0; j < keys.length; ++j) gen\n                (\"case %i:\", field.resolvedType.values[keys[j]]);\n            gen\n                    (\"break\")\n            (\"}\");\n        } else {\n            gen\n            (\"{\")\n                (\"var e=types[%i].verify(%s);\", fieldIndex, ref)\n                (\"if(e)\")\n                    (\"return%j+e\", field.name + \".\")\n            (\"}\");\n        }\n    } else {\n        switch (field.type) {\n            case \"int32\":\n            case \"uint32\":\n            case \"sint32\":\n            case \"fixed32\":\n            case \"sfixed32\": gen\n                (\"if(!util.isInteger(%s))\", ref)\n                    (\"return%j\", invalid(field, \"integer\"));\n                break;\n            case \"int64\":\n            case \"uint64\":\n            case \"sint64\":\n            case \"fixed64\":\n            case \"sfixed64\": gen\n                (\"if(!util.isInteger(%s)&&!(%s&&util.isInteger(%s.low)&&util.isInteger(%s.high)))\", ref, ref, ref, ref)\n                    (\"return%j\", invalid(field, \"integer|Long\"));\n                break;\n            case \"float\":\n            case \"double\": gen\n                (\"if(typeof %s!==\\\"number\\\")\", ref)\n                    (\"return%j\", invalid(field, \"number\"));\n                break;\n            case \"bool\": gen\n                (\"if(typeof %s!==\\\"boolean\\\")\", ref)\n                    (\"return%j\", invalid(field, \"boolean\"));\n                break;\n            case \"string\": gen\n                (\"if(!util.isString(%s))\", ref)\n                    (\"return%j\", invalid(field, \"string\"));\n                break;\n            case \"bytes\": gen\n                (\"if(!(%s&&typeof %s.length===\\\"number\\\"||util.isString(%s)))\", ref, ref, ref)\n                    (\"return%j\", invalid(field, \"buffer\"));\n                break;\n        }\n    }\n    return gen;\n    /* eslint-enable no-unexpected-multiline */\n}\n\n/**\n * Generates a partial key verifier.\n * @param {Codegen} gen Codegen instance\n * @param {Field} field Reflected field\n * @param {string} ref Variable reference\n * @returns {Codegen} Codegen instance\n * @ignore\n */\nfunction genVerifyKey(gen, field, ref) {\n    /* eslint-disable no-unexpected-multiline */\n    switch (field.keyType) {\n        case \"int32\":\n        case \"uint32\":\n        case \"sint32\":\n        case \"fixed32\":\n        case \"sfixed32\": gen\n            (\"if(!util.key32Re.test(%s))\", ref)\n                (\"return%j\", invalid(field, \"integer key\"));\n            break;\n        case \"int64\":\n        case \"uint64\":\n        case \"sint64\":\n        case \"fixed64\":\n        case \"sfixed64\": gen\n            (\"if(!util.key64Re.test(%s))\", ref) // see comment above: x is ok, d is not\n                (\"return%j\", invalid(field, \"integer|Long key\"));\n            break;\n        case \"bool\": gen\n            (\"if(!util.key2Re.test(%s))\", ref)\n                (\"return%j\", invalid(field, \"boolean key\"));\n            break;\n    }\n    return gen;\n    /* eslint-enable no-unexpected-multiline */\n}\n\n/**\n * Generates a verifier specific to the specified message type.\n * @param {Type} mtype Message type\n * @returns {Codegen} Codegen instance\n */\nfunction verifier(mtype) {\n    /* eslint-disable no-unexpected-multiline */\n\n    var gen = util.codegen([\"m\"], mtype.name + \"$verify\")\n    (\"if(typeof m!==\\\"object\\\"||m===null)\")\n        (\"return%j\", \"object expected\");\n    var oneofs = mtype.oneofsArray,\n        seenFirstField = {};\n    if (oneofs.length) gen\n    (\"var p={}\");\n\n    for (var i = 0; i < /* initializes */ mtype.fieldsArray.length; ++i) {\n        var field = mtype._fieldsArray[i].resolve(),\n            ref   = \"m\" + util.safeProp(field.name);\n\n        if (field.optional) gen\n        (\"if(%s!=null&&m.hasOwnProperty(%j)){\", ref, field.name); // !== undefined && !== null\n\n        // map fields\n        if (field.map) { gen\n            (\"if(!util.isObject(%s))\", ref)\n                (\"return%j\", invalid(field, \"object\"))\n            (\"var k=Object.keys(%s)\", ref)\n            (\"for(var i=0;i<k.length;++i){\");\n                genVerifyKey(gen, field, \"k[i]\");\n                genVerifyValue(gen, field, i, ref + \"[k[i]]\")\n            (\"}\");\n\n        // repeated fields\n        } else if (field.repeated) { gen\n            (\"if(!Array.isArray(%s))\", ref)\n                (\"return%j\", invalid(field, \"array\"))\n            (\"for(var i=0;i<%s.length;++i){\", ref);\n                genVerifyValue(gen, field, i, ref + \"[i]\")\n            (\"}\");\n\n        // required or present fields\n        } else {\n            if (field.partOf) {\n                var oneofProp = util.safeProp(field.partOf.name);\n                if (seenFirstField[field.partOf.name] === 1) gen\n            (\"if(p%s===1)\", oneofProp)\n                (\"return%j\", field.partOf.name + \": multiple values\");\n                seenFirstField[field.partOf.name] = 1;\n                gen\n            (\"p%s=1\", oneofProp);\n            }\n            genVerifyValue(gen, field, i, ref);\n        }\n        if (field.optional) gen\n        (\"}\");\n    }\n    return gen\n    (\"return null\");\n    /* eslint-enable no-unexpected-multiline */\n}", "\"use strict\";\n/**\n * Runtime message from/to plain object converters.\n * @namespace\n */\nvar converter = exports;\n\nvar Enum = require(\"./enum\"),\n    util = require(\"./util\");\n\n/**\n * Generates a partial value fromObject conveter.\n * @param {Codegen} gen Codegen instance\n * @param {Field} field Reflected field\n * @param {number} fieldIndex Field index\n * @param {string} prop Property reference\n * @returns {Codegen} Codegen instance\n * @ignore\n */\nfunction genValuePartial_fromObject(gen, field, fieldIndex, prop) {\n    /* eslint-disable no-unexpected-multiline, block-scoped-var, no-redeclare */\n    if (field.resolvedType) {\n        if (field.resolvedType instanceof Enum) { gen\n            (\"switch(d%s){\", prop);\n            for (var values = field.resolvedType.values, keys = Object.keys(values), i = 0; i < keys.length; ++i) {\n                if (field.repeated && values[keys[i]] === field.typeDefault) gen\n                (\"default:\");\n                gen\n                (\"case%j:\", keys[i])\n                (\"case %i:\", values[keys[i]])\n                    (\"m%s=%j\", prop, values[keys[i]])\n                    (\"break\");\n            } gen\n            (\"}\");\n        } else gen\n            (\"if(typeof d%s!==\\\"object\\\")\", prop)\n                (\"throw TypeError(%j)\", field.fullName + \": object expected\")\n            (\"m%s=types[%i].fromObject(d%s)\", prop, fieldIndex, prop);\n    } else {\n        var isUnsigned = false;\n        switch (field.type) {\n            case \"double\":\n            case \"float\": gen\n                (\"m%s=Number(d%s)\", prop, prop); // also catches \"NaN\", \"Infinity\"\n                break;\n            case \"uint32\":\n            case \"fixed32\": gen\n                (\"m%s=d%s>>>0\", prop, prop);\n                break;\n            case \"int32\":\n            case \"sint32\":\n            case \"sfixed32\": gen\n                (\"m%s=d%s|0\", prop, prop);\n                break;\n            case \"uint64\":\n                isUnsigned = true;\n                // eslint-disable-line no-fallthrough\n            case \"int64\":\n            case \"sint64\":\n            case \"fixed64\":\n            case \"sfixed64\": gen\n                (\"if(util.Long)\")\n                    (\"(m%s=util.Long.fromValue(d%s)).unsigned=%j\", prop, prop, isUnsigned)\n                (\"else if(typeof d%s===\\\"string\\\")\", prop)\n                    (\"m%s=parseInt(d%s,10)\", prop, prop)\n                (\"else if(typeof d%s===\\\"number\\\")\", prop)\n                    (\"m%s=d%s\", prop, prop)\n                (\"else if(typeof d%s===\\\"object\\\")\", prop)\n                    (\"m%s=new util.LongBits(d%s.low>>>0,d%s.high>>>0).toNumber(%s)\", prop, prop, prop, isUnsigned ? \"true\" : \"\");\n                break;\n            case \"bytes\": gen\n                (\"if(typeof d%s===\\\"string\\\")\", prop)\n                    (\"util.base64.decode(d%s,m%s=util.newBuffer(util.base64.length(d%s)),0)\", prop, prop, prop)\n                (\"else if(d%s.length)\", prop)\n                    (\"m%s=d%s\", prop, prop);\n                break;\n            case \"string\": gen\n                (\"m%s=String(d%s)\", prop, prop);\n                break;\n            case \"bool\": gen\n                (\"m%s=Boolean(d%s)\", prop, prop);\n                break;\n            /* default: gen\n                (\"m%s=d%s\", prop, prop);\n                break; */\n        }\n    }\n    return gen;\n    /* eslint-enable no-unexpected-multiline, block-scoped-var, no-redeclare */\n}\n\n/**\n * Generates a plain object to runtime message converter specific to the specified message type.\n * @param {Type} mtype Message type\n * @returns {Codegen} Codegen instance\n */\nconverter.fromObject = function fromObject(mtype) {\n    /* eslint-disable no-unexpected-multiline, block-scoped-var, no-redeclare */\n    var fields = mtype.fieldsArray;\n    var gen = util.codegen([\"d\"], mtype.name + \"$fromObject\")\n    (\"if(d instanceof this.ctor)\")\n        (\"return d\");\n    if (!fields.length) return gen\n    (\"return new this.ctor\");\n    gen\n    (\"var m=new this.ctor\");\n    for (var i = 0; i < fields.length; ++i) {\n        var field  = fields[i].resolve(),\n            prop   = util.safeProp(field.name);\n\n        // Map fields\n        if (field.map) { gen\n    (\"if(d%s){\", prop)\n        (\"if(typeof d%s!==\\\"object\\\")\", prop)\n            (\"throw TypeError(%j)\", field.fullName + \": object expected\")\n        (\"m%s={}\", prop)\n        (\"for(var ks=Object.keys(d%s),i=0;i<ks.length;++i){\", prop);\n            genValuePartial_fromObject(gen, field, /* not sorted */ i, prop + \"[ks[i]]\")\n        (\"}\")\n    (\"}\");\n\n        // Repeated fields\n        } else if (field.repeated) { gen\n    (\"if(d%s){\", prop)\n        (\"if(!Array.isArray(d%s))\", prop)\n            (\"throw TypeError(%j)\", field.fullName + \": array expected\")\n        (\"m%s=[]\", prop)\n        (\"for(var i=0;i<d%s.length;++i){\", prop);\n            genValuePartial_fromObject(gen, field, /* not sorted */ i, prop + \"[i]\")\n        (\"}\")\n    (\"}\");\n\n        // Non-repeated fields\n        } else {\n            if (!(field.resolvedType instanceof Enum)) gen // no need to test for null/undefined if an enum (uses switch)\n    (\"if(d%s!=null){\", prop); // !== undefined && !== null\n        genValuePartial_fromObject(gen, field, /* not sorted */ i, prop);\n            if (!(field.resolvedType instanceof Enum)) gen\n    (\"}\");\n        }\n    } return gen\n    (\"return m\");\n    /* eslint-enable no-unexpected-multiline, block-scoped-var, no-redeclare */\n};\n\n/**\n * Generates a partial value toObject converter.\n * @param {Codegen} gen Codegen instance\n * @param {Field} field Reflected field\n * @param {number} fieldIndex Field index\n * @param {string} prop Property reference\n * @returns {Codegen} Codegen instance\n * @ignore\n */\nfunction genValuePartial_toObject(gen, field, fieldIndex, prop) {\n    /* eslint-disable no-unexpected-multiline, block-scoped-var, no-redeclare */\n    if (field.resolvedType) {\n        if (field.resolvedType instanceof Enum) gen\n            (\"d%s=o.enums===String?types[%i].values[m%s]:m%s\", prop, fieldIndex, prop, prop);\n        else gen\n            (\"d%s=types[%i].toObject(m%s,o)\", prop, fieldIndex, prop);\n    } else {\n        var isUnsigned = false;\n        switch (field.type) {\n            case \"double\":\n            case \"float\": gen\n            (\"d%s=o.json&&!isFinite(m%s)?String(m%s):m%s\", prop, prop, prop, prop);\n                break;\n            case \"uint64\":\n                isUnsigned = true;\n                // eslint-disable-line no-fallthrough\n            case \"int64\":\n            case \"sint64\":\n            case \"fixed64\":\n            case \"sfixed64\": gen\n            (\"if(typeof m%s===\\\"number\\\")\", prop)\n                (\"d%s=o.longs===String?String(m%s):m%s\", prop, prop, prop)\n            (\"else\") // Long-like\n                (\"d%s=o.longs===String?util.Long.prototype.toString.call(m%s):o.longs===Number?new util.LongBits(m%s.low>>>0,m%s.high>>>0).toNumber(%s):m%s\", prop, prop, prop, prop, isUnsigned ? \"true\": \"\", prop);\n                break;\n            case \"bytes\": gen\n            (\"d%s=o.bytes===String?util.base64.encode(m%s,0,m%s.length):o.bytes===Array?Array.prototype.slice.call(m%s):m%s\", prop, prop, prop, prop, prop);\n                break;\n            default: gen\n            (\"d%s=m%s\", prop, prop);\n                break;\n        }\n    }\n    return gen;\n    /* eslint-enable no-unexpected-multiline, block-scoped-var, no-redeclare */\n}\n\n/**\n * Generates a runtime message to plain object converter specific to the specified message type.\n * @param {Type} mtype Message type\n * @returns {Codegen} Codegen instance\n */\nconverter.toObject = function toObject(mtype) {\n    /* eslint-disable no-unexpected-multiline, block-scoped-var, no-redeclare */\n    var fields = mtype.fieldsArray.slice().sort(util.compareFieldsById);\n    if (!fields.length)\n        return util.codegen()(\"return {}\");\n    var gen = util.codegen([\"m\", \"o\"], mtype.name + \"$toObject\")\n    (\"if(!o)\")\n        (\"o={}\")\n    (\"var d={}\");\n\n    var repeatedFields = [],\n        mapFields = [],\n        normalFields = [],\n        i = 0;\n    for (; i < fields.length; ++i)\n        if (!fields[i].partOf)\n            ( fields[i].resolve().repeated ? repeatedFields\n            : fields[i].map ? mapFields\n            : normalFields).push(fields[i]);\n\n    if (repeatedFields.length) { gen\n    (\"if(o.arrays||o.defaults){\");\n        for (i = 0; i < repeatedFields.length; ++i) gen\n        (\"d%s=[]\", util.safeProp(repeatedFields[i].name));\n        gen\n    (\"}\");\n    }\n\n    if (mapFields.length) { gen\n    (\"if(o.objects||o.defaults){\");\n        for (i = 0; i < mapFields.length; ++i) gen\n        (\"d%s={}\", util.safeProp(mapFields[i].name));\n        gen\n    (\"}\");\n    }\n\n    if (normalFields.length) { gen\n    (\"if(o.defaults){\");\n        for (i = 0; i < normalFields.length; ++i) {\n            var field = normalFields[i],\n                prop  = util.safeProp(field.name);\n            if (field.resolvedType instanceof Enum) gen\n        (\"d%s=o.enums===String?%j:%j\", prop, field.resolvedType.valuesById[field.typeDefault], field.typeDefault);\n            else if (field.long) gen\n        (\"if(util.Long){\")\n            (\"var n=new util.Long(%i,%i,%j)\", field.typeDefault.low, field.typeDefault.high, field.typeDefault.unsigned)\n            (\"d%s=o.longs===String?n.toString():o.longs===Number?n.toNumber():n\", prop)\n        (\"}else\")\n            (\"d%s=o.longs===String?%j:%i\", prop, field.typeDefault.toString(), field.typeDefault.toNumber());\n            else if (field.bytes) {\n                var arrayDefault = \"[\" + Array.prototype.slice.call(field.typeDefault).join(\",\") + \"]\";\n                gen\n        (\"if(o.bytes===String)d%s=%j\", prop, String.fromCharCode.apply(String, field.typeDefault))\n        (\"else{\")\n            (\"d%s=%s\", prop, arrayDefault)\n            (\"if(o.bytes!==Array)d%s=util.newBuffer(d%s)\", prop, prop)\n        (\"}\");\n            } else gen\n        (\"d%s=%j\", prop, field.typeDefault); // also messages (=null)\n        } gen\n    (\"}\");\n    }\n    var hasKs2 = false;\n    for (i = 0; i < fields.length; ++i) {\n        var field = fields[i],\n            index = mtype._fieldsArray.indexOf(field),\n            prop  = util.safeProp(field.name);\n        if (field.map) {\n            if (!hasKs2) { hasKs2 = true; gen\n    (\"var ks2\");\n            } gen\n    (\"if(m%s&&(ks2=Object.keys(m%s)).length){\", prop, prop)\n        (\"d%s={}\", prop)\n        (\"for(var j=0;j<ks2.length;++j){\");\n            genValuePartial_toObject(gen, field, /* sorted */ index, prop + \"[ks2[j]]\")\n        (\"}\");\n        } else if (field.repeated) { gen\n    (\"if(m%s&&m%s.length){\", prop, prop)\n        (\"d%s=[]\", prop)\n        (\"for(var j=0;j<m%s.length;++j){\", prop);\n            genValuePartial_toObject(gen, field, /* sorted */ index, prop + \"[j]\")\n        (\"}\");\n        } else { gen\n    (\"if(m%s!=null&&m.hasOwnProperty(%j)){\", prop, field.name); // !== undefined && !== null\n        genValuePartial_toObject(gen, field, /* sorted */ index, prop);\n        if (field.partOf) gen\n        (\"if(o.oneofs)\")\n            (\"d%s=%j\", util.safeProp(field.partOf.name), field.name);\n        }\n        gen\n    (\"}\");\n    }\n    return gen\n    (\"return d\");\n    /* eslint-enable no-unexpected-multiline, block-scoped-var, no-redeclare */\n};\n", "\"use strict\";\n\n/**\n * Wrappers for common types.\n * @type {Object.<string,IWrapper>}\n * @const\n */\nvar wrappers = exports;\n\nvar Message = require(\"./message\");\n\n/**\n * From object converter part of an {@link IWrapper}.\n * @typedef WrapperFromObjectConverter\n * @type {function}\n * @param {Object.<string,*>} object Plain object\n * @returns {Message<{}>} Message instance\n * @this Type\n */\n\n/**\n * To object converter part of an {@link IWrapper}.\n * @typedef WrapperToObjectConverter\n * @type {function}\n * @param {Message<{}>} message Message instance\n * @param {IConversionOptions} [options] Conversion options\n * @returns {Object.<string,*>} Plain object\n * @this Type\n */\n\n/**\n * Common type wrapper part of {@link wrappers}.\n * @interface IWrapper\n * @property {WrapperFromObjectConverter} [fromObject] From object converter\n * @property {WrapperToObjectConverter} [toObject] To object converter\n */\n\n// Custom wrapper for Any\nwrappers[\".google.protobuf.Any\"] = {\n\n    fromObject: function(object) {\n\n        // unwrap value type if mapped\n        if (object && object[\"@type\"]) {\n             // Only use fully qualified type name after the last '/'\n            var name = object[\"@type\"].substring(object[\"@type\"].lastIndexOf(\"/\") + 1);\n            var type = this.lookup(name);\n            /* istanbul ignore else */\n            if (type) {\n                // type_url does not accept leading \".\"\n                var type_url = object[\"@type\"].charAt(0) === \".\" ?\n                    object[\"@type\"].substr(1) : object[\"@type\"];\n                // type_url prefix is optional, but path seperator is required\n                if (type_url.indexOf(\"/\") === -1) {\n                    type_url = \"/\" + type_url;\n                }\n                return this.create({\n                    type_url: type_url,\n                    value: type.encode(type.fromObject(object)).finish()\n                });\n            }\n        }\n\n        return this.fromObject(object);\n    },\n\n    toObject: function(message, options) {\n\n        // Default prefix\n        var googleApi = \"type.googleapis.com/\";\n        var prefix = \"\";\n        var name = \"\";\n\n        // decode value if requested and unmapped\n        if (options && options.json && message.type_url && message.value) {\n            // Only use fully qualified type name after the last '/'\n            name = message.type_url.substring(message.type_url.lastIndexOf(\"/\") + 1);\n            // Separate the prefix used\n            prefix = message.type_url.substring(0, message.type_url.lastIndexOf(\"/\") + 1);\n            var type = this.lookup(name);\n            /* istanbul ignore else */\n            if (type)\n                message = type.decode(message.value);\n        }\n\n        // wrap value if unmapped\n        if (!(message instanceof this.ctor) && message instanceof Message) {\n            var object = message.$type.toObject(message, options);\n            var messageName = message.$type.fullName[0] === \".\" ?\n                message.$type.fullName.substr(1) : message.$type.fullName;\n            // Default to type.googleapis.com prefix if no prefix is used\n            if (prefix === \"\") {\n                prefix = googleApi;\n            }\n            name = prefix + messageName;\n            object[\"@type\"] = name;\n            return object;\n        }\n\n        return this.toObject(message, options);\n    }\n};\n", "\"use strict\";\nmodule.exports = Type;\n\n// extends Namespace\nvar Namespace = require(\"./namespace\");\n((Type.prototype = Object.create(Namespace.prototype)).constructor = Type).className = \"Type\";\n\nvar Enum      = require(\"./enum\"),\n    OneOf     = require(\"./oneof\"),\n    Field     = require(\"./field\"),\n    MapField  = require(\"./mapfield\"),\n    Service   = require(\"./service\"),\n    Message   = require(\"./message\"),\n    Reader    = require(\"./reader\"),\n    Writer    = require(\"./writer\"),\n    util      = require(\"./util\"),\n    encoder   = require(\"./encoder\"),\n    decoder   = require(\"./decoder\"),\n    verifier  = require(\"./verifier\"),\n    converter = require(\"./converter\"),\n    wrappers  = require(\"./wrappers\");\n\n/**\n * Constructs a new reflected message type instance.\n * @classdesc Reflected message type.\n * @extends NamespaceBase\n * @constructor\n * @param {string} name Message name\n * @param {Object.<string,*>} [options] Declared options\n */\nfunction Type(name, options) {\n    Namespace.call(this, name, options);\n\n    /**\n     * Message fields.\n     * @type {Object.<string,Field>}\n     */\n    this.fields = {};  // toJSON, marker\n\n    /**\n     * Oneofs declared within this namespace, if any.\n     * @type {Object.<string,OneOf>}\n     */\n    this.oneofs = undefined; // toJSON\n\n    /**\n     * Extension ranges, if any.\n     * @type {number[][]}\n     */\n    this.extensions = undefined; // toJSON\n\n    /**\n     * Reserved ranges, if any.\n     * @type {Array.<number[]|string>}\n     */\n    this.reserved = undefined; // toJSON\n\n    /*?\n     * Whether this type is a legacy group.\n     * @type {boolean|undefined}\n     */\n    this.group = undefined; // toJSON\n\n    /**\n     * Cached fields by id.\n     * @type {Object.<number,Field>|null}\n     * @private\n     */\n    this._fieldsById = null;\n\n    /**\n     * Cached fields as an array.\n     * @type {Field[]|null}\n     * @private\n     */\n    this._fieldsArray = null;\n\n    /**\n     * Cached oneofs as an array.\n     * @type {OneOf[]|null}\n     * @private\n     */\n    this._oneofsArray = null;\n\n    /**\n     * Cached constructor.\n     * @type {Constructor<{}>}\n     * @private\n     */\n    this._ctor = null;\n}\n\nObject.defineProperties(Type.prototype, {\n\n    /**\n     * Message fields by id.\n     * @name Type#fieldsById\n     * @type {Object.<number,Field>}\n     * @readonly\n     */\n    fieldsById: {\n        get: function() {\n\n            /* istanbul ignore if */\n            if (this._fieldsById)\n                return this._fieldsById;\n\n            this._fieldsById = {};\n            for (var names = Object.keys(this.fields), i = 0; i < names.length; ++i) {\n                var field = this.fields[names[i]],\n                    id = field.id;\n\n                /* istanbul ignore if */\n                if (this._fieldsById[id])\n                    throw Error(\"duplicate id \" + id + \" in \" + this);\n\n                this._fieldsById[id] = field;\n            }\n            return this._fieldsById;\n        }\n    },\n\n    /**\n     * Fields of this message as an array for iteration.\n     * @name Type#fieldsArray\n     * @type {Field[]}\n     * @readonly\n     */\n    fieldsArray: {\n        get: function() {\n            return this._fieldsArray || (this._fieldsArray = util.toArray(this.fields));\n        }\n    },\n\n    /**\n     * Oneofs of this message as an array for iteration.\n     * @name Type#oneofsArray\n     * @type {OneOf[]}\n     * @readonly\n     */\n    oneofsArray: {\n        get: function() {\n            return this._oneofsArray || (this._oneofsArray = util.toArray(this.oneofs));\n        }\n    },\n\n    /**\n     * The registered constructor, if any registered, otherwise a generic constructor.\n     * Assigning a function replaces the internal constructor. If the function does not extend {@link Message} yet, its prototype will be setup accordingly and static methods will be populated. If it already extends {@link Message}, it will just replace the internal constructor.\n     * @name Type#ctor\n     * @type {Constructor<{}>}\n     */\n    ctor: {\n        get: function() {\n            return this._ctor || (this.ctor = Type.generateConstructor(this)());\n        },\n        set: function(ctor) {\n\n            // Ensure proper prototype\n            var prototype = ctor.prototype;\n            if (!(prototype instanceof Message)) {\n                (ctor.prototype = new Message()).constructor = ctor;\n                util.merge(ctor.prototype, prototype);\n            }\n\n            // Classes and messages reference their reflected type\n            ctor.$type = ctor.prototype.$type = this;\n\n            // Mix in static methods\n            util.merge(ctor, Message, true);\n\n            this._ctor = ctor;\n\n            // Messages have non-enumerable default values on their prototype\n            var i = 0;\n            for (; i < /* initializes */ this.fieldsArray.length; ++i)\n                this._fieldsArray[i].resolve(); // ensures a proper value\n\n            // Messages have non-enumerable getters and setters for each virtual oneof field\n            var ctorProperties = {};\n            for (i = 0; i < /* initializes */ this.oneofsArray.length; ++i)\n                ctorProperties[this._oneofsArray[i].resolve().name] = {\n                    get: util.oneOfGetter(this._oneofsArray[i].oneof),\n                    set: util.oneOfSetter(this._oneofsArray[i].oneof)\n                };\n            if (i)\n                Object.defineProperties(ctor.prototype, ctorProperties);\n        }\n    }\n});\n\n/**\n * Generates a constructor function for the specified type.\n * @param {Type} mtype Message type\n * @returns {Codegen} Codegen instance\n */\nType.generateConstructor = function generateConstructor(mtype) {\n    /* eslint-disable no-unexpected-multiline */\n    var gen = util.codegen([\"p\"], mtype.name);\n    // explicitly initialize mutable object/array fields so that these aren't just inherited from the prototype\n    for (var i = 0, field; i < mtype.fieldsArray.length; ++i)\n        if ((field = mtype._fieldsArray[i]).map) gen\n            (\"this%s={}\", util.safeProp(field.name));\n        else if (field.repeated) gen\n            (\"this%s=[]\", util.safeProp(field.name));\n    return gen\n    (\"if(p)for(var ks=Object.keys(p),i=0;i<ks.length;++i)if(p[ks[i]]!=null)\") // omit undefined or null\n        (\"this[ks[i]]=p[ks[i]]\");\n    /* eslint-enable no-unexpected-multiline */\n};\n\nfunction clearCache(type) {\n    type._fieldsById = type._fieldsArray = type._oneofsArray = null;\n    delete type.encode;\n    delete type.decode;\n    delete type.verify;\n    return type;\n}\n\n/**\n * Message type descriptor.\n * @interface IType\n * @extends INamespace\n * @property {Object.<string,IOneOf>} [oneofs] Oneof descriptors\n * @property {Object.<string,IField>} fields Field descriptors\n * @property {number[][]} [extensions] Extension ranges\n * @property {number[][]} [reserved] Reserved ranges\n * @property {boolean} [group=false] Whether a legacy group or not\n */\n\n/**\n * Creates a message type from a message type descriptor.\n * @param {string} name Message name\n * @param {IType} json Message type descriptor\n * @returns {Type} Created message type\n */\nType.fromJSON = function fromJSON(name, json) {\n    var type = new Type(name, json.options);\n    type.extensions = json.extensions;\n    type.reserved = json.reserved;\n    var names = Object.keys(json.fields),\n        i = 0;\n    for (; i < names.length; ++i)\n        type.add(\n            ( typeof json.fields[names[i]].keyType !== \"undefined\"\n            ? MapField.fromJSON\n            : Field.fromJSON )(names[i], json.fields[names[i]])\n        );\n    if (json.oneofs)\n        for (names = Object.keys(json.oneofs), i = 0; i < names.length; ++i)\n            type.add(OneOf.fromJSON(names[i], json.oneofs[names[i]]));\n    if (json.nested)\n        for (names = Object.keys(json.nested), i = 0; i < names.length; ++i) {\n            var nested = json.nested[names[i]];\n            type.add( // most to least likely\n                ( nested.id !== undefined\n                ? Field.fromJSON\n                : nested.fields !== undefined\n                ? Type.fromJSON\n                : nested.values !== undefined\n                ? Enum.fromJSON\n                : nested.methods !== undefined\n                ? Service.fromJSON\n                : Namespace.fromJSON )(names[i], nested)\n            );\n        }\n    if (json.extensions && json.extensions.length)\n        type.extensions = json.extensions;\n    if (json.reserved && json.reserved.length)\n        type.reserved = json.reserved;\n    if (json.group)\n        type.group = true;\n    if (json.comment)\n        type.comment = json.comment;\n    return type;\n};\n\n/**\n * Converts this message type to a message type descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {IType} Message type descriptor\n */\nType.prototype.toJSON = function toJSON(toJSONOptions) {\n    var inherited = Namespace.prototype.toJSON.call(this, toJSONOptions);\n    var keepComments = toJSONOptions ? Boolean(toJSONOptions.keepComments) : false;\n    return util.toObject([\n        \"options\"    , inherited && inherited.options || undefined,\n        \"oneofs\"     , Namespace.arrayToJSON(this.oneofsArray, toJSONOptions),\n        \"fields\"     , Namespace.arrayToJSON(this.fieldsArray.filter(function(obj) { return !obj.declaringField; }), toJSONOptions) || {},\n        \"extensions\" , this.extensions && this.extensions.length ? this.extensions : undefined,\n        \"reserved\"   , this.reserved && this.reserved.length ? this.reserved : undefined,\n        \"group\"      , this.group || undefined,\n        \"nested\"     , inherited && inherited.nested || undefined,\n        \"comment\"    , keepComments ? this.comment : undefined\n    ]);\n};\n\n/**\n * @override\n */\nType.prototype.resolveAll = function resolveAll() {\n    var fields = this.fieldsArray, i = 0;\n    while (i < fields.length)\n        fields[i++].resolve();\n    var oneofs = this.oneofsArray; i = 0;\n    while (i < oneofs.length)\n        oneofs[i++].resolve();\n    return Namespace.prototype.resolveAll.call(this);\n};\n\n/**\n * @override\n */\nType.prototype.get = function get(name) {\n    return this.fields[name]\n        || this.oneofs && this.oneofs[name]\n        || this.nested && this.nested[name]\n        || null;\n};\n\n/**\n * Adds a nested object to this type.\n * @param {ReflectionObject} object Nested object to add\n * @returns {Type} `this`\n * @throws {TypeError} If arguments are invalid\n * @throws {Error} If there is already a nested object with this name or, if a field, when there is already a field with this id\n */\nType.prototype.add = function add(object) {\n\n    if (this.get(object.name))\n        throw Error(\"duplicate name '\" + object.name + \"' in \" + this);\n\n    if (object instanceof Field && object.extend === undefined) {\n        // NOTE: Extension fields aren't actual fields on the declaring type, but nested objects.\n        // The root object takes care of adding distinct sister-fields to the respective extended\n        // type instead.\n\n        // avoids calling the getter if not absolutely necessary because it's called quite frequently\n        if (this._fieldsById ? /* istanbul ignore next */ this._fieldsById[object.id] : this.fieldsById[object.id])\n            throw Error(\"duplicate id \" + object.id + \" in \" + this);\n        if (this.isReservedId(object.id))\n            throw Error(\"id \" + object.id + \" is reserved in \" + this);\n        if (this.isReservedName(object.name))\n            throw Error(\"name '\" + object.name + \"' is reserved in \" + this);\n\n        if (object.parent)\n            object.parent.remove(object);\n        this.fields[object.name] = object;\n        object.message = this;\n        object.onAdd(this);\n        return clearCache(this);\n    }\n    if (object instanceof OneOf) {\n        if (!this.oneofs)\n            this.oneofs = {};\n        this.oneofs[object.name] = object;\n        object.onAdd(this);\n        return clearCache(this);\n    }\n    return Namespace.prototype.add.call(this, object);\n};\n\n/**\n * Removes a nested object from this type.\n * @param {ReflectionObject} object Nested object to remove\n * @returns {Type} `this`\n * @throws {TypeError} If arguments are invalid\n * @throws {Error} If `object` is not a member of this type\n */\nType.prototype.remove = function remove(object) {\n    if (object instanceof Field && object.extend === undefined) {\n        // See Type#add for the reason why extension fields are excluded here.\n\n        /* istanbul ignore if */\n        if (!this.fields || this.fields[object.name] !== object)\n            throw Error(object + \" is not a member of \" + this);\n\n        delete this.fields[object.name];\n        object.parent = null;\n        object.onRemove(this);\n        return clearCache(this);\n    }\n    if (object instanceof OneOf) {\n\n        /* istanbul ignore if */\n        if (!this.oneofs || this.oneofs[object.name] !== object)\n            throw Error(object + \" is not a member of \" + this);\n\n        delete this.oneofs[object.name];\n        object.parent = null;\n        object.onRemove(this);\n        return clearCache(this);\n    }\n    return Namespace.prototype.remove.call(this, object);\n};\n\n/**\n * Tests if the specified id is reserved.\n * @param {number} id Id to test\n * @returns {boolean} `true` if reserved, otherwise `false`\n */\nType.prototype.isReservedId = function isReservedId(id) {\n    return Namespace.isReservedId(this.reserved, id);\n};\n\n/**\n * Tests if the specified name is reserved.\n * @param {string} name Name to test\n * @returns {boolean} `true` if reserved, otherwise `false`\n */\nType.prototype.isReservedName = function isReservedName(name) {\n    return Namespace.isReservedName(this.reserved, name);\n};\n\n/**\n * Creates a new message of this type using the specified properties.\n * @param {Object.<string,*>} [properties] Properties to set\n * @returns {Message<{}>} Message instance\n */\nType.prototype.create = function create(properties) {\n    return new this.ctor(properties);\n};\n\n/**\n * Sets up {@link Type#encode|encode}, {@link Type#decode|decode} and {@link Type#verify|verify}.\n * @returns {Type} `this`\n */\nType.prototype.setup = function setup() {\n    // Sets up everything at once so that the prototype chain does not have to be re-evaluated\n    // multiple times (V8, soft-deopt prototype-check).\n\n    var fullName = this.fullName,\n        types    = [];\n    for (var i = 0; i < /* initializes */ this.fieldsArray.length; ++i)\n        types.push(this._fieldsArray[i].resolve().resolvedType);\n\n    // Replace setup methods with type-specific generated functions\n    this.encode = encoder(this)({\n        Writer : Writer,\n        types  : types,\n        util   : util\n    });\n    this.decode = decoder(this)({\n        Reader : Reader,\n        types  : types,\n        util   : util\n    });\n    this.verify = verifier(this)({\n        types : types,\n        util  : util\n    });\n    this.fromObject = converter.fromObject(this)({\n        types : types,\n        util  : util\n    });\n    this.toObject = converter.toObject(this)({\n        types : types,\n        util  : util\n    });\n\n    // Inject custom wrappers for common types\n    var wrapper = wrappers[fullName];\n    if (wrapper) {\n        var originalThis = Object.create(this);\n        // if (wrapper.fromObject) {\n            originalThis.fromObject = this.fromObject;\n            this.fromObject = wrapper.fromObject.bind(originalThis);\n        // }\n        // if (wrapper.toObject) {\n            originalThis.toObject = this.toObject;\n            this.toObject = wrapper.toObject.bind(originalThis);\n        // }\n    }\n\n    return this;\n};\n\n/**\n * Encodes a message of this type. Does not implicitly {@link Type#verify|verify} messages.\n * @param {Message<{}>|Object.<string,*>} message Message instance or plain object\n * @param {Writer} [writer] Writer to encode to\n * @returns {Writer} writer\n */\nType.prototype.encode = function encode_setup(message, writer) {\n    return this.setup().encode(message, writer); // overrides this method\n};\n\n/**\n * Encodes a message of this type preceeded by its byte length as a varint. Does not implicitly {@link Type#verify|verify} messages.\n * @param {Message<{}>|Object.<string,*>} message Message instance or plain object\n * @param {Writer} [writer] Writer to encode to\n * @returns {Writer} writer\n */\nType.prototype.encodeDelimited = function encodeDelimited(message, writer) {\n    return this.encode(message, writer && writer.len ? writer.fork() : writer).ldelim();\n};\n\n/**\n * Decodes a message of this type.\n * @param {Reader|Uint8Array} reader Reader or buffer to decode from\n * @param {number} [length] Length of the message, if known beforehand\n * @returns {Message<{}>} Decoded message\n * @throws {Error} If the payload is not a reader or valid buffer\n * @throws {util.ProtocolError<{}>} If required fields are missing\n */\nType.prototype.decode = function decode_setup(reader, length) {\n    return this.setup().decode(reader, length); // overrides this method\n};\n\n/**\n * Decodes a message of this type preceeded by its byte length as a varint.\n * @param {Reader|Uint8Array} reader Reader or buffer to decode from\n * @returns {Message<{}>} Decoded message\n * @throws {Error} If the payload is not a reader or valid buffer\n * @throws {util.ProtocolError} If required fields are missing\n */\nType.prototype.decodeDelimited = function decodeDelimited(reader) {\n    if (!(reader instanceof Reader))\n        reader = Reader.create(reader);\n    return this.decode(reader, reader.uint32());\n};\n\n/**\n * Verifies that field values are valid and that required fields are present.\n * @param {Object.<string,*>} message Plain object to verify\n * @returns {null|string} `null` if valid, otherwise the reason why it is not\n */\nType.prototype.verify = function verify_setup(message) {\n    return this.setup().verify(message); // overrides this method\n};\n\n/**\n * Creates a new message of this type from a plain object. Also converts values to their respective internal types.\n * @param {Object.<string,*>} object Plain object to convert\n * @returns {Message<{}>} Message instance\n */\nType.prototype.fromObject = function fromObject(object) {\n    return this.setup().fromObject(object);\n};\n\n/**\n * Conversion options as used by {@link Type#toObject} and {@link Message.toObject}.\n * @interface IConversionOptions\n * @property {Function} [longs] Long conversion type.\n * Valid values are `String` and `Number` (the global types).\n * Defaults to copy the present value, which is a possibly unsafe number without and a {@link Long} with a long library.\n * @property {Function} [enums] Enum value conversion type.\n * Only valid value is `String` (the global type).\n * Defaults to copy the present value, which is the numeric id.\n * @property {Function} [bytes] Bytes value conversion type.\n * Valid values are `Array` and (a base64 encoded) `String` (the global types).\n * Defaults to copy the present value, which usually is a Buffer under node and an Uint8Array in the browser.\n * @property {boolean} [defaults=false] Also sets default values on the resulting object\n * @property {boolean} [arrays=false] Sets empty arrays for missing repeated fields even if `defaults=false`\n * @property {boolean} [objects=false] Sets empty objects for missing map fields even if `defaults=false`\n * @property {boolean} [oneofs=false] Includes virtual oneof properties set to the present field's name, if any\n * @property {boolean} [json=false] Performs additional JSON compatibility conversions, i.e. NaN and Infinity to strings\n */\n\n/**\n * Creates a plain object from a message of this type. Also converts values to other types if specified.\n * @param {Message<{}>} message Message instance\n * @param {IConversionOptions} [options] Conversion options\n * @returns {Object.<string,*>} Plain object\n */\nType.prototype.toObject = function toObject(message, options) {\n    return this.setup().toObject(message, options);\n};\n\n/**\n * Decorator function as returned by {@link Type.d} (TypeScript).\n * @typedef TypeDecorator\n * @type {function}\n * @param {Constructor<T>} target Target constructor\n * @returns {undefined}\n * @template T extends Message<T>\n */\n\n/**\n * Type decorator (TypeScript).\n * @param {string} [typeName] Type name, defaults to the constructor's name\n * @returns {TypeDecorator<T>} Decorator function\n * @template T extends Message<T>\n */\nType.d = function decorateType(typeName) {\n    return function typeDecorator(target) {\n        util.decorateType(target, typeName);\n    };\n};\n", "\"use strict\";\nmodule.exports = Root;\n\n// extends Namespace\nvar Namespace = require(\"./namespace\");\n((Root.prototype = Object.create(Namespace.prototype)).constructor = Root).className = \"Root\";\n\nvar Field   = require(\"./field\"),\n    Enum    = require(\"./enum\"),\n    OneOf   = require(\"./oneof\"),\n    util    = require(\"./util\");\n\nvar Type,   // cyclic\n    parse,  // might be excluded\n    common; // \"\n\n/**\n * Constructs a new root namespace instance.\n * @classdesc Root namespace wrapping all types, enums, services, sub-namespaces etc. that belong together.\n * @extends NamespaceBase\n * @constructor\n * @param {Object.<string,*>} [options] Top level options\n */\nfunction Root(options) {\n    Namespace.call(this, \"\", options);\n\n    /**\n     * Deferred extension fields.\n     * @type {Field[]}\n     */\n    this.deferred = [];\n\n    /**\n     * Resolved file names of loaded files.\n     * @type {string[]}\n     */\n    this.files = [];\n}\n\n/**\n * Loads a namespace descriptor into a root namespace.\n * @param {INamespace} json Nameespace descriptor\n * @param {Root} [root] Root namespace, defaults to create a new one if omitted\n * @returns {Root} Root namespace\n */\nRoot.fromJSON = function fromJSON(json, root) {\n    if (!root)\n        root = new Root();\n    if (json.options)\n        root.setOptions(json.options);\n    return root.addJSON(json.nested);\n};\n\n/**\n * Resolves the path of an imported file, relative to the importing origin.\n * This method exists so you can override it with your own logic in case your imports are scattered over multiple directories.\n * @function\n * @param {string} origin The file name of the importing file\n * @param {string} target The file name being imported\n * @returns {string|null} Resolved path to `target` or `null` to skip the file\n */\nRoot.prototype.resolvePath = util.path.resolve;\n\n/**\n * Fetch content from file path or url\n * This method exists so you can override it with your own logic.\n * @function\n * @param {string} path File path or url\n * @param {FetchCallback} callback Callback function\n * @returns {undefined}\n */\nRoot.prototype.fetch = util.fetch;\n\n// A symbol-like function to safely signal synchronous loading\n/* istanbul ignore next */\nfunction SYNC() {} // eslint-disable-line no-empty-function\n\n/**\n * Loads one or multiple .proto or preprocessed .json files into this root namespace and calls the callback.\n * @param {string|string[]} filename Names of one or multiple files to load\n * @param {IParseOptions} options Parse options\n * @param {LoadCallback} callback Callback function\n * @returns {undefined}\n */\nRoot.prototype.load = function load(filename, options, callback) {\n    if (typeof options === \"function\") {\n        callback = options;\n        options = undefined;\n    }\n    var self = this;\n    if (!callback)\n        return util.asPromise(load, self, filename, options);\n\n    var sync = callback === SYNC; // undocumented\n\n    // Finishes loading by calling the callback (exactly once)\n    function finish(err, root) {\n        /* istanbul ignore if */\n        if (!callback)\n            return;\n        var cb = callback;\n        callback = null;\n        if (sync)\n            throw err;\n        cb(err, root);\n    }\n\n    // Bundled definition existence checking\n    function getBundledFileName(filename) {\n        var idx = filename.lastIndexOf(\"google/protobuf/\");\n        if (idx > -1) {\n            var altname = filename.substring(idx);\n            if (altname in common) return altname;\n        }\n        return null;\n    }\n\n    // Processes a single file\n    function process(filename, source) {\n        try {\n            if (util.isString(source) && source.charAt(0) === \"{\")\n                source = JSON.parse(source);\n            if (!util.isString(source))\n                self.setOptions(source.options).addJSON(source.nested);\n            else {\n                parse.filename = filename;\n                var parsed = parse(source, self, options),\n                    resolved,\n                    i = 0;\n                if (parsed.imports)\n                    for (; i < parsed.imports.length; ++i)\n                        if (resolved = getBundledFileName(parsed.imports[i]) || self.resolvePath(filename, parsed.imports[i]))\n                            fetch(resolved);\n                if (parsed.weakImports)\n                    for (i = 0; i < parsed.weakImports.length; ++i)\n                        if (resolved = getBundledFileName(parsed.weakImports[i]) || self.resolvePath(filename, parsed.weakImports[i]))\n                            fetch(resolved, true);\n            }\n        } catch (err) {\n            finish(err);\n        }\n        if (!sync && !queued)\n            finish(null, self); // only once anyway\n    }\n\n    // Fetches a single file\n    function fetch(filename, weak) {\n\n        // Skip if already loaded / attempted\n        if (self.files.indexOf(filename) > -1)\n            return;\n        self.files.push(filename);\n\n        // Shortcut bundled definitions\n        if (filename in common) {\n            if (sync)\n                process(filename, common[filename]);\n            else {\n                ++queued;\n                setTimeout(function() {\n                    --queued;\n                    process(filename, common[filename]);\n                });\n            }\n            return;\n        }\n\n        // Otherwise fetch from disk or network\n        if (sync) {\n            var source;\n            try {\n                source = util.fs.readFileSync(filename).toString(\"utf8\");\n            } catch (err) {\n                if (!weak)\n                    finish(err);\n                return;\n            }\n            process(filename, source);\n        } else {\n            ++queued;\n            self.fetch(filename, function(err, source) {\n                --queued;\n                /* istanbul ignore if */\n                if (!callback)\n                    return; // terminated meanwhile\n                if (err) {\n                    /* istanbul ignore else */\n                    if (!weak)\n                        finish(err);\n                    else if (!queued) // can't be covered reliably\n                        finish(null, self);\n                    return;\n                }\n                process(filename, source);\n            });\n        }\n    }\n    var queued = 0;\n\n    // Assembling the root namespace doesn't require working type\n    // references anymore, so we can load everything in parallel\n    if (util.isString(filename))\n        filename = [ filename ];\n    for (var i = 0, resolved; i < filename.length; ++i)\n        if (resolved = self.resolvePath(\"\", filename[i]))\n            fetch(resolved);\n\n    if (sync)\n        return self;\n    if (!queued)\n        finish(null, self);\n    return undefined;\n};\n// function load(filename:string, options:IParseOptions, callback:LoadCallback):undefined\n\n/**\n * Loads one or multiple .proto or preprocessed .json files into this root namespace and calls the callback.\n * @function Root#load\n * @param {string|string[]} filename Names of one or multiple files to load\n * @param {LoadCallback} callback Callback function\n * @returns {undefined}\n * @variation 2\n */\n// function load(filename:string, callback:LoadCallback):undefined\n\n/**\n * Loads one or multiple .proto or preprocessed .json files into this root namespace and returns a promise.\n * @function Root#load\n * @param {string|string[]} filename Names of one or multiple files to load\n * @param {IParseOptions} [options] Parse options. Defaults to {@link parse.defaults} when omitted.\n * @returns {Promise<Root>} Promise\n * @variation 3\n */\n// function load(filename:string, [options:IParseOptions]):Promise<Root>\n\n/**\n * Synchronously loads one or multiple .proto or preprocessed .json files into this root namespace (node only).\n * @function Root#loadSync\n * @param {string|string[]} filename Names of one or multiple files to load\n * @param {IParseOptions} [options] Parse options. Defaults to {@link parse.defaults} when omitted.\n * @returns {Root} Root namespace\n * @throws {Error} If synchronous fetching is not supported (i.e. in browsers) or if a file's syntax is invalid\n */\nRoot.prototype.loadSync = function loadSync(filename, options) {\n    if (!util.isNode)\n        throw Error(\"not supported\");\n    return this.load(filename, options, SYNC);\n};\n\n/**\n * @override\n */\nRoot.prototype.resolveAll = function resolveAll() {\n    if (this.deferred.length)\n        throw Error(\"unresolvable extensions: \" + this.deferred.map(function(field) {\n            return \"'extend \" + field.extend + \"' in \" + field.parent.fullName;\n        }).join(\", \"));\n    return Namespace.prototype.resolveAll.call(this);\n};\n\n// only uppercased (and thus conflict-free) children are exposed, see below\nvar exposeRe = /^[A-Z]/;\n\n/**\n * Handles a deferred declaring extension field by creating a sister field to represent it within its extended type.\n * @param {Root} root Root instance\n * @param {Field} field Declaring extension field witin the declaring type\n * @returns {boolean} `true` if successfully added to the extended type, `false` otherwise\n * @inner\n * @ignore\n */\nfunction tryHandleExtension(root, field) {\n    var extendedType = field.parent.lookup(field.extend);\n    if (extendedType) {\n        var sisterField = new Field(field.fullName, field.id, field.type, field.rule, undefined, field.options);\n        sisterField.declaringField = field;\n        field.extensionField = sisterField;\n        extendedType.add(sisterField);\n        return true;\n    }\n    return false;\n}\n\n/**\n * Called when any object is added to this root or its sub-namespaces.\n * @param {ReflectionObject} object Object added\n * @returns {undefined}\n * @private\n */\nRoot.prototype._handleAdd = function _handleAdd(object) {\n    if (object instanceof Field) {\n\n        if (/* an extension field (implies not part of a oneof) */ object.extend !== undefined && /* not already handled */ !object.extensionField)\n            if (!tryHandleExtension(this, object))\n                this.deferred.push(object);\n\n    } else if (object instanceof Enum) {\n\n        if (exposeRe.test(object.name))\n            object.parent[object.name] = object.values; // expose enum values as property of its parent\n\n    } else if (!(object instanceof OneOf)) /* everything else is a namespace */ {\n\n        if (object instanceof Type) // Try to handle any deferred extensions\n            for (var i = 0; i < this.deferred.length;)\n                if (tryHandleExtension(this, this.deferred[i]))\n                    this.deferred.splice(i, 1);\n                else\n                    ++i;\n        for (var j = 0; j < /* initializes */ object.nestedArray.length; ++j) // recurse into the namespace\n            this._handleAdd(object._nestedArray[j]);\n        if (exposeRe.test(object.name))\n            object.parent[object.name] = object; // expose namespace as property of its parent\n    }\n\n    // The above also adds uppercased (and thus conflict-free) nested types, services and enums as\n    // properties of namespaces just like static code does. This allows using a .d.ts generated for\n    // a static module with reflection-based solutions where the condition is met.\n};\n\n/**\n * Called when any object is removed from this root or its sub-namespaces.\n * @param {ReflectionObject} object Object removed\n * @returns {undefined}\n * @private\n */\nRoot.prototype._handleRemove = function _handleRemove(object) {\n    if (object instanceof Field) {\n\n        if (/* an extension field */ object.extend !== undefined) {\n            if (/* already handled */ object.extensionField) { // remove its sister field\n                object.extensionField.parent.remove(object.extensionField);\n                object.extensionField = null;\n            } else { // cancel the extension\n                var index = this.deferred.indexOf(object);\n                /* istanbul ignore else */\n                if (index > -1)\n                    this.deferred.splice(index, 1);\n            }\n        }\n\n    } else if (object instanceof Enum) {\n\n        if (exposeRe.test(object.name))\n            delete object.parent[object.name]; // unexpose enum values\n\n    } else if (object instanceof Namespace) {\n\n        for (var i = 0; i < /* initializes */ object.nestedArray.length; ++i) // recurse into the namespace\n            this._handleRemove(object._nestedArray[i]);\n\n        if (exposeRe.test(object.name))\n            delete object.parent[object.name]; // unexpose namespaces\n\n    }\n};\n\n// Sets up cyclic dependencies (called in index-light)\nRoot._configure = function(Type_, parse_, common_) {\n    Type   = Type_;\n    parse  = parse_;\n    common = common_;\n};\n", "\"use strict\";\n\n/**\n * Various utility functions.\n * @namespace\n */\nvar util = module.exports = require(\"./util/minimal\");\n\nvar roots = require(\"./roots\");\n\nvar Type, // cyclic\n    Enum;\n\nutil.codegen = require(\"@protobufjs/codegen\");\nutil.fetch   = require(\"@protobufjs/fetch\");\nutil.path    = require(\"@protobufjs/path\");\n\n/**\n * Node's fs module if available.\n * @type {Object.<string,*>}\n */\nutil.fs = util.inquire(\"fs\");\n\n/**\n * Converts an object's values to an array.\n * @param {Object.<string,*>} object Object to convert\n * @returns {Array.<*>} Converted array\n */\nutil.toArray = function toArray(object) {\n    if (object) {\n        var keys  = Object.keys(object),\n            array = new Array(keys.length),\n            index = 0;\n        while (index < keys.length)\n            array[index] = object[keys[index++]];\n        return array;\n    }\n    return [];\n};\n\n/**\n * Converts an array of keys immediately followed by their respective value to an object, omitting undefined values.\n * @param {Array.<*>} array Array to convert\n * @returns {Object.<string,*>} Converted object\n */\nutil.toObject = function toObject(array) {\n    var object = {},\n        index  = 0;\n    while (index < array.length) {\n        var key = array[index++],\n            val = array[index++];\n        if (val !== undefined)\n            object[key] = val;\n    }\n    return object;\n};\n\nvar safePropBackslashRe = /\\\\/g,\n    safePropQuoteRe     = /\"/g;\n\n/**\n * Tests whether the specified name is a reserved word in JS.\n * @param {string} name Name to test\n * @returns {boolean} `true` if reserved, otherwise `false`\n */\nutil.isReserved = function isReserved(name) {\n    return /^(?:do|if|in|for|let|new|try|var|case|else|enum|eval|false|null|this|true|void|with|break|catch|class|const|super|throw|while|yield|delete|export|import|public|return|static|switch|typeof|default|extends|finally|package|private|continue|debugger|function|arguments|interface|protected|implements|instanceof)$/.test(name);\n};\n\n/**\n * Returns a safe property accessor for the specified property name.\n * @param {string} prop Property name\n * @returns {string} Safe accessor\n */\nutil.safeProp = function safeProp(prop) {\n    if (!/^[$\\w_]+$/.test(prop) || util.isReserved(prop))\n        return \"[\\\"\" + prop.replace(safePropBackslashRe, \"\\\\\\\\\").replace(safePropQuoteRe, \"\\\\\\\"\") + \"\\\"]\";\n    return \".\" + prop;\n};\n\n/**\n * Converts the first character of a string to upper case.\n * @param {string} str String to convert\n * @returns {string} Converted string\n */\nutil.ucFirst = function ucFirst(str) {\n    return str.charAt(0).toUpperCase() + str.substring(1);\n};\n\nvar camelCaseRe = /_([a-z])/g;\n\n/**\n * Converts a string to camel case.\n * @param {string} str String to convert\n * @returns {string} Converted string\n */\nutil.camelCase = function camelCase(str) {\n    return str.substring(0, 1)\n         + str.substring(1)\n               .replace(camelCaseRe, function($0, $1) { return $1.toUpperCase(); });\n};\n\n/**\n * Compares reflected fields by id.\n * @param {Field} a First field\n * @param {Field} b Second field\n * @returns {number} Comparison value\n */\nutil.compareFieldsById = function compareFieldsById(a, b) {\n    return a.id - b.id;\n};\n\n/**\n * Decorator helper for types (TypeScript).\n * @param {Constructor<T>} ctor Constructor function\n * @param {string} [typeName] Type name, defaults to the constructor's name\n * @returns {Type} Reflected type\n * @template T extends Message<T>\n * @property {Root} root Decorators root\n */\nutil.decorateType = function decorateType(ctor, typeName) {\n\n    /* istanbul ignore if */\n    if (ctor.$type) {\n        if (typeName && ctor.$type.name !== typeName) {\n            util.decorateRoot.remove(ctor.$type);\n            ctor.$type.name = typeName;\n            util.decorateRoot.add(ctor.$type);\n        }\n        return ctor.$type;\n    }\n\n    /* istanbul ignore next */\n    if (!Type)\n        Type = require(\"./type\");\n\n    var type = new Type(typeName || ctor.name);\n    util.decorateRoot.add(type);\n    type.ctor = ctor; // sets up .encode, .decode etc.\n    Object.defineProperty(ctor, \"$type\", { value: type, enumerable: false });\n    Object.defineProperty(ctor.prototype, \"$type\", { value: type, enumerable: false });\n    return type;\n};\n\nvar decorateEnumIndex = 0;\n\n/**\n * Decorator helper for enums (TypeScript).\n * @param {Object} object Enum object\n * @returns {Enum} Reflected enum\n */\nutil.decorateEnum = function decorateEnum(object) {\n\n    /* istanbul ignore if */\n    if (object.$type)\n        return object.$type;\n\n    /* istanbul ignore next */\n    if (!Enum)\n        Enum = require(\"./enum\");\n\n    var enm = new Enum(\"Enum\" + decorateEnumIndex++, object);\n    util.decorateRoot.add(enm);\n    Object.defineProperty(object, \"$type\", { value: enm, enumerable: false });\n    return enm;\n};\n\n\n/**\n * Sets the value of a property by property path. If a value already exists, it is turned to an array\n * @param {Object.<string,*>} dst Destination object\n * @param {string} path dot '.' delimited path of the property to set\n * @param {Object} value the value to set\n * @returns {Object.<string,*>} Destination object\n */\nutil.setProperty = function setProperty(dst, path, value) {\n    function setProp(dst, path, value) {\n        var part = path.shift();\n        if (path.length > 0) {\n            dst[part] = setProp(dst[part] || {}, path, value);\n        } else {\n            var prevValue = dst[part];\n            if (prevValue)\n                value = [].concat(prevValue).concat(value);\n            dst[part] = value;\n        }\n        return dst;\n    }\n\n    if (typeof dst !== \"object\")\n        throw TypeError(\"dst must be an object\");\n    if (!path)\n        throw TypeError(\"path must be specified\");\n\n    path = path.split(\".\");\n    return setProp(dst, path, value);\n};\n\n/**\n * Decorator root (TypeScript).\n * @name util.decorateRoot\n * @type {Root}\n * @readonly\n */\nObject.defineProperty(util, \"decorateRoot\", {\n    get: function() {\n        return roots[\"decorated\"] || (roots[\"decorated\"] = new (require(\"./root\"))());\n    }\n});\n", "\"use strict\";\nmodule.exports = ReflectionObject;\n\nReflectionObject.className = \"ReflectionObject\";\n\nvar util = require(\"./util\");\n\nvar Root; // cyclic\n\n/**\n * Constructs a new reflection object instance.\n * @classdesc Base class of all reflection objects.\n * @constructor\n * @param {string} name Object name\n * @param {Object.<string,*>} [options] Declared options\n * @abstract\n */\nfunction ReflectionObject(name, options) {\n\n    if (!util.isString(name))\n        throw TypeError(\"name must be a string\");\n\n    if (options && !util.isObject(options))\n        throw TypeError(\"options must be an object\");\n\n    /**\n     * Options.\n     * @type {Object.<string,*>|undefined}\n     */\n    this.options = options; // toJSON\n\n    /**\n     * Parsed Options.\n     * @type {Array.<Object.<string,*>>|undefined}\n     */\n    this.parsedOptions = null;\n\n    /**\n     * Unique name within its namespace.\n     * @type {string}\n     */\n    this.name = name;\n\n    /**\n     * Parent namespace.\n     * @type {Namespace|null}\n     */\n    this.parent = null;\n\n    /**\n     * Whether already resolved or not.\n     * @type {boolean}\n     */\n    this.resolved = false;\n\n    /**\n     * Comment text, if any.\n     * @type {string|null}\n     */\n    this.comment = null;\n\n    /**\n     * Defining file name.\n     * @type {string|null}\n     */\n    this.filename = null;\n}\n\nObject.defineProperties(ReflectionObject.prototype, {\n\n    /**\n     * Reference to the root namespace.\n     * @name ReflectionObject#root\n     * @type {Root}\n     * @readonly\n     */\n    root: {\n        get: function() {\n            var ptr = this;\n            while (ptr.parent !== null)\n                ptr = ptr.parent;\n            return ptr;\n        }\n    },\n\n    /**\n     * Full name including leading dot.\n     * @name ReflectionObject#fullName\n     * @type {string}\n     * @readonly\n     */\n    fullName: {\n        get: function() {\n            var path = [ this.name ],\n                ptr = this.parent;\n            while (ptr) {\n                path.unshift(ptr.name);\n                ptr = ptr.parent;\n            }\n            return path.join(\".\");\n        }\n    }\n});\n\n/**\n * Converts this reflection object to its descriptor representation.\n * @returns {Object.<string,*>} Descriptor\n * @abstract\n */\nReflectionObject.prototype.toJSON = /* istanbul ignore next */ function toJSON() {\n    throw Error(); // not implemented, shouldn't happen\n};\n\n/**\n * Called when this object is added to a parent.\n * @param {ReflectionObject} parent Parent added to\n * @returns {undefined}\n */\nReflectionObject.prototype.onAdd = function onAdd(parent) {\n    if (this.parent && this.parent !== parent)\n        this.parent.remove(this);\n    this.parent = parent;\n    this.resolved = false;\n    var root = parent.root;\n    if (root instanceof Root)\n        root._handleAdd(this);\n};\n\n/**\n * Called when this object is removed from a parent.\n * @param {ReflectionObject} parent Parent removed from\n * @returns {undefined}\n */\nReflectionObject.prototype.onRemove = function onRemove(parent) {\n    var root = parent.root;\n    if (root instanceof Root)\n        root._handleRemove(this);\n    this.parent = null;\n    this.resolved = false;\n};\n\n/**\n * Resolves this objects type references.\n * @returns {ReflectionObject} `this`\n */\nReflectionObject.prototype.resolve = function resolve() {\n    if (this.resolved)\n        return this;\n    if (this.root instanceof Root)\n        this.resolved = true; // only if part of a root\n    return this;\n};\n\n/**\n * Gets an option value.\n * @param {string} name Option name\n * @returns {*} Option value or `undefined` if not set\n */\nReflectionObject.prototype.getOption = function getOption(name) {\n    if (this.options)\n        return this.options[name];\n    return undefined;\n};\n\n/**\n * Sets an option.\n * @param {string} name Option name\n * @param {*} value Option value\n * @param {boolean} [ifNotSet] Sets the option only if it isn't currently set\n * @returns {ReflectionObject} `this`\n */\nReflectionObject.prototype.setOption = function setOption(name, value, ifNotSet) {\n    if (!ifNotSet || !this.options || this.options[name] === undefined)\n        (this.options || (this.options = {}))[name] = value;\n    return this;\n};\n\n/**\n * Sets a parsed option.\n * @param {string} name parsed Option name\n * @param {*} value Option value\n * @param {string} propName dot '.' delimited full path of property within the option to set. if undefined\\empty, will add a new option with that value\n * @returns {ReflectionObject} `this`\n */\nReflectionObject.prototype.setParsedOption = function setParsedOption(name, value, propName) {\n    if (!this.parsedOptions) {\n        this.parsedOptions = [];\n    }\n    var parsedOptions = this.parsedOptions;\n    if (propName) {\n        // If setting a sub property of an option then try to merge it\n        // with an existing option\n        var opt = parsedOptions.find(function (opt) {\n            return Object.prototype.hasOwnProperty.call(opt, name);\n        });\n        if (opt) {\n            // If we found an existing option - just merge the property value\n            var newValue = opt[name];\n            util.setProperty(newValue, propName, value);\n        } else {\n            // otherwise, create a new option, set it's property and add it to the list\n            opt = {};\n            opt[name] = util.setProperty({}, propName, value);\n            parsedOptions.push(opt);\n        }\n    } else {\n        // Always create a new option when setting the value of the option itself\n        var newOpt = {};\n        newOpt[name] = value;\n        parsedOptions.push(newOpt);\n    }\n    return this;\n};\n\n/**\n * Sets multiple options.\n * @param {Object.<string,*>} options Options to set\n * @param {boolean} [ifNotSet] Sets an option only if it isn't currently set\n * @returns {ReflectionObject} `this`\n */\nReflectionObject.prototype.setOptions = function setOptions(options, ifNotSet) {\n    if (options)\n        for (var keys = Object.keys(options), i = 0; i < keys.length; ++i)\n            this.setOption(keys[i], options[keys[i]], ifNotSet);\n    return this;\n};\n\n/**\n * Converts this instance to its string representation.\n * @returns {string} Class name[, space, full name]\n */\nReflectionObject.prototype.toString = function toString() {\n    var className = this.constructor.className,\n        fullName  = this.fullName;\n    if (fullName.length)\n        return className + \" \" + fullName;\n    return className;\n};\n\n// Sets up cyclic dependencies (called in index-light)\nReflectionObject._configure = function(Root_) {\n    Root = Root_;\n};\n", "\"use strict\";\nmodule.exports = Enum;\n\n// extends ReflectionObject\nvar ReflectionObject = require(\"./object\");\n((Enum.prototype = Object.create(ReflectionObject.prototype)).constructor = Enum).className = \"Enum\";\n\nvar Namespace = require(\"./namespace\"),\n    util = require(\"./util\");\n\n/**\n * Constructs a new enum instance.\n * @classdesc Reflected enum.\n * @extends ReflectionObject\n * @constructor\n * @param {string} name Unique name within its namespace\n * @param {Object.<string,number>} [values] Enum values as an object, by name\n * @param {Object.<string,*>} [options] Declared options\n * @param {string} [comment] The comment for this enum\n * @param {Object.<string,string>} [comments] The value comments for this enum\n */\nfunction Enum(name, values, options, comment, comments) {\n    ReflectionObject.call(this, name, options);\n\n    if (values && typeof values !== \"object\")\n        throw TypeError(\"values must be an object\");\n\n    /**\n     * Enum values by id.\n     * @type {Object.<number,string>}\n     */\n    this.valuesById = {};\n\n    /**\n     * Enum values by name.\n     * @type {Object.<string,number>}\n     */\n    this.values = Object.create(this.valuesById); // toJSON, marker\n\n    /**\n     * Enum comment text.\n     * @type {string|null}\n     */\n    this.comment = comment;\n\n    /**\n     * Value comment texts, if any.\n     * @type {Object.<string,string>}\n     */\n    this.comments = comments || {};\n\n    /**\n     * Reserved ranges, if any.\n     * @type {Array.<number[]|string>}\n     */\n    this.reserved = undefined; // toJSON\n\n    // Note that values inherit valuesById on their prototype which makes them a TypeScript-\n    // compatible enum. This is used by pbts to write actual enum definitions that work for\n    // static and reflection code alike instead of emitting generic object definitions.\n\n    if (values)\n        for (var keys = Object.keys(values), i = 0; i < keys.length; ++i)\n            if (typeof values[keys[i]] === \"number\") // use forward entries only\n                this.valuesById[ this.values[keys[i]] = values[keys[i]] ] = keys[i];\n}\n\n/**\n * Enum descriptor.\n * @interface IEnum\n * @property {Object.<string,number>} values Enum values\n * @property {Object.<string,*>} [options] Enum options\n */\n\n/**\n * Constructs an enum from an enum descriptor.\n * @param {string} name Enum name\n * @param {IEnum} json Enum descriptor\n * @returns {Enum} Created enum\n * @throws {TypeError} If arguments are invalid\n */\nEnum.fromJSON = function fromJSON(name, json) {\n    var enm = new Enum(name, json.values, json.options, json.comment, json.comments);\n    enm.reserved = json.reserved;\n    return enm;\n};\n\n/**\n * Converts this enum to an enum descriptor.\n * @param {IToJSONOptions} [toJSONOptions] JSON conversion options\n * @returns {IEnum} Enum descriptor\n */\nEnum.prototype.toJSON = function toJSON(toJSONOptions) {\n    var keepComments = toJSONOptions ? Boolean(toJSONOptions.keepComments) : false;\n    return util.toObject([\n        \"options\"  , this.options,\n        \"values\"   , this.values,\n        \"reserved\" , this.reserved && this.reserved.length ? this.reserved : undefined,\n        \"comment\"  , keepComments ? this.comment : undefined,\n        \"comments\" , keepComments ? this.comments : undefined\n    ]);\n};\n\n/**\n * Adds a value to this enum.\n * @param {string} name Value name\n * @param {number} id Value id\n * @param {string} [comment] Comment, if any\n * @returns {Enum} `this`\n * @throws {TypeError} If arguments are invalid\n * @throws {Error} If there is already a value with this name or id\n */\nEnum.prototype.add = function add(name, id, comment) {\n    // utilized by the parser but not by .fromJSON\n\n    if (!util.isString(name))\n        throw TypeError(\"name must be a string\");\n\n    if (!util.isInteger(id))\n        throw TypeError(\"id must be an integer\");\n\n    if (this.values[name] !== undefined)\n        throw Error(\"duplicate name '\" + name + \"' in \" + this);\n\n    if (this.isReservedId(id))\n        throw Error(\"id \" + id + \" is reserved in \" + this);\n\n    if (this.isReservedName(name))\n        throw Error(\"name '\" + name + \"' is reserved in \" + this);\n\n    if (this.valuesById[id] !== undefined) {\n        if (!(this.options && this.options.allow_alias))\n            throw Error(\"duplicate id \" + id + \" in \" + this);\n        this.values[name] = id;\n    } else\n        this.valuesById[this.values[name] = id] = name;\n\n    this.comments[name] = comment || null;\n    return this;\n};\n\n/**\n * Removes a value from this enum\n * @param {string} name Value name\n * @returns {Enum} `this`\n * @throws {TypeError} If arguments are invalid\n * @throws {Error} If `name` is not a name of this enum\n */\nEnum.prototype.remove = function remove(name) {\n\n    if (!util.isString(name))\n        throw TypeError(\"name must be a string\");\n\n    var val = this.values[name];\n    if (val == null)\n        throw Error(\"name '\" + name + \"' does not exist in \" + this);\n\n    delete this.valuesById[val];\n    delete this.values[name];\n    delete this.comments[name];\n\n    return this;\n};\n\n/**\n * Tests if the specified id is reserved.\n * @param {number} id Id to test\n * @returns {boolean} `true` if reserved, otherwise `false`\n */\nEnum.prototype.isReservedId = function isReservedId(id) {\n    return Namespace.isReservedId(this.reserved, id);\n};\n\n/**\n * Tests if the specified name is reserved.\n * @param {string} name Name to test\n * @returns {boolean} `true` if reserved, otherwise `false`\n */\nEnum.prototype.isReservedName = function isReservedName(name) {\n    return Namespace.isReservedName(this.reserved, name);\n};\n", "\"use strict\";\nmodule.exports = encoder;\n\nvar Enum     = require(\"./enum\"),\n    types    = require(\"./types\"),\n    util     = require(\"./util\");\n\n/**\n * Generates a partial message type encoder.\n * @param {Codegen} gen Codegen instance\n * @param {Field} field Reflected field\n * @param {number} fieldIndex Field index\n * @param {string} ref Variable reference\n * @returns {Codegen} Codegen instance\n * @ignore\n */\nfunction genTypePartial(gen, field, fieldIndex, ref) {\n    return field.resolvedType.group\n        ? gen(\"types[%i].encode(%s,w.uint32(%i)).uint32(%i)\", fieldIndex, ref, (field.id << 3 | 3) >>> 0, (field.id << 3 | 4) >>> 0)\n        : gen(\"types[%i].encode(%s,w.uint32(%i).fork()).ldelim()\", fieldIndex, ref, (field.id << 3 | 2) >>> 0);\n}\n\n/**\n * Generates an encoder specific to the specified message type.\n * @param {Type} mtype Message type\n * @returns {Codegen} Codegen instance\n */\nfunction encoder(mtype) {\n    /* eslint-disable no-unexpected-multiline, block-scoped-var, no-redeclare */\n    var gen = util.codegen([\"m\", \"w\"], mtype.name + \"$encode\")\n    (\"if(!w)\")\n        (\"w=Writer.create()\");\n\n    var i, ref;\n\n    // \"when a message is serialized its known fields should be written sequentially by field number\"\n    var fields = /* initializes */ mtype.fieldsArray.slice().sort(util.compareFieldsById);\n\n    for (var i = 0; i < fields.length; ++i) {\n        var field    = fields[i].resolve(),\n            index    = mtype._fieldsArray.indexOf(field),\n            type     = field.resolvedType instanceof Enum ? \"int32\" : field.type,\n            wireType = types.basic[type];\n            ref      = \"m\" + util.safeProp(field.name);\n\n        // Map fields\n        if (field.map) {\n            gen\n    (\"if(%s!=null&&Object.hasOwnProperty.call(m,%j)){\", ref, field.name) // !== undefined && !== null\n        (\"for(var ks=Object.keys(%s),i=0;i<ks.length;++i){\", ref)\n            (\"w.uint32(%i).fork().uint32(%i).%s(ks[i])\", (field.id << 3 | 2) >>> 0, 8 | types.mapKey[field.keyType], field.keyType);\n            if (wireType === undefined) gen\n            (\"types[%i].encode(%s[ks[i]],w.uint32(18).fork()).ldelim().ldelim()\", index, ref); // can't be groups\n            else gen\n            (\".uint32(%i).%s(%s[ks[i]]).ldelim()\", 16 | wireType, type, ref);\n            gen\n        (\"}\")\n    (\"}\");\n\n            // Repeated fields\n        } else if (field.repeated) { gen\n    (\"if(%s!=null&&%s.length){\", ref, ref); // !== undefined && !== null\n\n            // Packed repeated\n            if (field.packed && types.packed[type] !== undefined) { gen\n\n        (\"w.uint32(%i).fork()\", (field.id << 3 | 2) >>> 0)\n        (\"for(var i=0;i<%s.length;++i)\", ref)\n            (\"w.%s(%s[i])\", type, ref)\n        (\"w.ldelim()\");\n\n            // Non-packed\n            } else { gen\n\n        (\"for(var i=0;i<%s.length;++i)\", ref);\n                if (wireType === undefined)\n            genTypePartial(gen, field, index, ref + \"[i]\");\n                else gen\n            (\"w.uint32(%i).%s(%s[i])\", (field.id << 3 | wireType) >>> 0, type, ref);\n\n            } gen\n    (\"}\");\n\n        // Non-repeated\n        } else {\n            if (field.optional) gen\n    (\"if(%s!=null&&Object.hasOwnProperty.call(m,%j))\", ref, field.name); // !== undefined && !== null\n\n            if (wireType === undefined)\n        genTypePartial(gen, field, index, ref);\n            else gen\n        (\"w.uint32(%i).%s(%s)\", (field.id << 3 | wireType) >>> 0, type, ref);\n\n        }\n    }\n\n    return gen\n    (\"return w\");\n    /* eslint-enable no-unexpected-multiline, block-scoped-var, no-redeclare */\n}\n", "\"use strict\";\nvar protobuf = module.exports = require(\"./index-minimal\");\n\nprotobuf.build = \"light\";\n\n/**\n * A node-style callback as used by {@link load} and {@link Root#load}.\n * @typedef LoadCallback\n * @type {function}\n * @param {Error|null} error Error, if any, otherwise `null`\n * @param {Root} [root] Root, if there hasn't been an error\n * @returns {undefined}\n */\n\n/**\n * Loads one or multiple .proto or preprocessed .json files into a common root namespace and calls the callback.\n * @param {string|string[]} filename One or multiple files to load\n * @param {Root} root Root namespace, defaults to create a new one if omitted.\n * @param {LoadCallback} callback Callback function\n * @returns {undefined}\n * @see {@link Root#load}\n */\nfunction load(filename, root, callback) {\n    if (typeof root === \"function\") {\n        callback = root;\n        root = new protobuf.Root();\n    } else if (!root)\n        root = new protobuf.Root();\n    return root.load(filename, callback);\n}\n\n/**\n * Loads one or multiple .proto or preprocessed .json files into a common root namespace and calls the callback.\n * @name load\n * @function\n * @param {string|string[]} filename One or multiple files to load\n * @param {LoadCallback} callback Callback function\n * @returns {undefined}\n * @see {@link Root#load}\n * @variation 2\n */\n// function load(filename:string, callback:LoadCallback):undefined\n\n/**\n * Loads one or multiple .proto or preprocessed .json files into a common root namespace and returns a promise.\n * @name load\n * @function\n * @param {string|string[]} filename One or multiple files to load\n * @param {Root} [root] Root namespace, defaults to create a new one if omitted.\n * @returns {Promise<Root>} Promise\n * @see {@link Root#load}\n * @variation 3\n */\n// function load(filename:string, [root:Root]):Promise<Root>\n\nprotobuf.load = load;\n\n/**\n * Synchronously loads one or multiple .proto or preprocessed .json files into a common root namespace (node only).\n * @param {string|string[]} filename One or multiple files to load\n * @param {Root} [root] Root namespace, defaults to create a new one if omitted.\n * @returns {Root} Root namespace\n * @throws {Error} If synchronous fetching is not supported (i.e. in browsers) or if a file's syntax is invalid\n * @see {@link Root#loadSync}\n */\nfunction loadSync(filename, root) {\n    if (!root)\n        root = new protobuf.Root();\n    return root.loadSync(filename);\n}\n\nprotobuf.loadSync = loadSync;\n\n// Serialization\nprotobuf.encoder          = require(\"./encoder\");\nprotobuf.decoder          = require(\"./decoder\");\nprotobuf.verifier         = require(\"./verifier\");\nprotobuf.converter        = require(\"./converter\");\n\n// Reflection\nprotobuf.ReflectionObject = require(\"./object\");\nprotobuf.Namespace        = require(\"./namespace\");\nprotobuf.Root             = require(\"./root\");\nprotobuf.Enum             = require(\"./enum\");\nprotobuf.Type             = require(\"./type\");\nprotobuf.Field            = require(\"./field\");\nprotobuf.OneOf            = require(\"./oneof\");\nprotobuf.MapField         = require(\"./mapfield\");\nprotobuf.Service          = require(\"./service\");\nprotobuf.Method           = require(\"./method\");\n\n// Runtime\nprotobuf.Message          = require(\"./message\");\nprotobuf.wrappers         = require(\"./wrappers\");\n\n// Utility\nprotobuf.types            = require(\"./types\");\nprotobuf.util             = require(\"./util\");\n\n// Set up possibly cyclic reflection dependencies\nprotobuf.ReflectionObject._configure(protobuf.Root);\nprotobuf.Namespace._configure(protobuf.Type, protobuf.Service, protobuf.Enum);\nprotobuf.Root._configure(protobuf.Type);\nprotobuf.Field._configure(protobuf.Type);\n", "\"use strict\";\nmodule.exports = tokenize;\n\nvar delimRe        = /[\\s{}=;:[\\],'\"()<>]/g,\n    stringDoubleRe = /(?:\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\")/g,\n    stringSingleRe = /(?:'([^'\\\\]*(?:\\\\.[^'\\\\]*)*)')/g;\n\nvar setCommentRe = /^ *[*/]+ */,\n    setCommentAltRe = /^\\s*\\*?\\/*/,\n    setCommentSplitRe = /\\n/g,\n    whitespaceRe = /\\s/,\n    unescapeRe = /\\\\(.?)/g;\n\nvar unescapeMap = {\n    \"0\": \"\\0\",\n    \"r\": \"\\r\",\n    \"n\": \"\\n\",\n    \"t\": \"\\t\"\n};\n\n/**\n * Unescapes a string.\n * @param {string} str String to unescape\n * @returns {string} Unescaped string\n * @property {Object.<string,string>} map Special characters map\n * @memberof tokenize\n */\nfunction unescape(str) {\n    return str.replace(unescapeRe, function($0, $1) {\n        switch ($1) {\n            case \"\\\\\":\n            case \"\":\n                return $1;\n            default:\n                return unescapeMap[$1] || \"\";\n        }\n    });\n}\n\ntokenize.unescape = unescape;\n\n/**\n * Gets the next token and advances.\n * @typedef TokenizerHandleNext\n * @type {function}\n * @returns {string|null} Next token or `null` on eof\n */\n\n/**\n * Peeks for the next token.\n * @typedef TokenizerHandlePeek\n * @type {function}\n * @returns {string|null} Next token or `null` on eof\n */\n\n/**\n * Pushes a token back to the stack.\n * @typedef TokenizerHandlePush\n * @type {function}\n * @param {string} token Token\n * @returns {undefined}\n */\n\n/**\n * Skips the next token.\n * @typedef TokenizerHandleSkip\n * @type {function}\n * @param {string} expected Expected token\n * @param {boolean} [optional=false] If optional\n * @returns {boolean} Whether the token matched\n * @throws {Error} If the token didn't match and is not optional\n */\n\n/**\n * Gets the comment on the previous line or, alternatively, the line comment on the specified line.\n * @typedef TokenizerHandleCmnt\n * @type {function}\n * @param {number} [line] Line number\n * @returns {string|null} Comment text or `null` if none\n */\n\n/**\n * Handle object returned from {@link tokenize}.\n * @interface ITokenizerHandle\n * @property {TokenizerHandleNext} next Gets the next token and advances (`null` on eof)\n * @property {TokenizerHandlePeek} peek Peeks for the next token (`null` on eof)\n * @property {TokenizerHandlePush} push Pushes a token back to the stack\n * @property {TokenizerHandleSkip} skip Skips a token, returns its presence and advances or, if non-optional and not present, throws\n * @property {TokenizerHandleCmnt} cmnt Gets the comment on the previous line or the line comment on the specified line, if any\n * @property {number} line Current line number\n */\n\n/**\n * Tokenizes the given .proto source and returns an object with useful utility functions.\n * @param {string} source Source contents\n * @param {boolean} alternateCommentMode Whether we should activate alternate comment parsing mode.\n * @returns {ITokenizerHandle} Tokenizer handle\n */\nfunction tokenize(source, alternateCommentMode) {\n    /* eslint-disable callback-return */\n    source = source.toString();\n\n    var offset = 0,\n        length = source.length,\n        line = 1,\n        commentType = null,\n        commentText = null,\n        commentLine = 0,\n        commentLineEmpty = false,\n        commentIsLeading = false;\n\n    var stack = [];\n\n    var stringDelim = null;\n\n    /* istanbul ignore next */\n    /**\n     * Creates an error for illegal syntax.\n     * @param {string} subject Subject\n     * @returns {Error} Error created\n     * @inner\n     */\n    function illegal(subject) {\n        return Error(\"illegal \" + subject + \" (line \" + line + \")\");\n    }\n\n    /**\n     * Reads a string till its end.\n     * @returns {string} String read\n     * @inner\n     */\n    function readString() {\n        var re = stringDelim === \"'\" ? stringSingleRe : stringDoubleRe;\n        re.lastIndex = offset - 1;\n        var match = re.exec(source);\n        if (!match)\n            throw illegal(\"string\");\n        offset = re.lastIndex;\n        push(stringDelim);\n        stringDelim = null;\n        return unescape(match[1]);\n    }\n\n    /**\n     * Gets the character at `pos` within the source.\n     * @param {number} pos Position\n     * @returns {string} Character\n     * @inner\n     */\n    function charAt(pos) {\n        return source.charAt(pos);\n    }\n\n    /**\n     * Sets the current comment text.\n     * @param {number} start Start offset\n     * @param {number} end End offset\n     * @param {boolean} isLeading set if a leading comment\n     * @returns {undefined}\n     * @inner\n     */\n    function setComment(start, end, isLeading) {\n        commentType = source.charAt(start++);\n        commentLine = line;\n        commentLineEmpty = false;\n        commentIsLeading = isLeading;\n        var lookback;\n        if (alternateCommentMode) {\n            lookback = 2;  // alternate comment parsing: \"//\" or \"/*\"\n        } else {\n            lookback = 3;  // \"///\" or \"/**\"\n        }\n        var commentOffset = start - lookback,\n            c;\n        do {\n            if (--commentOffset < 0 ||\n                    (c = source.charAt(commentOffset)) === \"\\n\") {\n                commentLineEmpty = true;\n                break;\n            }\n        } while (c === \" \" || c === \"\\t\");\n        var lines = source\n            .substring(start, end)\n            .split(setCommentSplitRe);\n        for (var i = 0; i < lines.length; ++i)\n            lines[i] = lines[i]\n                .replace(alternateCommentMode ? setCommentAltRe : setCommentRe, \"\")\n                .trim();\n        commentText = lines\n            .join(\"\\n\")\n            .trim();\n    }\n\n    function isDoubleSlashCommentLine(startOffset) {\n        var endOffset = findEndOfLine(startOffset);\n\n        // see if remaining line matches comment pattern\n        var lineText = source.substring(startOffset, endOffset);\n        // look for 1 or 2 slashes since startOffset would already point past\n        // the first slash that started the comment.\n        var isComment = /^\\s*\\/{1,2}/.test(lineText);\n        return isComment;\n    }\n\n    function findEndOfLine(cursor) {\n        // find end of cursor's line\n        var endOffset = cursor;\n        while (endOffset < length && charAt(endOffset) !== \"\\n\") {\n            endOffset++;\n        }\n        return endOffset;\n    }\n\n    /**\n     * Obtains the next token.\n     * @returns {string|null} Next token or `null` on eof\n     * @inner\n     */\n    function next() {\n        if (stack.length > 0)\n            return stack.shift();\n        if (stringDelim)\n            return readString();\n        var repeat,\n            prev,\n            curr,\n            start,\n            isDoc,\n            isLeadingComment = offset === 0;\n        do {\n            if (offset === length)\n                return null;\n            repeat = false;\n            while (whitespaceRe.test(curr = charAt(offset))) {\n                if (curr === \"\\n\") {\n                    isLeadingComment = true;\n                    ++line;\n                }\n                if (++offset === length)\n                    return null;\n            }\n\n            if (charAt(offset) === \"/\") {\n                if (++offset === length) {\n                    throw illegal(\"comment\");\n                }\n                if (charAt(offset) === \"/\") { // Line\n                    if (!alternateCommentMode) {\n                        // check for triple-slash comment\n                        isDoc = charAt(start = offset + 1) === \"/\";\n\n                        while (charAt(++offset) !== \"\\n\") {\n                            if (offset === length) {\n                                return null;\n                            }\n                        }\n                        ++offset;\n                        if (isDoc) {\n                            setComment(start, offset - 1, isLeadingComment);\n                        }\n                        ++line;\n                        repeat = true;\n                    } else {\n                        // check for double-slash comments, consolidating consecutive lines\n                        start = offset;\n                        isDoc = false;\n                        if (isDoubleSlashCommentLine(offset)) {\n                            isDoc = true;\n                            do {\n                                offset = findEndOfLine(offset);\n                                if (offset === length) {\n                                    break;\n                                }\n                                offset++;\n                            } while (isDoubleSlashCommentLine(offset));\n                        } else {\n                            offset = Math.min(length, findEndOfLine(offset) + 1);\n                        }\n                        if (isDoc) {\n                            setComment(start, offset, isLeadingComment);\n                        }\n                        line++;\n                        repeat = true;\n                    }\n                } else if ((curr = charAt(offset)) === \"*\") { /* Block */\n                    // check for /** (regular comment mode) or /* (alternate comment mode)\n                    start = offset + 1;\n                    isDoc = alternateCommentMode || charAt(start) === \"*\";\n                    do {\n                        if (curr === \"\\n\") {\n                            ++line;\n                        }\n                        if (++offset === length) {\n                            throw illegal(\"comment\");\n                        }\n                        prev = curr;\n                        curr = charAt(offset);\n                    } while (prev !== \"*\" || curr !== \"/\");\n                    ++offset;\n                    if (isDoc) {\n                        setComment(start, offset - 2, isLeadingComment);\n                    }\n                    repeat = true;\n                } else {\n                    return \"/\";\n                }\n            }\n        } while (repeat);\n\n        // offset !== length if we got here\n\n        var end = offset;\n        delimRe.lastIndex = 0;\n        var delim = delimRe.test(charAt(end++));\n        if (!delim)\n            while (end < length && !delimRe.test(charAt(end)))\n                ++end;\n        var token = source.substring(offset, offset = end);\n        if (token === \"\\\"\" || token === \"'\")\n            stringDelim = token;\n        return token;\n    }\n\n    /**\n     * Pushes a token back to the stack.\n     * @param {string} token Token\n     * @returns {undefined}\n     * @inner\n     */\n    function push(token) {\n        stack.push(token);\n    }\n\n    /**\n     * Peeks for the next token.\n     * @returns {string|null} Token or `null` on eof\n     * @inner\n     */\n    function peek() {\n        if (!stack.length) {\n            var token = next();\n            if (token === null)\n                return null;\n            push(token);\n        }\n        return stack[0];\n    }\n\n    /**\n     * Skips a token.\n     * @param {string} expected Expected token\n     * @param {boolean} [optional=false] Whether the token is optional\n     * @returns {boolean} `true` when skipped, `false` if not\n     * @throws {Error} When a required token is not present\n     * @inner\n     */\n    function skip(expected, optional) {\n        var actual = peek(),\n            equals = actual === expected;\n        if (equals) {\n            next();\n            return true;\n        }\n        if (!optional)\n            throw illegal(\"token '\" + actual + \"', '\" + expected + \"' expected\");\n        return false;\n    }\n\n    /**\n     * Gets a comment.\n     * @param {number} [trailingLine] Line number if looking for a trailing comment\n     * @returns {string|null} Comment text\n     * @inner\n     */\n    function cmnt(trailingLine) {\n        var ret = null;\n        if (trailingLine === undefined) {\n            if (commentLine === line - 1 && (alternateCommentMode || commentType === \"*\" || commentLineEmpty)) {\n                ret = commentIsLeading ? commentText : null;\n            }\n        } else {\n            /* istanbul ignore else */\n            if (commentLine < trailingLine) {\n                peek();\n            }\n            if (commentLine === trailingLine && !commentLineEmpty && (alternateCommentMode || commentType === \"/\")) {\n                ret = commentIsLeading ? null : commentText;\n            }\n        }\n        return ret;\n    }\n\n    return Object.defineProperty({\n        next: next,\n        peek: peek,\n        push: push,\n        skip: skip,\n        cmnt: cmnt\n    }, \"line\", {\n        get: function() { return line; }\n    });\n    /* eslint-enable callback-return */\n}\n", "\"use strict\";\nmodule.exports = parse;\n\nparse.filename = null;\nparse.defaults = { keepCase: false };\n\nvar tokenize  = require(\"./tokenize\"),\n    Root      = require(\"./root\"),\n    Type      = require(\"./type\"),\n    Field     = require(\"./field\"),\n    MapField  = require(\"./mapfield\"),\n    OneOf     = require(\"./oneof\"),\n    Enum      = require(\"./enum\"),\n    Service   = require(\"./service\"),\n    Method    = require(\"./method\"),\n    types     = require(\"./types\"),\n    util      = require(\"./util\");\n\nvar base10Re    = /^[1-9][0-9]*$/,\n    base10NegRe = /^-?[1-9][0-9]*$/,\n    base16Re    = /^0[x][0-9a-fA-F]+$/,\n    base16NegRe = /^-?0[x][0-9a-fA-F]+$/,\n    base8Re     = /^0[0-7]+$/,\n    base8NegRe  = /^-?0[0-7]+$/,\n    numberRe    = /^(?![eE])[0-9]*(?:\\.[0-9]*)?(?:[eE][+-]?[0-9]+)?$/,\n    nameRe      = /^[a-zA-Z_][a-zA-Z_0-9]*$/,\n    typeRefRe   = /^(?:\\.?[a-zA-Z_][a-zA-Z_0-9]*)(?:\\.[a-zA-Z_][a-zA-Z_0-9]*)*$/,\n    fqTypeRefRe = /^(?:\\.[a-zA-Z_][a-zA-Z_0-9]*)+$/;\n\n/**\n * Result object returned from {@link parse}.\n * @interface IParserResult\n * @property {string|undefined} package Package name, if declared\n * @property {string[]|undefined} imports Imports, if any\n * @property {string[]|undefined} weakImports Weak imports, if any\n * @property {string|undefined} syntax Syntax, if specified (either `\"proto2\"` or `\"proto3\"`)\n * @property {Root} root Populated root instance\n */\n\n/**\n * Options modifying the behavior of {@link parse}.\n * @interface IParseOptions\n * @property {boolean} [keepCase=false] Keeps field casing instead of converting to camel case\n * @property {boolean} [alternateCommentMode=false] Recognize double-slash comments in addition to doc-block comments.\n * @property {boolean} [preferTrailingComment=false] Use trailing comment when both leading comment and trailing comment exist.\n */\n\n/**\n * Options modifying the behavior of JSON serialization.\n * @interface IToJSONOptions\n * @property {boolean} [keepComments=false] Serializes comments.\n */\n\n/**\n * Parses the given .proto source and returns an object with the parsed contents.\n * @param {string} source Source contents\n * @param {Root} root Root to populate\n * @param {IParseOptions} [options] Parse options. Defaults to {@link parse.defaults} when omitted.\n * @returns {IParserResult} Parser result\n * @property {string} filename=null Currently processing file name for error reporting, if known\n * @property {IParseOptions} defaults Default {@link IParseOptions}\n */\nfunction parse(source, root, options) {\n    /* eslint-disable callback-return */\n    if (!(root instanceof Root)) {\n        options = root;\n        root = new Root();\n    }\n    if (!options)\n        options = parse.defaults;\n\n    var preferTrailingComment = options.preferTrailingComment || false;\n    var tn = tokenize(source, options.alternateCommentMode || false),\n        next = tn.next,\n        push = tn.push,\n        peek = tn.peek,\n        skip = tn.skip,\n        cmnt = tn.cmnt;\n\n    var head = true,\n        pkg,\n        imports,\n        weakImports,\n        syntax,\n        isProto3 = false;\n\n    var ptr = root;\n\n    var applyCase = options.keepCase ? function(name) { return name; } : util.camelCase;\n\n    /* istanbul ignore next */\n    function illegal(token, name, insideTryCatch) {\n        var filename = parse.filename;\n        if (!insideTryCatch)\n            parse.filename = null;\n        return Error(\"illegal \" + (name || \"token\") + \" '\" + token + \"' (\" + (filename ? filename + \", \" : \"\") + \"line \" + tn.line + \")\");\n    }\n\n    function readString() {\n        var values = [],\n            token;\n        do {\n            /* istanbul ignore if */\n            if ((token = next()) !== \"\\\"\" && token !== \"'\")\n                throw illegal(token);\n\n            values.push(next());\n            skip(token);\n            token = peek();\n        } while (token === \"\\\"\" || token === \"'\");\n        return values.join(\"\");\n    }\n\n    function readValue(acceptTypeRef) {\n        var token = next();\n        switch (token) {\n            case \"'\":\n            case \"\\\"\":\n                push(token);\n                return readString();\n            case \"true\": case \"TRUE\":\n                return true;\n            case \"false\": case \"FALSE\":\n                return false;\n        }\n        try {\n            return parseNumber(token, /* insideTryCatch */ true);\n        } catch (e) {\n\n            /* istanbul ignore else */\n            if (acceptTypeRef && typeRefRe.test(token))\n                return token;\n\n            /* istanbul ignore next */\n            throw illegal(token, \"value\");\n        }\n    }\n\n    function readRanges(target, acceptStrings) {\n        var token, start;\n        do {\n            if (acceptStrings && ((token = peek()) === \"\\\"\" || token === \"'\"))\n                target.push(readString());\n            else\n                target.push([ start = parseId(next()), skip(\"to\", true) ? parseId(next()) : start ]);\n        } while (skip(\",\", true));\n        skip(\";\");\n    }\n\n    function parseNumber(token, insideTryCatch) {\n        var sign = 1;\n        if (token.charAt(0) === \"-\") {\n            sign = -1;\n            token = token.substring(1);\n        }\n        switch (token) {\n            case \"inf\": case \"INF\": case \"Inf\":\n                return sign * Infinity;\n            case \"nan\": case \"NAN\": case \"Nan\": case \"NaN\":\n                return NaN;\n            case \"0\":\n                return 0;\n        }\n        if (base10Re.test(token))\n            return sign * parseInt(token, 10);\n        if (base16Re.test(token))\n            return sign * parseInt(token, 16);\n        if (base8Re.test(token))\n            return sign * parseInt(token, 8);\n\n        /* istanbul ignore else */\n        if (numberRe.test(token))\n            return sign * parseFloat(token);\n\n        /* istanbul ignore next */\n        throw illegal(token, \"number\", insideTryCatch);\n    }\n\n    function parseId(token, acceptNegative) {\n        switch (token) {\n            case \"max\": case \"MAX\": case \"Max\":\n                return 536870911;\n            case \"0\":\n                return 0;\n        }\n\n        /* istanbul ignore if */\n        if (!acceptNegative && token.charAt(0) === \"-\")\n            throw illegal(token, \"id\");\n\n        if (base10NegRe.test(token))\n            return parseInt(token, 10);\n        if (base16NegRe.test(token))\n            return parseInt(token, 16);\n\n        /* istanbul ignore else */\n        if (base8NegRe.test(token))\n            return parseInt(token, 8);\n\n        /* istanbul ignore next */\n        throw illegal(token, \"id\");\n    }\n\n    function parsePackage() {\n\n        /* istanbul ignore if */\n        if (pkg !== undefined)\n            throw illegal(\"package\");\n\n        pkg = next();\n\n        /* istanbul ignore if */\n        if (!typeRefRe.test(pkg))\n            throw illegal(pkg, \"name\");\n\n        ptr = ptr.define(pkg);\n        skip(\";\");\n    }\n\n    function parseImport() {\n        var token = peek();\n        var whichImports;\n        switch (token) {\n            case \"weak\":\n                whichImports = weakImports || (weakImports = []);\n                next();\n                break;\n            case \"public\":\n                next();\n                // eslint-disable-line no-fallthrough\n            default:\n                whichImports = imports || (imports = []);\n                break;\n        }\n        token = readString();\n        skip(\";\");\n        whichImports.push(token);\n    }\n\n    function parseSyntax() {\n        skip(\"=\");\n        syntax = readString();\n        isProto3 = syntax === \"proto3\";\n\n        /* istanbul ignore if */\n        if (!isProto3 && syntax !== \"proto2\")\n            throw illegal(syntax, \"syntax\");\n\n        skip(\";\");\n    }\n\n    function parseCommon(parent, token) {\n        switch (token) {\n\n            case \"option\":\n                parseOption(parent, token);\n                skip(\";\");\n                return true;\n\n            case \"message\":\n                parseType(parent, token);\n                return true;\n\n            case \"enum\":\n                parseEnum(parent, token);\n                return true;\n\n            case \"service\":\n                parseService(parent, token);\n                return true;\n\n            case \"extend\":\n                parseExtension(parent, token);\n                return true;\n        }\n        return false;\n    }\n\n    function ifBlock(obj, fnIf, fnElse) {\n        var trailingLine = tn.line;\n        if (obj) {\n            if(typeof obj.comment !== \"string\") {\n              obj.comment = cmnt(); // try block-type comment\n            }\n            obj.filename = parse.filename;\n        }\n        if (skip(\"{\", true)) {\n            var token;\n            while ((token = next()) !== \"}\")\n                fnIf(token);\n            skip(\";\", true);\n        } else {\n            if (fnElse)\n                fnElse();\n            skip(\";\");\n            if (obj && (typeof obj.comment !== \"string\" || preferTrailingComment))\n                obj.comment = cmnt(trailingLine) || obj.comment; // try line-type comment\n        }\n    }\n\n    function parseType(parent, token) {\n\n        /* istanbul ignore if */\n        if (!nameRe.test(token = next()))\n            throw illegal(token, \"type name\");\n\n        var type = new Type(token);\n        ifBlock(type, function parseType_block(token) {\n            if (parseCommon(type, token))\n                return;\n\n            switch (token) {\n\n                case \"map\":\n                    parseMapField(type, token);\n                    break;\n\n                case \"required\":\n                case \"repeated\":\n                    parseField(type, token);\n                    break;\n\n                case \"optional\":\n                    /* istanbul ignore if */\n                    if (isProto3) {\n                        parseField(type, \"proto3_optional\");\n                    } else {\n                        parseField(type, \"optional\");\n                    }\n                    break;\n\n                case \"oneof\":\n                    parseOneOf(type, token);\n                    break;\n\n                case \"extensions\":\n                    readRanges(type.extensions || (type.extensions = []));\n                    break;\n\n                case \"reserved\":\n                    readRanges(type.reserved || (type.reserved = []), true);\n                    break;\n\n                default:\n                    /* istanbul ignore if */\n                    if (!isProto3 || !typeRefRe.test(token))\n                        throw illegal(token);\n\n                    push(token);\n                    parseField(type, \"optional\");\n                    break;\n            }\n        });\n        parent.add(type);\n    }\n\n    function parseField(parent, rule, extend) {\n        var type = next();\n        if (type === \"group\") {\n            parseGroup(parent, rule);\n            return;\n        }\n\n        /* istanbul ignore if */\n        if (!typeRefRe.test(type))\n            throw illegal(type, \"type\");\n\n        var name = next();\n\n        /* istanbul ignore if */\n        if (!nameRe.test(name))\n            throw illegal(name, \"name\");\n\n        name = applyCase(name);\n        skip(\"=\");\n\n        var field = new Field(name, parseId(next()), type, rule, extend);\n        ifBlock(field, function parseField_block(token) {\n\n            /* istanbul ignore else */\n            if (token === \"option\") {\n                parseOption(field, token);\n                skip(\";\");\n            } else\n                throw illegal(token);\n\n        }, function parseField_line() {\n            parseInlineOptions(field);\n        });\n\n        if (rule === \"proto3_optional\") {\n            // for proto3 optional fields, we create a single-member Oneof to mimic \"optional\" behavior\n            var oneof = new OneOf(\"_\" + name);\n            field.setOption(\"proto3_optional\", true);\n            oneof.add(field);\n            parent.add(oneof);\n        } else {\n            parent.add(field);\n        }\n\n        // JSON defaults to packed=true if not set so we have to set packed=false explicity when\n        // parsing proto2 descriptors without the option, where applicable. This must be done for\n        // all known packable types and anything that could be an enum (= is not a basic type).\n        if (!isProto3 && field.repeated && (types.packed[type] !== undefined || types.basic[type] === undefined))\n            field.setOption(\"packed\", false, /* ifNotSet */ true);\n    }\n\n    function parseGroup(parent, rule) {\n        var name = next();\n\n        /* istanbul ignore if */\n        if (!nameRe.test(name))\n            throw illegal(name, \"name\");\n\n        var fieldName = util.lcFirst(name);\n        if (name === fieldName)\n            name = util.ucFirst(name);\n        skip(\"=\");\n        var id = parseId(next());\n        var type = new Type(name);\n        type.group = true;\n        var field = new Field(fieldName, id, name, rule);\n        field.filename = parse.filename;\n        ifBlock(type, function parseGroup_block(token) {\n            switch (token) {\n\n                case \"option\":\n                    parseOption(type, token);\n                    skip(\";\");\n                    break;\n\n                case \"required\":\n                case \"repeated\":\n                    parseField(type, token);\n                    break;\n\n                case \"optional\":\n                    /* istanbul ignore if */\n                    if (isProto3) {\n                        parseField(type, \"proto3_optional\");\n                    } else {\n                        parseField(type, \"optional\");\n                    }\n                    break;\n\n                /* istanbul ignore next */\n                default:\n                    throw illegal(token); // there are no groups with proto3 semantics\n            }\n        });\n        parent.add(type)\n              .add(field);\n    }\n\n    function parseMapField(parent) {\n        skip(\"<\");\n        var keyType = next();\n\n        /* istanbul ignore if */\n        if (types.mapKey[keyType] === undefined)\n            throw illegal(keyType, \"type\");\n\n        skip(\",\");\n        var valueType = next();\n\n        /* istanbul ignore if */\n        if (!typeRefRe.test(valueType))\n            throw illegal(valueType, \"type\");\n\n        skip(\">\");\n        var name = next();\n\n        /* istanbul ignore if */\n        if (!nameRe.test(name))\n            throw illegal(name, \"name\");\n\n        skip(\"=\");\n        var field = new MapField(applyCase(name), parseId(next()), keyType, valueType);\n        ifBlock(field, function parseMapField_block(token) {\n\n            /* istanbul ignore else */\n            if (token === \"option\") {\n                parseOption(field, token);\n                skip(\";\");\n            } else\n                throw illegal(token);\n\n        }, function parseMapField_line() {\n            parseInlineOptions(field);\n        });\n        parent.add(field);\n    }\n\n    function parseOneOf(parent, token) {\n\n        /* istanbul ignore if */\n        if (!nameRe.test(token = next()))\n            throw illegal(token, \"name\");\n\n        var oneof = new OneOf(applyCase(token));\n        ifBlock(oneof, function parseOneOf_block(token) {\n            if (token === \"option\") {\n                parseOption(oneof, token);\n                skip(\";\");\n            } else {\n                push(token);\n                parseField(oneof, \"optional\");\n            }\n        });\n        parent.add(oneof);\n    }\n\n    function parseEnum(parent, token) {\n\n        /* istanbul ignore if */\n        if (!nameRe.test(token = next()))\n            throw illegal(token, \"name\");\n\n        var enm = new Enum(token);\n        ifBlock(enm, function parseEnum_block(token) {\n          switch(token) {\n            case \"option\":\n              parseOption(enm, token);\n              skip(\";\");\n              break;\n\n            case \"reserved\":\n              readRanges(enm.reserved || (enm.reserved = []), true);\n              break;\n\n            default:\n              parseEnumValue(enm, token);\n          }\n        });\n        parent.add(enm);\n    }\n\n    function parseEnumValue(parent, token) {\n\n        /* istanbul ignore if */\n        if (!nameRe.test(token))\n            throw illegal(token, \"name\");\n\n        skip(\"=\");\n        var value = parseId(next(), true),\n            dummy = {};\n        ifBlock(dummy, function parseEnumValue_block(token) {\n\n            /* istanbul ignore else */\n            if (token === \"option\") {\n                parseOption(dummy, token); // skip\n                skip(\";\");\n            } else\n                throw illegal(token);\n\n        }, function parseEnumValue_line() {\n            parseInlineOptions(dummy); // skip\n        });\n        parent.add(token, value, dummy.comment);\n    }\n\n    function parseOption(parent, token) {\n        var isCustom = skip(\"(\", true);\n\n        /* istanbul ignore if */\n        if (!typeRefRe.test(token = next()))\n            throw illegal(token, \"name\");\n\n        var name = token;\n        var option = name;\n        var propName;\n\n        if (isCustom) {\n            skip(\")\");\n            name = \"(\" + name + \")\";\n            option = name;\n            token = peek();\n            if (fqTypeRefRe.test(token)) {\n                propName = token.substr(1); //remove '.' before property name\n                name += token;\n                next();\n            }\n        }\n        skip(\"=\");\n        var optionValue = parseOptionValue(parent, name);\n        setParsedOption(parent, option, optionValue, propName);\n    }\n\n    function parseOptionValue(parent, name) {\n        if (skip(\"{\", true)) { // { a: \"foo\" b { c: \"bar\" } }\n            var result = {};\n            while (!skip(\"}\", true)) {\n                /* istanbul ignore if */\n                if (!nameRe.test(token = next()))\n                    throw illegal(token, \"name\");\n\n                var value;\n                var propName = token;\n                if (peek() === \"{\")\n                    value = parseOptionValue(parent, name + \".\" + token);\n                else {\n                    skip(\":\");\n                    if (peek() === \"{\")\n                        value = parseOptionValue(parent, name + \".\" + token);\n                    else {\n                        value = readValue(true);\n                        setOption(parent, name + \".\" + token, value);\n                    }\n                }\n                var prevValue = result[propName];\n                if (prevValue)\n                    value = [].concat(prevValue).concat(value);\n                result[propName] = value;\n                skip(\",\", true);\n            }\n            return result;\n        }\n\n        var simpleValue = readValue(true);\n        setOption(parent, name, simpleValue);\n        return simpleValue;\n        // Does not enforce a delimiter to be universal\n    }\n\n    function setOption(parent, name, value) {\n        if (parent.setOption)\n            parent.setOption(name, value);\n    }\n\n    function setParsedOption(parent, name, value, propName) {\n        if (parent.setParsedOption)\n            parent.setParsedOption(name, value, propName);\n    }\n\n    function parseInlineOptions(parent) {\n        if (skip(\"[\", true)) {\n            do {\n                parseOption(parent, \"option\");\n            } while (skip(\",\", true));\n            skip(\"]\");\n        }\n        return parent;\n    }\n\n    function parseService(parent, token) {\n\n        /* istanbul ignore if */\n        if (!nameRe.test(token = next()))\n            throw illegal(token, \"service name\");\n\n        var service = new Service(token);\n        ifBlock(service, function parseService_block(token) {\n            if (parseCommon(service, token))\n                return;\n\n            /* istanbul ignore else */\n            if (token === \"rpc\")\n                parseMethod(service, token);\n            else\n                throw illegal(token);\n        });\n        parent.add(service);\n    }\n\n    function parseMethod(parent, token) {\n        // Get the comment of the preceding line now (if one exists) in case the\n        // method is defined across multiple lines.\n        var commentText = cmnt();\n\n        var type = token;\n\n        /* istanbul ignore if */\n        if (!nameRe.test(token = next()))\n            throw illegal(token, \"name\");\n\n        var name = token,\n            requestType, requestStream,\n            responseType, responseStream;\n\n        skip(\"(\");\n        if (skip(\"stream\", true))\n            requestStream = true;\n\n        /* istanbul ignore if */\n        if (!typeRefRe.test(token = next()))\n            throw illegal(token);\n\n        requestType = token;\n        skip(\")\"); skip(\"returns\"); skip(\"(\");\n        if (skip(\"stream\", true))\n            responseStream = true;\n\n        /* istanbul ignore if */\n        if (!typeRefRe.test(token = next()))\n            throw illegal(token);\n\n        responseType = token;\n        skip(\")\");\n\n        var method = new Method(name, type, requestType, responseType, requestStream, responseStream);\n        method.comment = commentText;\n        ifBlock(method, function parseMethod_block(token) {\n\n            /* istanbul ignore else */\n            if (token === \"option\") {\n                parseOption(method, token);\n                skip(\";\");\n            } else\n                throw illegal(token);\n\n        });\n        parent.add(method);\n    }\n\n    function parseExtension(parent, token) {\n\n        /* istanbul ignore if */\n        if (!typeRefRe.test(token = next()))\n            throw illegal(token, \"reference\");\n\n        var reference = token;\n        ifBlock(null, function parseExtension_block(token) {\n            switch (token) {\n\n                case \"required\":\n                case \"repeated\":\n                    parseField(parent, token, reference);\n                    break;\n\n                case \"optional\":\n                    /* istanbul ignore if */\n                    if (isProto3) {\n                        parseField(parent, \"proto3_optional\", reference);\n                    } else {\n                        parseField(parent, \"optional\", reference);\n                    }\n                    break;\n\n                default:\n                    /* istanbul ignore if */\n                    if (!isProto3 || !typeRefRe.test(token))\n                        throw illegal(token);\n                    push(token);\n                    parseField(parent, \"optional\", reference);\n                    break;\n            }\n        });\n    }\n\n    var token;\n    while ((token = next()) !== null) {\n        switch (token) {\n\n            case \"package\":\n\n                /* istanbul ignore if */\n                if (!head)\n                    throw illegal(token);\n\n                parsePackage();\n                break;\n\n            case \"import\":\n\n                /* istanbul ignore if */\n                if (!head)\n                    throw illegal(token);\n\n                parseImport();\n                break;\n\n            case \"syntax\":\n\n                /* istanbul ignore if */\n                if (!head)\n                    throw illegal(token);\n\n                parseSyntax();\n                break;\n\n            case \"option\":\n\n                parseOption(ptr, token);\n                skip(\";\");\n                break;\n\n            default:\n\n                /* istanbul ignore else */\n                if (parseCommon(ptr, token)) {\n                    head = false;\n                    continue;\n                }\n\n                /* istanbul ignore next */\n                throw illegal(token);\n        }\n    }\n\n    parse.filename = null;\n    return {\n        \"package\"     : pkg,\n        \"imports\"     : imports,\n         weakImports  : weakImports,\n         syntax       : syntax,\n         root         : root\n    };\n}\n\n/**\n * Parses the given .proto source and returns an object with the parsed contents.\n * @name parse\n * @function\n * @param {string} source Source contents\n * @param {IParseOptions} [options] Parse options. Defaults to {@link parse.defaults} when omitted.\n * @returns {IParserResult} Parser result\n * @property {string} filename=null Currently processing file name for error reporting, if known\n * @property {IParseOptions} defaults Default {@link IParseOptions}\n * @variation 2\n */\n", "\"use strict\";\nmodule.exports = common;\n\nvar commonRe = /\\/|\\./;\n\n/**\n * Provides common type definitions.\n * Can also be used to provide additional google types or your own custom types.\n * @param {string} name Short name as in `google/protobuf/[name].proto` or full file name\n * @param {Object.<string,*>} json JSON definition within `google.protobuf` if a short name, otherwise the file's root definition\n * @returns {undefined}\n * @property {INamespace} google/protobuf/any.proto Any\n * @property {INamespace} google/protobuf/duration.proto Duration\n * @property {INamespace} google/protobuf/empty.proto Empty\n * @property {INamespace} google/protobuf/field_mask.proto FieldMask\n * @property {INamespace} google/protobuf/struct.proto Struct, Value, NullValue and ListValue\n * @property {INamespace} google/protobuf/timestamp.proto Timestamp\n * @property {INamespace} google/protobuf/wrappers.proto Wrappers\n * @example\n * // manually provides descriptor.proto (assumes google/protobuf/ namespace and .proto extension)\n * protobuf.common(\"descriptor\", descriptorJson);\n *\n * // manually provides a custom definition (uses my.foo namespace)\n * protobuf.common(\"my/foo/bar.proto\", myFooBarJson);\n */\nfunction common(name, json) {\n    if (!commonRe.test(name)) {\n        name = \"google/protobuf/\" + name + \".proto\";\n        json = { nested: { google: { nested: { protobuf: { nested: json } } } } };\n    }\n    common[name] = json;\n}\n\n// Not provided because of limited use (feel free to discuss or to provide yourself):\n//\n// google/protobuf/descriptor.proto\n// google/protobuf/source_context.proto\n// google/protobuf/type.proto\n//\n// Stripped and pre-parsed versions of these non-bundled files are instead available as part of\n// the repository or package within the google/protobuf directory.\n\ncommon(\"any\", {\n\n    /**\n     * Properties of a google.protobuf.Any message.\n     * @interface IAny\n     * @type {Object}\n     * @property {string} [typeUrl]\n     * @property {Uint8Array} [bytes]\n     * @memberof common\n     */\n    Any: {\n        fields: {\n            type_url: {\n                type: \"string\",\n                id: 1\n            },\n            value: {\n                type: \"bytes\",\n                id: 2\n            }\n        }\n    }\n});\n\nvar timeType;\n\ncommon(\"duration\", {\n\n    /**\n     * Properties of a google.protobuf.Duration message.\n     * @interface IDuration\n     * @type {Object}\n     * @property {number|Long} [seconds]\n     * @property {number} [nanos]\n     * @memberof common\n     */\n    Duration: timeType = {\n        fields: {\n            seconds: {\n                type: \"int64\",\n                id: 1\n            },\n            nanos: {\n                type: \"int32\",\n                id: 2\n            }\n        }\n    }\n});\n\ncommon(\"timestamp\", {\n\n    /**\n     * Properties of a google.protobuf.Timestamp message.\n     * @interface ITimestamp\n     * @type {Object}\n     * @property {number|Long} [seconds]\n     * @property {number} [nanos]\n     * @memberof common\n     */\n    Timestamp: timeType\n});\n\ncommon(\"empty\", {\n\n    /**\n     * Properties of a google.protobuf.Empty message.\n     * @interface IEmpty\n     * @memberof common\n     */\n    Empty: {\n        fields: {}\n    }\n});\n\ncommon(\"struct\", {\n\n    /**\n     * Properties of a google.protobuf.Struct message.\n     * @interface IStruct\n     * @type {Object}\n     * @property {Object.<string,IValue>} [fields]\n     * @memberof common\n     */\n    Struct: {\n        fields: {\n            fields: {\n                keyType: \"string\",\n                type: \"Value\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.Value message.\n     * @interface IValue\n     * @type {Object}\n     * @property {string} [kind]\n     * @property {0} [nullValue]\n     * @property {number} [numberValue]\n     * @property {string} [stringValue]\n     * @property {boolean} [boolValue]\n     * @property {IStruct} [structValue]\n     * @property {IListValue} [listValue]\n     * @memberof common\n     */\n    Value: {\n        oneofs: {\n            kind: {\n                oneof: [\n                    \"nullValue\",\n                    \"numberValue\",\n                    \"stringValue\",\n                    \"boolValue\",\n                    \"structValue\",\n                    \"listValue\"\n                ]\n            }\n        },\n        fields: {\n            nullValue: {\n                type: \"NullValue\",\n                id: 1\n            },\n            numberValue: {\n                type: \"double\",\n                id: 2\n            },\n            stringValue: {\n                type: \"string\",\n                id: 3\n            },\n            boolValue: {\n                type: \"bool\",\n                id: 4\n            },\n            structValue: {\n                type: \"Struct\",\n                id: 5\n            },\n            listValue: {\n                type: \"ListValue\",\n                id: 6\n            }\n        }\n    },\n\n    NullValue: {\n        values: {\n            NULL_VALUE: 0\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.ListValue message.\n     * @interface IListValue\n     * @type {Object}\n     * @property {Array.<IValue>} [values]\n     * @memberof common\n     */\n    ListValue: {\n        fields: {\n            values: {\n                rule: \"repeated\",\n                type: \"Value\",\n                id: 1\n            }\n        }\n    }\n});\n\ncommon(\"wrappers\", {\n\n    /**\n     * Properties of a google.protobuf.DoubleValue message.\n     * @interface IDoubleValue\n     * @type {Object}\n     * @property {number} [value]\n     * @memberof common\n     */\n    DoubleValue: {\n        fields: {\n            value: {\n                type: \"double\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.FloatValue message.\n     * @interface IFloatValue\n     * @type {Object}\n     * @property {number} [value]\n     * @memberof common\n     */\n    FloatValue: {\n        fields: {\n            value: {\n                type: \"float\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.Int64Value message.\n     * @interface IInt64Value\n     * @type {Object}\n     * @property {number|Long} [value]\n     * @memberof common\n     */\n    Int64Value: {\n        fields: {\n            value: {\n                type: \"int64\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.UInt64Value message.\n     * @interface IUInt64Value\n     * @type {Object}\n     * @property {number|Long} [value]\n     * @memberof common\n     */\n    UInt64Value: {\n        fields: {\n            value: {\n                type: \"uint64\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.Int32Value message.\n     * @interface IInt32Value\n     * @type {Object}\n     * @property {number} [value]\n     * @memberof common\n     */\n    Int32Value: {\n        fields: {\n            value: {\n                type: \"int32\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.UInt32Value message.\n     * @interface IUInt32Value\n     * @type {Object}\n     * @property {number} [value]\n     * @memberof common\n     */\n    UInt32Value: {\n        fields: {\n            value: {\n                type: \"uint32\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.BoolValue message.\n     * @interface IBoolValue\n     * @type {Object}\n     * @property {boolean} [value]\n     * @memberof common\n     */\n    BoolValue: {\n        fields: {\n            value: {\n                type: \"bool\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.StringValue message.\n     * @interface IStringValue\n     * @type {Object}\n     * @property {string} [value]\n     * @memberof common\n     */\n    StringValue: {\n        fields: {\n            value: {\n                type: \"string\",\n                id: 1\n            }\n        }\n    },\n\n    /**\n     * Properties of a google.protobuf.BytesValue message.\n     * @interface IBytesValue\n     * @type {Object}\n     * @property {Uint8Array} [value]\n     * @memberof common\n     */\n    BytesValue: {\n        fields: {\n            value: {\n                type: \"bytes\",\n                id: 1\n            }\n        }\n    }\n});\n\ncommon(\"field_mask\", {\n\n    /**\n     * Properties of a google.protobuf.FieldMask message.\n     * @interface IDoubleValue\n     * @type {Object}\n     * @property {number} [value]\n     * @memberof common\n     */\n    FieldMask: {\n        fields: {\n            paths: {\n                rule: \"repeated\",\n                type: \"string\",\n                id: 1\n            }\n        }\n    }\n});\n\n/**\n * Gets the root definition of the specified common proto file.\n *\n * Bundled definitions are:\n * - google/protobuf/any.proto\n * - google/protobuf/duration.proto\n * - google/protobuf/empty.proto\n * - google/protobuf/field_mask.proto\n * - google/protobuf/struct.proto\n * - google/protobuf/timestamp.proto\n * - google/protobuf/wrappers.proto\n *\n * @param {string} file Proto file name\n * @returns {INamespace|null} Root definition or `null` if not defined\n */\ncommon.get = function get(file) {\n    return common[file] || null;\n};\n", "\"use strict\";\nvar protobuf = module.exports = require(\"./index-light\");\n\nprotobuf.build = \"full\";\n\n// Parser\nprotobuf.tokenize         = require(\"./tokenize\");\nprotobuf.parse            = require(\"./parse\");\nprotobuf.common           = require(\"./common\");\n\n// Configure parser\nprotobuf.Root._configure(protobuf.Type, protobuf.parse, protobuf.common);\n", "// full library entry point.\n\n\"use strict\";\nmodule.exports = require(\"./src/index\");\n", "\"use strict\";\nvar $protobuf = require(\"../..\");\nmodule.exports = exports = $protobuf.descriptor = $protobuf.Root.fromJSON(require(\"../../google/protobuf/descriptor.json\")).lookup(\".google.protobuf\");\n\nvar Namespace = $protobuf.Namespace,\n    Root      = $protobuf.Root,\n    Enum      = $protobuf.Enum,\n    Type      = $protobuf.Type,\n    Field     = $protobuf.Field,\n    MapField  = $protobuf.MapField,\n    OneOf     = $protobuf.OneOf,\n    Service   = $protobuf.Service,\n    Method    = $protobuf.Method;\n\n// --- Root ---\n\n/**\n * Properties of a FileDescriptorSet message.\n * @interface IFileDescriptorSet\n * @property {IFileDescriptorProto[]} file Files\n */\n\n/**\n * Properties of a FileDescriptorProto message.\n * @interface IFileDescriptorProto\n * @property {string} [name] File name\n * @property {string} [package] Package\n * @property {*} [dependency] Not supported\n * @property {*} [publicDependency] Not supported\n * @property {*} [weakDependency] Not supported\n * @property {IDescriptorProto[]} [messageType] Nested message types\n * @property {IEnumDescriptorProto[]} [enumType] Nested enums\n * @property {IServiceDescriptorProto[]} [service] Nested services\n * @property {IFieldDescriptorProto[]} [extension] Nested extension fields\n * @property {IFileOptions} [options] Options\n * @property {*} [sourceCodeInfo] Not supported\n * @property {string} [syntax=\"proto2\"] Syntax\n */\n\n/**\n * Properties of a FileOptions message.\n * @interface IFileOptions\n * @property {string} [javaPackage]\n * @property {string} [javaOuterClassname]\n * @property {boolean} [javaMultipleFiles]\n * @property {boolean} [javaGenerateEqualsAndHash]\n * @property {boolean} [javaStringCheckUtf8]\n * @property {IFileOptionsOptimizeMode} [optimizeFor=1]\n * @property {string} [goPackage]\n * @property {boolean} [ccGenericServices]\n * @property {boolean} [javaGenericServices]\n * @property {boolean} [pyGenericServices]\n * @property {boolean} [deprecated]\n * @property {boolean} [ccEnableArenas]\n * @property {string} [objcClassPrefix]\n * @property {string} [csharpNamespace]\n */\n\n/**\n * Values of he FileOptions.OptimizeMode enum.\n * @typedef IFileOptionsOptimizeMode\n * @type {number}\n * @property {number} SPEED=1\n * @property {number} CODE_SIZE=2\n * @property {number} LITE_RUNTIME=3\n */\n\n/**\n * Creates a root from a descriptor set.\n * @param {IFileDescriptorSet|Reader|Uint8Array} descriptor Descriptor\n * @returns {Root} Root instance\n */\nRoot.fromDescriptor = function fromDescriptor(descriptor) {\n\n    // Decode the descriptor message if specified as a buffer:\n    if (typeof descriptor.length === \"number\")\n        descriptor = exports.FileDescriptorSet.decode(descriptor);\n\n    var root = new Root();\n\n    if (descriptor.file) {\n        var fileDescriptor,\n            filePackage;\n        for (var j = 0, i; j < descriptor.file.length; ++j) {\n            filePackage = root;\n            if ((fileDescriptor = descriptor.file[j])[\"package\"] && fileDescriptor[\"package\"].length)\n                filePackage = root.define(fileDescriptor[\"package\"]);\n            if (fileDescriptor.name && fileDescriptor.name.length)\n                root.files.push(filePackage.filename = fileDescriptor.name);\n            if (fileDescriptor.messageType)\n                for (i = 0; i < fileDescriptor.messageType.length; ++i)\n                    filePackage.add(Type.fromDescriptor(fileDescriptor.messageType[i], fileDescriptor.syntax));\n            if (fileDescriptor.enumType)\n                for (i = 0; i < fileDescriptor.enumType.length; ++i)\n                    filePackage.add(Enum.fromDescriptor(fileDescriptor.enumType[i]));\n            if (fileDescriptor.extension)\n                for (i = 0; i < fileDescriptor.extension.length; ++i)\n                    filePackage.add(Field.fromDescriptor(fileDescriptor.extension[i]));\n            if (fileDescriptor.service)\n                for (i = 0; i < fileDescriptor.service.length; ++i)\n                    filePackage.add(Service.fromDescriptor(fileDescriptor.service[i]));\n            var opts = fromDescriptorOptions(fileDescriptor.options, exports.FileOptions);\n            if (opts) {\n                var ks = Object.keys(opts);\n                for (i = 0; i < ks.length; ++i)\n                    filePackage.setOption(ks[i], opts[ks[i]]);\n            }\n        }\n    }\n\n    return root;\n};\n\n/**\n * Converts a root to a descriptor set.\n * @returns {Message<IFileDescriptorSet>} Descriptor\n * @param {string} [syntax=\"proto2\"] Syntax\n */\nRoot.prototype.toDescriptor = function toDescriptor(syntax) {\n    var set = exports.FileDescriptorSet.create();\n    Root_toDescriptorRecursive(this, set.file, syntax);\n    return set;\n};\n\n// Traverses a namespace and assembles the descriptor set\nfunction Root_toDescriptorRecursive(ns, files, syntax) {\n\n    // Create a new file\n    var file = exports.FileDescriptorProto.create({ name: ns.filename || (ns.fullName.substring(1).replace(/\\./g, \"_\") || \"root\") + \".proto\" });\n    if (syntax)\n        file.syntax = syntax;\n    if (!(ns instanceof Root))\n        file[\"package\"] = ns.fullName.substring(1);\n\n    // Add nested types\n    for (var i = 0, nested; i < ns.nestedArray.length; ++i)\n        if ((nested = ns._nestedArray[i]) instanceof Type)\n            file.messageType.push(nested.toDescriptor(syntax));\n        else if (nested instanceof Enum)\n            file.enumType.push(nested.toDescriptor());\n        else if (nested instanceof Field)\n            file.extension.push(nested.toDescriptor(syntax));\n        else if (nested instanceof Service)\n            file.service.push(nested.toDescriptor());\n        else if (nested instanceof /* plain */ Namespace)\n            Root_toDescriptorRecursive(nested, files, syntax); // requires new file\n\n    // Keep package-level options\n    file.options = toDescriptorOptions(ns.options, exports.FileOptions);\n\n    // And keep the file only if there is at least one nested object\n    if (file.messageType.length + file.enumType.length + file.extension.length + file.service.length)\n        files.push(file);\n}\n\n// --- Type ---\n\n/**\n * Properties of a DescriptorProto message.\n * @interface IDescriptorProto\n * @property {string} [name] Message type name\n * @property {IFieldDescriptorProto[]} [field] Fields\n * @property {IFieldDescriptorProto[]} [extension] Extension fields\n * @property {IDescriptorProto[]} [nestedType] Nested message types\n * @property {IEnumDescriptorProto[]} [enumType] Nested enums\n * @property {IDescriptorProtoExtensionRange[]} [extensionRange] Extension ranges\n * @property {IOneofDescriptorProto[]} [oneofDecl] Oneofs\n * @property {IMessageOptions} [options] Not supported\n * @property {IDescriptorProtoReservedRange[]} [reservedRange] Reserved ranges\n * @property {string[]} [reservedName] Reserved names\n */\n\n/**\n * Properties of a MessageOptions message.\n * @interface IMessageOptions\n * @property {boolean} [mapEntry=false] Whether this message is a map entry\n */\n\n/**\n * Properties of an ExtensionRange message.\n * @interface IDescriptorProtoExtensionRange\n * @property {number} [start] Start field id\n * @property {number} [end] End field id\n */\n\n/**\n * Properties of a ReservedRange message.\n * @interface IDescriptorProtoReservedRange\n * @property {number} [start] Start field id\n * @property {number} [end] End field id\n */\n\nvar unnamedMessageIndex = 0;\n\n/**\n * Creates a type from a descriptor.\n * @param {IDescriptorProto|Reader|Uint8Array} descriptor Descriptor\n * @param {string} [syntax=\"proto2\"] Syntax\n * @returns {Type} Type instance\n */\nType.fromDescriptor = function fromDescriptor(descriptor, syntax) {\n\n    // Decode the descriptor message if specified as a buffer:\n    if (typeof descriptor.length === \"number\")\n        descriptor = exports.DescriptorProto.decode(descriptor);\n\n    // Create the message type\n    var type = new Type(descriptor.name.length ? descriptor.name : \"Type\" + unnamedMessageIndex++, fromDescriptorOptions(descriptor.options, exports.MessageOptions)),\n        i;\n\n    /* Oneofs */ if (descriptor.oneofDecl)\n        for (i = 0; i < descriptor.oneofDecl.length; ++i)\n            type.add(OneOf.fromDescriptor(descriptor.oneofDecl[i]));\n    /* Fields */ if (descriptor.field)\n        for (i = 0; i < descriptor.field.length; ++i) {\n            var field = Field.fromDescriptor(descriptor.field[i], syntax);\n            type.add(field);\n            if (descriptor.field[i].hasOwnProperty(\"oneofIndex\")) // eslint-disable-line no-prototype-builtins\n                type.oneofsArray[descriptor.field[i].oneofIndex].add(field);\n        }\n    /* Extension fields */ if (descriptor.extension)\n        for (i = 0; i < descriptor.extension.length; ++i)\n            type.add(Field.fromDescriptor(descriptor.extension[i], syntax));\n    /* Nested types */ if (descriptor.nestedType)\n        for (i = 0; i < descriptor.nestedType.length; ++i) {\n            type.add(Type.fromDescriptor(descriptor.nestedType[i], syntax));\n            if (descriptor.nestedType[i].options && descriptor.nestedType[i].options.mapEntry)\n                type.setOption(\"map_entry\", true);\n        }\n    /* Nested enums */ if (descriptor.enumType)\n        for (i = 0; i < descriptor.enumType.length; ++i)\n            type.add(Enum.fromDescriptor(descriptor.enumType[i]));\n    /* Extension ranges */ if (descriptor.extensionRange && descriptor.extensionRange.length) {\n        type.extensions = [];\n        for (i = 0; i < descriptor.extensionRange.length; ++i)\n            type.extensions.push([ descriptor.extensionRange[i].start, descriptor.extensionRange[i].end ]);\n    }\n    /* Reserved... */ if (descriptor.reservedRange && descriptor.reservedRange.length || descriptor.reservedName && descriptor.reservedName.length) {\n        type.reserved = [];\n        /* Ranges */ if (descriptor.reservedRange)\n            for (i = 0; i < descriptor.reservedRange.length; ++i)\n                type.reserved.push([ descriptor.reservedRange[i].start, descriptor.reservedRange[i].end ]);\n        /* Names */ if (descriptor.reservedName)\n            for (i = 0; i < descriptor.reservedName.length; ++i)\n                type.reserved.push(descriptor.reservedName[i]);\n    }\n\n    return type;\n};\n\n/**\n * Converts a type to a descriptor.\n * @returns {Message<IDescriptorProto>} Descriptor\n * @param {string} [syntax=\"proto2\"] Syntax\n */\nType.prototype.toDescriptor = function toDescriptor(syntax) {\n    var descriptor = exports.DescriptorProto.create({ name: this.name }),\n        i;\n\n    /* Fields */ for (i = 0; i < this.fieldsArray.length; ++i) {\n        var fieldDescriptor;\n        descriptor.field.push(fieldDescriptor = this._fieldsArray[i].toDescriptor(syntax));\n        if (this._fieldsArray[i] instanceof MapField) { // map fields are repeated FieldNameEntry\n            var keyType = toDescriptorType(this._fieldsArray[i].keyType, this._fieldsArray[i].resolvedKeyType),\n                valueType = toDescriptorType(this._fieldsArray[i].type, this._fieldsArray[i].resolvedType),\n                valueTypeName = valueType === /* type */ 11 || valueType === /* enum */ 14\n                    ? this._fieldsArray[i].resolvedType && shortname(this.parent, this._fieldsArray[i].resolvedType) || this._fieldsArray[i].type\n                    : undefined;\n            descriptor.nestedType.push(exports.DescriptorProto.create({\n                name: fieldDescriptor.typeName,\n                field: [\n                    exports.FieldDescriptorProto.create({ name: \"key\", number: 1, label: 1, type: keyType }), // can't reference a type or enum\n                    exports.FieldDescriptorProto.create({ name: \"value\", number: 2, label: 1, type: valueType, typeName: valueTypeName })\n                ],\n                options: exports.MessageOptions.create({ mapEntry: true })\n            }));\n        }\n    }\n    /* Oneofs */ for (i = 0; i < this.oneofsArray.length; ++i)\n        descriptor.oneofDecl.push(this._oneofsArray[i].toDescriptor());\n    /* Nested... */ for (i = 0; i < this.nestedArray.length; ++i) {\n        /* Extension fields */ if (this._nestedArray[i] instanceof Field)\n            descriptor.field.push(this._nestedArray[i].toDescriptor(syntax));\n        /* Types */ else if (this._nestedArray[i] instanceof Type)\n            descriptor.nestedType.push(this._nestedArray[i].toDescriptor(syntax));\n        /* Enums */ else if (this._nestedArray[i] instanceof Enum)\n            descriptor.enumType.push(this._nestedArray[i].toDescriptor());\n        // plain nested namespaces become packages instead in Root#toDescriptor\n    }\n    /* Extension ranges */ if (this.extensions)\n        for (i = 0; i < this.extensions.length; ++i)\n            descriptor.extensionRange.push(exports.DescriptorProto.ExtensionRange.create({ start: this.extensions[i][0], end: this.extensions[i][1] }));\n    /* Reserved... */ if (this.reserved)\n        for (i = 0; i < this.reserved.length; ++i)\n            /* Names */ if (typeof this.reserved[i] === \"string\")\n                descriptor.reservedName.push(this.reserved[i]);\n            /* Ranges */ else\n                descriptor.reservedRange.push(exports.DescriptorProto.ReservedRange.create({ start: this.reserved[i][0], end: this.reserved[i][1] }));\n\n    descriptor.options = toDescriptorOptions(this.options, exports.MessageOptions);\n\n    return descriptor;\n};\n\n// --- Field ---\n\n/**\n * Properties of a FieldDescriptorProto message.\n * @interface IFieldDescriptorProto\n * @property {string} [name] Field name\n * @property {number} [number] Field id\n * @property {IFieldDescriptorProtoLabel} [label] Field rule\n * @property {IFieldDescriptorProtoType} [type] Field basic type\n * @property {string} [typeName] Field type name\n * @property {string} [extendee] Extended type name\n * @property {string} [defaultValue] Literal default value\n * @property {number} [oneofIndex] Oneof index if part of a oneof\n * @property {*} [jsonName] Not supported\n * @property {IFieldOptions} [options] Field options\n */\n\n/**\n * Values of the FieldDescriptorProto.Label enum.\n * @typedef IFieldDescriptorProtoLabel\n * @type {number}\n * @property {number} LABEL_OPTIONAL=1\n * @property {number} LABEL_REQUIRED=2\n * @property {number} LABEL_REPEATED=3\n */\n\n/**\n * Values of the FieldDescriptorProto.Type enum.\n * @typedef IFieldDescriptorProtoType\n * @type {number}\n * @property {number} TYPE_DOUBLE=1\n * @property {number} TYPE_FLOAT=2\n * @property {number} TYPE_INT64=3\n * @property {number} TYPE_UINT64=4\n * @property {number} TYPE_INT32=5\n * @property {number} TYPE_FIXED64=6\n * @property {number} TYPE_FIXED32=7\n * @property {number} TYPE_BOOL=8\n * @property {number} TYPE_STRING=9\n * @property {number} TYPE_GROUP=10\n * @property {number} TYPE_MESSAGE=11\n * @property {number} TYPE_BYTES=12\n * @property {number} TYPE_UINT32=13\n * @property {number} TYPE_ENUM=14\n * @property {number} TYPE_SFIXED32=15\n * @property {number} TYPE_SFIXED64=16\n * @property {number} TYPE_SINT32=17\n * @property {number} TYPE_SINT64=18\n */\n\n/**\n * Properties of a FieldOptions message.\n * @interface IFieldOptions\n * @property {boolean} [packed] Whether packed or not (defaults to `false` for proto2 and `true` for proto3)\n * @property {IFieldOptionsJSType} [jstype] JavaScript value type (not used by protobuf.js)\n */\n\n/**\n * Values of the FieldOptions.JSType enum.\n * @typedef IFieldOptionsJSType\n * @type {number}\n * @property {number} JS_NORMAL=0\n * @property {number} JS_STRING=1\n * @property {number} JS_NUMBER=2\n */\n\n// copied here from parse.js\nvar numberRe = /^(?![eE])[0-9]*(?:\\.[0-9]*)?(?:[eE][+-]?[0-9]+)?$/;\n\n/**\n * Creates a field from a descriptor.\n * @param {IFieldDescriptorProto|Reader|Uint8Array} descriptor Descriptor\n * @param {string} [syntax=\"proto2\"] Syntax\n * @returns {Field} Field instance\n */\nField.fromDescriptor = function fromDescriptor(descriptor, syntax) {\n\n    // Decode the descriptor message if specified as a buffer:\n    if (typeof descriptor.length === \"number\")\n        descriptor = exports.DescriptorProto.decode(descriptor);\n\n    if (typeof descriptor.number !== \"number\")\n        throw Error(\"missing field id\");\n\n    // Rewire field type\n    var fieldType;\n    if (descriptor.typeName && descriptor.typeName.length)\n        fieldType = descriptor.typeName;\n    else\n        fieldType = fromDescriptorType(descriptor.type);\n\n    // Rewire field rule\n    var fieldRule;\n    switch (descriptor.label) {\n        // 0 is reserved for errors\n        case 1: fieldRule = undefined; break;\n        case 2: fieldRule = \"required\"; break;\n        case 3: fieldRule = \"repeated\"; break;\n        default: throw Error(\"illegal label: \" + descriptor.label);\n    }\n\n\tvar extendee = descriptor.extendee;\n\tif (descriptor.extendee !== undefined) {\n\t\textendee = extendee.length ? extendee : undefined;\n\t}\n    var field = new Field(\n        descriptor.name.length ? descriptor.name : \"field\" + descriptor.number,\n        descriptor.number,\n        fieldType,\n        fieldRule,\n        extendee\n    );\n\n    field.options = fromDescriptorOptions(descriptor.options, exports.FieldOptions);\n\n    if (descriptor.defaultValue && descriptor.defaultValue.length) {\n        var defaultValue = descriptor.defaultValue;\n        switch (defaultValue) {\n            case \"true\": case \"TRUE\":\n                defaultValue = true;\n                break;\n            case \"false\": case \"FALSE\":\n                defaultValue = false;\n                break;\n            default:\n                var match = numberRe.exec(defaultValue);\n                if (match)\n                    defaultValue = parseInt(defaultValue); // eslint-disable-line radix\n                break;\n        }\n        field.setOption(\"default\", defaultValue);\n    }\n\n    if (packableDescriptorType(descriptor.type)) {\n        if (syntax === \"proto3\") { // defaults to packed=true (internal preset is packed=true)\n            if (descriptor.options && !descriptor.options.packed)\n                field.setOption(\"packed\", false);\n        } else if (!(descriptor.options && descriptor.options.packed)) // defaults to packed=false\n            field.setOption(\"packed\", false);\n    }\n\n    return field;\n};\n\n/**\n * Converts a field to a descriptor.\n * @returns {Message<IFieldDescriptorProto>} Descriptor\n * @param {string} [syntax=\"proto2\"] Syntax\n */\nField.prototype.toDescriptor = function toDescriptor(syntax) {\n    var descriptor = exports.FieldDescriptorProto.create({ name: this.name, number: this.id });\n\n    if (this.map) {\n\n        descriptor.type = 11; // message\n        descriptor.typeName = $protobuf.util.ucFirst(this.name); // fieldName -> FieldNameEntry (built in Type#toDescriptor)\n        descriptor.label = 3; // repeated\n\n    } else {\n\n        // Rewire field type\n        switch (descriptor.type = toDescriptorType(this.type, this.resolve().resolvedType)) {\n            case 10: // group\n            case 11: // type\n            case 14: // enum\n                descriptor.typeName = this.resolvedType ? shortname(this.parent, this.resolvedType) : this.type;\n                break;\n        }\n\n        // Rewire field rule\n        switch (this.rule) {\n            case \"repeated\": descriptor.label = 3; break;\n            case \"required\": descriptor.label = 2; break;\n            default: descriptor.label = 1; break;\n        }\n\n    }\n\n    // Handle extension field\n    descriptor.extendee = this.extensionField ? this.extensionField.parent.fullName : this.extend;\n\n    // Handle part of oneof\n    if (this.partOf)\n        if ((descriptor.oneofIndex = this.parent.oneofsArray.indexOf(this.partOf)) < 0)\n            throw Error(\"missing oneof\");\n\n    if (this.options) {\n        descriptor.options = toDescriptorOptions(this.options, exports.FieldOptions);\n        if (this.options[\"default\"] != null)\n            descriptor.defaultValue = String(this.options[\"default\"]);\n    }\n\n    if (syntax === \"proto3\") { // defaults to packed=true\n        if (!this.packed)\n            (descriptor.options || (descriptor.options = exports.FieldOptions.create())).packed = false;\n    } else if (this.packed) // defaults to packed=false\n        (descriptor.options || (descriptor.options = exports.FieldOptions.create())).packed = true;\n\n    return descriptor;\n};\n\n// --- Enum ---\n\n/**\n * Properties of an EnumDescriptorProto message.\n * @interface IEnumDescriptorProto\n * @property {string} [name] Enum name\n * @property {IEnumValueDescriptorProto[]} [value] Enum values\n * @property {IEnumOptions} [options] Enum options\n */\n\n/**\n * Properties of an EnumValueDescriptorProto message.\n * @interface IEnumValueDescriptorProto\n * @property {string} [name] Name\n * @property {number} [number] Value\n * @property {*} [options] Not supported\n */\n\n/**\n * Properties of an EnumOptions message.\n * @interface IEnumOptions\n * @property {boolean} [allowAlias] Whether aliases are allowed\n * @property {boolean} [deprecated]\n */\n\nvar unnamedEnumIndex = 0;\n\n/**\n * Creates an enum from a descriptor.\n * @param {IEnumDescriptorProto|Reader|Uint8Array} descriptor Descriptor\n * @returns {Enum} Enum instance\n */\nEnum.fromDescriptor = function fromDescriptor(descriptor) {\n\n    // Decode the descriptor message if specified as a buffer:\n    if (typeof descriptor.length === \"number\")\n        descriptor = exports.EnumDescriptorProto.decode(descriptor);\n\n    // Construct values object\n    var values = {};\n    if (descriptor.value)\n        for (var i = 0; i < descriptor.value.length; ++i) {\n            var name  = descriptor.value[i].name,\n                value = descriptor.value[i].number || 0;\n            values[name && name.length ? name : \"NAME\" + value] = value;\n        }\n\n    return new Enum(\n        descriptor.name && descriptor.name.length ? descriptor.name : \"Enum\" + unnamedEnumIndex++,\n        values,\n        fromDescriptorOptions(descriptor.options, exports.EnumOptions)\n    );\n};\n\n/**\n * Converts an enum to a descriptor.\n * @returns {Message<IEnumDescriptorProto>} Descriptor\n */\nEnum.prototype.toDescriptor = function toDescriptor() {\n\n    // Values\n    var values = [];\n    for (var i = 0, ks = Object.keys(this.values); i < ks.length; ++i)\n        values.push(exports.EnumValueDescriptorProto.create({ name: ks[i], number: this.values[ks[i]] }));\n\n    return exports.EnumDescriptorProto.create({\n        name: this.name,\n        value: values,\n        options: toDescriptorOptions(this.options, exports.EnumOptions)\n    });\n};\n\n// --- OneOf ---\n\n/**\n * Properties of a OneofDescriptorProto message.\n * @interface IOneofDescriptorProto\n * @property {string} [name] Oneof name\n * @property {*} [options] Not supported\n */\n\nvar unnamedOneofIndex = 0;\n\n/**\n * Creates a oneof from a descriptor.\n * @param {IOneofDescriptorProto|Reader|Uint8Array} descriptor Descriptor\n * @returns {OneOf} OneOf instance\n */\nOneOf.fromDescriptor = function fromDescriptor(descriptor) {\n\n    // Decode the descriptor message if specified as a buffer:\n    if (typeof descriptor.length === \"number\")\n        descriptor = exports.OneofDescriptorProto.decode(descriptor);\n\n    return new OneOf(\n        // unnamedOneOfIndex is global, not per type, because we have no ref to a type here\n        descriptor.name && descriptor.name.length ? descriptor.name : \"oneof\" + unnamedOneofIndex++\n        // fromDescriptorOptions(descriptor.options, exports.OneofOptions) - only uninterpreted_option\n    );\n};\n\n/**\n * Converts a oneof to a descriptor.\n * @returns {Message<IOneofDescriptorProto>} Descriptor\n */\nOneOf.prototype.toDescriptor = function toDescriptor() {\n    return exports.OneofDescriptorProto.create({\n        name: this.name\n        // options: toDescriptorOptions(this.options, exports.OneofOptions) - only uninterpreted_option\n    });\n};\n\n// --- Service ---\n\n/**\n * Properties of a ServiceDescriptorProto message.\n * @interface IServiceDescriptorProto\n * @property {string} [name] Service name\n * @property {IMethodDescriptorProto[]} [method] Methods\n * @property {IServiceOptions} [options] Options\n */\n\n/**\n * Properties of a ServiceOptions message.\n * @interface IServiceOptions\n * @property {boolean} [deprecated]\n */\n\nvar unnamedServiceIndex = 0;\n\n/**\n * Creates a service from a descriptor.\n * @param {IServiceDescriptorProto|Reader|Uint8Array} descriptor Descriptor\n * @returns {Service} Service instance\n */\nService.fromDescriptor = function fromDescriptor(descriptor) {\n\n    // Decode the descriptor message if specified as a buffer:\n    if (typeof descriptor.length === \"number\")\n        descriptor = exports.ServiceDescriptorProto.decode(descriptor);\n\n    var service = new Service(descriptor.name && descriptor.name.length ? descriptor.name : \"Service\" + unnamedServiceIndex++, fromDescriptorOptions(descriptor.options, exports.ServiceOptions));\n    if (descriptor.method)\n        for (var i = 0; i < descriptor.method.length; ++i)\n            service.add(Method.fromDescriptor(descriptor.method[i]));\n\n    return service;\n};\n\n/**\n * Converts a service to a descriptor.\n * @returns {Message<IServiceDescriptorProto>} Descriptor\n */\nService.prototype.toDescriptor = function toDescriptor() {\n\n    // Methods\n    var methods = [];\n    for (var i = 0; i < this.methodsArray.length; ++i)\n        methods.push(this._methodsArray[i].toDescriptor());\n\n    return exports.ServiceDescriptorProto.create({\n        name: this.name,\n        method: methods,\n        options: toDescriptorOptions(this.options, exports.ServiceOptions)\n    });\n};\n\n// --- Method ---\n\n/**\n * Properties of a MethodDescriptorProto message.\n * @interface IMethodDescriptorProto\n * @property {string} [name] Method name\n * @property {string} [inputType] Request type name\n * @property {string} [outputType] Response type name\n * @property {IMethodOptions} [options] Not supported\n * @property {boolean} [clientStreaming=false] Whether requests are streamed\n * @property {boolean} [serverStreaming=false] Whether responses are streamed\n */\n\n/**\n * Properties of a MethodOptions message.\n * @interface IMethodOptions\n * @property {boolean} [deprecated]\n */\n\nvar unnamedMethodIndex = 0;\n\n/**\n * Creates a method from a descriptor.\n * @param {IMethodDescriptorProto|Reader|Uint8Array} descriptor Descriptor\n * @returns {Method} Reflected method instance\n */\nMethod.fromDescriptor = function fromDescriptor(descriptor) {\n\n    // Decode the descriptor message if specified as a buffer:\n    if (typeof descriptor.length === \"number\")\n        descriptor = exports.MethodDescriptorProto.decode(descriptor);\n\n    return new Method(\n        // unnamedMethodIndex is global, not per service, because we have no ref to a service here\n        descriptor.name && descriptor.name.length ? descriptor.name : \"Method\" + unnamedMethodIndex++,\n        \"rpc\",\n        descriptor.inputType,\n        descriptor.outputType,\n        Boolean(descriptor.clientStreaming),\n        Boolean(descriptor.serverStreaming),\n        fromDescriptorOptions(descriptor.options, exports.MethodOptions)\n    );\n};\n\n/**\n * Converts a method to a descriptor.\n * @returns {Message<IMethodDescriptorProto>} Descriptor\n */\nMethod.prototype.toDescriptor = function toDescriptor() {\n    return exports.MethodDescriptorProto.create({\n        name: this.name,\n        inputType: this.resolvedRequestType ? this.resolvedRequestType.fullName : this.requestType,\n        outputType: this.resolvedResponseType ? this.resolvedResponseType.fullName : this.responseType,\n        clientStreaming: this.requestStream,\n        serverStreaming: this.responseStream,\n        options: toDescriptorOptions(this.options, exports.MethodOptions)\n    });\n};\n\n// --- utility ---\n\n// Converts a descriptor type to a protobuf.js basic type\nfunction fromDescriptorType(type) {\n    switch (type) {\n        // 0 is reserved for errors\n        case 1: return \"double\";\n        case 2: return \"float\";\n        case 3: return \"int64\";\n        case 4: return \"uint64\";\n        case 5: return \"int32\";\n        case 6: return \"fixed64\";\n        case 7: return \"fixed32\";\n        case 8: return \"bool\";\n        case 9: return \"string\";\n        case 12: return \"bytes\";\n        case 13: return \"uint32\";\n        case 15: return \"sfixed32\";\n        case 16: return \"sfixed64\";\n        case 17: return \"sint32\";\n        case 18: return \"sint64\";\n    }\n    throw Error(\"illegal type: \" + type);\n}\n\n// Tests if a descriptor type is packable\nfunction packableDescriptorType(type) {\n    switch (type) {\n        case 1: // double\n        case 2: // float\n        case 3: // int64\n        case 4: // uint64\n        case 5: // int32\n        case 6: // fixed64\n        case 7: // fixed32\n        case 8: // bool\n        case 13: // uint32\n        case 14: // enum (!)\n        case 15: // sfixed32\n        case 16: // sfixed64\n        case 17: // sint32\n        case 18: // sint64\n            return true;\n    }\n    return false;\n}\n\n// Converts a protobuf.js basic type to a descriptor type\nfunction toDescriptorType(type, resolvedType) {\n    switch (type) {\n        // 0 is reserved for errors\n        case \"double\": return 1;\n        case \"float\": return 2;\n        case \"int64\": return 3;\n        case \"uint64\": return 4;\n        case \"int32\": return 5;\n        case \"fixed64\": return 6;\n        case \"fixed32\": return 7;\n        case \"bool\": return 8;\n        case \"string\": return 9;\n        case \"bytes\": return 12;\n        case \"uint32\": return 13;\n        case \"sfixed32\": return 15;\n        case \"sfixed64\": return 16;\n        case \"sint32\": return 17;\n        case \"sint64\": return 18;\n    }\n    if (resolvedType instanceof Enum)\n        return 14;\n    if (resolvedType instanceof Type)\n        return resolvedType.group ? 10 : 11;\n    throw Error(\"illegal type: \" + type);\n}\n\n// Converts descriptor options to an options object\nfunction fromDescriptorOptions(options, type) {\n    if (!options)\n        return undefined;\n    var out = [];\n    for (var i = 0, field, key, val; i < type.fieldsArray.length; ++i)\n        if ((key = (field = type._fieldsArray[i]).name) !== \"uninterpretedOption\")\n            if (options.hasOwnProperty(key)) { // eslint-disable-line no-prototype-builtins\n                val = options[key];\n                if (field.resolvedType instanceof Enum && typeof val === \"number\" && field.resolvedType.valuesById[val] !== undefined)\n                    val = field.resolvedType.valuesById[val];\n                out.push(underScore(key), val);\n            }\n    return out.length ? $protobuf.util.toObject(out) : undefined;\n}\n\n// Converts an options object to descriptor options\nfunction toDescriptorOptions(options, type) {\n    if (!options)\n        return undefined;\n    var out = [];\n    for (var i = 0, ks = Object.keys(options), key, val; i < ks.length; ++i) {\n        val = options[key = ks[i]];\n        if (key === \"default\")\n            continue;\n        var field = type.fields[key];\n        if (!field && !(field = type.fields[key = $protobuf.util.camelCase(key)]))\n            continue;\n        out.push(key, val);\n    }\n    return out.length ? type.fromObject($protobuf.util.toObject(out)) : undefined;\n}\n\n// Calculates the shortest relative path from `from` to `to`.\nfunction shortname(from, to) {\n    var fromPath = from.fullName.split(\".\"),\n        toPath = to.fullName.split(\".\"),\n        i = 0,\n        j = 0,\n        k = toPath.length - 1;\n    if (!(from instanceof Root) && to instanceof Namespace)\n        while (i < fromPath.length && j < k && fromPath[i] === toPath[j]) {\n            var other = to.lookup(fromPath[i++], true);\n            if (other !== null && other !== to)\n                break;\n            ++j;\n        }\n    else\n        for (; i < fromPath.length && j < k && fromPath[i] === toPath[j]; ++i, ++j);\n    return toPath.slice(j).join(\".\");\n}\n\n// copied here from cli/targets/proto.js\nfunction underScore(str) {\n    return str.substring(0,1)\n         + str.substring(1)\n               .replace(/([A-Z])(?=[a-z]|$)/g, function($0, $1) { return \"_\" + $1.toLowerCase(); });\n}\n\n// --- exports ---\n\n/**\n * Reflected file descriptor set.\n * @name FileDescriptorSet\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected file descriptor proto.\n * @name FileDescriptorProto\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected descriptor proto.\n * @name DescriptorProto\n * @type {Type}\n * @property {Type} ExtensionRange\n * @property {Type} ReservedRange\n * @const\n * @tstype $protobuf.Type & {\n *     ExtensionRange: $protobuf.Type,\n *     ReservedRange: $protobuf.Type\n * }\n */\n\n/**\n * Reflected field descriptor proto.\n * @name FieldDescriptorProto\n * @type {Type}\n * @property {Enum} Label\n * @property {Enum} Type\n * @const\n * @tstype $protobuf.Type & {\n *     Label: $protobuf.Enum,\n *     Type: $protobuf.Enum\n * }\n */\n\n/**\n * Reflected oneof descriptor proto.\n * @name OneofDescriptorProto\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected enum descriptor proto.\n * @name EnumDescriptorProto\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected service descriptor proto.\n * @name ServiceDescriptorProto\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected enum value descriptor proto.\n * @name EnumValueDescriptorProto\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected method descriptor proto.\n * @name MethodDescriptorProto\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected file options.\n * @name FileOptions\n * @type {Type}\n * @property {Enum} OptimizeMode\n * @const\n * @tstype $protobuf.Type & {\n *     OptimizeMode: $protobuf.Enum\n * }\n */\n\n/**\n * Reflected message options.\n * @name MessageOptions\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected field options.\n * @name FieldOptions\n * @type {Type}\n * @property {Enum} CType\n * @property {Enum} JSType\n * @const\n * @tstype $protobuf.Type & {\n *     CType: $protobuf.Enum,\n *     JSType: $protobuf.Enum\n * }\n */\n\n/**\n * Reflected oneof options.\n * @name OneofOptions\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected enum options.\n * @name EnumOptions\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected enum value options.\n * @name EnumValueOptions\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected service options.\n * @name ServiceOptions\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected method options.\n * @name MethodOptions\n * @type {Type}\n * @const\n * @tstype $protobuf.Type\n */\n\n/**\n * Reflected uninterpretet option.\n * @name UninterpretedOption\n * @type {Type}\n * @property {Type} NamePart\n * @const\n * @tstype $protobuf.Type & {\n *     NamePart: $protobuf.Type\n * }\n */\n\n/**\n * Reflected source code info.\n * @name SourceCodeInfo\n * @type {Type}\n * @property {Type} Location\n * @const\n * @tstype $protobuf.Type & {\n *     Location: $protobuf.Type\n * }\n */\n\n/**\n * Reflected generated code info.\n * @name GeneratedCodeInfo\n * @type {Type}\n * @property {Type} Annotation\n * @const\n * @tstype $protobuf.Type & {\n *     Annotation: $protobuf.Type\n * }\n */\n", "\"use strict\";\n/**\n * @license\n * Copyright 2018 gRPC authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst fs = require(\"fs\");\nconst path = require(\"path\");\nconst Protobuf = require(\"protobufjs\");\nfunction addIncludePathResolver(root, includePaths) {\n    const originalResolvePath = root.resolvePath;\n    root.resolvePath = (origin, target) => {\n        if (path.isAbsolute(target)) {\n            return target;\n        }\n        for (const directory of includePaths) {\n            const fullPath = path.join(directory, target);\n            try {\n                fs.accessSync(fullPath, fs.constants.R_OK);\n                return fullPath;\n            }\n            catch (err) {\n                continue;\n            }\n        }\n        process.emitWarning(`${target} not found in any of the include paths ${includePaths}`);\n        return originalResolvePath(origin, target);\n    };\n}\nasync function loadProtosWithOptions(filename, options) {\n    const root = new Protobuf.Root();\n    options = options || {};\n    if (!!options.includeDirs) {\n        if (!Array.isArray(options.includeDirs)) {\n            return Promise.reject(new Error('The includeDirs option must be an array'));\n        }\n        addIncludePathResolver(root, options.includeDirs);\n    }\n    const loadedRoot = await root.load(filename, options);\n    loadedRoot.resolveAll();\n    return loadedRoot;\n}\nexports.loadProtosWithOptions = loadProtosWithOptions;\nfunction loadProtosWithOptionsSync(filename, options) {\n    const root = new Protobuf.Root();\n    options = options || {};\n    if (!!options.includeDirs) {\n        if (!Array.isArray(options.includeDirs)) {\n            throw new Error('The includeDirs option must be an array');\n        }\n        addIncludePathResolver(root, options.includeDirs);\n    }\n    const loadedRoot = root.loadSync(filename, options);\n    loadedRoot.resolveAll();\n    return loadedRoot;\n}\nexports.loadProtosWithOptionsSync = loadProtosWithOptionsSync;\n/**\n * Load Google's well-known proto files that aren't exposed by Protobuf.js.\n */\nfunction addCommonProtos() {\n    // Protobuf.js exposes: any, duration, empty, field_mask, struct, timestamp,\n    // and wrappers. compiler/plugin is excluded in Protobuf.js and here.\n    // Using constant strings for compatibility with tools like Webpack\n    const apiDescriptor = require('protobufjs/google/protobuf/api.json');\n    const descriptorDescriptor = require('protobufjs/google/protobuf/descriptor.json');\n    const sourceContextDescriptor = require('protobufjs/google/protobuf/source_context.json');\n    const typeDescriptor = require('protobufjs/google/protobuf/type.json');\n    Protobuf.common('api', apiDescriptor.nested.google.nested.protobuf.nested);\n    Protobuf.common('descriptor', descriptorDescriptor.nested.google.nested.protobuf.nested);\n    Protobuf.common('source_context', sourceContextDescriptor.nested.google.nested.protobuf.nested);\n    Protobuf.common('type', typeDescriptor.nested.google.nested.protobuf.nested);\n}\nexports.addCommonProtos = addCommonProtos;\n//# sourceMappingURL=util.js.map", "\"use strict\";\n/**\n * @license\n * Copyright 2018 gRPC authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst camelCase = require(\"lodash.camelcase\");\nconst Protobuf = require(\"protobufjs\");\nconst descriptor = require(\"protobufjs/ext/descriptor\");\nconst util_1 = require(\"./util\");\nfunction isAnyExtension(obj) {\n    return ('@type' in obj) && (typeof obj['@type'] === 'string');\n}\nexports.isAnyExtension = isAnyExtension;\nconst descriptorOptions = {\n    longs: String,\n    enums: String,\n    bytes: String,\n    defaults: true,\n    oneofs: true,\n    json: true,\n};\nfunction joinName(baseName, name) {\n    if (baseName === '') {\n        return name;\n    }\n    else {\n        return baseName + '.' + name;\n    }\n}\nfunction isHandledReflectionObject(obj) {\n    return (obj instanceof Protobuf.Service ||\n        obj instanceof Protobuf.Type ||\n        obj instanceof Protobuf.Enum);\n}\nfunction isNamespaceBase(obj) {\n    return obj instanceof Protobuf.Namespace || obj instanceof Protobuf.Root;\n}\nfunction getAllHandledReflectionObjects(obj, parentName) {\n    const objName = joinName(parentName, obj.name);\n    if (isHandledReflectionObject(obj)) {\n        return [[objName, obj]];\n    }\n    else {\n        if (isNamespaceBase(obj) && typeof obj.nested !== 'undefined') {\n            return Object.keys(obj.nested)\n                .map(name => {\n                return getAllHandledReflectionObjects(obj.nested[name], objName);\n            })\n                .reduce((accumulator, currentValue) => accumulator.concat(currentValue), []);\n        }\n    }\n    return [];\n}\nfunction createDeserializer(cls, options) {\n    return function deserialize(argBuf) {\n        return cls.toObject(cls.decode(argBuf), options);\n    };\n}\nfunction createSerializer(cls) {\n    return function serialize(arg) {\n        if (Array.isArray(arg)) {\n            throw new Error(`Failed to serialize message: expected object with ${cls.name} structure, got array instead`);\n        }\n        const message = cls.fromObject(arg);\n        return cls.encode(message).finish();\n    };\n}\nfunction createMethodDefinition(method, serviceName, options, fileDescriptors) {\n    /* This is only ever called after the corresponding root.resolveAll(), so we\n     * can assume that the resolved request and response types are non-null */\n    const requestType = method.resolvedRequestType;\n    const responseType = method.resolvedResponseType;\n    return {\n        path: '/' + serviceName + '/' + method.name,\n        requestStream: !!method.requestStream,\n        responseStream: !!method.responseStream,\n        requestSerialize: createSerializer(requestType),\n        requestDeserialize: createDeserializer(requestType, options),\n        responseSerialize: createSerializer(responseType),\n        responseDeserialize: createDeserializer(responseType, options),\n        // TODO(murgatroid99): Find a better way to handle this\n        originalName: camelCase(method.name),\n        requestType: createMessageDefinition(requestType, fileDescriptors),\n        responseType: createMessageDefinition(responseType, fileDescriptors),\n    };\n}\nfunction createServiceDefinition(service, name, options, fileDescriptors) {\n    const def = {};\n    for (const method of service.methodsArray) {\n        def[method.name] = createMethodDefinition(method, name, options, fileDescriptors);\n    }\n    return def;\n}\nfunction createMessageDefinition(message, fileDescriptors) {\n    const messageDescriptor = message.toDescriptor('proto3');\n    return {\n        format: 'Protocol Buffer 3 DescriptorProto',\n        type: messageDescriptor.$type.toObject(messageDescriptor, descriptorOptions),\n        fileDescriptorProtos: fileDescriptors,\n    };\n}\nfunction createEnumDefinition(enumType, fileDescriptors) {\n    const enumDescriptor = enumType.toDescriptor('proto3');\n    return {\n        format: 'Protocol Buffer 3 EnumDescriptorProto',\n        type: enumDescriptor.$type.toObject(enumDescriptor, descriptorOptions),\n        fileDescriptorProtos: fileDescriptors,\n    };\n}\n/**\n * function createDefinition(obj: Protobuf.Service, name: string, options:\n * Options): ServiceDefinition; function createDefinition(obj: Protobuf.Type,\n * name: string, options: Options): MessageTypeDefinition; function\n * createDefinition(obj: Protobuf.Enum, name: string, options: Options):\n * EnumTypeDefinition;\n */\nfunction createDefinition(obj, name, options, fileDescriptors) {\n    if (obj instanceof Protobuf.Service) {\n        return createServiceDefinition(obj, name, options, fileDescriptors);\n    }\n    else if (obj instanceof Protobuf.Type) {\n        return createMessageDefinition(obj, fileDescriptors);\n    }\n    else if (obj instanceof Protobuf.Enum) {\n        return createEnumDefinition(obj, fileDescriptors);\n    }\n    else {\n        throw new Error('Type mismatch in reflection object handling');\n    }\n}\nfunction createPackageDefinition(root, options) {\n    const def = {};\n    root.resolveAll();\n    const descriptorList = root.toDescriptor('proto3').file;\n    const bufferList = descriptorList.map(value => Buffer.from(descriptor.FileDescriptorProto.encode(value).finish()));\n    for (const [name, obj] of getAllHandledReflectionObjects(root, '')) {\n        def[name] = createDefinition(obj, name, options, bufferList);\n    }\n    return def;\n}\nfunction createPackageDefinitionFromDescriptorSet(decodedDescriptorSet, options) {\n    options = options || {};\n    const root = Protobuf.Root.fromDescriptor(decodedDescriptorSet);\n    root.resolveAll();\n    return createPackageDefinition(root, options);\n}\n/**\n * Load a .proto file with the specified options.\n * @param filename One or multiple file paths to load. Can be an absolute path\n *     or relative to an include path.\n * @param options.keepCase Preserve field names. The default is to change them\n *     to camel case.\n * @param options.longs The type that should be used to represent `long` values.\n *     Valid options are `Number` and `String`. Defaults to a `Long` object type\n *     from a library.\n * @param options.enums The type that should be used to represent `enum` values.\n *     The only valid option is `String`. Defaults to the numeric value.\n * @param options.bytes The type that should be used to represent `bytes`\n *     values. Valid options are `Array` and `String`. The default is to use\n *     `Buffer`.\n * @param options.defaults Set default values on output objects. Defaults to\n *     `false`.\n * @param options.arrays Set empty arrays for missing array values even if\n *     `defaults` is `false`. Defaults to `false`.\n * @param options.objects Set empty objects for missing object values even if\n *     `defaults` is `false`. Defaults to `false`.\n * @param options.oneofs Set virtual oneof properties to the present field's\n *     name\n * @param options.json Represent Infinity and NaN as strings in float fields,\n *     and automatically decode google.protobuf.Any values.\n * @param options.includeDirs Paths to search for imported `.proto` files.\n */\nfunction load(filename, options) {\n    return util_1.loadProtosWithOptions(filename, options).then(loadedRoot => {\n        return createPackageDefinition(loadedRoot, options);\n    });\n}\nexports.load = load;\nfunction loadSync(filename, options) {\n    const loadedRoot = util_1.loadProtosWithOptionsSync(filename, options);\n    return createPackageDefinition(loadedRoot, options);\n}\nexports.loadSync = loadSync;\nfunction fromJSON(json, options) {\n    options = options || {};\n    const loadedRoot = Protobuf.Root.fromJSON(json);\n    loadedRoot.resolveAll();\n    return createPackageDefinition(loadedRoot, options);\n}\nexports.fromJSON = fromJSON;\nfunction loadFileDescriptorSetFromBuffer(descriptorSet, options) {\n    const decodedDescriptorSet = descriptor.FileDescriptorSet.decode(descriptorSet);\n    return createPackageDefinitionFromDescriptorSet(decodedDescriptorSet, options);\n}\nexports.loadFileDescriptorSetFromBuffer = loadFileDescriptorSetFromBuffer;\nfunction loadFileDescriptorSetFromObject(descriptorSet, options) {\n    const decodedDescriptorSet = descriptor.FileDescriptorSet.fromObject(descriptorSet);\n    return createPackageDefinitionFromDescriptorSet(decodedDescriptorSet, options);\n}\nexports.loadFileDescriptorSetFromObject = loadFileDescriptorSetFromObject;\nutil_1.addCommonProtos();\n//# sourceMappingURL=index.js.map", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * @fileoverview Firebase constants.  Some of these (@defines) can be overridden at compile-time.\n */\n\nexport const CONSTANTS = {\n  /**\n   * @define {boolean} Whether this is the client Node.js SDK.\n   */\n  NODE_CLIENT: false,\n  /**\n   * @define {boolean} Whether this is the Admin Node.js SDK.\n   */\n  NODE_ADMIN: false,\n\n  /**\n   * Firebase SDK Version\n   */\n  SDK_VERSION: '${JSCORE_VERSION}'\n};\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CONSTANTS } from './constants';\n\n/**\n * Throws an error if the provided assertion is falsy\n */\nexport const assert = function (assertion: unknown, message: string): void {\n  if (!assertion) {\n    throw assertionError(message);\n  }\n};\n\n/**\n * Returns an Error object suitable for throwing.\n */\nexport const assertionError = function (message: string): Error {\n  return new Error(\n    'Firebase Database (' +\n      CONSTANTS.SDK_VERSION +\n      ') INTERNAL ASSERT FAILED: ' +\n      message\n  );\n};\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst stringToByteArray = function (str: string): number[] {\n  // TODO(user): Use native implementations if/when available\n  const out: number[] = [];\n  let p = 0;\n  for (let i = 0; i < str.length; i++) {\n    let c = str.charCodeAt(i);\n    if (c < 128) {\n      out[p++] = c;\n    } else if (c < 2048) {\n      out[p++] = (c >> 6) | 192;\n      out[p++] = (c & 63) | 128;\n    } else if (\n      (c & 0xfc00) === 0xd800 &&\n      i + 1 < str.length &&\n      (str.charCodeAt(i + 1) & 0xfc00) === 0xdc00\n    ) {\n      // Surrogate Pair\n      c = 0x10000 + ((c & 0x03ff) << 10) + (str.charCodeAt(++i) & 0x03ff);\n      out[p++] = (c >> 18) | 240;\n      out[p++] = ((c >> 12) & 63) | 128;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    } else {\n      out[p++] = (c >> 12) | 224;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    }\n  }\n  return out;\n};\n\n/**\n * Turns an array of numbers into the string given by the concatenation of the\n * characters to which the numbers correspond.\n * @param bytes Array of numbers representing characters.\n * @return Stringification of the array.\n */\nconst byteArrayToString = function (bytes: number[]): string {\n  // TODO(user): Use native implementations if/when available\n  const out: string[] = [];\n  let pos = 0,\n    c = 0;\n  while (pos < bytes.length) {\n    const c1 = bytes[pos++];\n    if (c1 < 128) {\n      out[c++] = String.fromCharCode(c1);\n    } else if (c1 > 191 && c1 < 224) {\n      const c2 = bytes[pos++];\n      out[c++] = String.fromCharCode(((c1 & 31) << 6) | (c2 & 63));\n    } else if (c1 > 239 && c1 < 365) {\n      // Surrogate Pair\n      const c2 = bytes[pos++];\n      const c3 = bytes[pos++];\n      const c4 = bytes[pos++];\n      const u =\n        (((c1 & 7) << 18) | ((c2 & 63) << 12) | ((c3 & 63) << 6) | (c4 & 63)) -\n        0x10000;\n      out[c++] = String.fromCharCode(0xd800 + (u >> 10));\n      out[c++] = String.fromCharCode(0xdc00 + (u & 1023));\n    } else {\n      const c2 = bytes[pos++];\n      const c3 = bytes[pos++];\n      out[c++] = String.fromCharCode(\n        ((c1 & 15) << 12) | ((c2 & 63) << 6) | (c3 & 63)\n      );\n    }\n  }\n  return out.join('');\n};\n\ninterface Base64 {\n  byteToCharMap_: { [key: number]: string } | null;\n  charToByteMap_: { [key: string]: number } | null;\n  byteToCharMapWebSafe_: { [key: number]: string } | null;\n  charToByteMapWebSafe_: { [key: string]: number } | null;\n  ENCODED_VALS_BASE: string;\n  readonly ENCODED_VALS: string;\n  readonly ENCODED_VALS_WEBSAFE: string;\n  HAS_NATIVE_SUPPORT: boolean;\n  encodeByteArray(input: number[] | Uint8Array, webSafe?: boolean): string;\n  encodeString(input: string, webSafe?: boolean): string;\n  decodeString(input: string, webSafe: boolean): string;\n  decodeStringToByteArray(input: string, webSafe: boolean): number[];\n  init_(): void;\n}\n\n// We define it as an object literal instead of a class because a class compiled down to es5 can't\n// be treeshaked. https://github.com/rollup/rollup/issues/1691\n// Static lookup maps, lazily populated by init_()\nexport const base64: Base64 = {\n  /**\n   * Maps bytes to characters.\n   */\n  byteToCharMap_: null,\n\n  /**\n   * Maps characters to bytes.\n   */\n  charToByteMap_: null,\n\n  /**\n   * Maps bytes to websafe characters.\n   * @private\n   */\n  byteToCharMapWebSafe_: null,\n\n  /**\n   * Maps websafe characters to bytes.\n   * @private\n   */\n  charToByteMapWebSafe_: null,\n\n  /**\n   * Our default alphabet, shared between\n   * ENCODED_VALS and ENCODED_VALS_WEBSAFE\n   */\n  ENCODED_VALS_BASE:\n    'ABCDEFGHIJKLMNOPQRSTUVWXYZ' + 'abcdefghijklmnopqrstuvwxyz' + '0123456789',\n\n  /**\n   * Our default alphabet. Value 64 (=) is special; it means \"nothing.\"\n   */\n  get ENCODED_VALS() {\n    return this.ENCODED_VALS_BASE + '+/=';\n  },\n\n  /**\n   * Our websafe alphabet.\n   */\n  get ENCODED_VALS_WEBSAFE() {\n    return this.ENCODED_VALS_BASE + '-_.';\n  },\n\n  /**\n   * Whether this browser supports the atob and btoa functions. This extension\n   * started at Mozilla but is now implemented by many browsers. We use the\n   * ASSUME_* variables to avoid pulling in the full useragent detection library\n   * but still allowing the standard per-browser compilations.\n   *\n   */\n  HAS_NATIVE_SUPPORT: typeof atob === 'function',\n\n  /**\n   * Base64-encode an array of bytes.\n   *\n   * @param input An array of bytes (numbers with\n   *     value in [0, 255]) to encode.\n   * @param webSafe Boolean indicating we should use the\n   *     alternative alphabet.\n   * @return The base64 encoded string.\n   */\n  encodeByteArray(input: number[] | Uint8Array, webSafe?: boolean): string {\n    if (!Array.isArray(input)) {\n      throw Error('encodeByteArray takes an array as a parameter');\n    }\n\n    this.init_();\n\n    const byteToCharMap = webSafe\n      ? this.byteToCharMapWebSafe_!\n      : this.byteToCharMap_!;\n\n    const output = [];\n\n    for (let i = 0; i < input.length; i += 3) {\n      const byte1 = input[i];\n      const haveByte2 = i + 1 < input.length;\n      const byte2 = haveByte2 ? input[i + 1] : 0;\n      const haveByte3 = i + 2 < input.length;\n      const byte3 = haveByte3 ? input[i + 2] : 0;\n\n      const outByte1 = byte1 >> 2;\n      const outByte2 = ((byte1 & 0x03) << 4) | (byte2 >> 4);\n      let outByte3 = ((byte2 & 0x0f) << 2) | (byte3 >> 6);\n      let outByte4 = byte3 & 0x3f;\n\n      if (!haveByte3) {\n        outByte4 = 64;\n\n        if (!haveByte2) {\n          outByte3 = 64;\n        }\n      }\n\n      output.push(\n        byteToCharMap[outByte1],\n        byteToCharMap[outByte2],\n        byteToCharMap[outByte3],\n        byteToCharMap[outByte4]\n      );\n    }\n\n    return output.join('');\n  },\n\n  /**\n   * Base64-encode a string.\n   *\n   * @param input A string to encode.\n   * @param webSafe If true, we should use the\n   *     alternative alphabet.\n   * @return The base64 encoded string.\n   */\n  encodeString(input: string, webSafe?: boolean): string {\n    // Shortcut for Mozilla browsers that implement\n    // a native base64 encoder in the form of \"btoa/atob\"\n    if (this.HAS_NATIVE_SUPPORT && !webSafe) {\n      return btoa(input);\n    }\n    return this.encodeByteArray(stringToByteArray(input), webSafe);\n  },\n\n  /**\n   * Base64-decode a string.\n   *\n   * @param input to decode.\n   * @param webSafe True if we should use the\n   *     alternative alphabet.\n   * @return string representing the decoded value.\n   */\n  decodeString(input: string, webSafe: boolean): string {\n    // Shortcut for Mozilla browsers that implement\n    // a native base64 encoder in the form of \"btoa/atob\"\n    if (this.HAS_NATIVE_SUPPORT && !webSafe) {\n      return atob(input);\n    }\n    return byteArrayToString(this.decodeStringToByteArray(input, webSafe));\n  },\n\n  /**\n   * Base64-decode a string.\n   *\n   * In base-64 decoding, groups of four characters are converted into three\n   * bytes.  If the encoder did not apply padding, the input length may not\n   * be a multiple of 4.\n   *\n   * In this case, the last group will have fewer than 4 characters, and\n   * padding will be inferred.  If the group has one or two characters, it decodes\n   * to one byte.  If the group has three characters, it decodes to two bytes.\n   *\n   * @param input Input to decode.\n   * @param webSafe True if we should use the web-safe alphabet.\n   * @return bytes representing the decoded value.\n   */\n  decodeStringToByteArray(input: string, webSafe: boolean): number[] {\n    this.init_();\n\n    const charToByteMap = webSafe\n      ? this.charToByteMapWebSafe_!\n      : this.charToByteMap_!;\n\n    const output: number[] = [];\n\n    for (let i = 0; i < input.length; ) {\n      const byte1 = charToByteMap[input.charAt(i++)];\n\n      const haveByte2 = i < input.length;\n      const byte2 = haveByte2 ? charToByteMap[input.charAt(i)] : 0;\n      ++i;\n\n      const haveByte3 = i < input.length;\n      const byte3 = haveByte3 ? charToByteMap[input.charAt(i)] : 64;\n      ++i;\n\n      const haveByte4 = i < input.length;\n      const byte4 = haveByte4 ? charToByteMap[input.charAt(i)] : 64;\n      ++i;\n\n      if (byte1 == null || byte2 == null || byte3 == null || byte4 == null) {\n        throw Error();\n      }\n\n      const outByte1 = (byte1 << 2) | (byte2 >> 4);\n      output.push(outByte1);\n\n      if (byte3 !== 64) {\n        const outByte2 = ((byte2 << 4) & 0xf0) | (byte3 >> 2);\n        output.push(outByte2);\n\n        if (byte4 !== 64) {\n          const outByte3 = ((byte3 << 6) & 0xc0) | byte4;\n          output.push(outByte3);\n        }\n      }\n    }\n\n    return output;\n  },\n\n  /**\n   * Lazy static initialization function. Called before\n   * accessing any of the static map variables.\n   * @private\n   */\n  init_() {\n    if (!this.byteToCharMap_) {\n      this.byteToCharMap_ = {};\n      this.charToByteMap_ = {};\n      this.byteToCharMapWebSafe_ = {};\n      this.charToByteMapWebSafe_ = {};\n\n      // We want quick mappings back and forth, so we precompute two maps.\n      for (let i = 0; i < this.ENCODED_VALS.length; i++) {\n        this.byteToCharMap_[i] = this.ENCODED_VALS.charAt(i);\n        this.charToByteMap_[this.byteToCharMap_[i]] = i;\n        this.byteToCharMapWebSafe_[i] = this.ENCODED_VALS_WEBSAFE.charAt(i);\n        this.charToByteMapWebSafe_[this.byteToCharMapWebSafe_[i]] = i;\n\n        // Be forgiving when decoding and correctly decode both encodings.\n        if (i >= this.ENCODED_VALS_BASE.length) {\n          this.charToByteMap_[this.ENCODED_VALS_WEBSAFE.charAt(i)] = i;\n          this.charToByteMapWebSafe_[this.ENCODED_VALS.charAt(i)] = i;\n        }\n      }\n    }\n  }\n};\n\n/**\n * URL-safe base64 encoding\n */\nexport const base64Encode = function (str: string): string {\n  const utf8Bytes = stringToByteArray(str);\n  return base64.encodeByteArray(utf8Bytes, true);\n};\n\n/**\n * URL-safe base64 encoding (without \".\" padding in the end).\n * e.g. Used in JSON Web Token (JWT) parts.\n */\nexport const base64urlEncodeWithoutPadding = function (str: string): string {\n  // Use base64url encoding and remove padding in the end (dot characters).\n  return base64Encode(str).replace(/\\./g, '');\n};\n\n/**\n * URL-safe base64 decoding\n *\n * NOTE: DO NOT use the global atob() function - it does NOT support the\n * base64Url variant encoding.\n *\n * @param str To be decoded\n * @return Decoded result, if possible\n */\nexport const base64Decode = function (str: string): string | null {\n  try {\n    return base64.decodeString(str, true);\n  } catch (e) {\n    console.error('base64Decode failed: ', e);\n  }\n  return null;\n};\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Do a deep-copy of basic JavaScript Objects or Arrays.\n */\nexport function deepCopy<T>(value: T): T {\n  return deepExtend(undefined, value) as T;\n}\n\n/**\n * Copy properties from source to target (recursively allows extension\n * of Objects and Arrays).  Scalar values in the target are over-written.\n * If target is undefined, an object of the appropriate type will be created\n * (and returned).\n *\n * We recursively copy all child properties of plain Objects in the source- so\n * that namespace- like dictionaries are merged.\n *\n * Note that the target can be a function, in which case the properties in\n * the source Object are copied onto it as static properties of the Function.\n *\n * Note: we don't merge __proto__ to prevent prototype pollution\n */\nexport function deepExtend(target: unknown, source: unknown): unknown {\n  if (!(source instanceof Object)) {\n    return source;\n  }\n\n  switch (source.constructor) {\n    case Date:\n      // Treat Dates like scalars; if the target date object had any child\n      // properties - they will be lost!\n      const dateValue = source as Date;\n      return new Date(dateValue.getTime());\n\n    case Object:\n      if (target === undefined) {\n        target = {};\n      }\n      break;\n    case Array:\n      // Always copy the array source and overwrite the target.\n      target = [];\n      break;\n\n    default:\n      // Not a plain Object - treat it as a scalar.\n      return source;\n  }\n\n  for (const prop in source) {\n    // use isValidKey to guard against prototype pollution. See https://snyk.io/vuln/SNYK-JS-LODASH-450202\n    if (!source.hasOwnProperty(prop) || !isValidKey(prop)) {\n      continue;\n    }\n    (target as Record<string, unknown>)[prop] = deepExtend(\n      (target as Record<string, unknown>)[prop],\n      (source as Record<string, unknown>)[prop]\n    );\n  }\n\n  return target;\n}\n\nfunction isValidKey(key: string): boolean {\n  return key !== '__proto__';\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport class Deferred<R> {\n  promise: Promise<R>;\n  reject: (value?: unknown) => void = () => {};\n  resolve: (value?: unknown) => void = () => {};\n  constructor() {\n    this.promise = new Promise((resolve, reject) => {\n      this.resolve = resolve as (value?: unknown) => void;\n      this.reject = reject as (value?: unknown) => void;\n    });\n  }\n\n  /**\n   * Our API internals are not promiseified and cannot because our callback APIs have subtle expectations around\n   * invoking promises inline, which Promises are forbidden to do. This method accepts an optional node-style callback\n   * and returns a node-style callback which will resolve or reject the Deferred's promise.\n   */\n  wrapCallback(\n    callback?: (error?: unknown, value?: unknown) => void\n  ): (error: unknown, value?: unknown) => void {\n    return (error, value?) => {\n      if (error) {\n        this.reject(error);\n      } else {\n        this.resolve(value);\n      }\n      if (typeof callback === 'function') {\n        // Attaching noop handler just in case developer wasn't expecting\n        // promises\n        this.promise.catch(() => {});\n\n        // Some of our callbacks don't expect a value and our own tests\n        // assert that the parameter length is 1\n        if (callback.length === 1) {\n          callback(error);\n        } else {\n          callback(error, value);\n        }\n      }\n    };\n  }\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { base64urlEncodeWithoutPadding } from './crypt';\n\n// Firebase Auth tokens contain snake_case claims following the JWT standard / convention.\n/* eslint-disable camelcase */\n\nexport type FirebaseSignInProvider =\n  | 'custom'\n  | 'email'\n  | 'password'\n  | 'phone'\n  | 'anonymous'\n  | 'google.com'\n  | 'facebook.com'\n  | 'github.com'\n  | 'twitter.com'\n  | 'microsoft.com'\n  | 'apple.com';\n\ninterface FirebaseIdToken {\n  // Always set to https://securetoken.google.com/PROJECT_ID\n  iss: string;\n\n  // Always set to PROJECT_ID\n  aud: string;\n\n  // The user's unique ID\n  sub: string;\n\n  // The token issue time, in seconds since epoch\n  iat: number;\n\n  // The token expiry time, normally 'iat' + 3600\n  exp: number;\n\n  // The user's unique ID. Must be equal to 'sub'\n  user_id: string;\n\n  // The time the user authenticated, normally 'iat'\n  auth_time: number;\n\n  // The sign in provider, only set when the provider is 'anonymous'\n  provider_id?: 'anonymous';\n\n  // The user's primary email\n  email?: string;\n\n  // The user's email verification status\n  email_verified?: boolean;\n\n  // The user's primary phone number\n  phone_number?: string;\n\n  // The user's display name\n  name?: string;\n\n  // The user's profile photo URL\n  picture?: string;\n\n  // Information on all identities linked to this user\n  firebase: {\n    // The primary sign-in provider\n    sign_in_provider: FirebaseSignInProvider;\n\n    // A map of providers to the user's list of unique identifiers from\n    // each provider\n    identities?: { [provider in FirebaseSignInProvider]?: string[] };\n  };\n\n  // Custom claims set by the developer\n  [claim: string]: unknown;\n\n  uid?: never; // Try to catch a common mistake of \"uid\" (should be \"sub\" instead).\n}\n\nexport type EmulatorMockTokenOptions = ({ user_id: string } | { sub: string }) &\n  Partial<FirebaseIdToken>;\n\nexport function createMockUserToken(\n  token: EmulatorMockTokenOptions,\n  projectId?: string\n): string {\n  if (token.uid) {\n    throw new Error(\n      'The \"uid\" field is no longer supported by mockUserToken. Please use \"sub\" instead for Firebase Auth User ID.'\n    );\n  }\n  // Unsecured JWTs use \"none\" as the algorithm.\n  const header = {\n    alg: 'none',\n    type: 'JWT'\n  };\n\n  const project = projectId || 'demo-project';\n  const iat = token.iat || 0;\n  const sub = token.sub || token.user_id;\n  if (!sub) {\n    throw new Error(\"mockUserToken must contain 'sub' or 'user_id' field!\");\n  }\n\n  const payload: FirebaseIdToken = {\n    // Set all required fields to decent defaults\n    iss: `https://securetoken.google.com/${project}`,\n    aud: project,\n    iat,\n    exp: iat + 3600,\n    auth_time: iat,\n    sub,\n    user_id: sub,\n    firebase: {\n      sign_in_provider: 'custom',\n      identities: {}\n    },\n\n    // Override with user options\n    ...token\n  };\n\n  // Unsecured JWTs use the empty string as a signature.\n  const signature = '';\n  return [\n    base64urlEncodeWithoutPadding(JSON.stringify(header)),\n    base64urlEncodeWithoutPadding(JSON.stringify(payload)),\n    signature\n  ].join('.');\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CONSTANTS } from './constants';\n\n/**\n * Returns navigator.userAgent string or '' if it's not defined.\n * @return user agent string\n */\nexport function getUA(): string {\n  if (\n    typeof navigator !== 'undefined' &&\n    typeof navigator['userAgent'] === 'string'\n  ) {\n    return navigator['userAgent'];\n  } else {\n    return '';\n  }\n}\n\n/**\n * Detect Cordova / PhoneGap / Ionic frameworks on a mobile device.\n *\n * Deliberately does not rely on checking `file://` URLs (as this fails PhoneGap\n * in the Ripple emulator) nor Cordova `onDeviceReady`, which would normally\n * wait for a callback.\n */\nexport function isMobileCordova(): boolean {\n  return (\n    typeof window !== 'undefined' &&\n    // @ts-ignore Setting up an broadly applicable index signature for Window\n    // just to deal with this case would probably be a bad idea.\n    !!(window['cordova'] || window['phonegap'] || window['PhoneGap']) &&\n    /ios|iphone|ipod|ipad|android|blackberry|iemobile/i.test(getUA())\n  );\n}\n\n/**\n * Detect Node.js.\n *\n * @return true if Node.js environment is detected.\n */\n// Node detection logic from: https://github.com/iliakan/detect-node/\nexport function isNode(): boolean {\n  try {\n    return (\n      Object.prototype.toString.call(global.process) === '[object process]'\n    );\n  } catch (e) {\n    return false;\n  }\n}\n\n/**\n * Detect Browser Environment\n */\nexport function isBrowser(): boolean {\n  return typeof self === 'object' && self.self === self;\n}\n\n/**\n * Detect browser extensions (Chrome and Firefox at least).\n */\ninterface BrowserRuntime {\n  id?: unknown;\n}\ndeclare const chrome: { runtime?: BrowserRuntime };\ndeclare const browser: { runtime?: BrowserRuntime };\nexport function isBrowserExtension(): boolean {\n  const runtime =\n    typeof chrome === 'object'\n      ? chrome.runtime\n      : typeof browser === 'object'\n      ? browser.runtime\n      : undefined;\n  return typeof runtime === 'object' && runtime.id !== undefined;\n}\n\n/**\n * Detect React Native.\n *\n * @return true if ReactNative environment is detected.\n */\nexport function isReactNative(): boolean {\n  return (\n    typeof navigator === 'object' && navigator['product'] === 'ReactNative'\n  );\n}\n\n/** Detects Electron apps. */\nexport function isElectron(): boolean {\n  return getUA().indexOf('Electron/') >= 0;\n}\n\n/** Detects Internet Explorer. */\nexport function isIE(): boolean {\n  const ua = getUA();\n  return ua.indexOf('MSIE ') >= 0 || ua.indexOf('Trident/') >= 0;\n}\n\n/** Detects Universal Windows Platform apps. */\nexport function isUWP(): boolean {\n  return getUA().indexOf('MSAppHost/') >= 0;\n}\n\n/**\n * Detect whether the current SDK build is the Node version.\n *\n * @return true if it's the Node SDK build.\n */\nexport function isNodeSdk(): boolean {\n  return CONSTANTS.NODE_CLIENT === true || CONSTANTS.NODE_ADMIN === true;\n}\n\n/** Returns true if we are running in Safari. */\nexport function isSafari(): boolean {\n  return (\n    !isNode() &&\n    navigator.userAgent.includes('Safari') &&\n    !navigator.userAgent.includes('Chrome')\n  );\n}\n\n/**\n * This method checks if indexedDB is supported by current browser/service worker context\n * @return true if indexedDB is supported by current browser/service worker context\n */\nexport function isIndexedDBAvailable(): boolean {\n  return typeof indexedDB === 'object';\n}\n\n/**\n * This method validates browser/sw context for indexedDB by opening a dummy indexedDB database and reject\n * if errors occur during the database open operation.\n *\n * @throws exception if current browser/sw context can't run idb.open (ex: Safari iframe, Firefox\n * private browsing)\n */\nexport function validateIndexedDBOpenable(): Promise<boolean> {\n  return new Promise((resolve, reject) => {\n    try {\n      let preExist: boolean = true;\n      const DB_CHECK_NAME =\n        'validate-browser-context-for-indexeddb-analytics-module';\n      const request = self.indexedDB.open(DB_CHECK_NAME);\n      request.onsuccess = () => {\n        request.result.close();\n        // delete database only when it doesn't pre-exist\n        if (!preExist) {\n          self.indexedDB.deleteDatabase(DB_CHECK_NAME);\n        }\n        resolve(true);\n      };\n      request.onupgradeneeded = () => {\n        preExist = false;\n      };\n\n      request.onerror = () => {\n        reject(request.error?.message || '');\n      };\n    } catch (error) {\n      reject(error);\n    }\n  });\n}\n\n/**\n *\n * This method checks whether cookie is enabled within current browser\n * @return true if cookie is enabled within current browser\n */\nexport function areCookiesEnabled(): boolean {\n  if (typeof navigator === 'undefined' || !navigator.cookieEnabled) {\n    return false;\n  }\n  return true;\n}\n\n/**\n * Polyfill for `globalThis` object.\n * @returns the `globalThis` object for the given environment.\n */\nexport function getGlobal(): typeof globalThis {\n  if (typeof self !== 'undefined') {\n    return self;\n  }\n  if (typeof window !== 'undefined') {\n    return window;\n  }\n  if (typeof global !== 'undefined') {\n    return global;\n  }\n  throw new Error('Unable to locate global object.');\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @fileoverview Standardized Firebase Error.\n *\n * Usage:\n *\n *   // Typescript string literals for type-safe codes\n *   type Err =\n *     'unknown' |\n *     'object-not-found'\n *     ;\n *\n *   // Closure enum for type-safe error codes\n *   // at-enum {string}\n *   var Err = {\n *     UNKNOWN: 'unknown',\n *     OBJECT_NOT_FOUND: 'object-not-found',\n *   }\n *\n *   let errors: Map<Err, string> = {\n *     'generic-error': \"Unknown error\",\n *     'file-not-found': \"Could not find file: {$file}\",\n *   };\n *\n *   // Type-safe function - must pass a valid error code as param.\n *   let error = new ErrorFactory<Err>('service', 'Service', errors);\n *\n *   ...\n *   throw error.create(Err.GENERIC);\n *   ...\n *   throw error.create(Err.FILE_NOT_FOUND, {'file': fileName});\n *   ...\n *   // Service: Could not file file: foo.txt (service/file-not-found).\n *\n *   catch (e) {\n *     assert(e.message === \"Could not find file: foo.txt.\");\n *     if (e.code === 'service/file-not-found') {\n *       console.log(\"Could not read file: \" + e['file']);\n *     }\n *   }\n */\n\nexport type ErrorMap<ErrorCode extends string> = {\n  readonly [K in ErrorCode]: string;\n};\n\nconst ERROR_NAME = 'FirebaseError';\n\nexport interface StringLike {\n  toString(): string;\n}\n\nexport interface ErrorData {\n  [key: string]: unknown;\n}\n\n// Based on code from:\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error#Custom_Error_Types\nexport class FirebaseError extends Error {\n  readonly name = ERROR_NAME;\n\n  constructor(\n    readonly code: string,\n    message: string,\n    public customData?: Record<string, unknown>\n  ) {\n    super(message);\n\n    // Fix For ES5\n    // https://github.com/Microsoft/TypeScript-wiki/blob/master/Breaking-Changes.md#extending-built-ins-like-error-array-and-map-may-no-longer-work\n    Object.setPrototypeOf(this, FirebaseError.prototype);\n\n    // Maintains proper stack trace for where our error was thrown.\n    // Only available on V8.\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, ErrorFactory.prototype.create);\n    }\n  }\n}\n\nexport class ErrorFactory<\n  ErrorCode extends string,\n  ErrorParams extends { readonly [K in ErrorCode]?: ErrorData } = {}\n> {\n  constructor(\n    private readonly service: string,\n    private readonly serviceName: string,\n    private readonly errors: ErrorMap<ErrorCode>\n  ) {}\n\n  create<K extends ErrorCode>(\n    code: K,\n    ...data: K extends keyof ErrorParams ? [ErrorParams[K]] : []\n  ): FirebaseError {\n    const customData = (data[0] as ErrorData) || {};\n    const fullCode = `${this.service}/${code}`;\n    const template = this.errors[code];\n\n    const message = template ? replaceTemplate(template, customData) : 'Error';\n    // Service Name: Error message (service/code).\n    const fullMessage = `${this.serviceName}: ${message} (${fullCode}).`;\n\n    const error = new FirebaseError(fullCode, fullMessage, customData);\n\n    return error;\n  }\n}\n\nfunction replaceTemplate(template: string, data: ErrorData): string {\n  return template.replace(PATTERN, (_, key) => {\n    const value = data[key];\n    return value != null ? String(value) : `<${key}?>`;\n  });\n}\n\nconst PATTERN = /\\{\\$([^}]+)}/g;\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Evaluates a JSON string into a javascript object.\n *\n * @param {string} str A string containing JSON.\n * @return {*} The javascript object representing the specified JSON.\n */\nexport function jsonEval(str: string): unknown {\n  return JSON.parse(str);\n}\n\n/**\n * Returns JSON representing a javascript object.\n * @param {*} data Javascript object to be stringified.\n * @return {string} The JSON contents of the object.\n */\nexport function stringify(data: unknown): string {\n  return JSON.stringify(data);\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { base64Decode } from './crypt';\nimport { jsonEval } from './json';\n\ninterface Claims {\n  [key: string]: {};\n}\n\ninterface DecodedToken {\n  header: object;\n  claims: Claims;\n  data: object;\n  signature: string;\n}\n\n/**\n * Decodes a Firebase auth. token into constituent parts.\n *\n * Notes:\n * - May return with invalid / incomplete claims if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const decode = function (token: string): DecodedToken {\n  let header = {},\n    claims: Claims = {},\n    data = {},\n    signature = '';\n\n  try {\n    const parts = token.split('.');\n    header = jsonEval(base64Decode(parts[0]) || '') as object;\n    claims = jsonEval(base64Decode(parts[1]) || '') as Claims;\n    signature = parts[2];\n    data = claims['d'] || {};\n    delete claims['d'];\n  } catch (e) {}\n\n  return {\n    header,\n    claims,\n    data,\n    signature\n  };\n};\n\ninterface DecodedToken {\n  header: object;\n  claims: Claims;\n  data: object;\n  signature: string;\n}\n\n/**\n * Decodes a Firebase auth. token and checks the validity of its time-based claims. Will return true if the\n * token is within the time window authorized by the 'nbf' (not-before) and 'iat' (issued-at) claims.\n *\n * Notes:\n * - May return a false negative if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const isValidTimestamp = function (token: string): boolean {\n  const claims: Claims = decode(token).claims;\n  const now: number = Math.floor(new Date().getTime() / 1000);\n  let validSince: number = 0,\n    validUntil: number = 0;\n\n  if (typeof claims === 'object') {\n    if (claims.hasOwnProperty('nbf')) {\n      validSince = claims['nbf'] as number;\n    } else if (claims.hasOwnProperty('iat')) {\n      validSince = claims['iat'] as number;\n    }\n\n    if (claims.hasOwnProperty('exp')) {\n      validUntil = claims['exp'] as number;\n    } else {\n      // token will expire after 24h by default\n      validUntil = validSince + 86400;\n    }\n  }\n\n  return (\n    !!now &&\n    !!validSince &&\n    !!validUntil &&\n    now >= validSince &&\n    now <= validUntil\n  );\n};\n\n/**\n * Decodes a Firebase auth. token and returns its issued at time if valid, null otherwise.\n *\n * Notes:\n * - May return null if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const issuedAtTime = function (token: string): number | null {\n  const claims: Claims = decode(token).claims;\n  if (typeof claims === 'object' && claims.hasOwnProperty('iat')) {\n    return claims['iat'] as number;\n  }\n  return null;\n};\n\n/**\n * Decodes a Firebase auth. token and checks the validity of its format. Expects a valid issued-at time.\n *\n * Notes:\n * - May return a false negative if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const isValidFormat = function (token: string): boolean {\n  const decoded = decode(token),\n    claims = decoded.claims;\n\n  return !!claims && typeof claims === 'object' && claims.hasOwnProperty('iat');\n};\n\n/**\n * Attempts to peer into an auth token and determine if it's an admin auth token by looking at the claims portion.\n *\n * Notes:\n * - May return a false negative if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const isAdmin = function (token: string): boolean {\n  const claims: Claims = decode(token).claims;\n  return typeof claims === 'object' && claims['admin'] === true;\n};\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport function contains<T extends object>(obj: T, key: string): boolean {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexport function safeGet<T extends object, K extends keyof T>(\n  obj: T,\n  key: K\n): T[K] | undefined {\n  if (Object.prototype.hasOwnProperty.call(obj, key)) {\n    return obj[key];\n  } else {\n    return undefined;\n  }\n}\n\nexport function isEmpty(obj: object): obj is {} {\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function map<K extends string, V, U>(\n  obj: { [key in K]: V },\n  fn: (value: V, key: K, obj: { [key in K]: V }) => U,\n  contextObj?: unknown\n): { [key in K]: U } {\n  const res: Partial<{ [key in K]: U }> = {};\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      res[key] = fn.call(contextObj, obj[key], key, obj);\n    }\n  }\n  return res as { [key in K]: U };\n}\n\n/**\n * Deep equal two objects. Support Arrays and Objects.\n */\nexport function deepEqual(a: object, b: object): boolean {\n  if (a === b) {\n    return true;\n  }\n\n  const aKeys = Object.keys(a);\n  const bKeys = Object.keys(b);\n  for (const k of aKeys) {\n    if (!bKeys.includes(k)) {\n      return false;\n    }\n\n    const aProp = (a as Record<string, unknown>)[k];\n    const bProp = (b as Record<string, unknown>)[k];\n    if (isObject(aProp) && isObject(bProp)) {\n      if (!deepEqual(aProp, bProp)) {\n        return false;\n      }\n    } else if (aProp !== bProp) {\n      return false;\n    }\n  }\n\n  for (const k of bKeys) {\n    if (!aKeys.includes(k)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction isObject(thing: unknown): thing is object {\n  return thing !== null && typeof thing === 'object';\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Returns a querystring-formatted string (e.g. &arg=val&arg2=val2) from a\n * params object (e.g. {arg: 'val', arg2: 'val2'})\n * Note: You must prepend it with ? when adding it to a URL.\n */\nexport function querystring(querystringParams: {\n  [key: string]: string | number;\n}): string {\n  const params = [];\n  for (const [key, value] of Object.entries(querystringParams)) {\n    if (Array.isArray(value)) {\n      value.forEach(arrayVal => {\n        params.push(\n          encodeURIComponent(key) + '=' + encodeURIComponent(arrayVal)\n        );\n      });\n    } else {\n      params.push(encodeURIComponent(key) + '=' + encodeURIComponent(value));\n    }\n  }\n  return params.length ? '&' + params.join('&') : '';\n}\n\n/**\n * Decodes a querystring (e.g. ?arg=val&arg2=val2) into a params object\n * (e.g. {arg: 'val', arg2: 'val2'})\n */\nexport function querystringDecode(querystring: string): Record<string, string> {\n  const obj: Record<string, string> = {};\n  const tokens = querystring.replace(/^\\?/, '').split('&');\n\n  tokens.forEach(token => {\n    if (token) {\n      const [key, value] = token.split('=');\n      obj[decodeURIComponent(key)] = decodeURIComponent(value);\n    }\n  });\n  return obj;\n}\n\n/**\n * Extract the query string part of a URL, including the leading question mark (if present).\n */\nexport function extractQuerystring(url: string): string {\n  const queryStart = url.indexOf('?');\n  if (!queryStart) {\n    return '';\n  }\n  const fragmentStart = url.indexOf('#', queryStart);\n  return url.substring(\n    queryStart,\n    fragmentStart > 0 ? fragmentStart : undefined\n  );\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * @fileoverview SHA-1 cryptographic hash.\n * Variable names follow the notation in FIPS PUB 180-3:\n * http://csrc.nist.gov/publications/fips/fips180-3/fips180-3_final.pdf.\n *\n * Usage:\n *   var sha1 = new sha1();\n *   sha1.update(bytes);\n *   var hash = sha1.digest();\n *\n * Performance:\n *   Chrome 23:   ~400 Mbit/s\n *   Firefox 16:  ~250 Mbit/s\n *\n */\n\n/**\n * SHA-1 cryptographic hash constructor.\n *\n * The properties declared here are discussed in the above algorithm document.\n * @constructor\n * @final\n * @struct\n */\nexport class Sha1 {\n  /**\n   * Holds the previous values of accumulated variables a-e in the compress_\n   * function.\n   * @private\n   */\n  private chain_: number[] = [];\n\n  /**\n   * A buffer holding the partially computed hash result.\n   * @private\n   */\n  private buf_: number[] = [];\n\n  /**\n   * An array of 80 bytes, each a part of the message to be hashed.  Referred to\n   * as the message schedule in the docs.\n   * @private\n   */\n  private W_: number[] = [];\n\n  /**\n   * Contains data needed to pad messages less than 64 bytes.\n   * @private\n   */\n  private pad_: number[] = [];\n\n  /**\n   * @private {number}\n   */\n  private inbuf_: number = 0;\n\n  /**\n   * @private {number}\n   */\n  private total_: number = 0;\n\n  blockSize: number;\n\n  constructor() {\n    this.blockSize = 512 / 8;\n\n    this.pad_[0] = 128;\n    for (let i = 1; i < this.blockSize; ++i) {\n      this.pad_[i] = 0;\n    }\n\n    this.reset();\n  }\n\n  reset(): void {\n    this.chain_[0] = 0x67452301;\n    this.chain_[1] = 0xefcdab89;\n    this.chain_[2] = 0x98badcfe;\n    this.chain_[3] = 0x10325476;\n    this.chain_[4] = 0xc3d2e1f0;\n\n    this.inbuf_ = 0;\n    this.total_ = 0;\n  }\n\n  /**\n   * Internal compress helper function.\n   * @param buf Block to compress.\n   * @param offset Offset of the block in the buffer.\n   * @private\n   */\n  compress_(buf: number[] | Uint8Array | string, offset?: number): void {\n    if (!offset) {\n      offset = 0;\n    }\n\n    const W = this.W_;\n\n    // get 16 big endian words\n    if (typeof buf === 'string') {\n      for (let i = 0; i < 16; i++) {\n        // TODO(user): [bug 8140122] Recent versions of Safari for Mac OS and iOS\n        // have a bug that turns the post-increment ++ operator into pre-increment\n        // during JIT compilation.  We have code that depends heavily on SHA-1 for\n        // correctness and which is affected by this bug, so I've removed all uses\n        // of post-increment ++ in which the result value is used.  We can revert\n        // this change once the Safari bug\n        // (https://bugs.webkit.org/show_bug.cgi?id=109036) has been fixed and\n        // most clients have been updated.\n        W[i] =\n          (buf.charCodeAt(offset) << 24) |\n          (buf.charCodeAt(offset + 1) << 16) |\n          (buf.charCodeAt(offset + 2) << 8) |\n          buf.charCodeAt(offset + 3);\n        offset += 4;\n      }\n    } else {\n      for (let i = 0; i < 16; i++) {\n        W[i] =\n          (buf[offset] << 24) |\n          (buf[offset + 1] << 16) |\n          (buf[offset + 2] << 8) |\n          buf[offset + 3];\n        offset += 4;\n      }\n    }\n\n    // expand to 80 words\n    for (let i = 16; i < 80; i++) {\n      const t = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16];\n      W[i] = ((t << 1) | (t >>> 31)) & 0xffffffff;\n    }\n\n    let a = this.chain_[0];\n    let b = this.chain_[1];\n    let c = this.chain_[2];\n    let d = this.chain_[3];\n    let e = this.chain_[4];\n    let f, k;\n\n    // TODO(user): Try to unroll this loop to speed up the computation.\n    for (let i = 0; i < 80; i++) {\n      if (i < 40) {\n        if (i < 20) {\n          f = d ^ (b & (c ^ d));\n          k = 0x5a827999;\n        } else {\n          f = b ^ c ^ d;\n          k = 0x6ed9eba1;\n        }\n      } else {\n        if (i < 60) {\n          f = (b & c) | (d & (b | c));\n          k = 0x8f1bbcdc;\n        } else {\n          f = b ^ c ^ d;\n          k = 0xca62c1d6;\n        }\n      }\n\n      const t = (((a << 5) | (a >>> 27)) + f + e + k + W[i]) & 0xffffffff;\n      e = d;\n      d = c;\n      c = ((b << 30) | (b >>> 2)) & 0xffffffff;\n      b = a;\n      a = t;\n    }\n\n    this.chain_[0] = (this.chain_[0] + a) & 0xffffffff;\n    this.chain_[1] = (this.chain_[1] + b) & 0xffffffff;\n    this.chain_[2] = (this.chain_[2] + c) & 0xffffffff;\n    this.chain_[3] = (this.chain_[3] + d) & 0xffffffff;\n    this.chain_[4] = (this.chain_[4] + e) & 0xffffffff;\n  }\n\n  update(bytes?: number[] | Uint8Array | string, length?: number): void {\n    // TODO(johnlenz): tighten the function signature and remove this check\n    if (bytes == null) {\n      return;\n    }\n\n    if (length === undefined) {\n      length = bytes.length;\n    }\n\n    const lengthMinusBlock = length - this.blockSize;\n    let n = 0;\n    // Using local instead of member variables gives ~5% speedup on Firefox 16.\n    const buf = this.buf_;\n    let inbuf = this.inbuf_;\n\n    // The outer while loop should execute at most twice.\n    while (n < length) {\n      // When we have no data in the block to top up, we can directly process the\n      // input buffer (assuming it contains sufficient data). This gives ~25%\n      // speedup on Chrome 23 and ~15% speedup on Firefox 16, but requires that\n      // the data is provided in large chunks (or in multiples of 64 bytes).\n      if (inbuf === 0) {\n        while (n <= lengthMinusBlock) {\n          this.compress_(bytes, n);\n          n += this.blockSize;\n        }\n      }\n\n      if (typeof bytes === 'string') {\n        while (n < length) {\n          buf[inbuf] = bytes.charCodeAt(n);\n          ++inbuf;\n          ++n;\n          if (inbuf === this.blockSize) {\n            this.compress_(buf);\n            inbuf = 0;\n            // Jump to the outer loop so we use the full-block optimization.\n            break;\n          }\n        }\n      } else {\n        while (n < length) {\n          buf[inbuf] = bytes[n];\n          ++inbuf;\n          ++n;\n          if (inbuf === this.blockSize) {\n            this.compress_(buf);\n            inbuf = 0;\n            // Jump to the outer loop so we use the full-block optimization.\n            break;\n          }\n        }\n      }\n    }\n\n    this.inbuf_ = inbuf;\n    this.total_ += length;\n  }\n\n  /** @override */\n  digest(): number[] {\n    const digest: number[] = [];\n    let totalBits = this.total_ * 8;\n\n    // Add pad 0x80 0x00*.\n    if (this.inbuf_ < 56) {\n      this.update(this.pad_, 56 - this.inbuf_);\n    } else {\n      this.update(this.pad_, this.blockSize - (this.inbuf_ - 56));\n    }\n\n    // Add # bits.\n    for (let i = this.blockSize - 1; i >= 56; i--) {\n      this.buf_[i] = totalBits & 255;\n      totalBits /= 256; // Don't use bit-shifting here!\n    }\n\n    this.compress_(this.buf_);\n\n    let n = 0;\n    for (let i = 0; i < 5; i++) {\n      for (let j = 24; j >= 0; j -= 8) {\n        digest[n] = (this.chain_[i] >> j) & 255;\n        ++n;\n      }\n    }\n    return digest;\n  }\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nexport type NextFn<T> = (value: T) => void;\nexport type ErrorFn = (error: Error) => void;\nexport type CompleteFn = () => void;\n\nexport interface Observer<T> {\n  // Called once for each value in a stream of values.\n  next: NextFn<T>;\n\n  // A stream terminates by a single call to EITHER error() or complete().\n  error: ErrorFn;\n\n  // No events will be sent to next() once complete() is called.\n  complete: CompleteFn;\n}\n\nexport type PartialObserver<T> = Partial<Observer<T>>;\n\n// TODO: Support also Unsubscribe.unsubscribe?\nexport type Unsubscribe = () => void;\n\n/**\n * The Subscribe interface has two forms - passing the inline function\n * callbacks, or a object interface with callback properties.\n */\nexport interface Subscribe<T> {\n  (next?: NextFn<T>, error?: ErrorFn, complete?: CompleteFn): Unsubscribe;\n  (observer: PartialObserver<T>): Unsubscribe;\n}\n\nexport interface Observable<T> {\n  // Subscribe method\n  subscribe: Subscribe<T>;\n}\n\nexport type Executor<T> = (observer: Observer<T>) => void;\n\n/**\n * Helper to make a Subscribe function (just like Promise helps make a\n * Thenable).\n *\n * @param executor Function which can make calls to a single Observer\n *     as a proxy.\n * @param onNoObservers Callback when count of Observers goes to zero.\n */\nexport function createSubscribe<T>(\n  executor: Executor<T>,\n  onNoObservers?: Executor<T>\n): Subscribe<T> {\n  const proxy = new ObserverProxy<T>(executor, onNoObservers);\n  return proxy.subscribe.bind(proxy);\n}\n\n/**\n * Implement fan-out for any number of Observers attached via a subscribe\n * function.\n */\nclass ObserverProxy<T> implements Observer<T> {\n  private observers: Array<Observer<T>> | undefined = [];\n  private unsubscribes: Unsubscribe[] = [];\n  private onNoObservers: Executor<T> | undefined;\n  private observerCount = 0;\n  // Micro-task scheduling by calling task.then().\n  private task = Promise.resolve();\n  private finalized = false;\n  private finalError?: Error;\n\n  /**\n   * @param executor Function which can make calls to a single Observer\n   *     as a proxy.\n   * @param onNoObservers Callback when count of Observers goes to zero.\n   */\n  constructor(executor: Executor<T>, onNoObservers?: Executor<T>) {\n    this.onNoObservers = onNoObservers;\n    // Call the executor asynchronously so subscribers that are called\n    // synchronously after the creation of the subscribe function\n    // can still receive the very first value generated in the executor.\n    this.task\n      .then(() => {\n        executor(this);\n      })\n      .catch(e => {\n        this.error(e);\n      });\n  }\n\n  next(value: T): void {\n    this.forEachObserver((observer: Observer<T>) => {\n      observer.next(value);\n    });\n  }\n\n  error(error: Error): void {\n    this.forEachObserver((observer: Observer<T>) => {\n      observer.error(error);\n    });\n    this.close(error);\n  }\n\n  complete(): void {\n    this.forEachObserver((observer: Observer<T>) => {\n      observer.complete();\n    });\n    this.close();\n  }\n\n  /**\n   * Subscribe function that can be used to add an Observer to the fan-out list.\n   *\n   * - We require that no event is sent to a subscriber sychronously to their\n   *   call to subscribe().\n   */\n  subscribe(\n    nextOrObserver?: NextFn<T> | PartialObserver<T>,\n    error?: ErrorFn,\n    complete?: CompleteFn\n  ): Unsubscribe {\n    let observer: Observer<T>;\n\n    if (\n      nextOrObserver === undefined &&\n      error === undefined &&\n      complete === undefined\n    ) {\n      throw new Error('Missing Observer.');\n    }\n\n    // Assemble an Observer object when passed as callback functions.\n    if (\n      implementsAnyMethods(nextOrObserver as { [key: string]: unknown }, [\n        'next',\n        'error',\n        'complete'\n      ])\n    ) {\n      observer = nextOrObserver as Observer<T>;\n    } else {\n      observer = {\n        next: nextOrObserver as NextFn<T>,\n        error,\n        complete\n      } as Observer<T>;\n    }\n\n    if (observer.next === undefined) {\n      observer.next = noop as NextFn<T>;\n    }\n    if (observer.error === undefined) {\n      observer.error = noop as ErrorFn;\n    }\n    if (observer.complete === undefined) {\n      observer.complete = noop as CompleteFn;\n    }\n\n    const unsub = this.unsubscribeOne.bind(this, this.observers!.length);\n\n    // Attempt to subscribe to a terminated Observable - we\n    // just respond to the Observer with the final error or complete\n    // event.\n    if (this.finalized) {\n      // eslint-disable-next-line @typescript-eslint/no-floating-promises\n      this.task.then(() => {\n        try {\n          if (this.finalError) {\n            observer.error(this.finalError);\n          } else {\n            observer.complete();\n          }\n        } catch (e) {\n          // nothing\n        }\n        return;\n      });\n    }\n\n    this.observers!.push(observer as Observer<T>);\n\n    return unsub;\n  }\n\n  // Unsubscribe is synchronous - we guarantee that no events are sent to\n  // any unsubscribed Observer.\n  private unsubscribeOne(i: number): void {\n    if (this.observers === undefined || this.observers[i] === undefined) {\n      return;\n    }\n\n    delete this.observers[i];\n\n    this.observerCount -= 1;\n    if (this.observerCount === 0 && this.onNoObservers !== undefined) {\n      this.onNoObservers(this);\n    }\n  }\n\n  private forEachObserver(fn: (observer: Observer<T>) => void): void {\n    if (this.finalized) {\n      // Already closed by previous event....just eat the additional values.\n      return;\n    }\n\n    // Since sendOne calls asynchronously - there is no chance that\n    // this.observers will become undefined.\n    for (let i = 0; i < this.observers!.length; i++) {\n      this.sendOne(i, fn);\n    }\n  }\n\n  // Call the Observer via one of it's callback function. We are careful to\n  // confirm that the observe has not been unsubscribed since this asynchronous\n  // function had been queued.\n  private sendOne(i: number, fn: (observer: Observer<T>) => void): void {\n    // Execute the callback asynchronously\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.task.then(() => {\n      if (this.observers !== undefined && this.observers[i] !== undefined) {\n        try {\n          fn(this.observers[i]);\n        } catch (e) {\n          // Ignore exceptions raised in Observers or missing methods of an\n          // Observer.\n          // Log error to console. b/31404806\n          if (typeof console !== 'undefined' && console.error) {\n            console.error(e);\n          }\n        }\n      }\n    });\n  }\n\n  private close(err?: Error): void {\n    if (this.finalized) {\n      return;\n    }\n    this.finalized = true;\n    if (err !== undefined) {\n      this.finalError = err;\n    }\n    // Proxy is no longer needed - garbage collect references\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.task.then(() => {\n      this.observers = undefined;\n      this.onNoObservers = undefined;\n    });\n  }\n}\n\n/** Turn synchronous function into one called asynchronously. */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function async(fn: Function, onError?: ErrorFn): Function {\n  return (...args: unknown[]) => {\n    Promise.resolve(true)\n      .then(() => {\n        fn(...args);\n      })\n      .catch((error: Error) => {\n        if (onError) {\n          onError(error);\n        }\n      });\n  };\n}\n\n/**\n * Return true if the object passed in implements any of the named methods.\n */\nfunction implementsAnyMethods(\n  obj: { [key: string]: unknown },\n  methods: string[]\n): boolean {\n  if (typeof obj !== 'object' || obj === null) {\n    return false;\n  }\n\n  for (const method of methods) {\n    if (method in obj && typeof obj[method] === 'function') {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nfunction noop(): void {\n  // do nothing\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Check to make sure the appropriate number of arguments are provided for a public function.\n * Throws an error if it fails.\n *\n * @param fnName The function name\n * @param minCount The minimum number of arguments to allow for the function call\n * @param maxCount The maximum number of argument to allow for the function call\n * @param argCount The actual number of arguments provided.\n */\nexport const validateArgCount = function (\n  fnName: string,\n  minCount: number,\n  maxCount: number,\n  argCount: number\n): void {\n  let argError;\n  if (argCount < minCount) {\n    argError = 'at least ' + minCount;\n  } else if (argCount > maxCount) {\n    argError = maxCount === 0 ? 'none' : 'no more than ' + maxCount;\n  }\n  if (argError) {\n    const error =\n      fnName +\n      ' failed: Was called with ' +\n      argCount +\n      (argCount === 1 ? ' argument.' : ' arguments.') +\n      ' Expects ' +\n      argError +\n      '.';\n    throw new Error(error);\n  }\n};\n\n/**\n * Generates a string to prefix an error message about failed argument validation\n *\n * @param fnName The function name\n * @param argName The name of the argument\n * @return The prefix to add to the error thrown for validation.\n */\nexport function errorPrefix(fnName: string, argName: string): string {\n  return `${fnName} failed: ${argName} argument `;\n}\n\n/**\n * @param fnName\n * @param argumentNumber\n * @param namespace\n * @param optional\n */\nexport function validateNamespace(\n  fnName: string,\n  namespace: string,\n  optional: boolean\n): void {\n  if (optional && !namespace) {\n    return;\n  }\n  if (typeof namespace !== 'string') {\n    //TODO: I should do more validation here. We only allow certain chars in namespaces.\n    throw new Error(\n      errorPrefix(fnName, 'namespace') + 'must be a valid firebase namespace.'\n    );\n  }\n}\n\nexport function validateCallback(\n  fnName: string,\n  argumentName: string,\n  // eslint-disable-next-line @typescript-eslint/ban-types\n  callback: Function,\n  optional: boolean\n): void {\n  if (optional && !callback) {\n    return;\n  }\n  if (typeof callback !== 'function') {\n    throw new Error(\n      errorPrefix(fnName, argumentName) + 'must be a valid function.'\n    );\n  }\n}\n\nexport function validateContextObject(\n  fnName: string,\n  argumentName: string,\n  context: unknown,\n  optional: boolean\n): void {\n  if (optional && !context) {\n    return;\n  }\n  if (typeof context !== 'object' || context === null) {\n    throw new Error(\n      errorPrefix(fnName, argumentName) + 'must be a valid context object.'\n    );\n  }\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from './assert';\n\n// Code originally came from goog.crypt.stringToUtf8ByteArray, but for some reason they\n// automatically replaced '\\r\\n' with '\\n', and they didn't handle surrogate pairs,\n// so it's been modified.\n\n// Note that not all Unicode characters appear as single characters in JavaScript strings.\n// fromCharCode returns the UTF-16 encoding of a character - so some Unicode characters\n// use 2 characters in Javascript.  All 4-byte UTF-8 characters begin with a first\n// character in the range 0xD800 - 0xDBFF (the first character of a so-called surrogate\n// pair).\n// See http://www.ecma-international.org/ecma-262/5.1/#sec-15.1.3\n\n/**\n * @param {string} str\n * @return {Array}\n */\nexport const stringToByteArray = function (str: string): number[] {\n  const out: number[] = [];\n  let p = 0;\n  for (let i = 0; i < str.length; i++) {\n    let c = str.charCodeAt(i);\n\n    // Is this the lead surrogate in a surrogate pair?\n    if (c >= 0xd800 && c <= 0xdbff) {\n      const high = c - 0xd800; // the high 10 bits.\n      i++;\n      assert(i < str.length, 'Surrogate pair missing trail surrogate.');\n      const low = str.charCodeAt(i) - 0xdc00; // the low 10 bits.\n      c = 0x10000 + (high << 10) + low;\n    }\n\n    if (c < 128) {\n      out[p++] = c;\n    } else if (c < 2048) {\n      out[p++] = (c >> 6) | 192;\n      out[p++] = (c & 63) | 128;\n    } else if (c < 65536) {\n      out[p++] = (c >> 12) | 224;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    } else {\n      out[p++] = (c >> 18) | 240;\n      out[p++] = ((c >> 12) & 63) | 128;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    }\n  }\n  return out;\n};\n\n/**\n * Calculate length without actually converting; useful for doing cheaper validation.\n * @param {string} str\n * @return {number}\n */\nexport const stringLength = function (str: string): number {\n  let p = 0;\n  for (let i = 0; i < str.length; i++) {\n    const c = str.charCodeAt(i);\n    if (c < 128) {\n      p++;\n    } else if (c < 2048) {\n      p += 2;\n    } else if (c >= 0xd800 && c <= 0xdbff) {\n      // Lead surrogate of a surrogate pair.  The pair together will take 4 bytes to represent.\n      p += 4;\n      i++; // skip trail surrogate.\n    } else {\n      p += 3;\n    }\n  }\n  return p;\n};\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * The amount of milliseconds to exponentially increase.\n */\nconst DEFAULT_INTERVAL_MILLIS = 1000;\n\n/**\n * The factor to backoff by.\n * Should be a number greater than 1.\n */\nconst DEFAULT_BACKOFF_FACTOR = 2;\n\n/**\n * The maximum milliseconds to increase to.\n *\n * <p>Visible for testing\n */\nexport const MAX_VALUE_MILLIS = 4 * 60 * 60 * 1000; // Four hours, like iOS and Android.\n\n/**\n * The percentage of backoff time to randomize by.\n * See\n * http://go/safe-client-behavior#step-1-determine-the-appropriate-retry-interval-to-handle-spike-traffic\n * for context.\n *\n * <p>Visible for testing\n */\nexport const RANDOM_FACTOR = 0.5;\n\n/**\n * Based on the backoff method from\n * https://github.com/google/closure-library/blob/master/closure/goog/math/exponentialbackoff.js.\n * Extracted here so we don't need to pass metadata and a stateful ExponentialBackoff object around.\n */\nexport function calculateBackoffMillis(\n  backoffCount: number,\n  intervalMillis: number = DEFAULT_INTERVAL_MILLIS,\n  backoffFactor: number = DEFAULT_BACKOFF_FACTOR\n): number {\n  // Calculates an exponentially increasing value.\n  // Deviation: calculates value from count and a constant interval, so we only need to save value\n  // and count to restore state.\n  const currBaseValue = intervalMillis * Math.pow(backoffFactor, backoffCount);\n\n  // A random \"fuzz\" to avoid waves of retries.\n  // Deviation: randomFactor is required.\n  const randomWait = Math.round(\n    // A fraction of the backoff value to add/subtract.\n    // Deviation: changes multiplication order to improve readability.\n    RANDOM_FACTOR *\n      currBaseValue *\n      // A random float (rounded to int by Math.round above) in the range [-1, 1]. Determines\n      // if we add or subtract.\n      (Math.random() - 0.5) *\n      2\n  );\n\n  // Limits backoff to max to avoid effectively permanent backoff.\n  return Math.min(MAX_VALUE_MILLIS, currBaseValue + randomWait);\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Provide English ordinal letters after a number\n */\nexport function ordinal(i: number): string {\n  if (!Number.isFinite(i)) {\n    return `${i}`;\n  }\n  return i + indicator(i);\n}\n\nfunction indicator(i: number): string {\n  i = Math.abs(i);\n  const cent = i % 100;\n  if (cent >= 10 && cent <= 20) {\n    return 'th';\n  }\n  const dec = i % 10;\n  if (dec === 1) {\n    return 'st';\n  }\n  if (dec === 2) {\n    return 'nd';\n  }\n  if (dec === 3) {\n    return 'rd';\n  }\n  return 'th';\n}\n", "/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport interface Compat<T> {\n  _delegate: T;\n}\n\nexport function getModularInstance<ExpService>(\n  service: Compat<ExpService> | ExpService\n): ExpService {\n  if (service && (service as Compat<ExpService>)._delegate) {\n    return (service as Compat<ExpService>)._delegate;\n  } else {\n    return service as ExpService;\n  }\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CONSTANTS } from './src/constants';\n\n// Overriding the constant (we should be the only ones doing this)\nCONSTANTS.NODE_CLIENT = true;\n\nexport * from './src/assert';\nexport * from './src/crypt';\nexport * from './src/constants';\nexport * from './src/deepCopy';\nexport * from './src/deferred';\nexport * from './src/emulator';\nexport * from './src/environment';\nexport * from './src/errors';\nexport * from './src/json';\nexport * from './src/jwt';\nexport * from './src/obj';\nexport * from './src/query';\nexport * from './src/sha1';\nexport * from './src/subscribe';\nexport * from './src/validation';\nexport * from './src/utf8';\nexport * from './src/exponential_backoff';\nexport * from './src/formatters';\nexport * from './src/compat';\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport {\n  InstantiationMode,\n  InstanceFactory,\n  ComponentType,\n  Dictionary,\n  Name,\n  onInstanceCreatedCallback\n} from './types';\n\n/**\n * Component for service name T, e.g. `auth`, `auth-internal`\n */\nexport class Component<T extends Name = Name> {\n  multipleInstances = false;\n  /**\n   * Properties to be added to the service namespace\n   */\n  serviceProps: Dictionary = {};\n\n  instantiationMode = InstantiationMode.LAZY;\n\n  onInstanceCreated: onInstanceCreatedCallback<T> | null = null;\n\n  /**\n   *\n   * @param name The public service name, e.g. app, auth, firestore, database\n   * @param instanceFactory Service factory responsible for creating the public interface\n   * @param type whether the service provided by the component is public or private\n   */\n  constructor(\n    readonly name: T,\n    readonly instanceFactory: InstanceFactory<T>,\n    readonly type: ComponentType\n  ) {}\n\n  setInstantiationMode(mode: InstantiationMode): this {\n    this.instantiationMode = mode;\n    return this;\n  }\n\n  setMultipleInstances(multipleInstances: boolean): this {\n    this.multipleInstances = multipleInstances;\n    return this;\n  }\n\n  setServiceProps(props: Dictionary): this {\n    this.serviceProps = props;\n    return this;\n  }\n\n  setInstanceCreatedCallback(callback: onInstanceCreatedCallback<T>): this {\n    this.onInstanceCreated = callback;\n    return this;\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport const DEFAULT_ENTRY_NAME = '[DEFAULT]';\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Deferred } from '@firebase/util';\nimport { ComponentContainer } from './component_container';\nimport { DEFAULT_ENTRY_NAME } from './constants';\nimport {\n  InitializeOptions,\n  InstantiationMode,\n  Name,\n  NameServiceMapping,\n  OnInitCallBack\n} from './types';\nimport { Component } from './component';\n\n/**\n * Provider for instance for service name T, e.g. 'auth', 'auth-internal'\n * NameServiceMapping[T] is an alias for the type of the instance\n */\nexport class Provider<T extends Name> {\n  private component: Component<T> | null = null;\n  private readonly instances: Map<string, NameServiceMapping[T]> = new Map();\n  private readonly instancesDeferred: Map<\n    string,\n    Deferred<NameServiceMapping[T]>\n  > = new Map();\n  private readonly instancesOptions: Map<string, Record<string, unknown>> =\n    new Map();\n  private onInitCallbacks: Map<string, Set<OnInitCallBack<T>>> = new Map();\n\n  constructor(\n    private readonly name: T,\n    private readonly container: ComponentContainer\n  ) {}\n\n  /**\n   * @param identifier A provider can provide mulitple instances of a service\n   * if this.component.multipleInstances is true.\n   */\n  get(identifier?: string): Promise<NameServiceMapping[T]> {\n    // if multipleInstances is not supported, use the default name\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(identifier);\n\n    if (!this.instancesDeferred.has(normalizedIdentifier)) {\n      const deferred = new Deferred<NameServiceMapping[T]>();\n      this.instancesDeferred.set(normalizedIdentifier, deferred);\n\n      if (\n        this.isInitialized(normalizedIdentifier) ||\n        this.shouldAutoInitialize()\n      ) {\n        // initialize the service if it can be auto-initialized\n        try {\n          const instance = this.getOrInitializeService({\n            instanceIdentifier: normalizedIdentifier\n          });\n          if (instance) {\n            deferred.resolve(instance);\n          }\n        } catch (e) {\n          // when the instance factory throws an exception during get(), it should not cause\n          // a fatal error. We just return the unresolved promise in this case.\n        }\n      }\n    }\n\n    return this.instancesDeferred.get(normalizedIdentifier)!.promise;\n  }\n\n  /**\n   *\n   * @param options.identifier A provider can provide mulitple instances of a service\n   * if this.component.multipleInstances is true.\n   * @param options.optional If optional is false or not provided, the method throws an error when\n   * the service is not immediately available.\n   * If optional is true, the method returns null if the service is not immediately available.\n   */\n  getImmediate(options: {\n    identifier?: string;\n    optional: true;\n  }): NameServiceMapping[T] | null;\n  getImmediate(options?: {\n    identifier?: string;\n    optional?: false;\n  }): NameServiceMapping[T];\n  getImmediate(options?: {\n    identifier?: string;\n    optional?: boolean;\n  }): NameServiceMapping[T] | null {\n    // if multipleInstances is not supported, use the default name\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(\n      options?.identifier\n    );\n    const optional = options?.optional ?? false;\n\n    if (\n      this.isInitialized(normalizedIdentifier) ||\n      this.shouldAutoInitialize()\n    ) {\n      try {\n        return this.getOrInitializeService({\n          instanceIdentifier: normalizedIdentifier\n        });\n      } catch (e) {\n        if (optional) {\n          return null;\n        } else {\n          throw e;\n        }\n      }\n    } else {\n      // In case a component is not initialized and should/can not be auto-initialized at the moment, return null if the optional flag is set, or throw\n      if (optional) {\n        return null;\n      } else {\n        throw Error(`Service ${this.name} is not available`);\n      }\n    }\n  }\n\n  getComponent(): Component<T> | null {\n    return this.component;\n  }\n\n  setComponent(component: Component<T>): void {\n    if (component.name !== this.name) {\n      throw Error(\n        `Mismatching Component ${component.name} for Provider ${this.name}.`\n      );\n    }\n\n    if (this.component) {\n      throw Error(`Component for ${this.name} has already been provided`);\n    }\n\n    this.component = component;\n\n    // return early without attempting to initialize the component if the component requires explicit initialization (calling `Provider.initialize()`)\n    if (!this.shouldAutoInitialize()) {\n      return;\n    }\n\n    // if the service is eager, initialize the default instance\n    if (isComponentEager(component)) {\n      try {\n        this.getOrInitializeService({ instanceIdentifier: DEFAULT_ENTRY_NAME });\n      } catch (e) {\n        // when the instance factory for an eager Component throws an exception during the eager\n        // initialization, it should not cause a fatal error.\n        // TODO: Investigate if we need to make it configurable, because some component may want to cause\n        // a fatal error in this case?\n      }\n    }\n\n    // Create service instances for the pending promises and resolve them\n    // NOTE: if this.multipleInstances is false, only the default instance will be created\n    // and all promises with resolve with it regardless of the identifier.\n    for (const [\n      instanceIdentifier,\n      instanceDeferred\n    ] of this.instancesDeferred.entries()) {\n      const normalizedIdentifier =\n        this.normalizeInstanceIdentifier(instanceIdentifier);\n\n      try {\n        // `getOrInitializeService()` should always return a valid instance since a component is guaranteed. use ! to make typescript happy.\n        const instance = this.getOrInitializeService({\n          instanceIdentifier: normalizedIdentifier\n        })!;\n        instanceDeferred.resolve(instance);\n      } catch (e) {\n        // when the instance factory throws an exception, it should not cause\n        // a fatal error. We just leave the promise unresolved.\n      }\n    }\n  }\n\n  clearInstance(identifier: string = DEFAULT_ENTRY_NAME): void {\n    this.instancesDeferred.delete(identifier);\n    this.instancesOptions.delete(identifier);\n    this.instances.delete(identifier);\n  }\n\n  // app.delete() will call this method on every provider to delete the services\n  // TODO: should we mark the provider as deleted?\n  async delete(): Promise<void> {\n    const services = Array.from(this.instances.values());\n\n    await Promise.all([\n      ...services\n        .filter(service => 'INTERNAL' in service) // legacy services\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        .map(service => (service as any).INTERNAL!.delete()),\n      ...services\n        .filter(service => '_delete' in service) // modularized services\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        .map(service => (service as any)._delete())\n    ]);\n  }\n\n  isComponentSet(): boolean {\n    return this.component != null;\n  }\n\n  isInitialized(identifier: string = DEFAULT_ENTRY_NAME): boolean {\n    return this.instances.has(identifier);\n  }\n\n  getOptions(identifier: string = DEFAULT_ENTRY_NAME): Record<string, unknown> {\n    return this.instancesOptions.get(identifier) || {};\n  }\n\n  initialize(opts: InitializeOptions = {}): NameServiceMapping[T] {\n    const { options = {} } = opts;\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(\n      opts.instanceIdentifier\n    );\n    if (this.isInitialized(normalizedIdentifier)) {\n      throw Error(\n        `${this.name}(${normalizedIdentifier}) has already been initialized`\n      );\n    }\n\n    if (!this.isComponentSet()) {\n      throw Error(`Component ${this.name} has not been registered yet`);\n    }\n\n    const instance = this.getOrInitializeService({\n      instanceIdentifier: normalizedIdentifier,\n      options\n    })!;\n\n    // resolve any pending promise waiting for the service instance\n    for (const [\n      instanceIdentifier,\n      instanceDeferred\n    ] of this.instancesDeferred.entries()) {\n      const normalizedDeferredIdentifier =\n        this.normalizeInstanceIdentifier(instanceIdentifier);\n      if (normalizedIdentifier === normalizedDeferredIdentifier) {\n        instanceDeferred.resolve(instance);\n      }\n    }\n\n    return instance;\n  }\n\n  /**\n   *\n   * @param callback - a function that will be invoked  after the provider has been initialized by calling provider.initialize().\n   * The function is invoked SYNCHRONOUSLY, so it should not execute any longrunning tasks in order to not block the program.\n   *\n   * @param identifier An optional instance identifier\n   * @returns a function to unregister the callback\n   */\n  onInit(callback: OnInitCallBack<T>, identifier?: string): () => void {\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(identifier);\n    const existingCallbacks =\n      this.onInitCallbacks.get(normalizedIdentifier) ??\n      new Set<OnInitCallBack<T>>();\n    existingCallbacks.add(callback);\n    this.onInitCallbacks.set(normalizedIdentifier, existingCallbacks);\n\n    const existingInstance = this.instances.get(normalizedIdentifier);\n    if (existingInstance) {\n      callback(existingInstance, normalizedIdentifier);\n    }\n\n    return () => {\n      existingCallbacks.delete(callback);\n    };\n  }\n\n  /**\n   * Invoke onInit callbacks synchronously\n   * @param instance the service instance`\n   */\n  private invokeOnInitCallbacks(\n    instance: NameServiceMapping[T],\n    identifier: string\n  ): void {\n    const callbacks = this.onInitCallbacks.get(identifier);\n    if (!callbacks) {\n      return;\n    }\n    for (const callback of callbacks) {\n      try {\n        callback(instance, identifier);\n      } catch {\n        // ignore errors in the onInit callback\n      }\n    }\n  }\n\n  private getOrInitializeService({\n    instanceIdentifier,\n    options = {}\n  }: {\n    instanceIdentifier: string;\n    options?: Record<string, unknown>;\n  }): NameServiceMapping[T] | null {\n    let instance = this.instances.get(instanceIdentifier);\n    if (!instance && this.component) {\n      instance = this.component.instanceFactory(this.container, {\n        instanceIdentifier: normalizeIdentifierForFactory(instanceIdentifier),\n        options\n      });\n      this.instances.set(instanceIdentifier, instance);\n      this.instancesOptions.set(instanceIdentifier, options);\n\n      /**\n       * Invoke onInit listeners.\n       * Note this.component.onInstanceCreated is different, which is used by the component creator,\n       * while onInit listeners are registered by consumers of the provider.\n       */\n      this.invokeOnInitCallbacks(instance, instanceIdentifier);\n\n      /**\n       * Order is important\n       * onInstanceCreated() should be called after this.instances.set(instanceIdentifier, instance); which\n       * makes `isInitialized()` return true.\n       */\n      if (this.component.onInstanceCreated) {\n        try {\n          this.component.onInstanceCreated(\n            this.container,\n            instanceIdentifier,\n            instance\n          );\n        } catch {\n          // ignore errors in the onInstanceCreatedCallback\n        }\n      }\n    }\n\n    return instance || null;\n  }\n\n  private normalizeInstanceIdentifier(\n    identifier: string = DEFAULT_ENTRY_NAME\n  ): string {\n    if (this.component) {\n      return this.component.multipleInstances ? identifier : DEFAULT_ENTRY_NAME;\n    } else {\n      return identifier; // assume multiple instances are supported before the component is provided.\n    }\n  }\n\n  private shouldAutoInitialize(): boolean {\n    return (\n      !!this.component &&\n      this.component.instantiationMode !== InstantiationMode.EXPLICIT\n    );\n  }\n}\n\n// undefined should be passed to the service factory for the default instance\nfunction normalizeIdentifierForFactory(identifier: string): string | undefined {\n  return identifier === DEFAULT_ENTRY_NAME ? undefined : identifier;\n}\n\nfunction isComponentEager<T extends Name>(component: Component<T>): boolean {\n  return component.instantiationMode === InstantiationMode.EAGER;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Provider } from './provider';\nimport { Component } from './component';\nimport { Name } from './types';\n\n/**\n * ComponentContainer that provides Providers for service name T, e.g. `auth`, `auth-internal`\n */\nexport class ComponentContainer {\n  private readonly providers = new Map<string, Provider<Name>>();\n\n  constructor(private readonly name: string) {}\n\n  /**\n   *\n   * @param component Component being added\n   * @param overwrite When a component with the same name has already been registered,\n   * if overwrite is true: overwrite the existing component with the new component and create a new\n   * provider with the new component. It can be useful in tests where you want to use different mocks\n   * for different tests.\n   * if overwrite is false: throw an exception\n   */\n  addComponent<T extends Name>(component: Component<T>): void {\n    const provider = this.getProvider(component.name);\n    if (provider.isComponentSet()) {\n      throw new Error(\n        `Component ${component.name} has already been registered with ${this.name}`\n      );\n    }\n\n    provider.setComponent(component);\n  }\n\n  addOrOverwriteComponent<T extends Name>(component: Component<T>): void {\n    const provider = this.getProvider(component.name);\n    if (provider.isComponentSet()) {\n      // delete the existing provider from the container, so we can register the new component\n      this.providers.delete(component.name);\n    }\n\n    this.addComponent(component);\n  }\n\n  /**\n   * getProvider provides a type safe interface where it can only be called with a field name\n   * present in NameServiceMapping interface.\n   *\n   * Firebase SDKs providing services should extend NameServiceMapping interface to register\n   * themselves.\n   */\n  getProvider<T extends Name>(name: T): Provider<T> {\n    if (this.providers.has(name)) {\n      return this.providers.get(name) as unknown as Provider<T>;\n    }\n\n    // create a Provider for a service that hasn't registered with Firebase\n    const provider = new Provider<T>(name, this);\n    this.providers.set(name, provider as unknown as Provider<Name>);\n\n    return provider as Provider<T>;\n  }\n\n  getProviders(): Array<Provider<Name>> {\n    return Array.from(this.providers.values());\n  }\n}\n", "/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport type LogLevelString =\n  | 'debug'\n  | 'verbose'\n  | 'info'\n  | 'warn'\n  | 'error'\n  | 'silent';\n\nexport interface LogOptions {\n  level: LogLevelString;\n}\n\nexport type LogCallback = (callbackParams: LogCallbackParams) => void;\n\nexport interface LogCallbackParams {\n  level: LogLevelString;\n  message: string;\n  args: unknown[];\n  type: string;\n}\n\n/**\n * A container for all of the Logger instances\n */\nexport const instances: Logger[] = [];\n\n/**\n * The JS SDK supports 5 log levels and also allows a user the ability to\n * silence the logs altogether.\n *\n * The order is a follows:\n * DEBUG < VERBOSE < INFO < WARN < ERROR\n *\n * All of the log types above the current log level will be captured (i.e. if\n * you set the log level to `INFO`, errors will still be logged, but `DEBUG` and\n * `VERBOSE` logs will not)\n */\nexport enum LogLevel {\n  DEBUG,\n  VERBOSE,\n  INFO,\n  WARN,\n  ERROR,\n  SILENT\n}\n\nconst levelStringToEnum: { [key in LogLevelString]: LogLevel } = {\n  'debug': LogLevel.DEBUG,\n  'verbose': LogLevel.VERBOSE,\n  'info': LogLevel.INFO,\n  'warn': LogLevel.WARN,\n  'error': LogLevel.ERROR,\n  'silent': LogLevel.SILENT\n};\n\n/**\n * The default log level\n */\nconst defaultLogLevel: LogLevel = LogLevel.INFO;\n\n/**\n * We allow users the ability to pass their own log handler. We will pass the\n * type of log, the current log level, and any other arguments passed (i.e. the\n * messages that the user wants to log) to this function.\n */\nexport type LogHandler = (\n  loggerInstance: Logger,\n  logType: LogLevel,\n  ...args: unknown[]\n) => void;\n\n/**\n * By default, `console.debug` is not displayed in the developer console (in\n * chrome). To avoid forcing users to have to opt-in to these logs twice\n * (i.e. once for firebase, and once in the console), we are sending `DEBUG`\n * logs to the `console.log` function.\n */\nconst ConsoleMethod = {\n  [LogLevel.DEBUG]: 'log',\n  [LogLevel.VERBOSE]: 'log',\n  [LogLevel.INFO]: 'info',\n  [LogLevel.WARN]: 'warn',\n  [LogLevel.ERROR]: 'error'\n};\n\n/**\n * The default log handler will forward DEBUG, VERBOSE, INFO, WARN, and ERROR\n * messages on to their corresponding console counterparts (if the log method\n * is supported by the current log level)\n */\nconst defaultLogHandler: LogHandler = (instance, logType, ...args): void => {\n  if (logType < instance.logLevel) {\n    return;\n  }\n  const now = new Date().toISOString();\n  const method = ConsoleMethod[logType as keyof typeof ConsoleMethod];\n  if (method) {\n    console[method as 'log' | 'info' | 'warn' | 'error'](\n      `[${now}]  ${instance.name}:`,\n      ...args\n    );\n  } else {\n    throw new Error(\n      `Attempted to log a message with an invalid logType (value: ${logType})`\n    );\n  }\n};\n\nexport class Logger {\n  /**\n   * Gives you an instance of a Logger to capture messages according to\n   * Firebase's logging scheme.\n   *\n   * @param name The name that the logs will be associated with\n   */\n  constructor(public name: string) {\n    /**\n     * Capture the current instance for later use\n     */\n    instances.push(this);\n  }\n\n  /**\n   * The log level of the given Logger instance.\n   */\n  private _logLevel = defaultLogLevel;\n\n  get logLevel(): LogLevel {\n    return this._logLevel;\n  }\n\n  set logLevel(val: LogLevel) {\n    if (!(val in LogLevel)) {\n      throw new TypeError(`Invalid value \"${val}\" assigned to \\`logLevel\\``);\n    }\n    this._logLevel = val;\n  }\n\n  // Workaround for setter/getter having to be the same type.\n  setLogLevel(val: LogLevel | LogLevelString): void {\n    this._logLevel = typeof val === 'string' ? levelStringToEnum[val] : val;\n  }\n\n  /**\n   * The main (internal) log handler for the Logger instance.\n   * Can be set to a new function in internal package code but not by user.\n   */\n  private _logHandler: LogHandler = defaultLogHandler;\n  get logHandler(): LogHandler {\n    return this._logHandler;\n  }\n  set logHandler(val: LogHandler) {\n    if (typeof val !== 'function') {\n      throw new TypeError('Value assigned to `logHandler` must be a function');\n    }\n    this._logHandler = val;\n  }\n\n  /**\n   * The optional, additional, user-defined log handler for the Logger instance.\n   */\n  private _userLogHandler: LogHandler | null = null;\n  get userLogHandler(): LogHandler | null {\n    return this._userLogHandler;\n  }\n  set userLogHandler(val: LogHandler | null) {\n    this._userLogHandler = val;\n  }\n\n  /**\n   * The functions below are all based on the `console` interface\n   */\n\n  debug(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.DEBUG, ...args);\n    this._logHandler(this, LogLevel.DEBUG, ...args);\n  }\n  log(...args: unknown[]): void {\n    this._userLogHandler &&\n      this._userLogHandler(this, LogLevel.VERBOSE, ...args);\n    this._logHandler(this, LogLevel.VERBOSE, ...args);\n  }\n  info(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.INFO, ...args);\n    this._logHandler(this, LogLevel.INFO, ...args);\n  }\n  warn(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.WARN, ...args);\n    this._logHandler(this, LogLevel.WARN, ...args);\n  }\n  error(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.ERROR, ...args);\n    this._logHandler(this, LogLevel.ERROR, ...args);\n  }\n}\n\nexport function setLogLevel(level: LogLevelString | LogLevel): void {\n  instances.forEach(inst => {\n    inst.setLogLevel(level);\n  });\n}\n\nexport function setUserLogHandler(\n  logCallback: LogCallback | null,\n  options?: LogOptions\n): void {\n  for (const instance of instances) {\n    let customLogLevel: LogLevel | null = null;\n    if (options && options.level) {\n      customLogLevel = levelStringToEnum[options.level];\n    }\n    if (logCallback === null) {\n      instance.userLogHandler = null;\n    } else {\n      instance.userLogHandler = (\n        instance: Logger,\n        level: LogLevel,\n        ...args: unknown[]\n      ) => {\n        const message = args\n          .map(arg => {\n            if (arg == null) {\n              return null;\n            } else if (typeof arg === 'string') {\n              return arg;\n            } else if (typeof arg === 'number' || typeof arg === 'boolean') {\n              return arg.toString();\n            } else if (arg instanceof Error) {\n              return arg.message;\n            } else {\n              try {\n                return JSON.stringify(arg);\n              } catch (ignored) {\n                return null;\n              }\n            }\n          })\n          .filter(arg => arg)\n          .join(' ');\n        if (level >= (customLogLevel ?? instance.logLevel)) {\n          logCallback({\n            level: LogLevel[level].toLowerCase() as LogLevelString,\n            message,\n            args,\n            type: instance.name\n          });\n        }\n      };\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ComponentContainer,\n  ComponentType,\n  Provider,\n  Name\n} from '@firebase/component';\nimport { PlatformLoggerService, VersionService } from './types';\n\nexport class PlatformLoggerServiceImpl implements PlatformLoggerService {\n  constructor(private readonly container: ComponentContainer) {}\n  // In initial implementation, this will be called by installations on\n  // auth token refresh, and installations will send this string.\n  getPlatformInfoString(): string {\n    const providers = this.container.getProviders();\n    // Loop through providers and get library/version pairs from any that are\n    // version components.\n    return providers\n      .map(provider => {\n        if (isVersionServiceProvider(provider)) {\n          const service = provider.getImmediate() as VersionService;\n          return `${service.library}/${service.version}`;\n        } else {\n          return null;\n        }\n      })\n      .filter(logString => logString)\n      .join(' ');\n  }\n}\n/**\n *\n * @param provider check if this provider provides a VersionService\n *\n * NOTE: Using Provider<'app-version'> is a hack to indicate that the provider\n * provides VersionService. The provider is not necessarily a 'app-version'\n * provider.\n */\nfunction isVersionServiceProvider(provider: Provider<Name>): boolean {\n  const component = provider.getComponent();\n  return component?.type === ComponentType.VERSION;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from '@firebase/logger';\n\nexport const logger = new Logger('@firebase/app');\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { name as appName } from '../package.json';\nimport { name as appCompatName } from '../../app-compat/package.json';\nimport { name as analyticsCompatName } from '../../../packages/analytics-compat/package.json';\nimport { name as analyticsName } from '../../../packages/analytics/package.json';\nimport { name as appCheckCompatName } from '../../../packages/app-check-compat/package.json';\nimport { name as appCheckName } from '../../../packages/app-check/package.json';\nimport { name as authName } from '../../../packages/auth/package.json';\nimport { name as authCompatName } from '../../../packages/auth-compat/package.json';\nimport { name as databaseName } from '../../../packages/database/package.json';\nimport { name as databaseCompatName } from '../../../packages/database-compat/package.json';\nimport { name as functionsName } from '../../../packages/functions/package.json';\nimport { name as functionsCompatName } from '../../../packages/functions-compat/package.json';\nimport { name as installationsName } from '../../../packages/installations/package.json';\nimport { name as installationsCompatName } from '../../../packages/installations-compat/package.json';\nimport { name as messagingName } from '../../../packages/messaging/package.json';\nimport { name as messagingCompatName } from '../../../packages/messaging-compat/package.json';\nimport { name as performanceName } from '../../../packages/performance/package.json';\nimport { name as performanceCompatName } from '../../../packages/performance-compat/package.json';\nimport { name as remoteConfigName } from '../../../packages/remote-config/package.json';\nimport { name as remoteConfigCompatName } from '../../../packages/remote-config-compat/package.json';\nimport { name as storageName } from '../../../packages/storage/package.json';\nimport { name as storageCompatName } from '../../../packages/storage-compat/package.json';\nimport { name as firestoreName } from '../../../packages/firestore/package.json';\nimport { name as firestoreCompatName } from '../../../packages/firestore-compat/package.json';\nimport { name as packageName } from '../../../packages/firebase/package.json';\n\n/**\n * The default app name\n *\n * @internal\n */\nexport const DEFAULT_ENTRY_NAME = '[DEFAULT]';\n\nexport const PLATFORM_LOG_STRING = {\n  [appName]: 'fire-core',\n  [appCompatName]: 'fire-core-compat',\n  [analyticsName]: 'fire-analytics',\n  [analyticsCompatName]: 'fire-analytics-compat',\n  [appCheckName]: 'fire-app-check',\n  [appCheckCompatName]: 'fire-app-check-compat',\n  [authName]: 'fire-auth',\n  [authCompatName]: 'fire-auth-compat',\n  [databaseName]: 'fire-rtdb',\n  [databaseCompatName]: 'fire-rtdb-compat',\n  [functionsName]: 'fire-fn',\n  [functionsCompatName]: 'fire-fn-compat',\n  [installationsName]: 'fire-iid',\n  [installationsCompatName]: 'fire-iid-compat',\n  [messagingName]: 'fire-fcm',\n  [messagingCompatName]: 'fire-fcm-compat',\n  [performanceName]: 'fire-perf',\n  [performanceCompatName]: 'fire-perf-compat',\n  [remoteConfigName]: 'fire-rc',\n  [remoteConfigCompatName]: 'fire-rc-compat',\n  [storageName]: 'fire-gcs',\n  [storageCompatName]: 'fire-gcs-compat',\n  [firestoreName]: 'fire-fst',\n  [firestoreCompatName]: 'fire-fst-compat',\n  'fire-js': 'fire-js', // Platform identifier for JS SDK.\n  [packageName]: 'fire-js-all'\n} as const;\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp } from './public-types';\nimport { Component, Provider, Name } from '@firebase/component';\nimport { logger } from './logger';\nimport { DEFAULT_ENTRY_NAME } from './constants';\nimport { FirebaseAppImpl } from './firebaseApp';\n\n/**\n * @internal\n */\nexport const _apps = new Map<string, FirebaseApp>();\n\n/**\n * Registered components.\n *\n * @internal\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport const _components = new Map<string, Component<any>>();\n\n/**\n * @param component - the component being added to this app's container\n *\n * @internal\n */\nexport function _addComponent<T extends Name>(\n  app: FirebaseApp,\n  component: Component<T>\n): void {\n  try {\n    (app as FirebaseAppImpl).container.addComponent(component);\n  } catch (e) {\n    logger.debug(\n      `Component ${component.name} failed to register with FirebaseApp ${app.name}`,\n      e\n    );\n  }\n}\n\n/**\n *\n * @internal\n */\nexport function _addOrOverwriteComponent(\n  app: FirebaseApp,\n  component: Component\n): void {\n  (app as FirebaseAppImpl).container.addOrOverwriteComponent(component);\n}\n\n/**\n *\n * @param component - the component to register\n * @returns whether or not the component is registered successfully\n *\n * @internal\n */\nexport function _registerComponent<T extends Name>(\n  component: Component<T>\n): boolean {\n  const componentName = component.name;\n  if (_components.has(componentName)) {\n    logger.debug(\n      `There were multiple attempts to register component ${componentName}.`\n    );\n\n    return false;\n  }\n\n  _components.set(componentName, component);\n\n  // add the component to existing app instances\n  for (const app of _apps.values()) {\n    _addComponent(app as FirebaseAppImpl, component);\n  }\n\n  return true;\n}\n\n/**\n *\n * @param app - FirebaseApp instance\n * @param name - service name\n *\n * @returns the provider for the service with the matching name\n *\n * @internal\n */\nexport function _getProvider<T extends Name>(\n  app: FirebaseApp,\n  name: T\n): Provider<T> {\n  return (app as FirebaseAppImpl).container.getProvider(name);\n}\n\n/**\n *\n * @param app - FirebaseApp instance\n * @param name - service name\n * @param instanceIdentifier - service instance identifier in case the service supports multiple instances\n *\n * @internal\n */\nexport function _removeServiceInstance<T extends Name>(\n  app: FirebaseApp,\n  name: T,\n  instanceIdentifier: string = DEFAULT_ENTRY_NAME\n): void {\n  _getProvider(app, name).clearInstance(instanceIdentifier);\n}\n\n/**\n * Test only\n *\n * @internal\n */\nexport function _clearComponents(): void {\n  _components.clear();\n}\n\n/**\n * Exported in order to be used in app-compat package\n */\nexport { DEFAULT_ENTRY_NAME as _DEFAULT_ENTRY_NAME };\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ErrorFactory, ErrorMap } from '@firebase/util';\n\nexport const enum AppError {\n  NO_APP = 'no-app',\n  BAD_APP_NAME = 'bad-app-name',\n  DUPLICATE_APP = 'duplicate-app',\n  APP_DELETED = 'app-deleted',\n  INVALID_APP_ARGUMENT = 'invalid-app-argument',\n  INVALID_LOG_ARGUMENT = 'invalid-log-argument'\n}\n\nconst ERRORS: ErrorMap<AppError> = {\n  [AppError.NO_APP]:\n    \"No Firebase App '{$appName}' has been created - \" +\n    'call Firebase App.initializeApp()',\n  [AppError.BAD_APP_NAME]: \"Illegal App name: '{$appName}\",\n  [AppError.DUPLICATE_APP]:\n    \"Firebase App named '{$appName}' already exists with different options or config\",\n  [AppError.APP_DELETED]: \"Firebase App named '{$appName}' already deleted\",\n  [AppError.INVALID_APP_ARGUMENT]:\n    'firebase.{$appName}() takes either no argument or a ' +\n    'Firebase App instance.',\n  [AppError.INVALID_LOG_ARGUMENT]:\n    'First argument to `onLog` must be null or a function.'\n};\n\ninterface ErrorParams {\n  [AppError.NO_APP]: { appName: string };\n  [AppError.BAD_APP_NAME]: { appName: string };\n  [AppError.DUPLICATE_APP]: { appName: string };\n  [AppError.APP_DELETED]: { appName: string };\n  [AppError.INVALID_APP_ARGUMENT]: { appName: string };\n}\n\nexport const ERROR_FACTORY = new ErrorFactory<AppError, ErrorParams>(\n  'app',\n  'Firebase',\n  ERRORS\n);\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  FirebaseApp,\n  FirebaseOptions,\n  FirebaseAppSettings\n} from './public-types';\nimport {\n  ComponentContainer,\n  Component,\n  ComponentType\n} from '@firebase/component';\nimport { ERROR_FACTORY, AppError } from './errors';\n\nexport class FirebaseAppImpl implements FirebaseApp {\n  private readonly _options: FirebaseOptions;\n  private readonly _name: string;\n  /**\n   * Original config values passed in as a constructor parameter.\n   * It is only used to compare with another config object to support idempotent initializeApp().\n   *\n   * Updating automaticDataCollectionEnabled on the App instance will not change its value in _config.\n   */\n  private readonly _config: Required<FirebaseAppSettings>;\n  private _automaticDataCollectionEnabled: boolean;\n  private _isDeleted = false;\n  private readonly _container: ComponentContainer;\n\n  constructor(\n    options: FirebaseOptions,\n    config: Required<FirebaseAppSettings>,\n    container: ComponentContainer\n  ) {\n    this._options = { ...options };\n    this._config = { ...config };\n    this._name = config.name;\n    this._automaticDataCollectionEnabled =\n      config.automaticDataCollectionEnabled;\n    this._container = container;\n    this.container.addComponent(\n      new Component('app', () => this, ComponentType.PUBLIC)\n    );\n  }\n\n  get automaticDataCollectionEnabled(): boolean {\n    this.checkDestroyed();\n    return this._automaticDataCollectionEnabled;\n  }\n\n  set automaticDataCollectionEnabled(val: boolean) {\n    this.checkDestroyed();\n    this._automaticDataCollectionEnabled = val;\n  }\n\n  get name(): string {\n    this.checkDestroyed();\n    return this._name;\n  }\n\n  get options(): FirebaseOptions {\n    this.checkDestroyed();\n    return this._options;\n  }\n\n  get config(): Required<FirebaseAppSettings> {\n    this.checkDestroyed();\n    return this._config;\n  }\n\n  get container(): ComponentContainer {\n    return this._container;\n  }\n\n  get isDeleted(): boolean {\n    return this._isDeleted;\n  }\n\n  set isDeleted(val: boolean) {\n    this._isDeleted = val;\n  }\n\n  /**\n   * This function will throw an Error if the App has already been deleted -\n   * use before performing API actions on the App.\n   */\n  private checkDestroyed(): void {\n    if (this.isDeleted) {\n      throw ERROR_FACTORY.create(AppError.APP_DELETED, { appName: this._name });\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  FirebaseApp,\n  FirebaseOptions,\n  FirebaseAppSettings\n} from './public-types';\nimport { DEFAULT_ENTRY_NAME, PLATFORM_LOG_STRING } from './constants';\nimport { ERROR_FACTORY, AppError } from './errors';\nimport {\n  ComponentContainer,\n  Component,\n  Name,\n  ComponentType\n} from '@firebase/component';\nimport { version } from '../../firebase/package.json';\nimport { FirebaseAppImpl } from './firebaseApp';\nimport { _apps, _components, _registerComponent } from './internal';\nimport { logger } from './logger';\nimport {\n  LogLevelString,\n  setLogLevel as setLogLevelImpl,\n  LogCallback,\n  LogOptions,\n  setUserLogHandler\n} from '@firebase/logger';\nimport { deepEqual } from '@firebase/util';\n\nexport { FirebaseError } from '@firebase/util';\n\n/**\n * The current SDK version.\n *\n * @public\n */\nexport const SDK_VERSION = version;\n\n/**\n * Creates and initializes a {@link @firebase/app#FirebaseApp} instance.\n *\n * See\n * {@link\n *   https://firebase.google.com/docs/web/setup#add_firebase_to_your_app\n *   | Add Firebase to your app} and\n * {@link\n *   https://firebase.google.com/docs/web/setup#multiple-projects\n *   | Initialize multiple projects} for detailed documentation.\n *\n * @example\n * ```javascript\n *\n * // Initialize default app\n * // Retrieve your own options values by adding a web app on\n * // https://console.firebase.google.com\n * initializeApp({\n *   apiKey: \"AIza....\",                             // Auth / General Use\n *   authDomain: \"YOUR_APP.firebaseapp.com\",         // Auth with popup/redirect\n *   databaseURL: \"https://YOUR_APP.firebaseio.com\", // Realtime Database\n *   storageBucket: \"YOUR_APP.appspot.com\",          // Storage\n *   messagingSenderId: \"123456789\"                  // Cloud Messaging\n * });\n * ```\n *\n * @example\n * ```javascript\n *\n * // Initialize another app\n * const otherApp = initializeApp({\n *   databaseURL: \"https://<OTHER_DATABASE_NAME>.firebaseio.com\",\n *   storageBucket: \"<OTHER_STORAGE_BUCKET>.appspot.com\"\n * }, \"otherApp\");\n * ```\n *\n * @param options - Options to configure the app's services.\n * @param name - Optional name of the app to initialize. If no name\n *   is provided, the default is `\"[DEFAULT]\"`.\n *\n * @returns The initialized app.\n *\n * @public\n */\nexport function initializeApp(\n  options: FirebaseOptions,\n  name?: string\n): FirebaseApp;\n/**\n * Creates and initializes a FirebaseApp instance.\n *\n * @param options - Options to configure the app's services.\n * @param config - FirebaseApp Configuration\n *\n * @public\n */\nexport function initializeApp(\n  options: FirebaseOptions,\n  config?: FirebaseAppSettings\n): FirebaseApp;\nexport function initializeApp(\n  options: FirebaseOptions,\n  rawConfig = {}\n): FirebaseApp {\n  if (typeof rawConfig !== 'object') {\n    const name = rawConfig;\n    rawConfig = { name };\n  }\n\n  const config: Required<FirebaseAppSettings> = {\n    name: DEFAULT_ENTRY_NAME,\n    automaticDataCollectionEnabled: false,\n    ...rawConfig\n  };\n  const name = config.name;\n\n  if (typeof name !== 'string' || !name) {\n    throw ERROR_FACTORY.create(AppError.BAD_APP_NAME, {\n      appName: String(name)\n    });\n  }\n\n  const existingApp = _apps.get(name) as FirebaseAppImpl;\n  if (existingApp) {\n    // return the existing app if options and config deep equal the ones in the existing app.\n    if (\n      deepEqual(options, existingApp.options) &&\n      deepEqual(config, existingApp.config)\n    ) {\n      return existingApp;\n    } else {\n      throw ERROR_FACTORY.create(AppError.DUPLICATE_APP, { appName: name });\n    }\n  }\n\n  const container = new ComponentContainer(name);\n  for (const component of _components.values()) {\n    container.addComponent(component);\n  }\n\n  const newApp = new FirebaseAppImpl(options, config, container);\n\n  _apps.set(name, newApp);\n\n  return newApp;\n}\n\n/**\n * Retrieves a {@link @firebase/app#FirebaseApp} instance.\n *\n * When called with no arguments, the default app is returned. When an app name\n * is provided, the app corresponding to that name is returned.\n *\n * An exception is thrown if the app being retrieved has not yet been\n * initialized.\n *\n * @example\n * ```javascript\n * // Return the default app\n * const app = getApp();\n * ```\n *\n * @example\n * ```javascript\n * // Return a named app\n * const otherApp = getApp(\"otherApp\");\n * ```\n *\n * @param name - Optional name of the app to return. If no name is\n *   provided, the default is `\"[DEFAULT]\"`.\n *\n * @returns The app corresponding to the provided app name.\n *   If no app name is provided, the default app is returned.\n *\n * @public\n */\nexport function getApp(name: string = DEFAULT_ENTRY_NAME): FirebaseApp {\n  const app = _apps.get(name);\n  if (!app) {\n    throw ERROR_FACTORY.create(AppError.NO_APP, { appName: name });\n  }\n\n  return app;\n}\n\n/**\n * A (read-only) array of all initialized apps.\n * @public\n */\nexport function getApps(): FirebaseApp[] {\n  return Array.from(_apps.values());\n}\n\n/**\n * Renders this app unusable and frees the resources of all associated\n * services.\n *\n * @example\n * ```javascript\n * deleteApp(app)\n *   .then(function() {\n *     console.log(\"App deleted successfully\");\n *   })\n *   .catch(function(error) {\n *     console.log(\"Error deleting app:\", error);\n *   });\n * ```\n *\n * @public\n */\nexport async function deleteApp(app: FirebaseApp): Promise<void> {\n  const name = app.name;\n  if (_apps.has(name)) {\n    _apps.delete(name);\n    await Promise.all(\n      (app as FirebaseAppImpl).container\n        .getProviders()\n        .map(provider => provider.delete())\n    );\n    (app as FirebaseAppImpl).isDeleted = true;\n  }\n}\n\n/**\n * Registers a library's name and version for platform logging purposes.\n * @param library - Name of 1p or 3p library (e.g. firestore, angularfire)\n * @param version - Current version of that library.\n * @param variant - Bundle variant, e.g., node, rn, etc.\n *\n * @public\n */\nexport function registerVersion(\n  libraryKeyOrName: string,\n  version: string,\n  variant?: string\n): void {\n  // TODO: We can use this check to whitelist strings when/if we set up\n  // a good whitelist system.\n  let library = PLATFORM_LOG_STRING[libraryKeyOrName] ?? libraryKeyOrName;\n  if (variant) {\n    library += `-${variant}`;\n  }\n  const libraryMismatch = library.match(/\\s|\\//);\n  const versionMismatch = version.match(/\\s|\\//);\n  if (libraryMismatch || versionMismatch) {\n    const warning = [\n      `Unable to register library \"${library}\" with version \"${version}\":`\n    ];\n    if (libraryMismatch) {\n      warning.push(\n        `library name \"${library}\" contains illegal characters (whitespace or \"/\")`\n      );\n    }\n    if (libraryMismatch && versionMismatch) {\n      warning.push('and');\n    }\n    if (versionMismatch) {\n      warning.push(\n        `version name \"${version}\" contains illegal characters (whitespace or \"/\")`\n      );\n    }\n    logger.warn(warning.join(' '));\n    return;\n  }\n  _registerComponent(\n    new Component(\n      `${library}-version` as Name,\n      () => ({ library, version }),\n      ComponentType.VERSION\n    )\n  );\n}\n\n/**\n * Sets log handler for all Firebase SDKs.\n * @param logCallback - An optional custom log handler that executes user code whenever\n * the Firebase SDK makes a logging call.\n *\n * @public\n */\nexport function onLog(\n  logCallback: LogCallback | null,\n  options?: LogOptions\n): void {\n  if (logCallback !== null && typeof logCallback !== 'function') {\n    throw ERROR_FACTORY.create(AppError.INVALID_LOG_ARGUMENT);\n  }\n  setUserLogHandler(logCallback, options);\n}\n\n/**\n * Sets log level for all Firebase SDKs.\n *\n * All of the log types above the current log level are captured (i.e. if\n * you set the log level to `info`, errors are logged, but `debug` and\n * `verbose` logs are not).\n *\n * @public\n */\nexport function setLogLevel(logLevel: LogLevelString): void {\n  setLogLevelImpl(logLevel);\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Component, ComponentType } from '@firebase/component';\nimport { PlatformLoggerServiceImpl } from './platformLoggerService';\nimport { name, version } from '../package.json';\nimport { _registerComponent } from './internal';\nimport { registerVersion } from './api';\n\nexport function registerCoreComponents(variant?: string): void {\n  _registerComponent(\n    new Component(\n      'platform-logger',\n      container => new PlatformLoggerServiceImpl(container),\n      ComponentType.PRIVATE\n    )\n  );\n\n  // Register `app` package.\n  registerVersion(name, version, variant);\n  // BUILD_TARGET will be replaced by values like esm5, esm2017, cjs5, etc during the compilation\n  registerVersion(name, version, '__BUILD_TARGET__');\n  // Register platform SDK identifier (no version).\n  registerVersion('fire-js', '');\n}\n", "/**\n * Firebase App\n *\n * @remarks This package coordinates the communication between the different Firebase components\n * @packageDocumentation\n */\n\n/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { registerCoreComponents } from './registerCoreComponents';\n\nexport * from './api';\nexport * from './internal';\nexport * from './public-types';\n\nregisterCoreComponents('__RUNTIME_ENV__');\n", "/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { registerVersion } from '@firebase/app';\nimport { name, version } from '../package.json';\n\nregisterVersion(name, version, 'app');\nexport * from '@firebase/app';\n", "import { _getProvider, getApp, _removeServiceInstance, _registerComponent, registerVersion, SDK_VERSION as SDK_VERSION$1 } from '@firebase/app';\nimport { Component } from '@firebase/component';\nimport { Logger, LogLevel } from '@firebase/logger';\nimport { inspect, TextEncoder, TextDecoder } from 'util';\nimport { getUA, isIndexedDBAvailable, isSafari, createMockUserToken, getModularInstance, deepEqual } from '@firebase/util';\nimport { randomBytes as randomBytes$1 } from 'crypto';\nimport module from 'module';\nimport { credentials, Metadata, loadPackageDefinition } from '@grpc/grpc-js';\nimport { dirname, resolve, join } from 'path';\nimport { fileURLToPath } from 'url';\nimport { loadSync } from '@grpc/proto-loader';\n\nconst name = \"@firebase/firestore\";\nconst version$1 = \"3.3.1\";\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Simple wrapper around a nullable UID. Mostly exists to make code more\r\n * readable.\r\n */\r\nclass User {\r\n    constructor(uid) {\r\n        this.uid = uid;\r\n    }\r\n    isAuthenticated() {\r\n        return this.uid != null;\r\n    }\r\n    /**\r\n     * Returns a key representing this user, suitable for inclusion in a\r\n     * dictionary.\r\n     */\r\n    toKey() {\r\n        if (this.isAuthenticated()) {\r\n            return 'uid:' + this.uid;\r\n        }\r\n        else {\r\n            return 'anonymous-user';\r\n        }\r\n    }\r\n    isEqual(otherUser) {\r\n        return otherUser.uid === this.uid;\r\n    }\r\n}\r\n/** A user with a null UID. */\r\nUser.UNAUTHENTICATED = new User(null);\r\n// TODO(mikelehen): Look into getting a proper uid-equivalent for\r\n// non-FirebaseAuth providers.\r\nUser.GOOGLE_CREDENTIALS = new User('google-credentials-uid');\r\nUser.FIRST_PARTY = new User('first-party-uid');\r\nUser.MOCK_USER = new User('mock-user');\n\nconst version = \"9.5.0\";\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nlet SDK_VERSION = version;\r\nfunction setSDKVersion(version) {\r\n    SDK_VERSION = version;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Formats an object as a JSON string, suitable for logging. */\r\nfunction formatJSON(value) {\r\n    // util.inspect() results in much more readable output than JSON.stringify()\r\n    return inspect(value, { depth: 100 });\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst logClient = new Logger('@firebase/firestore');\r\n// Helper methods are needed because variables can't be exported as read/write\r\nfunction getLogLevel() {\r\n    return logClient.logLevel;\r\n}\r\n/**\r\n * Sets the verbosity of Cloud Firestore logs (debug, error, or silent).\r\n *\r\n * @param logLevel - The verbosity you set for activity and error logging. Can\r\n *   be any of the following values:\r\n *\r\n *   <ul>\r\n *     <li>`debug` for the most verbose logging level, primarily for\r\n *     debugging.</li>\r\n *     <li>`error` to log errors only.</li>\r\n *     <li><code>`silent` to turn off logging.</li>\r\n *   </ul>\r\n */\r\nfunction setLogLevel(logLevel) {\r\n    logClient.setLogLevel(logLevel);\r\n}\r\nfunction logDebug(msg, ...obj) {\r\n    if (logClient.logLevel <= LogLevel.DEBUG) {\r\n        const args = obj.map(argToString);\r\n        logClient.debug(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\r\n    }\r\n}\r\nfunction logError(msg, ...obj) {\r\n    if (logClient.logLevel <= LogLevel.ERROR) {\r\n        const args = obj.map(argToString);\r\n        logClient.error(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\r\n    }\r\n}\r\n/**\r\n * @internal\r\n */\r\nfunction logWarn(msg, ...obj) {\r\n    if (logClient.logLevel <= LogLevel.WARN) {\r\n        const args = obj.map(argToString);\r\n        logClient.warn(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\r\n    }\r\n}\r\n/**\r\n * Converts an additional log parameter to a string representation.\r\n */\r\nfunction argToString(obj) {\r\n    if (typeof obj === 'string') {\r\n        return obj;\r\n    }\r\n    else {\r\n        try {\r\n            return formatJSON(obj);\r\n        }\r\n        catch (e) {\r\n            // Converting to JSON failed, just log the object directly\r\n            return obj;\r\n        }\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Unconditionally fails, throwing an Error with the given message.\r\n * Messages are stripped in production builds.\r\n *\r\n * Returns `never` and can be used in expressions:\r\n * @example\r\n * let futureVar = fail('not implemented yet');\r\n */\r\nfunction fail(failure = 'Unexpected state') {\r\n    // Log the failure in addition to throw an exception, just in case the\r\n    // exception is swallowed.\r\n    const message = `FIRESTORE (${SDK_VERSION}) INTERNAL ASSERTION FAILED: ` + failure;\r\n    logError(message);\r\n    // NOTE: We don't use FirestoreError here because these are internal failures\r\n    // that cannot be handled by the user. (Also it would create a circular\r\n    // dependency between the error and assert modules which doesn't work.)\r\n    throw new Error(message);\r\n}\r\n/**\r\n * Fails if the given assertion condition is false, throwing an Error with the\r\n * given message if it did.\r\n *\r\n * Messages are stripped in production builds.\r\n */\r\nfunction hardAssert(assertion, message) {\r\n    if (!assertion) {\r\n        fail();\r\n    }\r\n}\r\n/**\r\n * Fails if the given assertion condition is false, throwing an Error with the\r\n * given message if it did.\r\n *\r\n * The code of callsites invoking this function are stripped out in production\r\n * builds. Any side-effects of code within the debugAssert() invocation will not\r\n * happen in this case.\r\n *\r\n * @internal\r\n */\r\nfunction debugAssert(assertion, message) {\r\n    if (!assertion) {\r\n        fail();\r\n    }\r\n}\r\n/**\r\n * Casts `obj` to `T`. In non-production builds, verifies that `obj` is an\r\n * instance of `T` before casting.\r\n */\r\nfunction debugCast(obj, \r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nconstructor) {\r\n    return obj;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst Code = {\r\n    // Causes are copied from:\r\n    // https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\r\n    /** Not an error; returned on success. */\r\n    OK: 'ok',\r\n    /** The operation was cancelled (typically by the caller). */\r\n    CANCELLED: 'cancelled',\r\n    /** Unknown error or an error from a different error domain. */\r\n    UNKNOWN: 'unknown',\r\n    /**\r\n     * Client specified an invalid argument. Note that this differs from\r\n     * FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are\r\n     * problematic regardless of the state of the system (e.g., a malformed file\r\n     * name).\r\n     */\r\n    INVALID_ARGUMENT: 'invalid-argument',\r\n    /**\r\n     * Deadline expired before operation could complete. For operations that\r\n     * change the state of the system, this error may be returned even if the\r\n     * operation has completed successfully. For example, a successful response\r\n     * from a server could have been delayed long enough for the deadline to\r\n     * expire.\r\n     */\r\n    DEADLINE_EXCEEDED: 'deadline-exceeded',\r\n    /** Some requested entity (e.g., file or directory) was not found. */\r\n    NOT_FOUND: 'not-found',\r\n    /**\r\n     * Some entity that we attempted to create (e.g., file or directory) already\r\n     * exists.\r\n     */\r\n    ALREADY_EXISTS: 'already-exists',\r\n    /**\r\n     * The caller does not have permission to execute the specified operation.\r\n     * PERMISSION_DENIED must not be used for rejections caused by exhausting\r\n     * some resource (use RESOURCE_EXHAUSTED instead for those errors).\r\n     * PERMISSION_DENIED must not be used if the caller can not be identified\r\n     * (use UNAUTHENTICATED instead for those errors).\r\n     */\r\n    PERMISSION_DENIED: 'permission-denied',\r\n    /**\r\n     * The request does not have valid authentication credentials for the\r\n     * operation.\r\n     */\r\n    UNAUTHENTICATED: 'unauthenticated',\r\n    /**\r\n     * Some resource has been exhausted, perhaps a per-user quota, or perhaps the\r\n     * entire file system is out of space.\r\n     */\r\n    RESOURCE_EXHAUSTED: 'resource-exhausted',\r\n    /**\r\n     * Operation was rejected because the system is not in a state required for\r\n     * the operation's execution. For example, directory to be deleted may be\r\n     * non-empty, an rmdir operation is applied to a non-directory, etc.\r\n     *\r\n     * A litmus test that may help a service implementor in deciding\r\n     * between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:\r\n     *  (a) Use UNAVAILABLE if the client can retry just the failing call.\r\n     *  (b) Use ABORTED if the client should retry at a higher-level\r\n     *      (e.g., restarting a read-modify-write sequence).\r\n     *  (c) Use FAILED_PRECONDITION if the client should not retry until\r\n     *      the system state has been explicitly fixed. E.g., if an \"rmdir\"\r\n     *      fails because the directory is non-empty, FAILED_PRECONDITION\r\n     *      should be returned since the client should not retry unless\r\n     *      they have first fixed up the directory by deleting files from it.\r\n     *  (d) Use FAILED_PRECONDITION if the client performs conditional\r\n     *      REST Get/Update/Delete on a resource and the resource on the\r\n     *      server does not match the condition. E.g., conflicting\r\n     *      read-modify-write on the same resource.\r\n     */\r\n    FAILED_PRECONDITION: 'failed-precondition',\r\n    /**\r\n     * The operation was aborted, typically due to a concurrency issue like\r\n     * sequencer check failures, transaction aborts, etc.\r\n     *\r\n     * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\r\n     * and UNAVAILABLE.\r\n     */\r\n    ABORTED: 'aborted',\r\n    /**\r\n     * Operation was attempted past the valid range. E.g., seeking or reading\r\n     * past end of file.\r\n     *\r\n     * Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed\r\n     * if the system state changes. For example, a 32-bit file system will\r\n     * generate INVALID_ARGUMENT if asked to read at an offset that is not in the\r\n     * range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from\r\n     * an offset past the current file size.\r\n     *\r\n     * There is a fair bit of overlap between FAILED_PRECONDITION and\r\n     * OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error)\r\n     * when it applies so that callers who are iterating through a space can\r\n     * easily look for an OUT_OF_RANGE error to detect when they are done.\r\n     */\r\n    OUT_OF_RANGE: 'out-of-range',\r\n    /** Operation is not implemented or not supported/enabled in this service. */\r\n    UNIMPLEMENTED: 'unimplemented',\r\n    /**\r\n     * Internal errors. Means some invariants expected by underlying System has\r\n     * been broken. If you see one of these errors, Something is very broken.\r\n     */\r\n    INTERNAL: 'internal',\r\n    /**\r\n     * The service is currently unavailable. This is a most likely a transient\r\n     * condition and may be corrected by retrying with a backoff.\r\n     *\r\n     * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\r\n     * and UNAVAILABLE.\r\n     */\r\n    UNAVAILABLE: 'unavailable',\r\n    /** Unrecoverable data loss or corruption. */\r\n    DATA_LOSS: 'data-loss'\r\n};\r\n/** An error returned by a Firestore operation. */\r\nclass FirestoreError extends Error {\r\n    /** @hideconstructor */\r\n    constructor(\r\n    /**\r\n     * The backend error code associated with this error.\r\n     */\r\n    code, \r\n    /**\r\n     * A custom error description.\r\n     */\r\n    message) {\r\n        super(message);\r\n        this.code = code;\r\n        this.message = message;\r\n        /** The custom name for all FirestoreErrors. */\r\n        this.name = 'FirebaseError';\r\n        // HACK: We write a toString property directly because Error is not a real\r\n        // class and so inheritance does not work correctly. We could alternatively\r\n        // do the same \"back-door inheritance\" trick that FirebaseError does.\r\n        this.toString = () => `${this.name}: [code=${this.code}]: ${this.message}`;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass Deferred {\r\n    constructor() {\r\n        this.promise = new Promise((resolve, reject) => {\r\n            this.resolve = resolve;\r\n            this.reject = reject;\r\n        });\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass OAuthToken {\r\n    constructor(value, user) {\r\n        this.user = user;\r\n        this.type = 'OAuth';\r\n        this.authHeaders = {};\r\n        // Set the headers using Object Literal notation to avoid minification\r\n        this.authHeaders['Authorization'] = `Bearer ${value}`;\r\n    }\r\n}\r\n/**\r\n * A CredentialsProvider that always yields an empty token.\r\n * @internal\r\n */\r\nclass EmptyCredentialsProvider {\r\n    getToken() {\r\n        return Promise.resolve(null);\r\n    }\r\n    invalidateToken() { }\r\n    start(asyncQueue, changeListener) {\r\n        // Fire with initial user.\r\n        asyncQueue.enqueueRetryable(() => changeListener(User.UNAUTHENTICATED));\r\n    }\r\n    shutdown() { }\r\n}\r\n/**\r\n * A CredentialsProvider that always returns a constant token. Used for\r\n * emulator token mocking.\r\n */\r\nclass EmulatorCredentialsProvider {\r\n    constructor(token) {\r\n        this.token = token;\r\n        /**\r\n         * Stores the listener registered with setChangeListener()\r\n         * This isn't actually necessary since the UID never changes, but we use this\r\n         * to verify the listen contract is adhered to in tests.\r\n         */\r\n        this.changeListener = null;\r\n    }\r\n    getToken() {\r\n        return Promise.resolve(this.token);\r\n    }\r\n    invalidateToken() { }\r\n    start(asyncQueue, changeListener) {\r\n        this.changeListener = changeListener;\r\n        // Fire with initial user.\r\n        asyncQueue.enqueueRetryable(() => changeListener(this.token.user));\r\n    }\r\n    shutdown() {\r\n        this.changeListener = null;\r\n    }\r\n}\r\nclass FirebaseCredentialsProvider {\r\n    constructor(authProvider) {\r\n        this.authProvider = authProvider;\r\n        /** Tracks the current User. */\r\n        this.currentUser = User.UNAUTHENTICATED;\r\n        /**\r\n         * Counter used to detect if the token changed while a getToken request was\r\n         * outstanding.\r\n         */\r\n        this.tokenCounter = 0;\r\n        this.forceRefresh = false;\r\n        this.auth = null;\r\n    }\r\n    start(asyncQueue, changeListener) {\r\n        let lastTokenId = this.tokenCounter;\r\n        // A change listener that prevents double-firing for the same token change.\r\n        const guardedChangeListener = user => {\r\n            if (this.tokenCounter !== lastTokenId) {\r\n                lastTokenId = this.tokenCounter;\r\n                return changeListener(user);\r\n            }\r\n            else {\r\n                return Promise.resolve();\r\n            }\r\n        };\r\n        // A promise that can be waited on to block on the next token change.\r\n        // This promise is re-created after each change.\r\n        let nextToken = new Deferred();\r\n        this.tokenListener = () => {\r\n            this.tokenCounter++;\r\n            this.currentUser = this.getUser();\r\n            nextToken.resolve();\r\n            nextToken = new Deferred();\r\n            asyncQueue.enqueueRetryable(() => guardedChangeListener(this.currentUser));\r\n        };\r\n        const awaitNextToken = () => {\r\n            const currentTokenAttempt = nextToken;\r\n            asyncQueue.enqueueRetryable(async () => {\r\n                await currentTokenAttempt.promise;\r\n                await guardedChangeListener(this.currentUser);\r\n            });\r\n        };\r\n        const registerAuth = (auth) => {\r\n            logDebug('FirebaseCredentialsProvider', 'Auth detected');\r\n            this.auth = auth;\r\n            this.auth.addAuthTokenListener(this.tokenListener);\r\n            awaitNextToken();\r\n        };\r\n        this.authProvider.onInit(auth => registerAuth(auth));\r\n        // Our users can initialize Auth right after Firestore, so we give it\r\n        // a chance to register itself with the component framework before we\r\n        // determine whether to start up in unauthenticated mode.\r\n        setTimeout(() => {\r\n            if (!this.auth) {\r\n                const auth = this.authProvider.getImmediate({ optional: true });\r\n                if (auth) {\r\n                    registerAuth(auth);\r\n                }\r\n                else {\r\n                    // If auth is still not available, proceed with `null` user\r\n                    logDebug('FirebaseCredentialsProvider', 'Auth not yet detected');\r\n                    nextToken.resolve();\r\n                    nextToken = new Deferred();\r\n                }\r\n            }\r\n        }, 0);\r\n        awaitNextToken();\r\n    }\r\n    getToken() {\r\n        // Take note of the current value of the tokenCounter so that this method\r\n        // can fail (with an ABORTED error) if there is a token change while the\r\n        // request is outstanding.\r\n        const initialTokenCounter = this.tokenCounter;\r\n        const forceRefresh = this.forceRefresh;\r\n        this.forceRefresh = false;\r\n        if (!this.auth) {\r\n            return Promise.resolve(null);\r\n        }\r\n        return this.auth.getToken(forceRefresh).then(tokenData => {\r\n            // Cancel the request since the token changed while the request was\r\n            // outstanding so the response is potentially for a previous user (which\r\n            // user, we can't be sure).\r\n            if (this.tokenCounter !== initialTokenCounter) {\r\n                logDebug('FirebaseCredentialsProvider', 'getToken aborted due to token change.');\r\n                return this.getToken();\r\n            }\r\n            else {\r\n                if (tokenData) {\r\n                    hardAssert(typeof tokenData.accessToken === 'string');\r\n                    return new OAuthToken(tokenData.accessToken, this.currentUser);\r\n                }\r\n                else {\r\n                    return null;\r\n                }\r\n            }\r\n        });\r\n    }\r\n    invalidateToken() {\r\n        this.forceRefresh = true;\r\n    }\r\n    shutdown() {\r\n        if (this.auth) {\r\n            this.auth.removeAuthTokenListener(this.tokenListener);\r\n        }\r\n    }\r\n    // Auth.getUid() can return null even with a user logged in. It is because\r\n    // getUid() is synchronous, but the auth code populating Uid is asynchronous.\r\n    // This method should only be called in the AuthTokenListener callback\r\n    // to guarantee to get the actual user.\r\n    getUser() {\r\n        const currentUid = this.auth && this.auth.getUid();\r\n        hardAssert(currentUid === null || typeof currentUid === 'string');\r\n        return new User(currentUid);\r\n    }\r\n}\r\n/*\r\n * FirstPartyToken provides a fresh token each time its value\r\n * is requested, because if the token is too old, requests will be rejected.\r\n * Technically this may no longer be necessary since the SDK should gracefully\r\n * recover from unauthenticated errors (see b/33147818 for context), but it's\r\n * safer to keep the implementation as-is.\r\n */\r\nclass FirstPartyToken {\r\n    constructor(gapi, sessionIndex, iamToken) {\r\n        this.gapi = gapi;\r\n        this.sessionIndex = sessionIndex;\r\n        this.iamToken = iamToken;\r\n        this.type = 'FirstParty';\r\n        this.user = User.FIRST_PARTY;\r\n    }\r\n    get authHeaders() {\r\n        const headers = {\r\n            'X-Goog-AuthUser': this.sessionIndex\r\n        };\r\n        // Use array notation to prevent minification\r\n        const authHeader = this.gapi['auth']['getAuthHeaderValueForFirstParty']([]);\r\n        if (authHeader) {\r\n            headers['Authorization'] = authHeader;\r\n        }\r\n        if (this.iamToken) {\r\n            headers['X-Goog-Iam-Authorization-Token'] = this.iamToken;\r\n        }\r\n        return headers;\r\n    }\r\n}\r\n/*\r\n * Provides user credentials required for the Firestore JavaScript SDK\r\n * to authenticate the user, using technique that is only available\r\n * to applications hosted by Google.\r\n */\r\nclass FirstPartyCredentialsProvider {\r\n    constructor(gapi, sessionIndex, iamToken) {\r\n        this.gapi = gapi;\r\n        this.sessionIndex = sessionIndex;\r\n        this.iamToken = iamToken;\r\n    }\r\n    getToken() {\r\n        return Promise.resolve(new FirstPartyToken(this.gapi, this.sessionIndex, this.iamToken));\r\n    }\r\n    start(asyncQueue, changeListener) {\r\n        // Fire with initial uid.\r\n        asyncQueue.enqueueRetryable(() => changeListener(User.FIRST_PARTY));\r\n    }\r\n    shutdown() { }\r\n    invalidateToken() { }\r\n}\r\n/**\r\n * Builds a CredentialsProvider depending on the type of\r\n * the credentials passed in.\r\n */\r\nfunction makeCredentialsProvider(credentials) {\r\n    if (!credentials) {\r\n        return new EmptyCredentialsProvider();\r\n    }\r\n    switch (credentials['type']) {\r\n        case 'gapi':\r\n            const client = credentials['client'];\r\n            // Make sure this really is a Gapi client.\r\n            hardAssert(!!(typeof client === 'object' &&\r\n                client !== null &&\r\n                client['auth'] &&\r\n                client['auth']['getAuthHeaderValueForFirstParty']));\r\n            return new FirstPartyCredentialsProvider(client, credentials['sessionIndex'] || '0', credentials['iamToken'] || null);\r\n        case 'provider':\r\n            return credentials['client'];\r\n        default:\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'makeCredentialsProvider failed due to invalid credential type');\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * `ListenSequence` is a monotonic sequence. It is initialized with a minimum value to\r\n * exceed. All subsequent calls to next will return increasing values. If provided with a\r\n * `SequenceNumberSyncer`, it will additionally bump its next value when told of a new value, as\r\n * well as write out sequence numbers that it produces via `next()`.\r\n */\r\nclass ListenSequence {\r\n    constructor(previousValue, sequenceNumberSyncer) {\r\n        this.previousValue = previousValue;\r\n        if (sequenceNumberSyncer) {\r\n            sequenceNumberSyncer.sequenceNumberHandler = sequenceNumber => this.setPreviousValue(sequenceNumber);\r\n            this.writeNewSequenceNumber = sequenceNumber => sequenceNumberSyncer.writeSequenceNumber(sequenceNumber);\r\n        }\r\n    }\r\n    setPreviousValue(externalPreviousValue) {\r\n        this.previousValue = Math.max(externalPreviousValue, this.previousValue);\r\n        return this.previousValue;\r\n    }\r\n    next() {\r\n        const nextValue = ++this.previousValue;\r\n        if (this.writeNewSequenceNumber) {\r\n            this.writeNewSequenceNumber(nextValue);\r\n        }\r\n        return nextValue;\r\n    }\r\n}\r\nListenSequence.INVALID = -1;\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst DOCUMENT_KEY_NAME = '__name__';\r\n/**\r\n * Path represents an ordered sequence of string segments.\r\n */\r\nclass BasePath {\r\n    constructor(segments, offset, length) {\r\n        if (offset === undefined) {\r\n            offset = 0;\r\n        }\r\n        else if (offset > segments.length) {\r\n            fail();\r\n        }\r\n        if (length === undefined) {\r\n            length = segments.length - offset;\r\n        }\r\n        else if (length > segments.length - offset) {\r\n            fail();\r\n        }\r\n        this.segments = segments;\r\n        this.offset = offset;\r\n        this.len = length;\r\n    }\r\n    get length() {\r\n        return this.len;\r\n    }\r\n    isEqual(other) {\r\n        return BasePath.comparator(this, other) === 0;\r\n    }\r\n    child(nameOrPath) {\r\n        const segments = this.segments.slice(this.offset, this.limit());\r\n        if (nameOrPath instanceof BasePath) {\r\n            nameOrPath.forEach(segment => {\r\n                segments.push(segment);\r\n            });\r\n        }\r\n        else {\r\n            segments.push(nameOrPath);\r\n        }\r\n        return this.construct(segments);\r\n    }\r\n    /** The index of one past the last segment of the path. */\r\n    limit() {\r\n        return this.offset + this.length;\r\n    }\r\n    popFirst(size) {\r\n        size = size === undefined ? 1 : size;\r\n        return this.construct(this.segments, this.offset + size, this.length - size);\r\n    }\r\n    popLast() {\r\n        return this.construct(this.segments, this.offset, this.length - 1);\r\n    }\r\n    firstSegment() {\r\n        return this.segments[this.offset];\r\n    }\r\n    lastSegment() {\r\n        return this.get(this.length - 1);\r\n    }\r\n    get(index) {\r\n        return this.segments[this.offset + index];\r\n    }\r\n    isEmpty() {\r\n        return this.length === 0;\r\n    }\r\n    isPrefixOf(other) {\r\n        if (other.length < this.length) {\r\n            return false;\r\n        }\r\n        for (let i = 0; i < this.length; i++) {\r\n            if (this.get(i) !== other.get(i)) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n    isImmediateParentOf(potentialChild) {\r\n        if (this.length + 1 !== potentialChild.length) {\r\n            return false;\r\n        }\r\n        for (let i = 0; i < this.length; i++) {\r\n            if (this.get(i) !== potentialChild.get(i)) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n    forEach(fn) {\r\n        for (let i = this.offset, end = this.limit(); i < end; i++) {\r\n            fn(this.segments[i]);\r\n        }\r\n    }\r\n    toArray() {\r\n        return this.segments.slice(this.offset, this.limit());\r\n    }\r\n    static comparator(p1, p2) {\r\n        const len = Math.min(p1.length, p2.length);\r\n        for (let i = 0; i < len; i++) {\r\n            const left = p1.get(i);\r\n            const right = p2.get(i);\r\n            if (left < right) {\r\n                return -1;\r\n            }\r\n            if (left > right) {\r\n                return 1;\r\n            }\r\n        }\r\n        if (p1.length < p2.length) {\r\n            return -1;\r\n        }\r\n        if (p1.length > p2.length) {\r\n            return 1;\r\n        }\r\n        return 0;\r\n    }\r\n}\r\n/**\r\n * A slash-separated path for navigating resources (documents and collections)\r\n * within Firestore.\r\n *\r\n * @internal\r\n */\r\nclass ResourcePath extends BasePath {\r\n    construct(segments, offset, length) {\r\n        return new ResourcePath(segments, offset, length);\r\n    }\r\n    canonicalString() {\r\n        // NOTE: The client is ignorant of any path segments containing escape\r\n        // sequences (e.g. __id123__) and just passes them through raw (they exist\r\n        // for legacy reasons and should not be used frequently).\r\n        return this.toArray().join('/');\r\n    }\r\n    toString() {\r\n        return this.canonicalString();\r\n    }\r\n    /**\r\n     * Creates a resource path from the given slash-delimited string. If multiple\r\n     * arguments are provided, all components are combined. Leading and trailing\r\n     * slashes from all components are ignored.\r\n     */\r\n    static fromString(...pathComponents) {\r\n        // NOTE: The client is ignorant of any path segments containing escape\r\n        // sequences (e.g. __id123__) and just passes them through raw (they exist\r\n        // for legacy reasons and should not be used frequently).\r\n        const segments = [];\r\n        for (const path of pathComponents) {\r\n            if (path.indexOf('//') >= 0) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid segment (${path}). Paths must not contain // in them.`);\r\n            }\r\n            // Strip leading and traling slashed.\r\n            segments.push(...path.split('/').filter(segment => segment.length > 0));\r\n        }\r\n        return new ResourcePath(segments);\r\n    }\r\n    static emptyPath() {\r\n        return new ResourcePath([]);\r\n    }\r\n}\r\nconst identifierRegExp = /^[_a-zA-Z][_a-zA-Z0-9]*$/;\r\n/**\r\n * A dot-separated path for navigating sub-objects within a document.\r\n * @internal\r\n */\r\nclass FieldPath$1 extends BasePath {\r\n    construct(segments, offset, length) {\r\n        return new FieldPath$1(segments, offset, length);\r\n    }\r\n    /**\r\n     * Returns true if the string could be used as a segment in a field path\r\n     * without escaping.\r\n     */\r\n    static isValidIdentifier(segment) {\r\n        return identifierRegExp.test(segment);\r\n    }\r\n    canonicalString() {\r\n        return this.toArray()\r\n            .map(str => {\r\n            str = str.replace(/\\\\/g, '\\\\\\\\').replace(/`/g, '\\\\`');\r\n            if (!FieldPath$1.isValidIdentifier(str)) {\r\n                str = '`' + str + '`';\r\n            }\r\n            return str;\r\n        })\r\n            .join('.');\r\n    }\r\n    toString() {\r\n        return this.canonicalString();\r\n    }\r\n    /**\r\n     * Returns true if this field references the key of a document.\r\n     */\r\n    isKeyField() {\r\n        return this.length === 1 && this.get(0) === DOCUMENT_KEY_NAME;\r\n    }\r\n    /**\r\n     * The field designating the key of a document.\r\n     */\r\n    static keyField() {\r\n        return new FieldPath$1([DOCUMENT_KEY_NAME]);\r\n    }\r\n    /**\r\n     * Parses a field string from the given server-formatted string.\r\n     *\r\n     * - Splitting the empty string is not allowed (for now at least).\r\n     * - Empty segments within the string (e.g. if there are two consecutive\r\n     *   separators) are not allowed.\r\n     *\r\n     * TODO(b/37244157): we should make this more strict. Right now, it allows\r\n     * non-identifier path components, even if they aren't escaped.\r\n     */\r\n    static fromServerFormat(path) {\r\n        const segments = [];\r\n        let current = '';\r\n        let i = 0;\r\n        const addCurrentSegment = () => {\r\n            if (current.length === 0) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid field path (${path}). Paths must not be empty, begin ` +\r\n                    `with '.', end with '.', or contain '..'`);\r\n            }\r\n            segments.push(current);\r\n            current = '';\r\n        };\r\n        let inBackticks = false;\r\n        while (i < path.length) {\r\n            const c = path[i];\r\n            if (c === '\\\\') {\r\n                if (i + 1 === path.length) {\r\n                    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Path has trailing escape character: ' + path);\r\n                }\r\n                const next = path[i + 1];\r\n                if (!(next === '\\\\' || next === '.' || next === '`')) {\r\n                    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Path has invalid escape sequence: ' + path);\r\n                }\r\n                current += next;\r\n                i += 2;\r\n            }\r\n            else if (c === '`') {\r\n                inBackticks = !inBackticks;\r\n                i++;\r\n            }\r\n            else if (c === '.' && !inBackticks) {\r\n                addCurrentSegment();\r\n                i++;\r\n            }\r\n            else {\r\n                current += c;\r\n                i++;\r\n            }\r\n        }\r\n        addCurrentSegment();\r\n        if (inBackticks) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Unterminated ` in path: ' + path);\r\n        }\r\n        return new FieldPath$1(segments);\r\n    }\r\n    static emptyPath() {\r\n        return new FieldPath$1([]);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst escapeChar = '\\u0001';\r\nconst encodedSeparatorChar = '\\u0001';\r\nconst encodedNul = '\\u0010';\r\nconst encodedEscape = '\\u0011';\r\n/**\r\n * Encodes a resource path into a IndexedDb-compatible string form.\r\n */\r\nfunction encodeResourcePath(path) {\r\n    let result = '';\r\n    for (let i = 0; i < path.length; i++) {\r\n        if (result.length > 0) {\r\n            result = encodeSeparator(result);\r\n        }\r\n        result = encodeSegment(path.get(i), result);\r\n    }\r\n    return encodeSeparator(result);\r\n}\r\n/** Encodes a single segment of a resource path into the given result */\r\nfunction encodeSegment(segment, resultBuf) {\r\n    let result = resultBuf;\r\n    const length = segment.length;\r\n    for (let i = 0; i < length; i++) {\r\n        const c = segment.charAt(i);\r\n        switch (c) {\r\n            case '\\0':\r\n                result += escapeChar + encodedNul;\r\n                break;\r\n            case escapeChar:\r\n                result += escapeChar + encodedEscape;\r\n                break;\r\n            default:\r\n                result += c;\r\n        }\r\n    }\r\n    return result;\r\n}\r\n/** Encodes a path separator into the given result */\r\nfunction encodeSeparator(result) {\r\n    return result + escapeChar + encodedSeparatorChar;\r\n}\r\n/**\r\n * Decodes the given IndexedDb-compatible string form of a resource path into\r\n * a ResourcePath instance. Note that this method is not suitable for use with\r\n * decoding resource names from the server; those are One Platform format\r\n * strings.\r\n */\r\nfunction decodeResourcePath(path) {\r\n    // Event the empty path must encode as a path of at least length 2. A path\r\n    // with exactly 2 must be the empty path.\r\n    const length = path.length;\r\n    hardAssert(length >= 2);\r\n    if (length === 2) {\r\n        hardAssert(path.charAt(0) === escapeChar && path.charAt(1) === encodedSeparatorChar);\r\n        return ResourcePath.emptyPath();\r\n    }\r\n    // Escape characters cannot exist past the second-to-last position in the\r\n    // source value.\r\n    const lastReasonableEscapeIndex = length - 2;\r\n    const segments = [];\r\n    let segmentBuilder = '';\r\n    for (let start = 0; start < length;) {\r\n        // The last two characters of a valid encoded path must be a separator, so\r\n        // there must be an end to this segment.\r\n        const end = path.indexOf(escapeChar, start);\r\n        if (end < 0 || end > lastReasonableEscapeIndex) {\r\n            fail();\r\n        }\r\n        const next = path.charAt(end + 1);\r\n        switch (next) {\r\n            case encodedSeparatorChar:\r\n                const currentPiece = path.substring(start, end);\r\n                let segment;\r\n                if (segmentBuilder.length === 0) {\r\n                    // Avoid copying for the common case of a segment that excludes \\0\r\n                    // and \\001\r\n                    segment = currentPiece;\r\n                }\r\n                else {\r\n                    segmentBuilder += currentPiece;\r\n                    segment = segmentBuilder;\r\n                    segmentBuilder = '';\r\n                }\r\n                segments.push(segment);\r\n                break;\r\n            case encodedNul:\r\n                segmentBuilder += path.substring(start, end);\r\n                segmentBuilder += '\\0';\r\n                break;\r\n            case encodedEscape:\r\n                // The escape character can be used in the output to encode itself.\r\n                segmentBuilder += path.substring(start, end + 1);\r\n                break;\r\n            default:\r\n                fail();\r\n        }\r\n        start = end + 2;\r\n    }\r\n    return new ResourcePath(segments);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Schema Version for the Web client:\r\n * 1.  Initial version including Mutation Queue, Query Cache, and Remote\r\n *     Document Cache\r\n * 2.  Used to ensure a targetGlobal object exists and add targetCount to it. No\r\n *     longer required because migration 3 unconditionally clears it.\r\n * 3.  Dropped and re-created Query Cache to deal with cache corruption related\r\n *     to limbo resolution. Addresses\r\n *     https://github.com/firebase/firebase-ios-sdk/issues/1548\r\n * 4.  Multi-Tab Support.\r\n * 5.  Removal of held write acks.\r\n * 6.  Create document global for tracking document cache size.\r\n * 7.  Ensure every cached document has a sentinel row with a sequence number.\r\n * 8.  Add collection-parent index for Collection Group queries.\r\n * 9.  Change RemoteDocumentChanges store to be keyed by readTime rather than\r\n *     an auto-incrementing ID. This is required for Index-Free queries.\r\n * 10. Rewrite the canonical IDs to the explicit Protobuf-based format.\r\n * 11. Add bundles and named_queries for bundle support.\r\n */\r\nconst SCHEMA_VERSION = 11;\r\n/**\r\n * Wrapper class to store timestamps (seconds and nanos) in IndexedDb objects.\r\n */\r\nclass DbTimestamp {\r\n    constructor(seconds, nanoseconds) {\r\n        this.seconds = seconds;\r\n        this.nanoseconds = nanoseconds;\r\n    }\r\n}\r\n/**\r\n * A singleton object to be stored in the 'owner' store in IndexedDb.\r\n *\r\n * A given database can have a single primary tab assigned at a given time. That\r\n * tab must validate that it is still holding the primary lease before every\r\n * operation that requires locked access. The primary tab should regularly\r\n * write an updated timestamp to this lease to prevent other tabs from\r\n * \"stealing\" the primary lease\r\n */\r\nclass DbPrimaryClient {\r\n    constructor(ownerId, \r\n    /** Whether to allow shared access from multiple tabs. */\r\n    allowTabSynchronization, leaseTimestampMs) {\r\n        this.ownerId = ownerId;\r\n        this.allowTabSynchronization = allowTabSynchronization;\r\n        this.leaseTimestampMs = leaseTimestampMs;\r\n    }\r\n}\r\n/**\r\n * Name of the IndexedDb object store.\r\n *\r\n * Note that the name 'owner' is chosen to ensure backwards compatibility with\r\n * older clients that only supported single locked access to the persistence\r\n * layer.\r\n */\r\nDbPrimaryClient.store = 'owner';\r\n/**\r\n * The key string used for the single object that exists in the\r\n * DbPrimaryClient store.\r\n */\r\nDbPrimaryClient.key = 'owner';\r\n/**\r\n * An object to be stored in the 'mutationQueues' store in IndexedDb.\r\n *\r\n * Each user gets a single queue of MutationBatches to apply to the server.\r\n * DbMutationQueue tracks the metadata about the queue.\r\n */\r\nclass DbMutationQueue {\r\n    constructor(\r\n    /**\r\n     * The normalized user ID to which this queue belongs.\r\n     */\r\n    userId, \r\n    /**\r\n     * An identifier for the highest numbered batch that has been acknowledged\r\n     * by the server. All MutationBatches in this queue with batchIds less\r\n     * than or equal to this value are considered to have been acknowledged by\r\n     * the server.\r\n     *\r\n     * NOTE: this is deprecated and no longer used by the code.\r\n     */\r\n    lastAcknowledgedBatchId, \r\n    /**\r\n     * A stream token that was previously sent by the server.\r\n     *\r\n     * See StreamingWriteRequest in datastore.proto for more details about\r\n     * usage.\r\n     *\r\n     * After sending this token, earlier tokens may not be used anymore so\r\n     * only a single stream token is retained.\r\n     *\r\n     * NOTE: this is deprecated and no longer used by the code.\r\n     */\r\n    lastStreamToken) {\r\n        this.userId = userId;\r\n        this.lastAcknowledgedBatchId = lastAcknowledgedBatchId;\r\n        this.lastStreamToken = lastStreamToken;\r\n    }\r\n}\r\n/** Name of the IndexedDb object store.  */\r\nDbMutationQueue.store = 'mutationQueues';\r\n/** Keys are automatically assigned via the userId property. */\r\nDbMutationQueue.keyPath = 'userId';\r\n/**\r\n * An object to be stored in the 'mutations' store in IndexedDb.\r\n *\r\n * Represents a batch of user-level mutations intended to be sent to the server\r\n * in a single write. Each user-level batch gets a separate DbMutationBatch\r\n * with a new batchId.\r\n */\r\nclass DbMutationBatch {\r\n    constructor(\r\n    /**\r\n     * The normalized user ID to which this batch belongs.\r\n     */\r\n    userId, \r\n    /**\r\n     * An identifier for this batch, allocated using an auto-generated key.\r\n     */\r\n    batchId, \r\n    /**\r\n     * The local write time of the batch, stored as milliseconds since the\r\n     * epoch.\r\n     */\r\n    localWriteTimeMs, \r\n    /**\r\n     * A list of \"mutations\" that represent a partial base state from when this\r\n     * write batch was initially created. During local application of the write\r\n     * batch, these baseMutations are applied prior to the real writes in order\r\n     * to override certain document fields from the remote document cache. This\r\n     * is necessary in the case of non-idempotent writes (e.g. `increment()`\r\n     * transforms) to make sure that the local view of the modified documents\r\n     * doesn't flicker if the remote document cache receives the result of the\r\n     * non-idempotent write before the write is removed from the queue.\r\n     *\r\n     * These mutations are never sent to the backend.\r\n     */\r\n    baseMutations, \r\n    /**\r\n     * A list of mutations to apply. All mutations will be applied atomically.\r\n     *\r\n     * Mutations are serialized via toMutation().\r\n     */\r\n    mutations) {\r\n        this.userId = userId;\r\n        this.batchId = batchId;\r\n        this.localWriteTimeMs = localWriteTimeMs;\r\n        this.baseMutations = baseMutations;\r\n        this.mutations = mutations;\r\n    }\r\n}\r\n/** Name of the IndexedDb object store.  */\r\nDbMutationBatch.store = 'mutations';\r\n/** Keys are automatically assigned via the userId, batchId properties. */\r\nDbMutationBatch.keyPath = 'batchId';\r\n/** The index name for lookup of mutations by user. */\r\nDbMutationBatch.userMutationsIndex = 'userMutationsIndex';\r\n/** The user mutations index is keyed by [userId, batchId] pairs. */\r\nDbMutationBatch.userMutationsKeyPath = ['userId', 'batchId'];\r\n/**\r\n * An object to be stored in the 'documentMutations' store in IndexedDb.\r\n *\r\n * A manually maintained index of all the mutation batches that affect a given\r\n * document key. The rows in this table are references based on the contents of\r\n * DbMutationBatch.mutations.\r\n */\r\nclass DbDocumentMutation {\r\n    constructor() { }\r\n    /**\r\n     * Creates a [userId] key for use in the DbDocumentMutations index to iterate\r\n     * over all of a user's document mutations.\r\n     */\r\n    static prefixForUser(userId) {\r\n        return [userId];\r\n    }\r\n    /**\r\n     * Creates a [userId, encodedPath] key for use in the DbDocumentMutations\r\n     * index to iterate over all at document mutations for a given path or lower.\r\n     */\r\n    static prefixForPath(userId, path) {\r\n        return [userId, encodeResourcePath(path)];\r\n    }\r\n    /**\r\n     * Creates a full index key of [userId, encodedPath, batchId] for inserting\r\n     * and deleting into the DbDocumentMutations index.\r\n     */\r\n    static key(userId, path, batchId) {\r\n        return [userId, encodeResourcePath(path), batchId];\r\n    }\r\n}\r\nDbDocumentMutation.store = 'documentMutations';\r\n/**\r\n * Because we store all the useful information for this store in the key,\r\n * there is no useful information to store as the value. The raw (unencoded)\r\n * path cannot be stored because IndexedDb doesn't store prototype\r\n * information.\r\n */\r\nDbDocumentMutation.PLACEHOLDER = new DbDocumentMutation();\r\n/**\r\n * Represents the known absence of a document at a particular version.\r\n * Stored in IndexedDb as part of a DbRemoteDocument object.\r\n */\r\nclass DbNoDocument {\r\n    constructor(path, readTime) {\r\n        this.path = path;\r\n        this.readTime = readTime;\r\n    }\r\n}\r\n/**\r\n * Represents a document that is known to exist but whose data is unknown.\r\n * Stored in IndexedDb as part of a DbRemoteDocument object.\r\n */\r\nclass DbUnknownDocument {\r\n    constructor(path, version) {\r\n        this.path = path;\r\n        this.version = version;\r\n    }\r\n}\r\n/**\r\n * An object to be stored in the 'remoteDocuments' store in IndexedDb.\r\n * It represents either:\r\n *\r\n * - A complete document.\r\n * - A \"no document\" representing a document that is known not to exist (at\r\n * some version).\r\n * - An \"unknown document\" representing a document that is known to exist (at\r\n * some version) but whose contents are unknown.\r\n *\r\n * Note: This is the persisted equivalent of a MaybeDocument and could perhaps\r\n * be made more general if necessary.\r\n */\r\nclass DbRemoteDocument {\r\n    // TODO: We are currently storing full document keys almost three times\r\n    // (once as part of the primary key, once - partly - as `parentPath` and once\r\n    // inside the encoded documents). During our next migration, we should\r\n    // rewrite the primary key as parentPath + document ID which would allow us\r\n    // to drop one value.\r\n    constructor(\r\n    /**\r\n     * Set to an instance of DbUnknownDocument if the data for a document is\r\n     * not known, but it is known that a document exists at the specified\r\n     * version (e.g. it had a successful update applied to it)\r\n     */\r\n    unknownDocument, \r\n    /**\r\n     * Set to an instance of a DbNoDocument if it is known that no document\r\n     * exists.\r\n     */\r\n    noDocument, \r\n    /**\r\n     * Set to an instance of a Document if there's a cached version of the\r\n     * document.\r\n     */\r\n    document, \r\n    /**\r\n     * Documents that were written to the remote document store based on\r\n     * a write acknowledgment are marked with `hasCommittedMutations`. These\r\n     * documents are potentially inconsistent with the backend's copy and use\r\n     * the write's commit version as their document version.\r\n     */\r\n    hasCommittedMutations, \r\n    /**\r\n     * When the document was read from the backend. Undefined for data written\r\n     * prior to schema version 9.\r\n     */\r\n    readTime, \r\n    /**\r\n     * The path of the collection this document is part of. Undefined for data\r\n     * written prior to schema version 9.\r\n     */\r\n    parentPath) {\r\n        this.unknownDocument = unknownDocument;\r\n        this.noDocument = noDocument;\r\n        this.document = document;\r\n        this.hasCommittedMutations = hasCommittedMutations;\r\n        this.readTime = readTime;\r\n        this.parentPath = parentPath;\r\n    }\r\n}\r\nDbRemoteDocument.store = 'remoteDocuments';\r\n/**\r\n * An index that provides access to all entries sorted by read time (which\r\n * corresponds to the last modification time of each row).\r\n *\r\n * This index is used to provide a changelog for Multi-Tab.\r\n */\r\nDbRemoteDocument.readTimeIndex = 'readTimeIndex';\r\nDbRemoteDocument.readTimeIndexPath = 'readTime';\r\n/**\r\n * An index that provides access to documents in a collection sorted by read\r\n * time.\r\n *\r\n * This index is used to allow the RemoteDocumentCache to fetch newly changed\r\n * documents in a collection.\r\n */\r\nDbRemoteDocument.collectionReadTimeIndex = 'collectionReadTimeIndex';\r\nDbRemoteDocument.collectionReadTimeIndexPath = ['parentPath', 'readTime'];\r\n/**\r\n * Contains a single entry that has metadata about the remote document cache.\r\n */\r\nclass DbRemoteDocumentGlobal {\r\n    /**\r\n     * @param byteSize - Approximately the total size in bytes of all the\r\n     * documents in the document cache.\r\n     */\r\n    constructor(byteSize) {\r\n        this.byteSize = byteSize;\r\n    }\r\n}\r\nDbRemoteDocumentGlobal.store = 'remoteDocumentGlobal';\r\nDbRemoteDocumentGlobal.key = 'remoteDocumentGlobalKey';\r\n/**\r\n * An object to be stored in the 'targets' store in IndexedDb.\r\n *\r\n * This is based on and should be kept in sync with the proto used in the iOS\r\n * client.\r\n *\r\n * Each query the client listens to against the server is tracked on disk so\r\n * that the query can be efficiently resumed on restart.\r\n */\r\nclass DbTarget {\r\n    constructor(\r\n    /**\r\n     * An auto-generated sequential numeric identifier for the query.\r\n     *\r\n     * Queries are stored using their canonicalId as the key, but these\r\n     * canonicalIds can be quite long so we additionally assign a unique\r\n     * queryId which can be used by referenced data structures (e.g.\r\n     * indexes) to minimize the on-disk cost.\r\n     */\r\n    targetId, \r\n    /**\r\n     * The canonical string representing this query. This is not unique.\r\n     */\r\n    canonicalId, \r\n    /**\r\n     * The last readTime received from the Watch Service for this query.\r\n     *\r\n     * This is the same value as TargetChange.read_time in the protos.\r\n     */\r\n    readTime, \r\n    /**\r\n     * An opaque, server-assigned token that allows watching a query to be\r\n     * resumed after disconnecting without retransmitting all the data\r\n     * that matches the query. The resume token essentially identifies a\r\n     * point in time from which the server should resume sending results.\r\n     *\r\n     * This is related to the snapshotVersion in that the resumeToken\r\n     * effectively also encodes that value, but the resumeToken is opaque\r\n     * and sometimes encodes additional information.\r\n     *\r\n     * A consequence of this is that the resumeToken should be used when\r\n     * asking the server to reason about where this client is in the watch\r\n     * stream, but the client should use the snapshotVersion for its own\r\n     * purposes.\r\n     *\r\n     * This is the same value as TargetChange.resume_token in the protos.\r\n     */\r\n    resumeToken, \r\n    /**\r\n     * A sequence number representing the last time this query was\r\n     * listened to, used for garbage collection purposes.\r\n     *\r\n     * Conventionally this would be a timestamp value, but device-local\r\n     * clocks are unreliable and they must be able to create new listens\r\n     * even while disconnected. Instead this should be a monotonically\r\n     * increasing number that's incremented on each listen call.\r\n     *\r\n     * This is different from the queryId since the queryId is an\r\n     * immutable identifier assigned to the Query on first use while\r\n     * lastListenSequenceNumber is updated every time the query is\r\n     * listened to.\r\n     */\r\n    lastListenSequenceNumber, \r\n    /**\r\n     * Denotes the maximum snapshot version at which the associated query view\r\n     * contained no limbo documents.  Undefined for data written prior to\r\n     * schema version 9.\r\n     */\r\n    lastLimboFreeSnapshotVersion, \r\n    /**\r\n     * The query for this target.\r\n     *\r\n     * Because canonical ids are not unique we must store the actual query. We\r\n     * use the proto to have an object we can persist without having to\r\n     * duplicate translation logic to and from a `Query` object.\r\n     */\r\n    query) {\r\n        this.targetId = targetId;\r\n        this.canonicalId = canonicalId;\r\n        this.readTime = readTime;\r\n        this.resumeToken = resumeToken;\r\n        this.lastListenSequenceNumber = lastListenSequenceNumber;\r\n        this.lastLimboFreeSnapshotVersion = lastLimboFreeSnapshotVersion;\r\n        this.query = query;\r\n    }\r\n}\r\nDbTarget.store = 'targets';\r\n/** Keys are automatically assigned via the targetId property. */\r\nDbTarget.keyPath = 'targetId';\r\n/** The name of the queryTargets index. */\r\nDbTarget.queryTargetsIndexName = 'queryTargetsIndex';\r\n/**\r\n * The index of all canonicalIds to the targets that they match. This is not\r\n * a unique mapping because canonicalId does not promise a unique name for all\r\n * possible queries, so we append the targetId to make the mapping unique.\r\n */\r\nDbTarget.queryTargetsKeyPath = ['canonicalId', 'targetId'];\r\n/**\r\n * An object representing an association between a target and a document, or a\r\n * sentinel row marking the last sequence number at which a document was used.\r\n * Each document cached must have a corresponding sentinel row before lru\r\n * garbage collection is enabled.\r\n *\r\n * The target associations and sentinel rows are co-located so that orphaned\r\n * documents and their sequence numbers can be identified efficiently via a scan\r\n * of this store.\r\n */\r\nclass DbTargetDocument {\r\n    constructor(\r\n    /**\r\n     * The targetId identifying a target or 0 for a sentinel row.\r\n     */\r\n    targetId, \r\n    /**\r\n     * The path to the document, as encoded in the key.\r\n     */\r\n    path, \r\n    /**\r\n     * If this is a sentinel row, this should be the sequence number of the last\r\n     * time the document specified by `path` was used. Otherwise, it should be\r\n     * `undefined`.\r\n     */\r\n    sequenceNumber) {\r\n        this.targetId = targetId;\r\n        this.path = path;\r\n        this.sequenceNumber = sequenceNumber;\r\n    }\r\n}\r\n/** Name of the IndexedDb object store.  */\r\nDbTargetDocument.store = 'targetDocuments';\r\n/** Keys are automatically assigned via the targetId, path properties. */\r\nDbTargetDocument.keyPath = ['targetId', 'path'];\r\n/** The index name for the reverse index. */\r\nDbTargetDocument.documentTargetsIndex = 'documentTargetsIndex';\r\n/** We also need to create the reverse index for these properties. */\r\nDbTargetDocument.documentTargetsKeyPath = ['path', 'targetId'];\r\n/**\r\n * A record of global state tracked across all Targets, tracked separately\r\n * to avoid the need for extra indexes.\r\n *\r\n * This should be kept in-sync with the proto used in the iOS client.\r\n */\r\nclass DbTargetGlobal {\r\n    constructor(\r\n    /**\r\n     * The highest numbered target id across all targets.\r\n     *\r\n     * See DbTarget.targetId.\r\n     */\r\n    highestTargetId, \r\n    /**\r\n     * The highest numbered lastListenSequenceNumber across all targets.\r\n     *\r\n     * See DbTarget.lastListenSequenceNumber.\r\n     */\r\n    highestListenSequenceNumber, \r\n    /**\r\n     * A global snapshot version representing the last consistent snapshot we\r\n     * received from the backend. This is monotonically increasing and any\r\n     * snapshots received from the backend prior to this version (e.g. for\r\n     * targets resumed with a resumeToken) should be suppressed (buffered)\r\n     * until the backend has caught up to this snapshot version again. This\r\n     * prevents our cache from ever going backwards in time.\r\n     */\r\n    lastRemoteSnapshotVersion, \r\n    /**\r\n     * The number of targets persisted.\r\n     */\r\n    targetCount) {\r\n        this.highestTargetId = highestTargetId;\r\n        this.highestListenSequenceNumber = highestListenSequenceNumber;\r\n        this.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion;\r\n        this.targetCount = targetCount;\r\n    }\r\n}\r\n/**\r\n * The key string used for the single object that exists in the\r\n * DbTargetGlobal store.\r\n */\r\nDbTargetGlobal.key = 'targetGlobalKey';\r\nDbTargetGlobal.store = 'targetGlobal';\r\n/**\r\n * An object representing an association between a Collection id (e.g. 'messages')\r\n * to a parent path (e.g. '/chats/123') that contains it as a (sub)collection.\r\n * This is used to efficiently find all collections to query when performing\r\n * a Collection Group query.\r\n */\r\nclass DbCollectionParent {\r\n    constructor(\r\n    /**\r\n     * The collectionId (e.g. 'messages')\r\n     */\r\n    collectionId, \r\n    /**\r\n     * The path to the parent (either a document location or an empty path for\r\n     * a root-level collection).\r\n     */\r\n    parent) {\r\n        this.collectionId = collectionId;\r\n        this.parent = parent;\r\n    }\r\n}\r\n/** Name of the IndexedDb object store. */\r\nDbCollectionParent.store = 'collectionParents';\r\n/** Keys are automatically assigned via the collectionId, parent properties. */\r\nDbCollectionParent.keyPath = ['collectionId', 'parent'];\r\n/**\r\n * A record of the metadata state of each client.\r\n *\r\n * PORTING NOTE: This is used to synchronize multi-tab state and does not need\r\n * to be ported to iOS or Android.\r\n */\r\nclass DbClientMetadata {\r\n    constructor(\r\n    // Note: Previous schema versions included a field\r\n    // \"lastProcessedDocumentChangeId\". Don't use anymore.\r\n    /** The auto-generated client id assigned at client startup. */\r\n    clientId, \r\n    /** The last time this state was updated. */\r\n    updateTimeMs, \r\n    /** Whether the client's network connection is enabled. */\r\n    networkEnabled, \r\n    /** Whether this client is running in a foreground tab. */\r\n    inForeground) {\r\n        this.clientId = clientId;\r\n        this.updateTimeMs = updateTimeMs;\r\n        this.networkEnabled = networkEnabled;\r\n        this.inForeground = inForeground;\r\n    }\r\n}\r\n/** Name of the IndexedDb object store. */\r\nDbClientMetadata.store = 'clientMetadata';\r\n/** Keys are automatically assigned via the clientId properties. */\r\nDbClientMetadata.keyPath = 'clientId';\r\n/**\r\n * A object representing a bundle loaded by the SDK.\r\n */\r\nclass DbBundle {\r\n    constructor(\r\n    /** The ID of the loaded bundle. */\r\n    bundleId, \r\n    /** The create time of the loaded bundle. */\r\n    createTime, \r\n    /** The schema version of the loaded bundle. */\r\n    version) {\r\n        this.bundleId = bundleId;\r\n        this.createTime = createTime;\r\n        this.version = version;\r\n    }\r\n}\r\n/** Name of the IndexedDb object store. */\r\nDbBundle.store = 'bundles';\r\nDbBundle.keyPath = 'bundleId';\r\n/**\r\n * A object representing a named query loaded by the SDK via a bundle.\r\n */\r\nclass DbNamedQuery {\r\n    constructor(\r\n    /** The name of the query. */\r\n    name, \r\n    /** The read time of the results saved in the bundle from the named query. */\r\n    readTime, \r\n    /** The query saved in the bundle. */\r\n    bundledQuery) {\r\n        this.name = name;\r\n        this.readTime = readTime;\r\n        this.bundledQuery = bundledQuery;\r\n    }\r\n}\r\n/** Name of the IndexedDb object store. */\r\nDbNamedQuery.store = 'namedQueries';\r\nDbNamedQuery.keyPath = 'name';\r\n// Visible for testing\r\nconst V1_STORES = [\r\n    DbMutationQueue.store,\r\n    DbMutationBatch.store,\r\n    DbDocumentMutation.store,\r\n    DbRemoteDocument.store,\r\n    DbTarget.store,\r\n    DbPrimaryClient.store,\r\n    DbTargetGlobal.store,\r\n    DbTargetDocument.store\r\n];\r\n// V2 is no longer usable (see comment at top of file)\r\n// Visible for testing\r\nconst V3_STORES = V1_STORES;\r\n// Visible for testing\r\n// Note: DbRemoteDocumentChanges is no longer used and dropped with v9.\r\nconst V4_STORES = [...V3_STORES, DbClientMetadata.store];\r\n// V5 does not change the set of stores.\r\nconst V6_STORES = [...V4_STORES, DbRemoteDocumentGlobal.store];\r\n// V7 does not change the set of stores.\r\nconst V8_STORES = [...V6_STORES, DbCollectionParent.store];\r\n// V9 does not change the set of stores.\r\n// V10 does not change the set of stores.\r\nconst V11_STORES = [...V8_STORES, DbBundle.store, DbNamedQuery.store];\r\n/**\r\n * The list of all default IndexedDB stores used throughout the SDK. This is\r\n * used when creating transactions so that access across all stores is done\r\n * atomically.\r\n */\r\nconst ALL_STORES = V11_STORES;\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst PRIMARY_LEASE_LOST_ERROR_MSG = 'The current tab is not in the required state to perform this operation. ' +\r\n    'It might be necessary to refresh the browser tab.';\r\n/**\r\n * A base class representing a persistence transaction, encapsulating both the\r\n * transaction's sequence numbers as well as a list of onCommitted listeners.\r\n *\r\n * When you call Persistence.runTransaction(), it will create a transaction and\r\n * pass it to your callback. You then pass it to any method that operates\r\n * on persistence.\r\n */\r\nclass PersistenceTransaction {\r\n    constructor() {\r\n        this.onCommittedListeners = [];\r\n    }\r\n    addOnCommittedListener(listener) {\r\n        this.onCommittedListeners.push(listener);\r\n    }\r\n    raiseOnCommittedEvent() {\r\n        this.onCommittedListeners.forEach(listener => listener());\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * PersistencePromise is essentially a re-implementation of Promise except\r\n * it has a .next() method instead of .then() and .next() and .catch() callbacks\r\n * are executed synchronously when a PersistencePromise resolves rather than\r\n * asynchronously (Promise implementations use setImmediate() or similar).\r\n *\r\n * This is necessary to interoperate with IndexedDB which will automatically\r\n * commit transactions if control is returned to the event loop without\r\n * synchronously initiating another operation on the transaction.\r\n *\r\n * NOTE: .then() and .catch() only allow a single consumer, unlike normal\r\n * Promises.\r\n */\r\nclass PersistencePromise {\r\n    constructor(callback) {\r\n        // NOTE: next/catchCallback will always point to our own wrapper functions,\r\n        // not the user's raw next() or catch() callbacks.\r\n        this.nextCallback = null;\r\n        this.catchCallback = null;\r\n        // When the operation resolves, we'll set result or error and mark isDone.\r\n        this.result = undefined;\r\n        this.error = undefined;\r\n        this.isDone = false;\r\n        // Set to true when .then() or .catch() are called and prevents additional\r\n        // chaining.\r\n        this.callbackAttached = false;\r\n        callback(value => {\r\n            this.isDone = true;\r\n            this.result = value;\r\n            if (this.nextCallback) {\r\n                // value should be defined unless T is Void, but we can't express\r\n                // that in the type system.\r\n                this.nextCallback(value);\r\n            }\r\n        }, error => {\r\n            this.isDone = true;\r\n            this.error = error;\r\n            if (this.catchCallback) {\r\n                this.catchCallback(error);\r\n            }\r\n        });\r\n    }\r\n    catch(fn) {\r\n        return this.next(undefined, fn);\r\n    }\r\n    next(nextFn, catchFn) {\r\n        if (this.callbackAttached) {\r\n            fail();\r\n        }\r\n        this.callbackAttached = true;\r\n        if (this.isDone) {\r\n            if (!this.error) {\r\n                return this.wrapSuccess(nextFn, this.result);\r\n            }\r\n            else {\r\n                return this.wrapFailure(catchFn, this.error);\r\n            }\r\n        }\r\n        else {\r\n            return new PersistencePromise((resolve, reject) => {\r\n                this.nextCallback = (value) => {\r\n                    this.wrapSuccess(nextFn, value).next(resolve, reject);\r\n                };\r\n                this.catchCallback = (error) => {\r\n                    this.wrapFailure(catchFn, error).next(resolve, reject);\r\n                };\r\n            });\r\n        }\r\n    }\r\n    toPromise() {\r\n        return new Promise((resolve, reject) => {\r\n            this.next(resolve, reject);\r\n        });\r\n    }\r\n    wrapUserFunction(fn) {\r\n        try {\r\n            const result = fn();\r\n            if (result instanceof PersistencePromise) {\r\n                return result;\r\n            }\r\n            else {\r\n                return PersistencePromise.resolve(result);\r\n            }\r\n        }\r\n        catch (e) {\r\n            return PersistencePromise.reject(e);\r\n        }\r\n    }\r\n    wrapSuccess(nextFn, value) {\r\n        if (nextFn) {\r\n            return this.wrapUserFunction(() => nextFn(value));\r\n        }\r\n        else {\r\n            // If there's no nextFn, then R must be the same as T\r\n            return PersistencePromise.resolve(value);\r\n        }\r\n    }\r\n    wrapFailure(catchFn, error) {\r\n        if (catchFn) {\r\n            return this.wrapUserFunction(() => catchFn(error));\r\n        }\r\n        else {\r\n            return PersistencePromise.reject(error);\r\n        }\r\n    }\r\n    static resolve(result) {\r\n        return new PersistencePromise((resolve, reject) => {\r\n            resolve(result);\r\n        });\r\n    }\r\n    static reject(error) {\r\n        return new PersistencePromise((resolve, reject) => {\r\n            reject(error);\r\n        });\r\n    }\r\n    static waitFor(\r\n    // Accept all Promise types in waitFor().\r\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n    all) {\r\n        return new PersistencePromise((resolve, reject) => {\r\n            let expectedCount = 0;\r\n            let resolvedCount = 0;\r\n            let done = false;\r\n            all.forEach(element => {\r\n                ++expectedCount;\r\n                element.next(() => {\r\n                    ++resolvedCount;\r\n                    if (done && resolvedCount === expectedCount) {\r\n                        resolve();\r\n                    }\r\n                }, err => reject(err));\r\n            });\r\n            done = true;\r\n            if (resolvedCount === expectedCount) {\r\n                resolve();\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Given an array of predicate functions that asynchronously evaluate to a\r\n     * boolean, implements a short-circuiting `or` between the results. Predicates\r\n     * will be evaluated until one of them returns `true`, then stop. The final\r\n     * result will be whether any of them returned `true`.\r\n     */\r\n    static or(predicates) {\r\n        let p = PersistencePromise.resolve(false);\r\n        for (const predicate of predicates) {\r\n            p = p.next(isTrue => {\r\n                if (isTrue) {\r\n                    return PersistencePromise.resolve(isTrue);\r\n                }\r\n                else {\r\n                    return predicate();\r\n                }\r\n            });\r\n        }\r\n        return p;\r\n    }\r\n    static forEach(collection, f) {\r\n        const promises = [];\r\n        collection.forEach((r, s) => {\r\n            promises.push(f.call(this, r, s));\r\n        });\r\n        return this.waitFor(promises);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// References to `window` are guarded by SimpleDb.isAvailable()\r\n/* eslint-disable no-restricted-globals */\r\nconst LOG_TAG$g = 'SimpleDb';\r\n/**\r\n * The maximum number of retry attempts for an IndexedDb transaction that fails\r\n * with a DOMException.\r\n */\r\nconst TRANSACTION_RETRY_COUNT = 3;\r\n/**\r\n * Wraps an IDBTransaction and exposes a store() method to get a handle to a\r\n * specific object store.\r\n */\r\nclass SimpleDbTransaction {\r\n    constructor(action, transaction) {\r\n        this.action = action;\r\n        this.transaction = transaction;\r\n        this.aborted = false;\r\n        /**\r\n         * A `Promise` that resolves with the result of the IndexedDb transaction.\r\n         */\r\n        this.completionDeferred = new Deferred();\r\n        this.transaction.oncomplete = () => {\r\n            this.completionDeferred.resolve();\r\n        };\r\n        this.transaction.onabort = () => {\r\n            if (transaction.error) {\r\n                this.completionDeferred.reject(new IndexedDbTransactionError(action, transaction.error));\r\n            }\r\n            else {\r\n                this.completionDeferred.resolve();\r\n            }\r\n        };\r\n        this.transaction.onerror = (event) => {\r\n            const error = checkForAndReportiOSError(event.target.error);\r\n            this.completionDeferred.reject(new IndexedDbTransactionError(action, error));\r\n        };\r\n    }\r\n    static open(db, action, mode, objectStoreNames) {\r\n        try {\r\n            return new SimpleDbTransaction(action, db.transaction(objectStoreNames, mode));\r\n        }\r\n        catch (e) {\r\n            throw new IndexedDbTransactionError(action, e);\r\n        }\r\n    }\r\n    get completionPromise() {\r\n        return this.completionDeferred.promise;\r\n    }\r\n    abort(error) {\r\n        if (error) {\r\n            this.completionDeferred.reject(error);\r\n        }\r\n        if (!this.aborted) {\r\n            logDebug(LOG_TAG$g, 'Aborting transaction:', error ? error.message : 'Client-initiated abort');\r\n            this.aborted = true;\r\n            this.transaction.abort();\r\n        }\r\n    }\r\n    /**\r\n     * Returns a SimpleDbStore<KeyType, ValueType> for the specified store. All\r\n     * operations performed on the SimpleDbStore happen within the context of this\r\n     * transaction and it cannot be used anymore once the transaction is\r\n     * completed.\r\n     *\r\n     * Note that we can't actually enforce that the KeyType and ValueType are\r\n     * correct, but they allow type safety through the rest of the consuming code.\r\n     */\r\n    store(storeName) {\r\n        const store = this.transaction.objectStore(storeName);\r\n        return new SimpleDbStore(store);\r\n    }\r\n}\r\n/**\r\n * Provides a wrapper around IndexedDb with a simplified interface that uses\r\n * Promise-like return values to chain operations. Real promises cannot be used\r\n * since .then() continuations are executed asynchronously (e.g. via\r\n * .setImmediate), which would cause IndexedDB to end the transaction.\r\n * See PersistencePromise for more details.\r\n */\r\nclass SimpleDb {\r\n    /*\r\n     * Creates a new SimpleDb wrapper for IndexedDb database `name`.\r\n     *\r\n     * Note that `version` must not be a downgrade. IndexedDB does not support\r\n     * downgrading the schema version. We currently do not support any way to do\r\n     * versioning outside of IndexedDB's versioning mechanism, as only\r\n     * version-upgrade transactions are allowed to do things like create\r\n     * objectstores.\r\n     */\r\n    constructor(name, version, schemaConverter) {\r\n        this.name = name;\r\n        this.version = version;\r\n        this.schemaConverter = schemaConverter;\r\n        const iOSVersion = SimpleDb.getIOSVersion(getUA());\r\n        // NOTE: According to https://bugs.webkit.org/show_bug.cgi?id=197050, the\r\n        // bug we're checking for should exist in iOS >= 12.2 and < 13, but for\r\n        // whatever reason it's much harder to hit after 12.2 so we only proactively\r\n        // log on 12.2.\r\n        if (iOSVersion === 12.2) {\r\n            logError('Firestore persistence suffers from a bug in iOS 12.2 ' +\r\n                'Safari that may cause your app to stop working. See ' +\r\n                'https://stackoverflow.com/q/56496296/110915 for details ' +\r\n                'and a potential workaround.');\r\n        }\r\n    }\r\n    /** Deletes the specified database. */\r\n    static delete(name) {\r\n        logDebug(LOG_TAG$g, 'Removing database:', name);\r\n        return wrapRequest(window.indexedDB.deleteDatabase(name)).toPromise();\r\n    }\r\n    /** Returns true if IndexedDB is available in the current environment. */\r\n    static isAvailable() {\r\n        if (!isIndexedDBAvailable()) {\r\n            return false;\r\n        }\r\n        if (SimpleDb.isMockPersistence()) {\r\n            return true;\r\n        }\r\n        // We extensively use indexed array values and compound keys,\r\n        // which IE and Edge do not support. However, they still have indexedDB\r\n        // defined on the window, so we need to check for them here and make sure\r\n        // to return that persistence is not enabled for those browsers.\r\n        // For tracking support of this feature, see here:\r\n        // https://developer.microsoft.com/en-us/microsoft-edge/platform/status/indexeddbarraysandmultientrysupport/\r\n        // Check the UA string to find out the browser.\r\n        const ua = getUA();\r\n        // IE 10\r\n        // ua = 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)';\r\n        // IE 11\r\n        // ua = 'Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko';\r\n        // Edge\r\n        // ua = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,\r\n        // like Gecko) Chrome/39.0.2171.71 Safari/537.36 Edge/12.0';\r\n        // iOS Safari: Disable for users running iOS version < 10.\r\n        const iOSVersion = SimpleDb.getIOSVersion(ua);\r\n        const isUnsupportedIOS = 0 < iOSVersion && iOSVersion < 10;\r\n        // Android browser: Disable for userse running version < 4.5.\r\n        const androidVersion = SimpleDb.getAndroidVersion(ua);\r\n        const isUnsupportedAndroid = 0 < androidVersion && androidVersion < 4.5;\r\n        if (ua.indexOf('MSIE ') > 0 ||\r\n            ua.indexOf('Trident/') > 0 ||\r\n            ua.indexOf('Edge/') > 0 ||\r\n            isUnsupportedIOS ||\r\n            isUnsupportedAndroid) {\r\n            return false;\r\n        }\r\n        else {\r\n            return true;\r\n        }\r\n    }\r\n    /**\r\n     * Returns true if the backing IndexedDB store is the Node IndexedDBShim\r\n     * (see https://github.com/axemclion/IndexedDBShim).\r\n     */\r\n    static isMockPersistence() {\r\n        var _a;\r\n        return (typeof process !== 'undefined' &&\r\n            ((_a = process.env) === null || _a === void 0 ? void 0 : _a.USE_MOCK_PERSISTENCE) === 'YES');\r\n    }\r\n    /** Helper to get a typed SimpleDbStore from a transaction. */\r\n    static getStore(txn, store) {\r\n        return txn.store(store);\r\n    }\r\n    // visible for testing\r\n    /** Parse User Agent to determine iOS version. Returns -1 if not found. */\r\n    static getIOSVersion(ua) {\r\n        const iOSVersionRegex = ua.match(/i(?:phone|pad|pod) os ([\\d_]+)/i);\r\n        const version = iOSVersionRegex\r\n            ? iOSVersionRegex[1].split('_').slice(0, 2).join('.')\r\n            : '-1';\r\n        return Number(version);\r\n    }\r\n    // visible for testing\r\n    /** Parse User Agent to determine Android version. Returns -1 if not found. */\r\n    static getAndroidVersion(ua) {\r\n        const androidVersionRegex = ua.match(/Android ([\\d.]+)/i);\r\n        const version = androidVersionRegex\r\n            ? androidVersionRegex[1].split('.').slice(0, 2).join('.')\r\n            : '-1';\r\n        return Number(version);\r\n    }\r\n    /**\r\n     * Opens the specified database, creating or upgrading it if necessary.\r\n     */\r\n    async ensureDb(action) {\r\n        if (!this.db) {\r\n            logDebug(LOG_TAG$g, 'Opening database:', this.name);\r\n            this.db = await new Promise((resolve, reject) => {\r\n                // TODO(mikelehen): Investigate browser compatibility.\r\n                // https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB\r\n                // suggests IE9 and older WebKit browsers handle upgrade\r\n                // differently. They expect setVersion, as described here:\r\n                // https://developer.mozilla.org/en-US/docs/Web/API/IDBVersionChangeRequest/setVersion\r\n                const request = indexedDB.open(this.name, this.version);\r\n                request.onsuccess = (event) => {\r\n                    const db = event.target.result;\r\n                    resolve(db);\r\n                };\r\n                request.onblocked = () => {\r\n                    reject(new IndexedDbTransactionError(action, 'Cannot upgrade IndexedDB schema while another tab is open. ' +\r\n                        'Close all tabs that access Firestore and reload this page to proceed.'));\r\n                };\r\n                request.onerror = (event) => {\r\n                    const error = event.target.error;\r\n                    if (error.name === 'VersionError') {\r\n                        reject(new FirestoreError(Code.FAILED_PRECONDITION, 'A newer version of the Firestore SDK was previously used and so the persisted ' +\r\n                            'data is not compatible with the version of the SDK you are now using. The SDK ' +\r\n                            'will operate with persistence disabled. If you need persistence, please ' +\r\n                            're-upgrade to a newer version of the SDK or else clear the persisted IndexedDB ' +\r\n                            'data for your app to start fresh.'));\r\n                    }\r\n                    else if (error.name === 'InvalidStateError') {\r\n                        reject(new FirestoreError(Code.FAILED_PRECONDITION, 'Unable to open an IndexedDB connection. This could be due to running in a ' +\r\n                            'private browsing session on a browser whose private browsing sessions do not ' +\r\n                            'support IndexedDB: ' +\r\n                            error));\r\n                    }\r\n                    else {\r\n                        reject(new IndexedDbTransactionError(action, error));\r\n                    }\r\n                };\r\n                request.onupgradeneeded = (event) => {\r\n                    logDebug(LOG_TAG$g, 'Database \"' + this.name + '\" requires upgrade from version:', event.oldVersion);\r\n                    const db = event.target.result;\r\n                    this.schemaConverter\r\n                        .createOrUpgrade(db, request.transaction, event.oldVersion, this.version)\r\n                        .next(() => {\r\n                        logDebug(LOG_TAG$g, 'Database upgrade to version ' + this.version + ' complete');\r\n                    });\r\n                };\r\n            });\r\n        }\r\n        if (this.versionchangelistener) {\r\n            this.db.onversionchange = event => this.versionchangelistener(event);\r\n        }\r\n        return this.db;\r\n    }\r\n    setVersionChangeListener(versionChangeListener) {\r\n        this.versionchangelistener = versionChangeListener;\r\n        if (this.db) {\r\n            this.db.onversionchange = (event) => {\r\n                return versionChangeListener(event);\r\n            };\r\n        }\r\n    }\r\n    async runTransaction(action, mode, objectStores, transactionFn) {\r\n        const readonly = mode === 'readonly';\r\n        let attemptNumber = 0;\r\n        while (true) {\r\n            ++attemptNumber;\r\n            try {\r\n                this.db = await this.ensureDb(action);\r\n                const transaction = SimpleDbTransaction.open(this.db, action, readonly ? 'readonly' : 'readwrite', objectStores);\r\n                const transactionFnResult = transactionFn(transaction)\r\n                    .catch(error => {\r\n                    // Abort the transaction if there was an error.\r\n                    transaction.abort(error);\r\n                    // We cannot actually recover, and calling `abort()` will cause the transaction's\r\n                    // completion promise to be rejected. This in turn means that we won't use\r\n                    // `transactionFnResult` below. We return a rejection here so that we don't add the\r\n                    // possibility of returning `void` to the type of `transactionFnResult`.\r\n                    return PersistencePromise.reject(error);\r\n                })\r\n                    .toPromise();\r\n                // As noted above, errors are propagated by aborting the transaction. So\r\n                // we swallow any error here to avoid the browser logging it as unhandled.\r\n                transactionFnResult.catch(() => { });\r\n                // Wait for the transaction to complete (i.e. IndexedDb's onsuccess event to\r\n                // fire), but still return the original transactionFnResult back to the\r\n                // caller.\r\n                await transaction.completionPromise;\r\n                return transactionFnResult;\r\n            }\r\n            catch (error) {\r\n                // TODO(schmidt-sebastian): We could probably be smarter about this and\r\n                // not retry exceptions that are likely unrecoverable (such as quota\r\n                // exceeded errors).\r\n                // Note: We cannot use an instanceof check for FirestoreException, since the\r\n                // exception is wrapped in a generic error by our async/await handling.\r\n                const retryable = error.name !== 'FirebaseError' &&\r\n                    attemptNumber < TRANSACTION_RETRY_COUNT;\r\n                logDebug(LOG_TAG$g, 'Transaction failed with error:', error.message, 'Retrying:', retryable);\r\n                this.close();\r\n                if (!retryable) {\r\n                    return Promise.reject(error);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    close() {\r\n        if (this.db) {\r\n            this.db.close();\r\n        }\r\n        this.db = undefined;\r\n    }\r\n}\r\n/**\r\n * A controller for iterating over a key range or index. It allows an iterate\r\n * callback to delete the currently-referenced object, or jump to a new key\r\n * within the key range or index.\r\n */\r\nclass IterationController {\r\n    constructor(dbCursor) {\r\n        this.dbCursor = dbCursor;\r\n        this.shouldStop = false;\r\n        this.nextKey = null;\r\n    }\r\n    get isDone() {\r\n        return this.shouldStop;\r\n    }\r\n    get skipToKey() {\r\n        return this.nextKey;\r\n    }\r\n    set cursor(value) {\r\n        this.dbCursor = value;\r\n    }\r\n    /**\r\n     * This function can be called to stop iteration at any point.\r\n     */\r\n    done() {\r\n        this.shouldStop = true;\r\n    }\r\n    /**\r\n     * This function can be called to skip to that next key, which could be\r\n     * an index or a primary key.\r\n     */\r\n    skip(key) {\r\n        this.nextKey = key;\r\n    }\r\n    /**\r\n     * Delete the current cursor value from the object store.\r\n     *\r\n     * NOTE: You CANNOT do this with a keysOnly query.\r\n     */\r\n    delete() {\r\n        return wrapRequest(this.dbCursor.delete());\r\n    }\r\n}\r\n/** An error that wraps exceptions that thrown during IndexedDB execution. */\r\nclass IndexedDbTransactionError extends FirestoreError {\r\n    constructor(actionName, cause) {\r\n        super(Code.UNAVAILABLE, `IndexedDB transaction '${actionName}' failed: ${cause}`);\r\n        this.name = 'IndexedDbTransactionError';\r\n    }\r\n}\r\n/** Verifies whether `e` is an IndexedDbTransactionError. */\r\nfunction isIndexedDbTransactionError(e) {\r\n    // Use name equality, as instanceof checks on errors don't work with errors\r\n    // that wrap other errors.\r\n    return e.name === 'IndexedDbTransactionError';\r\n}\r\n/**\r\n * A wrapper around an IDBObjectStore providing an API that:\r\n *\r\n * 1) Has generic KeyType / ValueType parameters to provide strongly-typed\r\n * methods for acting against the object store.\r\n * 2) Deals with IndexedDB's onsuccess / onerror event callbacks, making every\r\n * method return a PersistencePromise instead.\r\n * 3) Provides a higher-level API to avoid needing to do excessive wrapping of\r\n * intermediate IndexedDB types (IDBCursorWithValue, etc.)\r\n */\r\nclass SimpleDbStore {\r\n    constructor(store) {\r\n        this.store = store;\r\n    }\r\n    put(keyOrValue, value) {\r\n        let request;\r\n        if (value !== undefined) {\r\n            logDebug(LOG_TAG$g, 'PUT', this.store.name, keyOrValue, value);\r\n            request = this.store.put(value, keyOrValue);\r\n        }\r\n        else {\r\n            logDebug(LOG_TAG$g, 'PUT', this.store.name, '<auto-key>', keyOrValue);\r\n            request = this.store.put(keyOrValue);\r\n        }\r\n        return wrapRequest(request);\r\n    }\r\n    /**\r\n     * Adds a new value into an Object Store and returns the new key. Similar to\r\n     * IndexedDb's `add()`, this method will fail on primary key collisions.\r\n     *\r\n     * @param value - The object to write.\r\n     * @returns The key of the value to add.\r\n     */\r\n    add(value) {\r\n        logDebug(LOG_TAG$g, 'ADD', this.store.name, value, value);\r\n        const request = this.store.add(value);\r\n        return wrapRequest(request);\r\n    }\r\n    /**\r\n     * Gets the object with the specified key from the specified store, or null\r\n     * if no object exists with the specified key.\r\n     *\r\n     * @key The key of the object to get.\r\n     * @returns The object with the specified key or null if no object exists.\r\n     */\r\n    get(key) {\r\n        const request = this.store.get(key);\r\n        // We're doing an unsafe cast to ValueType.\r\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        return wrapRequest(request).next(result => {\r\n            // Normalize nonexistence to null.\r\n            if (result === undefined) {\r\n                result = null;\r\n            }\r\n            logDebug(LOG_TAG$g, 'GET', this.store.name, key, result);\r\n            return result;\r\n        });\r\n    }\r\n    delete(key) {\r\n        logDebug(LOG_TAG$g, 'DELETE', this.store.name, key);\r\n        const request = this.store.delete(key);\r\n        return wrapRequest(request);\r\n    }\r\n    /**\r\n     * If we ever need more of the count variants, we can add overloads. For now,\r\n     * all we need is to count everything in a store.\r\n     *\r\n     * Returns the number of rows in the store.\r\n     */\r\n    count() {\r\n        logDebug(LOG_TAG$g, 'COUNT', this.store.name);\r\n        const request = this.store.count();\r\n        return wrapRequest(request);\r\n    }\r\n    loadAll(indexOrRange, range) {\r\n        const cursor = this.cursor(this.options(indexOrRange, range));\r\n        const results = [];\r\n        return this.iterateCursor(cursor, (key, value) => {\r\n            results.push(value);\r\n        }).next(() => {\r\n            return results;\r\n        });\r\n    }\r\n    deleteAll(indexOrRange, range) {\r\n        logDebug(LOG_TAG$g, 'DELETE ALL', this.store.name);\r\n        const options = this.options(indexOrRange, range);\r\n        options.keysOnly = false;\r\n        const cursor = this.cursor(options);\r\n        return this.iterateCursor(cursor, (key, value, control) => {\r\n            // NOTE: Calling delete() on a cursor is documented as more efficient than\r\n            // calling delete() on an object store with a single key\r\n            // (https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/delete),\r\n            // however, this requires us *not* to use a keysOnly cursor\r\n            // (https://developer.mozilla.org/en-US/docs/Web/API/IDBCursor/delete). We\r\n            // may want to compare the performance of each method.\r\n            return control.delete();\r\n        });\r\n    }\r\n    iterate(optionsOrCallback, callback) {\r\n        let options;\r\n        if (!callback) {\r\n            options = {};\r\n            callback = optionsOrCallback;\r\n        }\r\n        else {\r\n            options = optionsOrCallback;\r\n        }\r\n        const cursor = this.cursor(options);\r\n        return this.iterateCursor(cursor, callback);\r\n    }\r\n    /**\r\n     * Iterates over a store, but waits for the given callback to complete for\r\n     * each entry before iterating the next entry. This allows the callback to do\r\n     * asynchronous work to determine if this iteration should continue.\r\n     *\r\n     * The provided callback should return `true` to continue iteration, and\r\n     * `false` otherwise.\r\n     */\r\n    iterateSerial(callback) {\r\n        const cursorRequest = this.cursor({});\r\n        return new PersistencePromise((resolve, reject) => {\r\n            cursorRequest.onerror = (event) => {\r\n                const error = checkForAndReportiOSError(event.target.error);\r\n                reject(error);\r\n            };\r\n            cursorRequest.onsuccess = (event) => {\r\n                const cursor = event.target.result;\r\n                if (!cursor) {\r\n                    resolve();\r\n                    return;\r\n                }\r\n                callback(cursor.primaryKey, cursor.value).next(shouldContinue => {\r\n                    if (shouldContinue) {\r\n                        cursor.continue();\r\n                    }\r\n                    else {\r\n                        resolve();\r\n                    }\r\n                });\r\n            };\r\n        });\r\n    }\r\n    iterateCursor(cursorRequest, fn) {\r\n        const results = [];\r\n        return new PersistencePromise((resolve, reject) => {\r\n            cursorRequest.onerror = (event) => {\r\n                reject(event.target.error);\r\n            };\r\n            cursorRequest.onsuccess = (event) => {\r\n                const cursor = event.target.result;\r\n                if (!cursor) {\r\n                    resolve();\r\n                    return;\r\n                }\r\n                const controller = new IterationController(cursor);\r\n                const userResult = fn(cursor.primaryKey, cursor.value, controller);\r\n                if (userResult instanceof PersistencePromise) {\r\n                    const userPromise = userResult.catch(err => {\r\n                        controller.done();\r\n                        return PersistencePromise.reject(err);\r\n                    });\r\n                    results.push(userPromise);\r\n                }\r\n                if (controller.isDone) {\r\n                    resolve();\r\n                }\r\n                else if (controller.skipToKey === null) {\r\n                    cursor.continue();\r\n                }\r\n                else {\r\n                    cursor.continue(controller.skipToKey);\r\n                }\r\n            };\r\n        }).next(() => {\r\n            return PersistencePromise.waitFor(results);\r\n        });\r\n    }\r\n    options(indexOrRange, range) {\r\n        let indexName = undefined;\r\n        if (indexOrRange !== undefined) {\r\n            if (typeof indexOrRange === 'string') {\r\n                indexName = indexOrRange;\r\n            }\r\n            else {\r\n                range = indexOrRange;\r\n            }\r\n        }\r\n        return { index: indexName, range };\r\n    }\r\n    cursor(options) {\r\n        let direction = 'next';\r\n        if (options.reverse) {\r\n            direction = 'prev';\r\n        }\r\n        if (options.index) {\r\n            const index = this.store.index(options.index);\r\n            if (options.keysOnly) {\r\n                return index.openKeyCursor(options.range, direction);\r\n            }\r\n            else {\r\n                return index.openCursor(options.range, direction);\r\n            }\r\n        }\r\n        else {\r\n            return this.store.openCursor(options.range, direction);\r\n        }\r\n    }\r\n}\r\n/**\r\n * Wraps an IDBRequest in a PersistencePromise, using the onsuccess / onerror\r\n * handlers to resolve / reject the PersistencePromise as appropriate.\r\n */\r\nfunction wrapRequest(request) {\r\n    return new PersistencePromise((resolve, reject) => {\r\n        request.onsuccess = (event) => {\r\n            const result = event.target.result;\r\n            resolve(result);\r\n        };\r\n        request.onerror = (event) => {\r\n            const error = checkForAndReportiOSError(event.target.error);\r\n            reject(error);\r\n        };\r\n    });\r\n}\r\n// Guard so we only report the error once.\r\nlet reportedIOSError = false;\r\nfunction checkForAndReportiOSError(error) {\r\n    const iOSVersion = SimpleDb.getIOSVersion(getUA());\r\n    if (iOSVersion >= 12.2 && iOSVersion < 13) {\r\n        const IOS_ERROR = 'An internal error was encountered in the Indexed Database server';\r\n        if (error.message.indexOf(IOS_ERROR) >= 0) {\r\n            // Wrap error in a more descriptive one.\r\n            const newError = new FirestoreError('internal', `IOS_INDEXEDDB_BUG1: IndexedDb has thrown '${IOS_ERROR}'. This is likely ` +\r\n                `due to an unavoidable bug in iOS. See https://stackoverflow.com/q/56496296/110915 ` +\r\n                `for details and a potential workaround.`);\r\n            if (!reportedIOSError) {\r\n                reportedIOSError = true;\r\n                // Throw a global exception outside of this promise chain, for the user to\r\n                // potentially catch.\r\n                setTimeout(() => {\r\n                    throw newError;\r\n                }, 0);\r\n            }\r\n            return newError;\r\n        }\r\n    }\r\n    return error;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass IndexedDbTransaction extends PersistenceTransaction {\r\n    constructor(simpleDbTransaction, currentSequenceNumber) {\r\n        super();\r\n        this.simpleDbTransaction = simpleDbTransaction;\r\n        this.currentSequenceNumber = currentSequenceNumber;\r\n    }\r\n}\r\nfunction getStore(txn, store) {\r\n    const indexedDbTransaction = debugCast(txn);\r\n    return SimpleDb.getStore(indexedDbTransaction.simpleDbTransaction, store);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Generates `nBytes` of random bytes.\r\n *\r\n * If `nBytes < 0` , an error will be thrown.\r\n */\r\nfunction randomBytes(nBytes) {\r\n    return randomBytes$1(nBytes);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass AutoId {\r\n    static newId() {\r\n        // Alphanumeric characters\r\n        const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\r\n        // The largest byte value that is a multiple of `char.length`.\r\n        const maxMultiple = Math.floor(256 / chars.length) * chars.length;\r\n        let autoId = '';\r\n        const targetLength = 20;\r\n        while (autoId.length < targetLength) {\r\n            const bytes = randomBytes(40);\r\n            for (let i = 0; i < bytes.length; ++i) {\r\n                // Only accept values that are [0, maxMultiple), this ensures they can\r\n                // be evenly mapped to indices of `chars` via a modulo operation.\r\n                if (autoId.length < targetLength && bytes[i] < maxMultiple) {\r\n                    autoId += chars.charAt(bytes[i] % chars.length);\r\n                }\r\n            }\r\n        }\r\n        return autoId;\r\n    }\r\n}\r\nfunction primitiveComparator(left, right) {\r\n    if (left < right) {\r\n        return -1;\r\n    }\r\n    if (left > right) {\r\n        return 1;\r\n    }\r\n    return 0;\r\n}\r\n/** Helper to compare arrays using isEqual(). */\r\nfunction arrayEquals(left, right, comparator) {\r\n    if (left.length !== right.length) {\r\n        return false;\r\n    }\r\n    return left.every((value, index) => comparator(value, right[index]));\r\n}\r\n/**\r\n * Returns the immediate lexicographically-following string. This is useful to\r\n * construct an inclusive range for indexeddb iterators.\r\n */\r\nfunction immediateSuccessor(s) {\r\n    // Return the input string, with an additional NUL byte appended.\r\n    return s + '\\0';\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// The earliest date supported by Firestore timestamps (0001-01-01T00:00:00Z).\r\nconst MIN_SECONDS = -62135596800;\r\n// Number of nanoseconds in a millisecond.\r\nconst MS_TO_NANOS = 1e6;\r\n/**\r\n * A `Timestamp` represents a point in time independent of any time zone or\r\n * calendar, represented as seconds and fractions of seconds at nanosecond\r\n * resolution in UTC Epoch time.\r\n *\r\n * It is encoded using the Proleptic Gregorian Calendar which extends the\r\n * Gregorian calendar backwards to year one. It is encoded assuming all minutes\r\n * are 60 seconds long, i.e. leap seconds are \"smeared\" so that no leap second\r\n * table is needed for interpretation. Range is from 0001-01-01T00:00:00Z to\r\n * 9999-12-31T23:59:59.999999999Z.\r\n *\r\n * For examples and further specifications, refer to the\r\n * {@link https://github.com/google/protobuf/blob/master/src/google/protobuf/timestamp.proto | Timestamp definition}.\r\n */\r\nclass Timestamp {\r\n    /**\r\n     * Creates a new timestamp.\r\n     *\r\n     * @param seconds - The number of seconds of UTC time since Unix epoch\r\n     *     1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to\r\n     *     9999-12-31T23:59:59Z inclusive.\r\n     * @param nanoseconds - The non-negative fractions of a second at nanosecond\r\n     *     resolution. Negative second values with fractions must still have\r\n     *     non-negative nanoseconds values that count forward in time. Must be\r\n     *     from 0 to 999,999,999 inclusive.\r\n     */\r\n    constructor(\r\n    /**\r\n     * The number of seconds of UTC time since Unix epoch 1970-01-01T00:00:00Z.\r\n     */\r\n    seconds, \r\n    /**\r\n     * The fractions of a second at nanosecond resolution.*\r\n     */\r\n    nanoseconds) {\r\n        this.seconds = seconds;\r\n        this.nanoseconds = nanoseconds;\r\n        if (nanoseconds < 0) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp nanoseconds out of range: ' + nanoseconds);\r\n        }\r\n        if (nanoseconds >= 1e9) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp nanoseconds out of range: ' + nanoseconds);\r\n        }\r\n        if (seconds < MIN_SECONDS) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp seconds out of range: ' + seconds);\r\n        }\r\n        // This will break in the year 10,000.\r\n        if (seconds >= 253402300800) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp seconds out of range: ' + seconds);\r\n        }\r\n    }\r\n    /**\r\n     * Creates a new timestamp with the current date, with millisecond precision.\r\n     *\r\n     * @returns a new timestamp representing the current date.\r\n     */\r\n    static now() {\r\n        return Timestamp.fromMillis(Date.now());\r\n    }\r\n    /**\r\n     * Creates a new timestamp from the given date.\r\n     *\r\n     * @param date - The date to initialize the `Timestamp` from.\r\n     * @returns A new `Timestamp` representing the same point in time as the given\r\n     *     date.\r\n     */\r\n    static fromDate(date) {\r\n        return Timestamp.fromMillis(date.getTime());\r\n    }\r\n    /**\r\n     * Creates a new timestamp from the given number of milliseconds.\r\n     *\r\n     * @param milliseconds - Number of milliseconds since Unix epoch\r\n     *     1970-01-01T00:00:00Z.\r\n     * @returns A new `Timestamp` representing the same point in time as the given\r\n     *     number of milliseconds.\r\n     */\r\n    static fromMillis(milliseconds) {\r\n        const seconds = Math.floor(milliseconds / 1000);\r\n        const nanos = Math.floor((milliseconds - seconds * 1000) * MS_TO_NANOS);\r\n        return new Timestamp(seconds, nanos);\r\n    }\r\n    /**\r\n     * Converts a `Timestamp` to a JavaScript `Date` object. This conversion\r\n     * causes a loss of precision since `Date` objects only support millisecond\r\n     * precision.\r\n     *\r\n     * @returns JavaScript `Date` object representing the same point in time as\r\n     *     this `Timestamp`, with millisecond precision.\r\n     */\r\n    toDate() {\r\n        return new Date(this.toMillis());\r\n    }\r\n    /**\r\n     * Converts a `Timestamp` to a numeric timestamp (in milliseconds since\r\n     * epoch). This operation causes a loss of precision.\r\n     *\r\n     * @returns The point in time corresponding to this timestamp, represented as\r\n     *     the number of milliseconds since Unix epoch 1970-01-01T00:00:00Z.\r\n     */\r\n    toMillis() {\r\n        return this.seconds * 1000 + this.nanoseconds / MS_TO_NANOS;\r\n    }\r\n    _compareTo(other) {\r\n        if (this.seconds === other.seconds) {\r\n            return primitiveComparator(this.nanoseconds, other.nanoseconds);\r\n        }\r\n        return primitiveComparator(this.seconds, other.seconds);\r\n    }\r\n    /**\r\n     * Returns true if this `Timestamp` is equal to the provided one.\r\n     *\r\n     * @param other - The `Timestamp` to compare against.\r\n     * @returns true if this `Timestamp` is equal to the provided one.\r\n     */\r\n    isEqual(other) {\r\n        return (other.seconds === this.seconds && other.nanoseconds === this.nanoseconds);\r\n    }\r\n    /** Returns a textual representation of this `Timestamp`. */\r\n    toString() {\r\n        return ('Timestamp(seconds=' +\r\n            this.seconds +\r\n            ', nanoseconds=' +\r\n            this.nanoseconds +\r\n            ')');\r\n    }\r\n    /** Returns a JSON-serializable representation of this `Timestamp`. */\r\n    toJSON() {\r\n        return { seconds: this.seconds, nanoseconds: this.nanoseconds };\r\n    }\r\n    /**\r\n     * Converts this object to a primitive string, which allows `Timestamp` objects\r\n     * to be compared using the `>`, `<=`, `>=` and `>` operators.\r\n     */\r\n    valueOf() {\r\n        // This method returns a string of the form <seconds>.<nanoseconds> where\r\n        // <seconds> is translated to have a non-negative value and both <seconds>\r\n        // and <nanoseconds> are left-padded with zeroes to be a consistent length.\r\n        // Strings with this format then have a lexiographical ordering that matches\r\n        // the expected ordering. The <seconds> translation is done to avoid having\r\n        // a leading negative sign (i.e. a leading '-' character) in its string\r\n        // representation, which would affect its lexiographical ordering.\r\n        const adjustedSeconds = this.seconds - MIN_SECONDS;\r\n        // Note: Up to 12 decimal digits are required to represent all valid\r\n        // 'seconds' values.\r\n        const formattedSeconds = String(adjustedSeconds).padStart(12, '0');\r\n        const formattedNanoseconds = String(this.nanoseconds).padStart(9, '0');\r\n        return formattedSeconds + '.' + formattedNanoseconds;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A version of a document in Firestore. This corresponds to the version\r\n * timestamp, such as update_time or read_time.\r\n */\r\nclass SnapshotVersion {\r\n    constructor(timestamp) {\r\n        this.timestamp = timestamp;\r\n    }\r\n    static fromTimestamp(value) {\r\n        return new SnapshotVersion(value);\r\n    }\r\n    static min() {\r\n        return new SnapshotVersion(new Timestamp(0, 0));\r\n    }\r\n    compareTo(other) {\r\n        return this.timestamp._compareTo(other.timestamp);\r\n    }\r\n    isEqual(other) {\r\n        return this.timestamp.isEqual(other.timestamp);\r\n    }\r\n    /** Returns a number representation of the version for use in spec tests. */\r\n    toMicroseconds() {\r\n        // Convert to microseconds.\r\n        return this.timestamp.seconds * 1e6 + this.timestamp.nanoseconds / 1000;\r\n    }\r\n    toString() {\r\n        return 'SnapshotVersion(' + this.timestamp.toString() + ')';\r\n    }\r\n    toTimestamp() {\r\n        return this.timestamp;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction objectSize(obj) {\r\n    let count = 0;\r\n    for (const key in obj) {\r\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\r\n            count++;\r\n        }\r\n    }\r\n    return count;\r\n}\r\nfunction forEach(obj, fn) {\r\n    for (const key in obj) {\r\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\r\n            fn(key, obj[key]);\r\n        }\r\n    }\r\n}\r\nfunction isEmpty(obj) {\r\n    for (const key in obj) {\r\n        if (Object.prototype.hasOwnProperty.call(obj, key)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Provides a set of fields that can be used to partially patch a document.\r\n * FieldMask is used in conjunction with ObjectValue.\r\n * Examples:\r\n *   foo - Overwrites foo entirely with the provided value. If foo is not\r\n *         present in the companion ObjectValue, the field is deleted.\r\n *   foo.bar - Overwrites only the field bar of the object foo.\r\n *             If foo is not an object, foo is replaced with an object\r\n *             containing foo\r\n */\r\nclass FieldMask {\r\n    constructor(fields) {\r\n        this.fields = fields;\r\n        // TODO(dimond): validation of FieldMask\r\n        // Sort the field mask to support `FieldMask.isEqual()` and assert below.\r\n        fields.sort(FieldPath$1.comparator);\r\n    }\r\n    /**\r\n     * Verifies that `fieldPath` is included by at least one field in this field\r\n     * mask.\r\n     *\r\n     * This is an O(n) operation, where `n` is the size of the field mask.\r\n     */\r\n    covers(fieldPath) {\r\n        for (const fieldMaskPath of this.fields) {\r\n            if (fieldMaskPath.isPrefixOf(fieldPath)) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n    isEqual(other) {\r\n        return arrayEquals(this.fields, other.fields, (l, r) => l.isEqual(r));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction decodeBase64(encoded) {\r\n    // Node actually doesn't validate base64 strings.\r\n    // A quick sanity check that is not a fool-proof validation\r\n    if (/[^-A-Za-z0-9+/=]/.test(encoded)) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Not a valid Base64 string: ' + encoded);\r\n    }\r\n    return new Buffer(encoded, 'base64').toString('binary');\r\n}\r\n/** Converts a binary string to a Base64 encoded string. */\r\nfunction encodeBase64(raw) {\r\n    return new Buffer(raw, 'binary').toString('base64');\r\n}\r\n/** True if and only if the Base64 conversion functions are available. */\r\nfunction isBase64Available() {\r\n    return true;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Immutable class that represents a \"proto\" byte string.\r\n *\r\n * Proto byte strings can either be Base64-encoded strings or Uint8Arrays when\r\n * sent on the wire. This class abstracts away this differentiation by holding\r\n * the proto byte string in a common class that must be converted into a string\r\n * before being sent as a proto.\r\n * @internal\r\n */\r\nclass ByteString {\r\n    constructor(binaryString) {\r\n        this.binaryString = binaryString;\r\n    }\r\n    static fromBase64String(base64) {\r\n        const binaryString = decodeBase64(base64);\r\n        return new ByteString(binaryString);\r\n    }\r\n    static fromUint8Array(array) {\r\n        const binaryString = binaryStringFromUint8Array(array);\r\n        return new ByteString(binaryString);\r\n    }\r\n    toBase64() {\r\n        return encodeBase64(this.binaryString);\r\n    }\r\n    toUint8Array() {\r\n        return uint8ArrayFromBinaryString(this.binaryString);\r\n    }\r\n    approximateByteSize() {\r\n        return this.binaryString.length * 2;\r\n    }\r\n    compareTo(other) {\r\n        return primitiveComparator(this.binaryString, other.binaryString);\r\n    }\r\n    isEqual(other) {\r\n        return this.binaryString === other.binaryString;\r\n    }\r\n}\r\nByteString.EMPTY_BYTE_STRING = new ByteString('');\r\n/**\r\n * Helper function to convert an Uint8array to a binary string.\r\n */\r\nfunction binaryStringFromUint8Array(array) {\r\n    let binaryString = '';\r\n    for (let i = 0; i < array.length; ++i) {\r\n        binaryString += String.fromCharCode(array[i]);\r\n    }\r\n    return binaryString;\r\n}\r\n/**\r\n * Helper function to convert a binary string to an Uint8Array.\r\n */\r\nfunction uint8ArrayFromBinaryString(binaryString) {\r\n    const buffer = new Uint8Array(binaryString.length);\r\n    for (let i = 0; i < binaryString.length; i++) {\r\n        buffer[i] = binaryString.charCodeAt(i);\r\n    }\r\n    return buffer;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// A RegExp matching ISO 8601 UTC timestamps with optional fraction.\r\nconst ISO_TIMESTAMP_REG_EXP = new RegExp(/^\\d{4}-\\d\\d-\\d\\dT\\d\\d:\\d\\d:\\d\\d(?:\\.(\\d+))?Z$/);\r\n/**\r\n * Converts the possible Proto values for a timestamp value into a \"seconds and\r\n * nanos\" representation.\r\n */\r\nfunction normalizeTimestamp(date) {\r\n    hardAssert(!!date);\r\n    // The json interface (for the browser) will return an iso timestamp string,\r\n    // while the proto js library (for node) will return a\r\n    // google.protobuf.Timestamp instance.\r\n    if (typeof date === 'string') {\r\n        // The date string can have higher precision (nanos) than the Date class\r\n        // (millis), so we do some custom parsing here.\r\n        // Parse the nanos right out of the string.\r\n        let nanos = 0;\r\n        const fraction = ISO_TIMESTAMP_REG_EXP.exec(date);\r\n        hardAssert(!!fraction);\r\n        if (fraction[1]) {\r\n            // Pad the fraction out to 9 digits (nanos).\r\n            let nanoStr = fraction[1];\r\n            nanoStr = (nanoStr + '000000000').substr(0, 9);\r\n            nanos = Number(nanoStr);\r\n        }\r\n        // Parse the date to get the seconds.\r\n        const parsedDate = new Date(date);\r\n        const seconds = Math.floor(parsedDate.getTime() / 1000);\r\n        return { seconds, nanos };\r\n    }\r\n    else {\r\n        // TODO(b/37282237): Use strings for Proto3 timestamps\r\n        // assert(!this.options.useProto3Json,\r\n        //   'The timestamp instance format requires Proto JS.');\r\n        const seconds = normalizeNumber(date.seconds);\r\n        const nanos = normalizeNumber(date.nanos);\r\n        return { seconds, nanos };\r\n    }\r\n}\r\n/**\r\n * Converts the possible Proto types for numbers into a JavaScript number.\r\n * Returns 0 if the value is not numeric.\r\n */\r\nfunction normalizeNumber(value) {\r\n    // TODO(bjornick): Handle int64 greater than 53 bits.\r\n    if (typeof value === 'number') {\r\n        return value;\r\n    }\r\n    else if (typeof value === 'string') {\r\n        return Number(value);\r\n    }\r\n    else {\r\n        return 0;\r\n    }\r\n}\r\n/** Converts the possible Proto types for Blobs into a ByteString. */\r\nfunction normalizeByteString(blob) {\r\n    if (typeof blob === 'string') {\r\n        return ByteString.fromBase64String(blob);\r\n    }\r\n    else {\r\n        return ByteString.fromUint8Array(blob);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Represents a locally-applied ServerTimestamp.\r\n *\r\n * Server Timestamps are backed by MapValues that contain an internal field\r\n * `__type__` with a value of `server_timestamp`. The previous value and local\r\n * write time are stored in its `__previous_value__` and `__local_write_time__`\r\n * fields respectively.\r\n *\r\n * Notes:\r\n * - ServerTimestampValue instances are created as the result of applying a\r\n *   transform. They can only exist in the local view of a document. Therefore\r\n *   they do not need to be parsed or serialized.\r\n * - When evaluated locally (e.g. for snapshot.data()), they by default\r\n *   evaluate to `null`. This behavior can be configured by passing custom\r\n *   FieldValueOptions to value().\r\n * - With respect to other ServerTimestampValues, they sort by their\r\n *   localWriteTime.\r\n */\r\nconst SERVER_TIMESTAMP_SENTINEL = 'server_timestamp';\r\nconst TYPE_KEY = '__type__';\r\nconst PREVIOUS_VALUE_KEY = '__previous_value__';\r\nconst LOCAL_WRITE_TIME_KEY = '__local_write_time__';\r\nfunction isServerTimestamp(value) {\r\n    var _a, _b;\r\n    const type = (_b = (((_a = value === null || value === void 0 ? void 0 : value.mapValue) === null || _a === void 0 ? void 0 : _a.fields) || {})[TYPE_KEY]) === null || _b === void 0 ? void 0 : _b.stringValue;\r\n    return type === SERVER_TIMESTAMP_SENTINEL;\r\n}\r\n/**\r\n * Creates a new ServerTimestamp proto value (using the internal format).\r\n */\r\nfunction serverTimestamp$1(localWriteTime, previousValue) {\r\n    const mapValue = {\r\n        fields: {\r\n            [TYPE_KEY]: {\r\n                stringValue: SERVER_TIMESTAMP_SENTINEL\r\n            },\r\n            [LOCAL_WRITE_TIME_KEY]: {\r\n                timestampValue: {\r\n                    seconds: localWriteTime.seconds,\r\n                    nanos: localWriteTime.nanoseconds\r\n                }\r\n            }\r\n        }\r\n    };\r\n    if (previousValue) {\r\n        mapValue.fields[PREVIOUS_VALUE_KEY] = previousValue;\r\n    }\r\n    return { mapValue };\r\n}\r\n/**\r\n * Returns the value of the field before this ServerTimestamp was set.\r\n *\r\n * Preserving the previous values allows the user to display the last resoled\r\n * value until the backend responds with the timestamp.\r\n */\r\nfunction getPreviousValue(value) {\r\n    const previousValue = value.mapValue.fields[PREVIOUS_VALUE_KEY];\r\n    if (isServerTimestamp(previousValue)) {\r\n        return getPreviousValue(previousValue);\r\n    }\r\n    return previousValue;\r\n}\r\n/**\r\n * Returns the local time at which this timestamp was first set.\r\n */\r\nfunction getLocalWriteTime(value) {\r\n    const localWriteTime = normalizeTimestamp(value.mapValue.fields[LOCAL_WRITE_TIME_KEY].timestampValue);\r\n    return new Timestamp(localWriteTime.seconds, localWriteTime.nanos);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Sentinel value that sorts before any Mutation Batch ID. */\r\nconst BATCHID_UNKNOWN = -1;\r\n/**\r\n * Returns whether a variable is either undefined or null.\r\n */\r\nfunction isNullOrUndefined(value) {\r\n    return value === null || value === undefined;\r\n}\r\n/** Returns whether the value represents -0. */\r\nfunction isNegativeZero(value) {\r\n    // Detect if the value is -0.0. Based on polyfill from\r\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\r\n    return value === 0 && 1 / value === 1 / -0;\r\n}\r\n/**\r\n * Returns whether a value is an integer and in the safe integer range\r\n * @param value - The value to test for being an integer and in the safe range\r\n */\r\nfunction isSafeInteger(value) {\r\n    return (typeof value === 'number' &&\r\n        Number.isInteger(value) &&\r\n        !isNegativeZero(value) &&\r\n        value <= Number.MAX_SAFE_INTEGER &&\r\n        value >= Number.MIN_SAFE_INTEGER);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * @internal\r\n */\r\nclass DocumentKey {\r\n    constructor(path) {\r\n        this.path = path;\r\n    }\r\n    static fromPath(path) {\r\n        return new DocumentKey(ResourcePath.fromString(path));\r\n    }\r\n    static fromName(name) {\r\n        return new DocumentKey(ResourcePath.fromString(name).popFirst(5));\r\n    }\r\n    /** Returns true if the document is in the specified collectionId. */\r\n    hasCollectionId(collectionId) {\r\n        return (this.path.length >= 2 &&\r\n            this.path.get(this.path.length - 2) === collectionId);\r\n    }\r\n    isEqual(other) {\r\n        return (other !== null && ResourcePath.comparator(this.path, other.path) === 0);\r\n    }\r\n    toString() {\r\n        return this.path.toString();\r\n    }\r\n    static comparator(k1, k2) {\r\n        return ResourcePath.comparator(k1.path, k2.path);\r\n    }\r\n    static isDocumentKey(path) {\r\n        return path.length % 2 === 0;\r\n    }\r\n    /**\r\n     * Creates and returns a new document key with the given segments.\r\n     *\r\n     * @param segments - The segments of the path to the document\r\n     * @returns A new instance of DocumentKey\r\n     */\r\n    static fromSegments(segments) {\r\n        return new DocumentKey(new ResourcePath(segments.slice()));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Extracts the backend's type order for the provided value. */\r\nfunction typeOrder(value) {\r\n    if ('nullValue' in value) {\r\n        return 0 /* NullValue */;\r\n    }\r\n    else if ('booleanValue' in value) {\r\n        return 1 /* BooleanValue */;\r\n    }\r\n    else if ('integerValue' in value || 'doubleValue' in value) {\r\n        return 2 /* NumberValue */;\r\n    }\r\n    else if ('timestampValue' in value) {\r\n        return 3 /* TimestampValue */;\r\n    }\r\n    else if ('stringValue' in value) {\r\n        return 5 /* StringValue */;\r\n    }\r\n    else if ('bytesValue' in value) {\r\n        return 6 /* BlobValue */;\r\n    }\r\n    else if ('referenceValue' in value) {\r\n        return 7 /* RefValue */;\r\n    }\r\n    else if ('geoPointValue' in value) {\r\n        return 8 /* GeoPointValue */;\r\n    }\r\n    else if ('arrayValue' in value) {\r\n        return 9 /* ArrayValue */;\r\n    }\r\n    else if ('mapValue' in value) {\r\n        if (isServerTimestamp(value)) {\r\n            return 4 /* ServerTimestampValue */;\r\n        }\r\n        return 10 /* ObjectValue */;\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\n/** Tests `left` and `right` for equality based on the backend semantics. */\r\nfunction valueEquals(left, right) {\r\n    const leftType = typeOrder(left);\r\n    const rightType = typeOrder(right);\r\n    if (leftType !== rightType) {\r\n        return false;\r\n    }\r\n    switch (leftType) {\r\n        case 0 /* NullValue */:\r\n            return true;\r\n        case 1 /* BooleanValue */:\r\n            return left.booleanValue === right.booleanValue;\r\n        case 4 /* ServerTimestampValue */:\r\n            return getLocalWriteTime(left).isEqual(getLocalWriteTime(right));\r\n        case 3 /* TimestampValue */:\r\n            return timestampEquals(left, right);\r\n        case 5 /* StringValue */:\r\n            return left.stringValue === right.stringValue;\r\n        case 6 /* BlobValue */:\r\n            return blobEquals(left, right);\r\n        case 7 /* RefValue */:\r\n            return left.referenceValue === right.referenceValue;\r\n        case 8 /* GeoPointValue */:\r\n            return geoPointEquals(left, right);\r\n        case 2 /* NumberValue */:\r\n            return numberEquals(left, right);\r\n        case 9 /* ArrayValue */:\r\n            return arrayEquals(left.arrayValue.values || [], right.arrayValue.values || [], valueEquals);\r\n        case 10 /* ObjectValue */:\r\n            return objectEquals(left, right);\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction timestampEquals(left, right) {\r\n    if (typeof left.timestampValue === 'string' &&\r\n        typeof right.timestampValue === 'string' &&\r\n        left.timestampValue.length === right.timestampValue.length) {\r\n        // Use string equality for ISO 8601 timestamps\r\n        return left.timestampValue === right.timestampValue;\r\n    }\r\n    const leftTimestamp = normalizeTimestamp(left.timestampValue);\r\n    const rightTimestamp = normalizeTimestamp(right.timestampValue);\r\n    return (leftTimestamp.seconds === rightTimestamp.seconds &&\r\n        leftTimestamp.nanos === rightTimestamp.nanos);\r\n}\r\nfunction geoPointEquals(left, right) {\r\n    return (normalizeNumber(left.geoPointValue.latitude) ===\r\n        normalizeNumber(right.geoPointValue.latitude) &&\r\n        normalizeNumber(left.geoPointValue.longitude) ===\r\n            normalizeNumber(right.geoPointValue.longitude));\r\n}\r\nfunction blobEquals(left, right) {\r\n    return normalizeByteString(left.bytesValue).isEqual(normalizeByteString(right.bytesValue));\r\n}\r\nfunction numberEquals(left, right) {\r\n    if ('integerValue' in left && 'integerValue' in right) {\r\n        return (normalizeNumber(left.integerValue) === normalizeNumber(right.integerValue));\r\n    }\r\n    else if ('doubleValue' in left && 'doubleValue' in right) {\r\n        const n1 = normalizeNumber(left.doubleValue);\r\n        const n2 = normalizeNumber(right.doubleValue);\r\n        if (n1 === n2) {\r\n            return isNegativeZero(n1) === isNegativeZero(n2);\r\n        }\r\n        else {\r\n            return isNaN(n1) && isNaN(n2);\r\n        }\r\n    }\r\n    return false;\r\n}\r\nfunction objectEquals(left, right) {\r\n    const leftMap = left.mapValue.fields || {};\r\n    const rightMap = right.mapValue.fields || {};\r\n    if (objectSize(leftMap) !== objectSize(rightMap)) {\r\n        return false;\r\n    }\r\n    for (const key in leftMap) {\r\n        if (leftMap.hasOwnProperty(key)) {\r\n            if (rightMap[key] === undefined ||\r\n                !valueEquals(leftMap[key], rightMap[key])) {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n    return true;\r\n}\r\n/** Returns true if the ArrayValue contains the specified element. */\r\nfunction arrayValueContains(haystack, needle) {\r\n    return ((haystack.values || []).find(v => valueEquals(v, needle)) !== undefined);\r\n}\r\nfunction valueCompare(left, right) {\r\n    const leftType = typeOrder(left);\r\n    const rightType = typeOrder(right);\r\n    if (leftType !== rightType) {\r\n        return primitiveComparator(leftType, rightType);\r\n    }\r\n    switch (leftType) {\r\n        case 0 /* NullValue */:\r\n            return 0;\r\n        case 1 /* BooleanValue */:\r\n            return primitiveComparator(left.booleanValue, right.booleanValue);\r\n        case 2 /* NumberValue */:\r\n            return compareNumbers(left, right);\r\n        case 3 /* TimestampValue */:\r\n            return compareTimestamps(left.timestampValue, right.timestampValue);\r\n        case 4 /* ServerTimestampValue */:\r\n            return compareTimestamps(getLocalWriteTime(left), getLocalWriteTime(right));\r\n        case 5 /* StringValue */:\r\n            return primitiveComparator(left.stringValue, right.stringValue);\r\n        case 6 /* BlobValue */:\r\n            return compareBlobs(left.bytesValue, right.bytesValue);\r\n        case 7 /* RefValue */:\r\n            return compareReferences(left.referenceValue, right.referenceValue);\r\n        case 8 /* GeoPointValue */:\r\n            return compareGeoPoints(left.geoPointValue, right.geoPointValue);\r\n        case 9 /* ArrayValue */:\r\n            return compareArrays(left.arrayValue, right.arrayValue);\r\n        case 10 /* ObjectValue */:\r\n            return compareMaps(left.mapValue, right.mapValue);\r\n        default:\r\n            throw fail();\r\n    }\r\n}\r\nfunction compareNumbers(left, right) {\r\n    const leftNumber = normalizeNumber(left.integerValue || left.doubleValue);\r\n    const rightNumber = normalizeNumber(right.integerValue || right.doubleValue);\r\n    if (leftNumber < rightNumber) {\r\n        return -1;\r\n    }\r\n    else if (leftNumber > rightNumber) {\r\n        return 1;\r\n    }\r\n    else if (leftNumber === rightNumber) {\r\n        return 0;\r\n    }\r\n    else {\r\n        // one or both are NaN.\r\n        if (isNaN(leftNumber)) {\r\n            return isNaN(rightNumber) ? 0 : -1;\r\n        }\r\n        else {\r\n            return 1;\r\n        }\r\n    }\r\n}\r\nfunction compareTimestamps(left, right) {\r\n    if (typeof left === 'string' &&\r\n        typeof right === 'string' &&\r\n        left.length === right.length) {\r\n        return primitiveComparator(left, right);\r\n    }\r\n    const leftTimestamp = normalizeTimestamp(left);\r\n    const rightTimestamp = normalizeTimestamp(right);\r\n    const comparison = primitiveComparator(leftTimestamp.seconds, rightTimestamp.seconds);\r\n    if (comparison !== 0) {\r\n        return comparison;\r\n    }\r\n    return primitiveComparator(leftTimestamp.nanos, rightTimestamp.nanos);\r\n}\r\nfunction compareReferences(leftPath, rightPath) {\r\n    const leftSegments = leftPath.split('/');\r\n    const rightSegments = rightPath.split('/');\r\n    for (let i = 0; i < leftSegments.length && i < rightSegments.length; i++) {\r\n        const comparison = primitiveComparator(leftSegments[i], rightSegments[i]);\r\n        if (comparison !== 0) {\r\n            return comparison;\r\n        }\r\n    }\r\n    return primitiveComparator(leftSegments.length, rightSegments.length);\r\n}\r\nfunction compareGeoPoints(left, right) {\r\n    const comparison = primitiveComparator(normalizeNumber(left.latitude), normalizeNumber(right.latitude));\r\n    if (comparison !== 0) {\r\n        return comparison;\r\n    }\r\n    return primitiveComparator(normalizeNumber(left.longitude), normalizeNumber(right.longitude));\r\n}\r\nfunction compareBlobs(left, right) {\r\n    const leftBytes = normalizeByteString(left);\r\n    const rightBytes = normalizeByteString(right);\r\n    return leftBytes.compareTo(rightBytes);\r\n}\r\nfunction compareArrays(left, right) {\r\n    const leftArray = left.values || [];\r\n    const rightArray = right.values || [];\r\n    for (let i = 0; i < leftArray.length && i < rightArray.length; ++i) {\r\n        const compare = valueCompare(leftArray[i], rightArray[i]);\r\n        if (compare) {\r\n            return compare;\r\n        }\r\n    }\r\n    return primitiveComparator(leftArray.length, rightArray.length);\r\n}\r\nfunction compareMaps(left, right) {\r\n    const leftMap = left.fields || {};\r\n    const leftKeys = Object.keys(leftMap);\r\n    const rightMap = right.fields || {};\r\n    const rightKeys = Object.keys(rightMap);\r\n    // Even though MapValues are likely sorted correctly based on their insertion\r\n    // order (e.g. when received from the backend), local modifications can bring\r\n    // elements out of order. We need to re-sort the elements to ensure that\r\n    // canonical IDs are independent of insertion order.\r\n    leftKeys.sort();\r\n    rightKeys.sort();\r\n    for (let i = 0; i < leftKeys.length && i < rightKeys.length; ++i) {\r\n        const keyCompare = primitiveComparator(leftKeys[i], rightKeys[i]);\r\n        if (keyCompare !== 0) {\r\n            return keyCompare;\r\n        }\r\n        const compare = valueCompare(leftMap[leftKeys[i]], rightMap[rightKeys[i]]);\r\n        if (compare !== 0) {\r\n            return compare;\r\n        }\r\n    }\r\n    return primitiveComparator(leftKeys.length, rightKeys.length);\r\n}\r\n/**\r\n * Generates the canonical ID for the provided field value (as used in Target\r\n * serialization).\r\n */\r\nfunction canonicalId(value) {\r\n    return canonifyValue(value);\r\n}\r\nfunction canonifyValue(value) {\r\n    if ('nullValue' in value) {\r\n        return 'null';\r\n    }\r\n    else if ('booleanValue' in value) {\r\n        return '' + value.booleanValue;\r\n    }\r\n    else if ('integerValue' in value) {\r\n        return '' + value.integerValue;\r\n    }\r\n    else if ('doubleValue' in value) {\r\n        return '' + value.doubleValue;\r\n    }\r\n    else if ('timestampValue' in value) {\r\n        return canonifyTimestamp(value.timestampValue);\r\n    }\r\n    else if ('stringValue' in value) {\r\n        return value.stringValue;\r\n    }\r\n    else if ('bytesValue' in value) {\r\n        return canonifyByteString(value.bytesValue);\r\n    }\r\n    else if ('referenceValue' in value) {\r\n        return canonifyReference(value.referenceValue);\r\n    }\r\n    else if ('geoPointValue' in value) {\r\n        return canonifyGeoPoint(value.geoPointValue);\r\n    }\r\n    else if ('arrayValue' in value) {\r\n        return canonifyArray(value.arrayValue);\r\n    }\r\n    else if ('mapValue' in value) {\r\n        return canonifyMap(value.mapValue);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction canonifyByteString(byteString) {\r\n    return normalizeByteString(byteString).toBase64();\r\n}\r\nfunction canonifyTimestamp(timestamp) {\r\n    const normalizedTimestamp = normalizeTimestamp(timestamp);\r\n    return `time(${normalizedTimestamp.seconds},${normalizedTimestamp.nanos})`;\r\n}\r\nfunction canonifyGeoPoint(geoPoint) {\r\n    return `geo(${geoPoint.latitude},${geoPoint.longitude})`;\r\n}\r\nfunction canonifyReference(referenceValue) {\r\n    return DocumentKey.fromName(referenceValue).toString();\r\n}\r\nfunction canonifyMap(mapValue) {\r\n    // Iteration order in JavaScript is not guaranteed. To ensure that we generate\r\n    // matching canonical IDs for identical maps, we need to sort the keys.\r\n    const sortedKeys = Object.keys(mapValue.fields || {}).sort();\r\n    let result = '{';\r\n    let first = true;\r\n    for (const key of sortedKeys) {\r\n        if (!first) {\r\n            result += ',';\r\n        }\r\n        else {\r\n            first = false;\r\n        }\r\n        result += `${key}:${canonifyValue(mapValue.fields[key])}`;\r\n    }\r\n    return result + '}';\r\n}\r\nfunction canonifyArray(arrayValue) {\r\n    let result = '[';\r\n    let first = true;\r\n    for (const value of arrayValue.values || []) {\r\n        if (!first) {\r\n            result += ',';\r\n        }\r\n        else {\r\n            first = false;\r\n        }\r\n        result += canonifyValue(value);\r\n    }\r\n    return result + ']';\r\n}\r\n/** Returns a reference value for the provided database and key. */\r\nfunction refValue(databaseId, key) {\r\n    return {\r\n        referenceValue: `projects/${databaseId.projectId}/databases/${databaseId.database}/documents/${key.path.canonicalString()}`\r\n    };\r\n}\r\n/** Returns true if `value` is an IntegerValue . */\r\nfunction isInteger(value) {\r\n    return !!value && 'integerValue' in value;\r\n}\r\n/** Returns true if `value` is a DoubleValue. */\r\nfunction isDouble(value) {\r\n    return !!value && 'doubleValue' in value;\r\n}\r\n/** Returns true if `value` is either an IntegerValue or a DoubleValue. */\r\nfunction isNumber(value) {\r\n    return isInteger(value) || isDouble(value);\r\n}\r\n/** Returns true if `value` is an ArrayValue. */\r\nfunction isArray(value) {\r\n    return !!value && 'arrayValue' in value;\r\n}\r\n/** Returns true if `value` is a NullValue. */\r\nfunction isNullValue(value) {\r\n    return !!value && 'nullValue' in value;\r\n}\r\n/** Returns true if `value` is NaN. */\r\nfunction isNanValue(value) {\r\n    return !!value && 'doubleValue' in value && isNaN(Number(value.doubleValue));\r\n}\r\n/** Returns true if `value` is a MapValue. */\r\nfunction isMapValue(value) {\r\n    return !!value && 'mapValue' in value;\r\n}\r\n/** Creates a deep copy of `source`. */\r\nfunction deepClone(source) {\r\n    if (source.geoPointValue) {\r\n        return { geoPointValue: Object.assign({}, source.geoPointValue) };\r\n    }\r\n    else if (source.timestampValue &&\r\n        typeof source.timestampValue === 'object') {\r\n        return { timestampValue: Object.assign({}, source.timestampValue) };\r\n    }\r\n    else if (source.mapValue) {\r\n        const target = { mapValue: { fields: {} } };\r\n        forEach(source.mapValue.fields, (key, val) => (target.mapValue.fields[key] = deepClone(val)));\r\n        return target;\r\n    }\r\n    else if (source.arrayValue) {\r\n        const target = { arrayValue: { values: [] } };\r\n        for (let i = 0; i < (source.arrayValue.values || []).length; ++i) {\r\n            target.arrayValue.values[i] = deepClone(source.arrayValue.values[i]);\r\n        }\r\n        return target;\r\n    }\r\n    else {\r\n        return Object.assign({}, source);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An ObjectValue represents a MapValue in the Firestore Proto and offers the\r\n * ability to add and remove fields (via the ObjectValueBuilder).\r\n */\r\nclass ObjectValue {\r\n    constructor(value) {\r\n        this.value = value;\r\n    }\r\n    static empty() {\r\n        return new ObjectValue({ mapValue: {} });\r\n    }\r\n    /**\r\n     * Returns the value at the given path or null.\r\n     *\r\n     * @param path - the path to search\r\n     * @returns The value at the path or null if the path is not set.\r\n     */\r\n    field(path) {\r\n        if (path.isEmpty()) {\r\n            return this.value;\r\n        }\r\n        else {\r\n            let currentLevel = this.value;\r\n            for (let i = 0; i < path.length - 1; ++i) {\r\n                currentLevel = (currentLevel.mapValue.fields || {})[path.get(i)];\r\n                if (!isMapValue(currentLevel)) {\r\n                    return null;\r\n                }\r\n            }\r\n            currentLevel = (currentLevel.mapValue.fields || {})[path.lastSegment()];\r\n            return currentLevel || null;\r\n        }\r\n    }\r\n    /**\r\n     * Sets the field to the provided value.\r\n     *\r\n     * @param path - The field path to set.\r\n     * @param value - The value to set.\r\n     */\r\n    set(path, value) {\r\n        const fieldsMap = this.getFieldsMap(path.popLast());\r\n        fieldsMap[path.lastSegment()] = deepClone(value);\r\n    }\r\n    /**\r\n     * Sets the provided fields to the provided values.\r\n     *\r\n     * @param data - A map of fields to values (or null for deletes).\r\n     */\r\n    setAll(data) {\r\n        let parent = FieldPath$1.emptyPath();\r\n        let upserts = {};\r\n        let deletes = [];\r\n        data.forEach((value, path) => {\r\n            if (!parent.isImmediateParentOf(path)) {\r\n                // Insert the accumulated changes at this parent location\r\n                const fieldsMap = this.getFieldsMap(parent);\r\n                this.applyChanges(fieldsMap, upserts, deletes);\r\n                upserts = {};\r\n                deletes = [];\r\n                parent = path.popLast();\r\n            }\r\n            if (value) {\r\n                upserts[path.lastSegment()] = deepClone(value);\r\n            }\r\n            else {\r\n                deletes.push(path.lastSegment());\r\n            }\r\n        });\r\n        const fieldsMap = this.getFieldsMap(parent);\r\n        this.applyChanges(fieldsMap, upserts, deletes);\r\n    }\r\n    /**\r\n     * Removes the field at the specified path. If there is no field at the\r\n     * specified path, nothing is changed.\r\n     *\r\n     * @param path - The field path to remove.\r\n     */\r\n    delete(path) {\r\n        const nestedValue = this.field(path.popLast());\r\n        if (isMapValue(nestedValue) && nestedValue.mapValue.fields) {\r\n            delete nestedValue.mapValue.fields[path.lastSegment()];\r\n        }\r\n    }\r\n    isEqual(other) {\r\n        return valueEquals(this.value, other.value);\r\n    }\r\n    /**\r\n     * Returns the map that contains the leaf element of `path`. If the parent\r\n     * entry does not yet exist, or if it is not a map, a new map will be created.\r\n     */\r\n    getFieldsMap(path) {\r\n        let current = this.value;\r\n        if (!current.mapValue.fields) {\r\n            current.mapValue = { fields: {} };\r\n        }\r\n        for (let i = 0; i < path.length; ++i) {\r\n            let next = current.mapValue.fields[path.get(i)];\r\n            if (!isMapValue(next) || !next.mapValue.fields) {\r\n                next = { mapValue: { fields: {} } };\r\n                current.mapValue.fields[path.get(i)] = next;\r\n            }\r\n            current = next;\r\n        }\r\n        return current.mapValue.fields;\r\n    }\r\n    /**\r\n     * Modifies `fieldsMap` by adding, replacing or deleting the specified\r\n     * entries.\r\n     */\r\n    applyChanges(fieldsMap, inserts, deletes) {\r\n        forEach(inserts, (key, val) => (fieldsMap[key] = val));\r\n        for (const field of deletes) {\r\n            delete fieldsMap[field];\r\n        }\r\n    }\r\n    clone() {\r\n        return new ObjectValue(deepClone(this.value));\r\n    }\r\n}\r\n/**\r\n * Returns a FieldMask built from all fields in a MapValue.\r\n */\r\nfunction extractFieldMask(value) {\r\n    const fields = [];\r\n    forEach(value.fields, (key, value) => {\r\n        const currentPath = new FieldPath$1([key]);\r\n        if (isMapValue(value)) {\r\n            const nestedMask = extractFieldMask(value.mapValue);\r\n            const nestedFields = nestedMask.fields;\r\n            if (nestedFields.length === 0) {\r\n                // Preserve the empty map by adding it to the FieldMask.\r\n                fields.push(currentPath);\r\n            }\r\n            else {\r\n                // For nested and non-empty ObjectValues, add the FieldPath of the\r\n                // leaf nodes.\r\n                for (const nestedPath of nestedFields) {\r\n                    fields.push(currentPath.child(nestedPath));\r\n                }\r\n            }\r\n        }\r\n        else {\r\n            // For nested and non-empty ObjectValues, add the FieldPath of the leaf\r\n            // nodes.\r\n            fields.push(currentPath);\r\n        }\r\n    });\r\n    return new FieldMask(fields);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Represents a document in Firestore with a key, version, data and whether it\r\n * has local mutations applied to it.\r\n *\r\n * Documents can transition between states via `convertToFoundDocument()`,\r\n * `convertToNoDocument()` and `convertToUnknownDocument()`. If a document does\r\n * not transition to one of these states even after all mutations have been\r\n * applied, `isValidDocument()` returns false and the document should be removed\r\n * from all views.\r\n */\r\nclass MutableDocument {\r\n    constructor(key, documentType, version, data, documentState) {\r\n        this.key = key;\r\n        this.documentType = documentType;\r\n        this.version = version;\r\n        this.data = data;\r\n        this.documentState = documentState;\r\n    }\r\n    /**\r\n     * Creates a document with no known version or data, but which can serve as\r\n     * base document for mutations.\r\n     */\r\n    static newInvalidDocument(documentKey) {\r\n        return new MutableDocument(documentKey, 0 /* INVALID */, SnapshotVersion.min(), ObjectValue.empty(), 0 /* SYNCED */);\r\n    }\r\n    /**\r\n     * Creates a new document that is known to exist with the given data at the\r\n     * given version.\r\n     */\r\n    static newFoundDocument(documentKey, version, value) {\r\n        return new MutableDocument(documentKey, 1 /* FOUND_DOCUMENT */, version, value, 0 /* SYNCED */);\r\n    }\r\n    /** Creates a new document that is known to not exist at the given version. */\r\n    static newNoDocument(documentKey, version) {\r\n        return new MutableDocument(documentKey, 2 /* NO_DOCUMENT */, version, ObjectValue.empty(), 0 /* SYNCED */);\r\n    }\r\n    /**\r\n     * Creates a new document that is known to exist at the given version but\r\n     * whose data is not known (e.g. a document that was updated without a known\r\n     * base document).\r\n     */\r\n    static newUnknownDocument(documentKey, version) {\r\n        return new MutableDocument(documentKey, 3 /* UNKNOWN_DOCUMENT */, version, ObjectValue.empty(), 2 /* HAS_COMMITTED_MUTATIONS */);\r\n    }\r\n    /**\r\n     * Changes the document type to indicate that it exists and that its version\r\n     * and data are known.\r\n     */\r\n    convertToFoundDocument(version, value) {\r\n        this.version = version;\r\n        this.documentType = 1 /* FOUND_DOCUMENT */;\r\n        this.data = value;\r\n        this.documentState = 0 /* SYNCED */;\r\n        return this;\r\n    }\r\n    /**\r\n     * Changes the document type to indicate that it doesn't exist at the given\r\n     * version.\r\n     */\r\n    convertToNoDocument(version) {\r\n        this.version = version;\r\n        this.documentType = 2 /* NO_DOCUMENT */;\r\n        this.data = ObjectValue.empty();\r\n        this.documentState = 0 /* SYNCED */;\r\n        return this;\r\n    }\r\n    /**\r\n     * Changes the document type to indicate that it exists at a given version but\r\n     * that its data is not known (e.g. a document that was updated without a known\r\n     * base document).\r\n     */\r\n    convertToUnknownDocument(version) {\r\n        this.version = version;\r\n        this.documentType = 3 /* UNKNOWN_DOCUMENT */;\r\n        this.data = ObjectValue.empty();\r\n        this.documentState = 2 /* HAS_COMMITTED_MUTATIONS */;\r\n        return this;\r\n    }\r\n    setHasCommittedMutations() {\r\n        this.documentState = 2 /* HAS_COMMITTED_MUTATIONS */;\r\n        return this;\r\n    }\r\n    setHasLocalMutations() {\r\n        this.documentState = 1 /* HAS_LOCAL_MUTATIONS */;\r\n        return this;\r\n    }\r\n    get hasLocalMutations() {\r\n        return this.documentState === 1 /* HAS_LOCAL_MUTATIONS */;\r\n    }\r\n    get hasCommittedMutations() {\r\n        return this.documentState === 2 /* HAS_COMMITTED_MUTATIONS */;\r\n    }\r\n    get hasPendingWrites() {\r\n        return this.hasLocalMutations || this.hasCommittedMutations;\r\n    }\r\n    isValidDocument() {\r\n        return this.documentType !== 0 /* INVALID */;\r\n    }\r\n    isFoundDocument() {\r\n        return this.documentType === 1 /* FOUND_DOCUMENT */;\r\n    }\r\n    isNoDocument() {\r\n        return this.documentType === 2 /* NO_DOCUMENT */;\r\n    }\r\n    isUnknownDocument() {\r\n        return this.documentType === 3 /* UNKNOWN_DOCUMENT */;\r\n    }\r\n    isEqual(other) {\r\n        return (other instanceof MutableDocument &&\r\n            this.key.isEqual(other.key) &&\r\n            this.version.isEqual(other.version) &&\r\n            this.documentType === other.documentType &&\r\n            this.documentState === other.documentState &&\r\n            this.data.isEqual(other.data));\r\n    }\r\n    clone() {\r\n        return new MutableDocument(this.key, this.documentType, this.version, this.data.clone(), this.documentState);\r\n    }\r\n    toString() {\r\n        return (`Document(${this.key}, ${this.version}, ${JSON.stringify(this.data.value)}, ` +\r\n            `{documentType: ${this.documentType}}), ` +\r\n            `{documentState: ${this.documentState}})`);\r\n    }\r\n}\r\n/**\r\n * Compares the value for field `field` in the provided documents. Throws if\r\n * the field does not exist in both documents.\r\n */\r\nfunction compareDocumentsByField(field, d1, d2) {\r\n    const v1 = d1.data.field(field);\r\n    const v2 = d2.data.field(field);\r\n    if (v1 !== null && v2 !== null) {\r\n        return valueCompare(v1, v2);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// Visible for testing\r\nclass TargetImpl {\r\n    constructor(path, collectionGroup = null, orderBy = [], filters = [], limit = null, startAt = null, endAt = null) {\r\n        this.path = path;\r\n        this.collectionGroup = collectionGroup;\r\n        this.orderBy = orderBy;\r\n        this.filters = filters;\r\n        this.limit = limit;\r\n        this.startAt = startAt;\r\n        this.endAt = endAt;\r\n        this.memoizedCanonicalId = null;\r\n    }\r\n}\r\n/**\r\n * Initializes a Target with a path and optional additional query constraints.\r\n * Path must currently be empty if this is a collection group query.\r\n *\r\n * NOTE: you should always construct `Target` from `Query.toTarget` instead of\r\n * using this factory method, because `Query` provides an implicit `orderBy`\r\n * property.\r\n */\r\nfunction newTarget(path, collectionGroup = null, orderBy = [], filters = [], limit = null, startAt = null, endAt = null) {\r\n    return new TargetImpl(path, collectionGroup, orderBy, filters, limit, startAt, endAt);\r\n}\r\nfunction canonifyTarget(target) {\r\n    const targetImpl = debugCast(target);\r\n    if (targetImpl.memoizedCanonicalId === null) {\r\n        let canonicalId = targetImpl.path.canonicalString();\r\n        if (targetImpl.collectionGroup !== null) {\r\n            canonicalId += '|cg:' + targetImpl.collectionGroup;\r\n        }\r\n        canonicalId += '|f:';\r\n        canonicalId += targetImpl.filters.map(f => canonifyFilter(f)).join(',');\r\n        canonicalId += '|ob:';\r\n        canonicalId += targetImpl.orderBy.map(o => canonifyOrderBy(o)).join(',');\r\n        if (!isNullOrUndefined(targetImpl.limit)) {\r\n            canonicalId += '|l:';\r\n            canonicalId += targetImpl.limit;\r\n        }\r\n        if (targetImpl.startAt) {\r\n            canonicalId += '|lb:';\r\n            canonicalId += canonifyBound(targetImpl.startAt);\r\n        }\r\n        if (targetImpl.endAt) {\r\n            canonicalId += '|ub:';\r\n            canonicalId += canonifyBound(targetImpl.endAt);\r\n        }\r\n        targetImpl.memoizedCanonicalId = canonicalId;\r\n    }\r\n    return targetImpl.memoizedCanonicalId;\r\n}\r\nfunction stringifyTarget(target) {\r\n    let str = target.path.canonicalString();\r\n    if (target.collectionGroup !== null) {\r\n        str += ' collectionGroup=' + target.collectionGroup;\r\n    }\r\n    if (target.filters.length > 0) {\r\n        str += `, filters: [${target.filters\r\n            .map(f => stringifyFilter(f))\r\n            .join(', ')}]`;\r\n    }\r\n    if (!isNullOrUndefined(target.limit)) {\r\n        str += ', limit: ' + target.limit;\r\n    }\r\n    if (target.orderBy.length > 0) {\r\n        str += `, orderBy: [${target.orderBy\r\n            .map(o => stringifyOrderBy(o))\r\n            .join(', ')}]`;\r\n    }\r\n    if (target.startAt) {\r\n        str += ', startAt: ' + canonifyBound(target.startAt);\r\n    }\r\n    if (target.endAt) {\r\n        str += ', endAt: ' + canonifyBound(target.endAt);\r\n    }\r\n    return `Target(${str})`;\r\n}\r\nfunction targetEquals(left, right) {\r\n    if (left.limit !== right.limit) {\r\n        return false;\r\n    }\r\n    if (left.orderBy.length !== right.orderBy.length) {\r\n        return false;\r\n    }\r\n    for (let i = 0; i < left.orderBy.length; i++) {\r\n        if (!orderByEquals(left.orderBy[i], right.orderBy[i])) {\r\n            return false;\r\n        }\r\n    }\r\n    if (left.filters.length !== right.filters.length) {\r\n        return false;\r\n    }\r\n    for (let i = 0; i < left.filters.length; i++) {\r\n        if (!filterEquals(left.filters[i], right.filters[i])) {\r\n            return false;\r\n        }\r\n    }\r\n    if (left.collectionGroup !== right.collectionGroup) {\r\n        return false;\r\n    }\r\n    if (!left.path.isEqual(right.path)) {\r\n        return false;\r\n    }\r\n    if (!boundEquals(left.startAt, right.startAt)) {\r\n        return false;\r\n    }\r\n    return boundEquals(left.endAt, right.endAt);\r\n}\r\nfunction isDocumentTarget(target) {\r\n    return (DocumentKey.isDocumentKey(target.path) &&\r\n        target.collectionGroup === null &&\r\n        target.filters.length === 0);\r\n}\r\nclass Filter {\r\n}\r\nclass FieldFilter extends Filter {\r\n    constructor(field, op, value) {\r\n        super();\r\n        this.field = field;\r\n        this.op = op;\r\n        this.value = value;\r\n    }\r\n    /**\r\n     * Creates a filter based on the provided arguments.\r\n     */\r\n    static create(field, op, value) {\r\n        if (field.isKeyField()) {\r\n            if (op === \"in\" /* IN */ || op === \"not-in\" /* NOT_IN */) {\r\n                return this.createKeyFieldInFilter(field, op, value);\r\n            }\r\n            else {\r\n                return new KeyFieldFilter(field, op, value);\r\n            }\r\n        }\r\n        else if (op === \"array-contains\" /* ARRAY_CONTAINS */) {\r\n            return new ArrayContainsFilter(field, value);\r\n        }\r\n        else if (op === \"in\" /* IN */) {\r\n            return new InFilter(field, value);\r\n        }\r\n        else if (op === \"not-in\" /* NOT_IN */) {\r\n            return new NotInFilter(field, value);\r\n        }\r\n        else if (op === \"array-contains-any\" /* ARRAY_CONTAINS_ANY */) {\r\n            return new ArrayContainsAnyFilter(field, value);\r\n        }\r\n        else {\r\n            return new FieldFilter(field, op, value);\r\n        }\r\n    }\r\n    static createKeyFieldInFilter(field, op, value) {\r\n        return op === \"in\" /* IN */\r\n            ? new KeyFieldInFilter(field, value)\r\n            : new KeyFieldNotInFilter(field, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        // Types do not have to match in NOT_EQUAL filters.\r\n        if (this.op === \"!=\" /* NOT_EQUAL */) {\r\n            return (other !== null &&\r\n                this.matchesComparison(valueCompare(other, this.value)));\r\n        }\r\n        // Only compare types with matching backend order (such as double and int).\r\n        return (other !== null &&\r\n            typeOrder(this.value) === typeOrder(other) &&\r\n            this.matchesComparison(valueCompare(other, this.value)));\r\n    }\r\n    matchesComparison(comparison) {\r\n        switch (this.op) {\r\n            case \"<\" /* LESS_THAN */:\r\n                return comparison < 0;\r\n            case \"<=\" /* LESS_THAN_OR_EQUAL */:\r\n                return comparison <= 0;\r\n            case \"==\" /* EQUAL */:\r\n                return comparison === 0;\r\n            case \"!=\" /* NOT_EQUAL */:\r\n                return comparison !== 0;\r\n            case \">\" /* GREATER_THAN */:\r\n                return comparison > 0;\r\n            case \">=\" /* GREATER_THAN_OR_EQUAL */:\r\n                return comparison >= 0;\r\n            default:\r\n                return fail();\r\n        }\r\n    }\r\n    isInequality() {\r\n        return ([\r\n            \"<\" /* LESS_THAN */,\r\n            \"<=\" /* LESS_THAN_OR_EQUAL */,\r\n            \">\" /* GREATER_THAN */,\r\n            \">=\" /* GREATER_THAN_OR_EQUAL */,\r\n            \"!=\" /* NOT_EQUAL */,\r\n            \"not-in\" /* NOT_IN */\r\n        ].indexOf(this.op) >= 0);\r\n    }\r\n}\r\nfunction canonifyFilter(filter) {\r\n    // TODO(b/29183165): Technically, this won't be unique if two values have\r\n    // the same description, such as the int 3 and the string \"3\". So we should\r\n    // add the types in here somehow, too.\r\n    return (filter.field.canonicalString() +\r\n        filter.op.toString() +\r\n        canonicalId(filter.value));\r\n}\r\nfunction filterEquals(f1, f2) {\r\n    return (f1.op === f2.op &&\r\n        f1.field.isEqual(f2.field) &&\r\n        valueEquals(f1.value, f2.value));\r\n}\r\n/** Returns a debug description for `filter`. */\r\nfunction stringifyFilter(filter) {\r\n    return `${filter.field.canonicalString()} ${filter.op} ${canonicalId(filter.value)}`;\r\n}\r\n/** Filter that matches on key fields (i.e. '__name__'). */\r\nclass KeyFieldFilter extends FieldFilter {\r\n    constructor(field, op, value) {\r\n        super(field, op, value);\r\n        this.key = DocumentKey.fromName(value.referenceValue);\r\n    }\r\n    matches(doc) {\r\n        const comparison = DocumentKey.comparator(doc.key, this.key);\r\n        return this.matchesComparison(comparison);\r\n    }\r\n}\r\n/** Filter that matches on key fields within an array. */\r\nclass KeyFieldInFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"in\" /* IN */, value);\r\n        this.keys = extractDocumentKeysFromArrayValue(\"in\" /* IN */, value);\r\n    }\r\n    matches(doc) {\r\n        return this.keys.some(key => key.isEqual(doc.key));\r\n    }\r\n}\r\n/** Filter that matches on key fields not present within an array. */\r\nclass KeyFieldNotInFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"not-in\" /* NOT_IN */, value);\r\n        this.keys = extractDocumentKeysFromArrayValue(\"not-in\" /* NOT_IN */, value);\r\n    }\r\n    matches(doc) {\r\n        return !this.keys.some(key => key.isEqual(doc.key));\r\n    }\r\n}\r\nfunction extractDocumentKeysFromArrayValue(op, value) {\r\n    var _a;\r\n    return (((_a = value.arrayValue) === null || _a === void 0 ? void 0 : _a.values) || []).map(v => {\r\n        return DocumentKey.fromName(v.referenceValue);\r\n    });\r\n}\r\n/** A Filter that implements the array-contains operator. */\r\nclass ArrayContainsFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"array-contains\" /* ARRAY_CONTAINS */, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        return isArray(other) && arrayValueContains(other.arrayValue, this.value);\r\n    }\r\n}\r\n/** A Filter that implements the IN operator. */\r\nclass InFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"in\" /* IN */, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        return other !== null && arrayValueContains(this.value.arrayValue, other);\r\n    }\r\n}\r\n/** A Filter that implements the not-in operator. */\r\nclass NotInFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"not-in\" /* NOT_IN */, value);\r\n    }\r\n    matches(doc) {\r\n        if (arrayValueContains(this.value.arrayValue, { nullValue: 'NULL_VALUE' })) {\r\n            return false;\r\n        }\r\n        const other = doc.data.field(this.field);\r\n        return other !== null && !arrayValueContains(this.value.arrayValue, other);\r\n    }\r\n}\r\n/** A Filter that implements the array-contains-any operator. */\r\nclass ArrayContainsAnyFilter extends FieldFilter {\r\n    constructor(field, value) {\r\n        super(field, \"array-contains-any\" /* ARRAY_CONTAINS_ANY */, value);\r\n    }\r\n    matches(doc) {\r\n        const other = doc.data.field(this.field);\r\n        if (!isArray(other) || !other.arrayValue.values) {\r\n            return false;\r\n        }\r\n        return other.arrayValue.values.some(val => arrayValueContains(this.value.arrayValue, val));\r\n    }\r\n}\r\n/**\r\n * Represents a bound of a query.\r\n *\r\n * The bound is specified with the given components representing a position and\r\n * whether it's just before or just after the position (relative to whatever the\r\n * query order is).\r\n *\r\n * The position represents a logical index position for a query. It's a prefix\r\n * of values for the (potentially implicit) order by clauses of a query.\r\n *\r\n * Bound provides a function to determine whether a document comes before or\r\n * after a bound. This is influenced by whether the position is just before or\r\n * just after the provided values.\r\n */\r\nclass Bound {\r\n    constructor(position, before) {\r\n        this.position = position;\r\n        this.before = before;\r\n    }\r\n}\r\nfunction canonifyBound(bound) {\r\n    // TODO(b/29183165): Make this collision robust.\r\n    return `${bound.before ? 'b' : 'a'}:${bound.position\r\n        .map(p => canonicalId(p))\r\n        .join(',')}`;\r\n}\r\n/**\r\n * An ordering on a field, in some Direction. Direction defaults to ASCENDING.\r\n */\r\nclass OrderBy {\r\n    constructor(field, dir = \"asc\" /* ASCENDING */) {\r\n        this.field = field;\r\n        this.dir = dir;\r\n    }\r\n}\r\nfunction canonifyOrderBy(orderBy) {\r\n    // TODO(b/29183165): Make this collision robust.\r\n    return orderBy.field.canonicalString() + orderBy.dir;\r\n}\r\nfunction stringifyOrderBy(orderBy) {\r\n    return `${orderBy.field.canonicalString()} (${orderBy.dir})`;\r\n}\r\nfunction orderByEquals(left, right) {\r\n    return left.dir === right.dir && left.field.isEqual(right.field);\r\n}\r\n/**\r\n * Returns true if a document sorts before a bound using the provided sort\r\n * order.\r\n */\r\nfunction sortsBeforeDocument(bound, orderBy, doc) {\r\n    let comparison = 0;\r\n    for (let i = 0; i < bound.position.length; i++) {\r\n        const orderByComponent = orderBy[i];\r\n        const component = bound.position[i];\r\n        if (orderByComponent.field.isKeyField()) {\r\n            comparison = DocumentKey.comparator(DocumentKey.fromName(component.referenceValue), doc.key);\r\n        }\r\n        else {\r\n            const docValue = doc.data.field(orderByComponent.field);\r\n            comparison = valueCompare(component, docValue);\r\n        }\r\n        if (orderByComponent.dir === \"desc\" /* DESCENDING */) {\r\n            comparison = comparison * -1;\r\n        }\r\n        if (comparison !== 0) {\r\n            break;\r\n        }\r\n    }\r\n    return bound.before ? comparison <= 0 : comparison < 0;\r\n}\r\nfunction boundEquals(left, right) {\r\n    if (left === null) {\r\n        return right === null;\r\n    }\r\n    else if (right === null) {\r\n        return false;\r\n    }\r\n    if (left.before !== right.before ||\r\n        left.position.length !== right.position.length) {\r\n        return false;\r\n    }\r\n    for (let i = 0; i < left.position.length; i++) {\r\n        const leftPosition = left.position[i];\r\n        const rightPosition = right.position[i];\r\n        if (!valueEquals(leftPosition, rightPosition)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Query encapsulates all the query attributes we support in the SDK. It can\r\n * be run against the LocalStore, as well as be converted to a `Target` to\r\n * query the RemoteStore results.\r\n *\r\n * Visible for testing.\r\n */\r\nclass QueryImpl {\r\n    /**\r\n     * Initializes a Query with a path and optional additional query constraints.\r\n     * Path must currently be empty if this is a collection group query.\r\n     */\r\n    constructor(path, collectionGroup = null, explicitOrderBy = [], filters = [], limit = null, limitType = \"F\" /* First */, startAt = null, endAt = null) {\r\n        this.path = path;\r\n        this.collectionGroup = collectionGroup;\r\n        this.explicitOrderBy = explicitOrderBy;\r\n        this.filters = filters;\r\n        this.limit = limit;\r\n        this.limitType = limitType;\r\n        this.startAt = startAt;\r\n        this.endAt = endAt;\r\n        this.memoizedOrderBy = null;\r\n        // The corresponding `Target` of this `Query` instance.\r\n        this.memoizedTarget = null;\r\n        if (this.startAt) ;\r\n        if (this.endAt) ;\r\n    }\r\n}\r\n/** Creates a new Query instance with the options provided. */\r\nfunction newQuery(path, collectionGroup, explicitOrderBy, filters, limit, limitType, startAt, endAt) {\r\n    return new QueryImpl(path, collectionGroup, explicitOrderBy, filters, limit, limitType, startAt, endAt);\r\n}\r\n/** Creates a new Query for a query that matches all documents at `path` */\r\nfunction newQueryForPath(path) {\r\n    return new QueryImpl(path);\r\n}\r\n/**\r\n * Helper to convert a collection group query into a collection query at a\r\n * specific path. This is used when executing collection group queries, since\r\n * we have to split the query into a set of collection queries at multiple\r\n * paths.\r\n */\r\nfunction asCollectionQueryAtPath(query, path) {\r\n    return new QueryImpl(path, \r\n    /*collectionGroup=*/ null, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, query.startAt, query.endAt);\r\n}\r\n/**\r\n * Returns true if this query does not specify any query constraints that\r\n * could remove results.\r\n */\r\nfunction matchesAllDocuments(query) {\r\n    return (query.filters.length === 0 &&\r\n        query.limit === null &&\r\n        query.startAt == null &&\r\n        query.endAt == null &&\r\n        (query.explicitOrderBy.length === 0 ||\r\n            (query.explicitOrderBy.length === 1 &&\r\n                query.explicitOrderBy[0].field.isKeyField())));\r\n}\r\nfunction hasLimitToFirst(query) {\r\n    return !isNullOrUndefined(query.limit) && query.limitType === \"F\" /* First */;\r\n}\r\nfunction hasLimitToLast(query) {\r\n    return !isNullOrUndefined(query.limit) && query.limitType === \"L\" /* Last */;\r\n}\r\nfunction getFirstOrderByField(query) {\r\n    return query.explicitOrderBy.length > 0\r\n        ? query.explicitOrderBy[0].field\r\n        : null;\r\n}\r\nfunction getInequalityFilterField(query) {\r\n    for (const filter of query.filters) {\r\n        if (filter.isInequality()) {\r\n            return filter.field;\r\n        }\r\n    }\r\n    return null;\r\n}\r\n/**\r\n * Checks if any of the provided Operators are included in the query and\r\n * returns the first one that is, or null if none are.\r\n */\r\nfunction findFilterOperator(query, operators) {\r\n    for (const filter of query.filters) {\r\n        if (operators.indexOf(filter.op) >= 0) {\r\n            return filter.op;\r\n        }\r\n    }\r\n    return null;\r\n}\r\n/**\r\n * Creates a new Query for a collection group query that matches all documents\r\n * within the provided collection group.\r\n */\r\nfunction newQueryForCollectionGroup(collectionId) {\r\n    return new QueryImpl(ResourcePath.emptyPath(), collectionId);\r\n}\r\n/**\r\n * Returns whether the query matches a single document by path (rather than a\r\n * collection).\r\n */\r\nfunction isDocumentQuery$1(query) {\r\n    return (DocumentKey.isDocumentKey(query.path) &&\r\n        query.collectionGroup === null &&\r\n        query.filters.length === 0);\r\n}\r\n/**\r\n * Returns whether the query matches a collection group rather than a specific\r\n * collection.\r\n */\r\nfunction isCollectionGroupQuery(query) {\r\n    return query.collectionGroup !== null;\r\n}\r\n/**\r\n * Returns the implicit order by constraint that is used to execute the Query,\r\n * which can be different from the order by constraints the user provided (e.g.\r\n * the SDK and backend always orders by `__name__`).\r\n */\r\nfunction queryOrderBy(query) {\r\n    const queryImpl = debugCast(query);\r\n    if (queryImpl.memoizedOrderBy === null) {\r\n        queryImpl.memoizedOrderBy = [];\r\n        const inequalityField = getInequalityFilterField(queryImpl);\r\n        const firstOrderByField = getFirstOrderByField(queryImpl);\r\n        if (inequalityField !== null && firstOrderByField === null) {\r\n            // In order to implicitly add key ordering, we must also add the\r\n            // inequality filter field for it to be a valid query.\r\n            // Note that the default inequality field and key ordering is ascending.\r\n            if (!inequalityField.isKeyField()) {\r\n                queryImpl.memoizedOrderBy.push(new OrderBy(inequalityField));\r\n            }\r\n            queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath$1.keyField(), \"asc\" /* ASCENDING */));\r\n        }\r\n        else {\r\n            let foundKeyOrdering = false;\r\n            for (const orderBy of queryImpl.explicitOrderBy) {\r\n                queryImpl.memoizedOrderBy.push(orderBy);\r\n                if (orderBy.field.isKeyField()) {\r\n                    foundKeyOrdering = true;\r\n                }\r\n            }\r\n            if (!foundKeyOrdering) {\r\n                // The order of the implicit key ordering always matches the last\r\n                // explicit order by\r\n                const lastDirection = queryImpl.explicitOrderBy.length > 0\r\n                    ? queryImpl.explicitOrderBy[queryImpl.explicitOrderBy.length - 1]\r\n                        .dir\r\n                    : \"asc\" /* ASCENDING */;\r\n                queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath$1.keyField(), lastDirection));\r\n            }\r\n        }\r\n    }\r\n    return queryImpl.memoizedOrderBy;\r\n}\r\n/**\r\n * Converts this `Query` instance to it's corresponding `Target` representation.\r\n */\r\nfunction queryToTarget(query) {\r\n    const queryImpl = debugCast(query, QueryImpl);\r\n    if (!queryImpl.memoizedTarget) {\r\n        if (queryImpl.limitType === \"F\" /* First */) {\r\n            queryImpl.memoizedTarget = newTarget(queryImpl.path, queryImpl.collectionGroup, queryOrderBy(queryImpl), queryImpl.filters, queryImpl.limit, queryImpl.startAt, queryImpl.endAt);\r\n        }\r\n        else {\r\n            // Flip the orderBy directions since we want the last results\r\n            const orderBys = [];\r\n            for (const orderBy of queryOrderBy(queryImpl)) {\r\n                const dir = orderBy.dir === \"desc\" /* DESCENDING */\r\n                    ? \"asc\" /* ASCENDING */\r\n                    : \"desc\" /* DESCENDING */;\r\n                orderBys.push(new OrderBy(orderBy.field, dir));\r\n            }\r\n            // We need to swap the cursors to match the now-flipped query ordering.\r\n            const startAt = queryImpl.endAt\r\n                ? new Bound(queryImpl.endAt.position, !queryImpl.endAt.before)\r\n                : null;\r\n            const endAt = queryImpl.startAt\r\n                ? new Bound(queryImpl.startAt.position, !queryImpl.startAt.before)\r\n                : null;\r\n            // Now return as a LimitType.First query.\r\n            queryImpl.memoizedTarget = newTarget(queryImpl.path, queryImpl.collectionGroup, orderBys, queryImpl.filters, queryImpl.limit, startAt, endAt);\r\n        }\r\n    }\r\n    return queryImpl.memoizedTarget;\r\n}\r\nfunction queryWithAddedFilter(query, filter) {\r\n    const newFilters = query.filters.concat([filter]);\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), newFilters, query.limit, query.limitType, query.startAt, query.endAt);\r\n}\r\nfunction queryWithAddedOrderBy(query, orderBy) {\r\n    // TODO(dimond): validate that orderBy does not list the same key twice.\r\n    const newOrderBy = query.explicitOrderBy.concat([orderBy]);\r\n    return new QueryImpl(query.path, query.collectionGroup, newOrderBy, query.filters.slice(), query.limit, query.limitType, query.startAt, query.endAt);\r\n}\r\nfunction queryWithLimit(query, limit, limitType) {\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), limit, limitType, query.startAt, query.endAt);\r\n}\r\nfunction queryWithStartAt(query, bound) {\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, bound, query.endAt);\r\n}\r\nfunction queryWithEndAt(query, bound) {\r\n    return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, query.startAt, bound);\r\n}\r\nfunction queryEquals(left, right) {\r\n    return (targetEquals(queryToTarget(left), queryToTarget(right)) &&\r\n        left.limitType === right.limitType);\r\n}\r\n// TODO(b/29183165): This is used to get a unique string from a query to, for\r\n// example, use as a dictionary key, but the implementation is subject to\r\n// collisions. Make it collision-free.\r\nfunction canonifyQuery(query) {\r\n    return `${canonifyTarget(queryToTarget(query))}|lt:${query.limitType}`;\r\n}\r\nfunction stringifyQuery(query) {\r\n    return `Query(target=${stringifyTarget(queryToTarget(query))}; limitType=${query.limitType})`;\r\n}\r\n/** Returns whether `doc` matches the constraints of `query`. */\r\nfunction queryMatches(query, doc) {\r\n    return (doc.isFoundDocument() &&\r\n        queryMatchesPathAndCollectionGroup(query, doc) &&\r\n        queryMatchesOrderBy(query, doc) &&\r\n        queryMatchesFilters(query, doc) &&\r\n        queryMatchesBounds(query, doc));\r\n}\r\nfunction queryMatchesPathAndCollectionGroup(query, doc) {\r\n    const docPath = doc.key.path;\r\n    if (query.collectionGroup !== null) {\r\n        // NOTE: this.path is currently always empty since we don't expose Collection\r\n        // Group queries rooted at a document path yet.\r\n        return (doc.key.hasCollectionId(query.collectionGroup) &&\r\n            query.path.isPrefixOf(docPath));\r\n    }\r\n    else if (DocumentKey.isDocumentKey(query.path)) {\r\n        // exact match for document queries\r\n        return query.path.isEqual(docPath);\r\n    }\r\n    else {\r\n        // shallow ancestor queries by default\r\n        return query.path.isImmediateParentOf(docPath);\r\n    }\r\n}\r\n/**\r\n * A document must have a value for every ordering clause in order to show up\r\n * in the results.\r\n */\r\nfunction queryMatchesOrderBy(query, doc) {\r\n    for (const orderBy of query.explicitOrderBy) {\r\n        // order by key always matches\r\n        if (!orderBy.field.isKeyField() && doc.data.field(orderBy.field) === null) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\r\nfunction queryMatchesFilters(query, doc) {\r\n    for (const filter of query.filters) {\r\n        if (!filter.matches(doc)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\r\n/** Makes sure a document is within the bounds, if provided. */\r\nfunction queryMatchesBounds(query, doc) {\r\n    if (query.startAt &&\r\n        !sortsBeforeDocument(query.startAt, queryOrderBy(query), doc)) {\r\n        return false;\r\n    }\r\n    if (query.endAt &&\r\n        sortsBeforeDocument(query.endAt, queryOrderBy(query), doc)) {\r\n        return false;\r\n    }\r\n    return true;\r\n}\r\n/**\r\n * Returns a new comparator function that can be used to compare two documents\r\n * based on the Query's ordering constraint.\r\n */\r\nfunction newQueryComparator(query) {\r\n    return (d1, d2) => {\r\n        let comparedOnKeyField = false;\r\n        for (const orderBy of queryOrderBy(query)) {\r\n            const comp = compareDocs(orderBy, d1, d2);\r\n            if (comp !== 0) {\r\n                return comp;\r\n            }\r\n            comparedOnKeyField = comparedOnKeyField || orderBy.field.isKeyField();\r\n        }\r\n        return 0;\r\n    };\r\n}\r\nfunction compareDocs(orderBy, d1, d2) {\r\n    const comparison = orderBy.field.isKeyField()\r\n        ? DocumentKey.comparator(d1.key, d2.key)\r\n        : compareDocumentsByField(orderBy.field, d1, d2);\r\n    switch (orderBy.dir) {\r\n        case \"asc\" /* ASCENDING */:\r\n            return comparison;\r\n        case \"desc\" /* DESCENDING */:\r\n            return -1 * comparison;\r\n        default:\r\n            return fail();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// An immutable sorted map implementation, based on a Left-leaning Red-Black\r\n// tree.\r\nclass SortedMap {\r\n    constructor(comparator, root) {\r\n        this.comparator = comparator;\r\n        this.root = root ? root : LLRBNode.EMPTY;\r\n    }\r\n    // Returns a copy of the map, with the specified key/value added or replaced.\r\n    insert(key, value) {\r\n        return new SortedMap(this.comparator, this.root\r\n            .insert(key, value, this.comparator)\r\n            .copy(null, null, LLRBNode.BLACK, null, null));\r\n    }\r\n    // Returns a copy of the map, with the specified key removed.\r\n    remove(key) {\r\n        return new SortedMap(this.comparator, this.root\r\n            .remove(key, this.comparator)\r\n            .copy(null, null, LLRBNode.BLACK, null, null));\r\n    }\r\n    // Returns the value of the node with the given key, or null.\r\n    get(key) {\r\n        let node = this.root;\r\n        while (!node.isEmpty()) {\r\n            const cmp = this.comparator(key, node.key);\r\n            if (cmp === 0) {\r\n                return node.value;\r\n            }\r\n            else if (cmp < 0) {\r\n                node = node.left;\r\n            }\r\n            else if (cmp > 0) {\r\n                node = node.right;\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n    // Returns the index of the element in this sorted map, or -1 if it doesn't\r\n    // exist.\r\n    indexOf(key) {\r\n        // Number of nodes that were pruned when descending right\r\n        let prunedNodes = 0;\r\n        let node = this.root;\r\n        while (!node.isEmpty()) {\r\n            const cmp = this.comparator(key, node.key);\r\n            if (cmp === 0) {\r\n                return prunedNodes + node.left.size;\r\n            }\r\n            else if (cmp < 0) {\r\n                node = node.left;\r\n            }\r\n            else {\r\n                // Count all nodes left of the node plus the node itself\r\n                prunedNodes += node.left.size + 1;\r\n                node = node.right;\r\n            }\r\n        }\r\n        // Node not found\r\n        return -1;\r\n    }\r\n    isEmpty() {\r\n        return this.root.isEmpty();\r\n    }\r\n    // Returns the total number of nodes in the map.\r\n    get size() {\r\n        return this.root.size;\r\n    }\r\n    // Returns the minimum key in the map.\r\n    minKey() {\r\n        return this.root.minKey();\r\n    }\r\n    // Returns the maximum key in the map.\r\n    maxKey() {\r\n        return this.root.maxKey();\r\n    }\r\n    // Traverses the map in key order and calls the specified action function\r\n    // for each key/value pair. If action returns true, traversal is aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    inorderTraversal(action) {\r\n        return this.root.inorderTraversal(action);\r\n    }\r\n    forEach(fn) {\r\n        this.inorderTraversal((k, v) => {\r\n            fn(k, v);\r\n            return false;\r\n        });\r\n    }\r\n    toString() {\r\n        const descriptions = [];\r\n        this.inorderTraversal((k, v) => {\r\n            descriptions.push(`${k}:${v}`);\r\n            return false;\r\n        });\r\n        return `{${descriptions.join(', ')}}`;\r\n    }\r\n    // Traverses the map in reverse key order and calls the specified action\r\n    // function for each key/value pair. If action returns true, traversal is\r\n    // aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    reverseTraversal(action) {\r\n        return this.root.reverseTraversal(action);\r\n    }\r\n    // Returns an iterator over the SortedMap.\r\n    getIterator() {\r\n        return new SortedMapIterator(this.root, null, this.comparator, false);\r\n    }\r\n    getIteratorFrom(key) {\r\n        return new SortedMapIterator(this.root, key, this.comparator, false);\r\n    }\r\n    getReverseIterator() {\r\n        return new SortedMapIterator(this.root, null, this.comparator, true);\r\n    }\r\n    getReverseIteratorFrom(key) {\r\n        return new SortedMapIterator(this.root, key, this.comparator, true);\r\n    }\r\n} // end SortedMap\r\n// An iterator over an LLRBNode.\r\nclass SortedMapIterator {\r\n    constructor(node, startKey, comparator, isReverse) {\r\n        this.isReverse = isReverse;\r\n        this.nodeStack = [];\r\n        let cmp = 1;\r\n        while (!node.isEmpty()) {\r\n            cmp = startKey ? comparator(node.key, startKey) : 1;\r\n            // flip the comparison if we're going in reverse\r\n            if (isReverse) {\r\n                cmp *= -1;\r\n            }\r\n            if (cmp < 0) {\r\n                // This node is less than our start key. ignore it\r\n                if (this.isReverse) {\r\n                    node = node.left;\r\n                }\r\n                else {\r\n                    node = node.right;\r\n                }\r\n            }\r\n            else if (cmp === 0) {\r\n                // This node is exactly equal to our start key. Push it on the stack,\r\n                // but stop iterating;\r\n                this.nodeStack.push(node);\r\n                break;\r\n            }\r\n            else {\r\n                // This node is greater than our start key, add it to the stack and move\r\n                // to the next one\r\n                this.nodeStack.push(node);\r\n                if (this.isReverse) {\r\n                    node = node.right;\r\n                }\r\n                else {\r\n                    node = node.left;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    getNext() {\r\n        let node = this.nodeStack.pop();\r\n        const result = { key: node.key, value: node.value };\r\n        if (this.isReverse) {\r\n            node = node.left;\r\n            while (!node.isEmpty()) {\r\n                this.nodeStack.push(node);\r\n                node = node.right;\r\n            }\r\n        }\r\n        else {\r\n            node = node.right;\r\n            while (!node.isEmpty()) {\r\n                this.nodeStack.push(node);\r\n                node = node.left;\r\n            }\r\n        }\r\n        return result;\r\n    }\r\n    hasNext() {\r\n        return this.nodeStack.length > 0;\r\n    }\r\n    peek() {\r\n        if (this.nodeStack.length === 0) {\r\n            return null;\r\n        }\r\n        const node = this.nodeStack[this.nodeStack.length - 1];\r\n        return { key: node.key, value: node.value };\r\n    }\r\n} // end SortedMapIterator\r\n// Represents a node in a Left-leaning Red-Black tree.\r\nclass LLRBNode {\r\n    constructor(key, value, color, left, right) {\r\n        this.key = key;\r\n        this.value = value;\r\n        this.color = color != null ? color : LLRBNode.RED;\r\n        this.left = left != null ? left : LLRBNode.EMPTY;\r\n        this.right = right != null ? right : LLRBNode.EMPTY;\r\n        this.size = this.left.size + 1 + this.right.size;\r\n    }\r\n    // Returns a copy of the current node, optionally replacing pieces of it.\r\n    copy(key, value, color, left, right) {\r\n        return new LLRBNode(key != null ? key : this.key, value != null ? value : this.value, color != null ? color : this.color, left != null ? left : this.left, right != null ? right : this.right);\r\n    }\r\n    isEmpty() {\r\n        return false;\r\n    }\r\n    // Traverses the tree in key order and calls the specified action function\r\n    // for each node. If action returns true, traversal is aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    inorderTraversal(action) {\r\n        return (this.left.inorderTraversal(action) ||\r\n            action(this.key, this.value) ||\r\n            this.right.inorderTraversal(action));\r\n    }\r\n    // Traverses the tree in reverse key order and calls the specified action\r\n    // function for each node. If action returns true, traversal is aborted.\r\n    // Returns the first truthy value returned by action, or the last falsey\r\n    // value returned by action.\r\n    reverseTraversal(action) {\r\n        return (this.right.reverseTraversal(action) ||\r\n            action(this.key, this.value) ||\r\n            this.left.reverseTraversal(action));\r\n    }\r\n    // Returns the minimum node in the tree.\r\n    min() {\r\n        if (this.left.isEmpty()) {\r\n            return this;\r\n        }\r\n        else {\r\n            return this.left.min();\r\n        }\r\n    }\r\n    // Returns the maximum key in the tree.\r\n    minKey() {\r\n        return this.min().key;\r\n    }\r\n    // Returns the maximum key in the tree.\r\n    maxKey() {\r\n        if (this.right.isEmpty()) {\r\n            return this.key;\r\n        }\r\n        else {\r\n            return this.right.maxKey();\r\n        }\r\n    }\r\n    // Returns new tree, with the key/value added.\r\n    insert(key, value, comparator) {\r\n        let n = this;\r\n        const cmp = comparator(key, n.key);\r\n        if (cmp < 0) {\r\n            n = n.copy(null, null, null, n.left.insert(key, value, comparator), null);\r\n        }\r\n        else if (cmp === 0) {\r\n            n = n.copy(null, value, null, null, null);\r\n        }\r\n        else {\r\n            n = n.copy(null, null, null, null, n.right.insert(key, value, comparator));\r\n        }\r\n        return n.fixUp();\r\n    }\r\n    removeMin() {\r\n        if (this.left.isEmpty()) {\r\n            return LLRBNode.EMPTY;\r\n        }\r\n        let n = this;\r\n        if (!n.left.isRed() && !n.left.left.isRed()) {\r\n            n = n.moveRedLeft();\r\n        }\r\n        n = n.copy(null, null, null, n.left.removeMin(), null);\r\n        return n.fixUp();\r\n    }\r\n    // Returns new tree, with the specified item removed.\r\n    remove(key, comparator) {\r\n        let smallest;\r\n        let n = this;\r\n        if (comparator(key, n.key) < 0) {\r\n            if (!n.left.isEmpty() && !n.left.isRed() && !n.left.left.isRed()) {\r\n                n = n.moveRedLeft();\r\n            }\r\n            n = n.copy(null, null, null, n.left.remove(key, comparator), null);\r\n        }\r\n        else {\r\n            if (n.left.isRed()) {\r\n                n = n.rotateRight();\r\n            }\r\n            if (!n.right.isEmpty() && !n.right.isRed() && !n.right.left.isRed()) {\r\n                n = n.moveRedRight();\r\n            }\r\n            if (comparator(key, n.key) === 0) {\r\n                if (n.right.isEmpty()) {\r\n                    return LLRBNode.EMPTY;\r\n                }\r\n                else {\r\n                    smallest = n.right.min();\r\n                    n = n.copy(smallest.key, smallest.value, null, null, n.right.removeMin());\r\n                }\r\n            }\r\n            n = n.copy(null, null, null, null, n.right.remove(key, comparator));\r\n        }\r\n        return n.fixUp();\r\n    }\r\n    isRed() {\r\n        return this.color;\r\n    }\r\n    // Returns new tree after performing any needed rotations.\r\n    fixUp() {\r\n        let n = this;\r\n        if (n.right.isRed() && !n.left.isRed()) {\r\n            n = n.rotateLeft();\r\n        }\r\n        if (n.left.isRed() && n.left.left.isRed()) {\r\n            n = n.rotateRight();\r\n        }\r\n        if (n.left.isRed() && n.right.isRed()) {\r\n            n = n.colorFlip();\r\n        }\r\n        return n;\r\n    }\r\n    moveRedLeft() {\r\n        let n = this.colorFlip();\r\n        if (n.right.left.isRed()) {\r\n            n = n.copy(null, null, null, null, n.right.rotateRight());\r\n            n = n.rotateLeft();\r\n            n = n.colorFlip();\r\n        }\r\n        return n;\r\n    }\r\n    moveRedRight() {\r\n        let n = this.colorFlip();\r\n        if (n.left.left.isRed()) {\r\n            n = n.rotateRight();\r\n            n = n.colorFlip();\r\n        }\r\n        return n;\r\n    }\r\n    rotateLeft() {\r\n        const nl = this.copy(null, null, LLRBNode.RED, null, this.right.left);\r\n        return this.right.copy(null, null, this.color, nl, null);\r\n    }\r\n    rotateRight() {\r\n        const nr = this.copy(null, null, LLRBNode.RED, this.left.right, null);\r\n        return this.left.copy(null, null, this.color, null, nr);\r\n    }\r\n    colorFlip() {\r\n        const left = this.left.copy(null, null, !this.left.color, null, null);\r\n        const right = this.right.copy(null, null, !this.right.color, null, null);\r\n        return this.copy(null, null, !this.color, left, right);\r\n    }\r\n    // For testing.\r\n    checkMaxDepth() {\r\n        const blackDepth = this.check();\r\n        if (Math.pow(2.0, blackDepth) <= this.size + 1) {\r\n            return true;\r\n        }\r\n        else {\r\n            return false;\r\n        }\r\n    }\r\n    // In a balanced RB tree, the black-depth (number of black nodes) from root to\r\n    // leaves is equal on both sides.  This function verifies that or asserts.\r\n    check() {\r\n        if (this.isRed() && this.left.isRed()) {\r\n            throw fail();\r\n        }\r\n        if (this.right.isRed()) {\r\n            throw fail();\r\n        }\r\n        const blackDepth = this.left.check();\r\n        if (blackDepth !== this.right.check()) {\r\n            throw fail();\r\n        }\r\n        else {\r\n            return blackDepth + (this.isRed() ? 0 : 1);\r\n        }\r\n    }\r\n} // end LLRBNode\r\n// Empty node is shared between all LLRB trees.\r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nLLRBNode.EMPTY = null;\r\nLLRBNode.RED = true;\r\nLLRBNode.BLACK = false;\r\n// Represents an empty node (a leaf node in the Red-Black Tree).\r\nclass LLRBEmptyNode {\r\n    constructor() {\r\n        this.size = 0;\r\n    }\r\n    get key() {\r\n        throw fail();\r\n    }\r\n    get value() {\r\n        throw fail();\r\n    }\r\n    get color() {\r\n        throw fail();\r\n    }\r\n    get left() {\r\n        throw fail();\r\n    }\r\n    get right() {\r\n        throw fail();\r\n    }\r\n    // Returns a copy of the current node.\r\n    copy(key, value, color, left, right) {\r\n        return this;\r\n    }\r\n    // Returns a copy of the tree, with the specified key/value added.\r\n    insert(key, value, comparator) {\r\n        return new LLRBNode(key, value);\r\n    }\r\n    // Returns a copy of the tree, with the specified key removed.\r\n    remove(key, comparator) {\r\n        return this;\r\n    }\r\n    isEmpty() {\r\n        return true;\r\n    }\r\n    inorderTraversal(action) {\r\n        return false;\r\n    }\r\n    reverseTraversal(action) {\r\n        return false;\r\n    }\r\n    minKey() {\r\n        return null;\r\n    }\r\n    maxKey() {\r\n        return null;\r\n    }\r\n    isRed() {\r\n        return false;\r\n    }\r\n    // For testing.\r\n    checkMaxDepth() {\r\n        return true;\r\n    }\r\n    check() {\r\n        return 0;\r\n    }\r\n} // end LLRBEmptyNode\r\nLLRBNode.EMPTY = new LLRBEmptyNode();\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * SortedSet is an immutable (copy-on-write) collection that holds elements\r\n * in order specified by the provided comparator.\r\n *\r\n * NOTE: if provided comparator returns 0 for two elements, we consider them to\r\n * be equal!\r\n */\r\nclass SortedSet {\r\n    constructor(comparator) {\r\n        this.comparator = comparator;\r\n        this.data = new SortedMap(this.comparator);\r\n    }\r\n    has(elem) {\r\n        return this.data.get(elem) !== null;\r\n    }\r\n    first() {\r\n        return this.data.minKey();\r\n    }\r\n    last() {\r\n        return this.data.maxKey();\r\n    }\r\n    get size() {\r\n        return this.data.size;\r\n    }\r\n    indexOf(elem) {\r\n        return this.data.indexOf(elem);\r\n    }\r\n    /** Iterates elements in order defined by \"comparator\" */\r\n    forEach(cb) {\r\n        this.data.inorderTraversal((k, v) => {\r\n            cb(k);\r\n            return false;\r\n        });\r\n    }\r\n    /** Iterates over `elem`s such that: range[0] &lt;= elem &lt; range[1]. */\r\n    forEachInRange(range, cb) {\r\n        const iter = this.data.getIteratorFrom(range[0]);\r\n        while (iter.hasNext()) {\r\n            const elem = iter.getNext();\r\n            if (this.comparator(elem.key, range[1]) >= 0) {\r\n                return;\r\n            }\r\n            cb(elem.key);\r\n        }\r\n    }\r\n    /**\r\n     * Iterates over `elem`s such that: start &lt;= elem until false is returned.\r\n     */\r\n    forEachWhile(cb, start) {\r\n        let iter;\r\n        if (start !== undefined) {\r\n            iter = this.data.getIteratorFrom(start);\r\n        }\r\n        else {\r\n            iter = this.data.getIterator();\r\n        }\r\n        while (iter.hasNext()) {\r\n            const elem = iter.getNext();\r\n            const result = cb(elem.key);\r\n            if (!result) {\r\n                return;\r\n            }\r\n        }\r\n    }\r\n    /** Finds the least element greater than or equal to `elem`. */\r\n    firstAfterOrEqual(elem) {\r\n        const iter = this.data.getIteratorFrom(elem);\r\n        return iter.hasNext() ? iter.getNext().key : null;\r\n    }\r\n    getIterator() {\r\n        return new SortedSetIterator(this.data.getIterator());\r\n    }\r\n    getIteratorFrom(key) {\r\n        return new SortedSetIterator(this.data.getIteratorFrom(key));\r\n    }\r\n    /** Inserts or updates an element */\r\n    add(elem) {\r\n        return this.copy(this.data.remove(elem).insert(elem, true));\r\n    }\r\n    /** Deletes an element */\r\n    delete(elem) {\r\n        if (!this.has(elem)) {\r\n            return this;\r\n        }\r\n        return this.copy(this.data.remove(elem));\r\n    }\r\n    isEmpty() {\r\n        return this.data.isEmpty();\r\n    }\r\n    unionWith(other) {\r\n        let result = this;\r\n        // Make sure `result` always refers to the larger one of the two sets.\r\n        if (result.size < other.size) {\r\n            result = other;\r\n            other = this;\r\n        }\r\n        other.forEach(elem => {\r\n            result = result.add(elem);\r\n        });\r\n        return result;\r\n    }\r\n    isEqual(other) {\r\n        if (!(other instanceof SortedSet)) {\r\n            return false;\r\n        }\r\n        if (this.size !== other.size) {\r\n            return false;\r\n        }\r\n        const thisIt = this.data.getIterator();\r\n        const otherIt = other.data.getIterator();\r\n        while (thisIt.hasNext()) {\r\n            const thisElem = thisIt.getNext().key;\r\n            const otherElem = otherIt.getNext().key;\r\n            if (this.comparator(thisElem, otherElem) !== 0) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n    toArray() {\r\n        const res = [];\r\n        this.forEach(targetId => {\r\n            res.push(targetId);\r\n        });\r\n        return res;\r\n    }\r\n    toString() {\r\n        const result = [];\r\n        this.forEach(elem => result.push(elem));\r\n        return 'SortedSet(' + result.toString() + ')';\r\n    }\r\n    copy(data) {\r\n        const result = new SortedSet(this.comparator);\r\n        result.data = data;\r\n        return result;\r\n    }\r\n}\r\nclass SortedSetIterator {\r\n    constructor(iter) {\r\n        this.iter = iter;\r\n    }\r\n    getNext() {\r\n        return this.iter.getNext().key;\r\n    }\r\n    hasNext() {\r\n        return this.iter.hasNext();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst EMPTY_MUTABLE_DOCUMENT_MAP = new SortedMap(DocumentKey.comparator);\r\nfunction mutableDocumentMap() {\r\n    return EMPTY_MUTABLE_DOCUMENT_MAP;\r\n}\r\nconst EMPTY_DOCUMENT_MAP = new SortedMap(DocumentKey.comparator);\r\nfunction documentMap() {\r\n    return EMPTY_DOCUMENT_MAP;\r\n}\r\nconst EMPTY_DOCUMENT_VERSION_MAP = new SortedMap(DocumentKey.comparator);\r\nfunction documentVersionMap() {\r\n    return EMPTY_DOCUMENT_VERSION_MAP;\r\n}\r\nconst EMPTY_DOCUMENT_KEY_SET = new SortedSet(DocumentKey.comparator);\r\nfunction documentKeySet(...keys) {\r\n    let set = EMPTY_DOCUMENT_KEY_SET;\r\n    for (const key of keys) {\r\n        set = set.add(key);\r\n    }\r\n    return set;\r\n}\r\nconst EMPTY_TARGET_ID_SET = new SortedSet(primitiveComparator);\r\nfunction targetIdSet() {\r\n    return EMPTY_TARGET_ID_SET;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Returns an DoubleValue for `value` that is encoded based the serializer's\r\n * `useProto3Json` setting.\r\n */\r\nfunction toDouble(serializer, value) {\r\n    if (serializer.useProto3Json) {\r\n        if (isNaN(value)) {\r\n            return { doubleValue: 'NaN' };\r\n        }\r\n        else if (value === Infinity) {\r\n            return { doubleValue: 'Infinity' };\r\n        }\r\n        else if (value === -Infinity) {\r\n            return { doubleValue: '-Infinity' };\r\n        }\r\n    }\r\n    return { doubleValue: isNegativeZero(value) ? '-0' : value };\r\n}\r\n/**\r\n * Returns an IntegerValue for `value`.\r\n */\r\nfunction toInteger(value) {\r\n    return { integerValue: '' + value };\r\n}\r\n/**\r\n * Returns a value for a number that's appropriate to put into a proto.\r\n * The return value is an IntegerValue if it can safely represent the value,\r\n * otherwise a DoubleValue is returned.\r\n */\r\nfunction toNumber(serializer, value) {\r\n    return isSafeInteger(value) ? toInteger(value) : toDouble(serializer, value);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Used to represent a field transform on a mutation. */\r\nclass TransformOperation {\r\n    constructor() {\r\n        // Make sure that the structural type of `TransformOperation` is unique.\r\n        // See https://github.com/microsoft/TypeScript/issues/5451\r\n        this._ = undefined;\r\n    }\r\n}\r\n/**\r\n * Computes the local transform result against the provided `previousValue`,\r\n * optionally using the provided localWriteTime.\r\n */\r\nfunction applyTransformOperationToLocalView(transform, previousValue, localWriteTime) {\r\n    if (transform instanceof ServerTimestampTransform) {\r\n        return serverTimestamp$1(localWriteTime, previousValue);\r\n    }\r\n    else if (transform instanceof ArrayUnionTransformOperation) {\r\n        return applyArrayUnionTransformOperation(transform, previousValue);\r\n    }\r\n    else if (transform instanceof ArrayRemoveTransformOperation) {\r\n        return applyArrayRemoveTransformOperation(transform, previousValue);\r\n    }\r\n    else {\r\n        return applyNumericIncrementTransformOperationToLocalView(transform, previousValue);\r\n    }\r\n}\r\n/**\r\n * Computes a final transform result after the transform has been acknowledged\r\n * by the server, potentially using the server-provided transformResult.\r\n */\r\nfunction applyTransformOperationToRemoteDocument(transform, previousValue, transformResult) {\r\n    // The server just sends null as the transform result for array operations,\r\n    // so we have to calculate a result the same as we do for local\r\n    // applications.\r\n    if (transform instanceof ArrayUnionTransformOperation) {\r\n        return applyArrayUnionTransformOperation(transform, previousValue);\r\n    }\r\n    else if (transform instanceof ArrayRemoveTransformOperation) {\r\n        return applyArrayRemoveTransformOperation(transform, previousValue);\r\n    }\r\n    return transformResult;\r\n}\r\n/**\r\n * If this transform operation is not idempotent, returns the base value to\r\n * persist for this transform. If a base value is returned, the transform\r\n * operation is always applied to this base value, even if document has\r\n * already been updated.\r\n *\r\n * Base values provide consistent behavior for non-idempotent transforms and\r\n * allow us to return the same latency-compensated value even if the backend\r\n * has already applied the transform operation. The base value is null for\r\n * idempotent transforms, as they can be re-played even if the backend has\r\n * already applied them.\r\n *\r\n * @returns a base value to store along with the mutation, or null for\r\n * idempotent transforms.\r\n */\r\nfunction computeTransformOperationBaseValue(transform, previousValue) {\r\n    if (transform instanceof NumericIncrementTransformOperation) {\r\n        return isNumber(previousValue) ? previousValue : { integerValue: 0 };\r\n    }\r\n    return null;\r\n}\r\nfunction transformOperationEquals(left, right) {\r\n    if (left instanceof ArrayUnionTransformOperation &&\r\n        right instanceof ArrayUnionTransformOperation) {\r\n        return arrayEquals(left.elements, right.elements, valueEquals);\r\n    }\r\n    else if (left instanceof ArrayRemoveTransformOperation &&\r\n        right instanceof ArrayRemoveTransformOperation) {\r\n        return arrayEquals(left.elements, right.elements, valueEquals);\r\n    }\r\n    else if (left instanceof NumericIncrementTransformOperation &&\r\n        right instanceof NumericIncrementTransformOperation) {\r\n        return valueEquals(left.operand, right.operand);\r\n    }\r\n    return (left instanceof ServerTimestampTransform &&\r\n        right instanceof ServerTimestampTransform);\r\n}\r\n/** Transforms a value into a server-generated timestamp. */\r\nclass ServerTimestampTransform extends TransformOperation {\r\n}\r\n/** Transforms an array value via a union operation. */\r\nclass ArrayUnionTransformOperation extends TransformOperation {\r\n    constructor(elements) {\r\n        super();\r\n        this.elements = elements;\r\n    }\r\n}\r\nfunction applyArrayUnionTransformOperation(transform, previousValue) {\r\n    const values = coercedFieldValuesArray(previousValue);\r\n    for (const toUnion of transform.elements) {\r\n        if (!values.some(element => valueEquals(element, toUnion))) {\r\n            values.push(toUnion);\r\n        }\r\n    }\r\n    return { arrayValue: { values } };\r\n}\r\n/** Transforms an array value via a remove operation. */\r\nclass ArrayRemoveTransformOperation extends TransformOperation {\r\n    constructor(elements) {\r\n        super();\r\n        this.elements = elements;\r\n    }\r\n}\r\nfunction applyArrayRemoveTransformOperation(transform, previousValue) {\r\n    let values = coercedFieldValuesArray(previousValue);\r\n    for (const toRemove of transform.elements) {\r\n        values = values.filter(element => !valueEquals(element, toRemove));\r\n    }\r\n    return { arrayValue: { values } };\r\n}\r\n/**\r\n * Implements the backend semantics for locally computed NUMERIC_ADD (increment)\r\n * transforms. Converts all field values to integers or doubles, but unlike the\r\n * backend does not cap integer values at 2^63. Instead, JavaScript number\r\n * arithmetic is used and precision loss can occur for values greater than 2^53.\r\n */\r\nclass NumericIncrementTransformOperation extends TransformOperation {\r\n    constructor(serializer, operand) {\r\n        super();\r\n        this.serializer = serializer;\r\n        this.operand = operand;\r\n    }\r\n}\r\nfunction applyNumericIncrementTransformOperationToLocalView(transform, previousValue) {\r\n    // PORTING NOTE: Since JavaScript's integer arithmetic is limited to 53 bit\r\n    // precision and resolves overflows by reducing precision, we do not\r\n    // manually cap overflows at 2^63.\r\n    const baseValue = computeTransformOperationBaseValue(transform, previousValue);\r\n    const sum = asNumber(baseValue) + asNumber(transform.operand);\r\n    if (isInteger(baseValue) && isInteger(transform.operand)) {\r\n        return toInteger(sum);\r\n    }\r\n    else {\r\n        return toDouble(transform.serializer, sum);\r\n    }\r\n}\r\nfunction asNumber(value) {\r\n    return normalizeNumber(value.integerValue || value.doubleValue);\r\n}\r\nfunction coercedFieldValuesArray(value) {\r\n    return isArray(value) && value.arrayValue.values\r\n        ? value.arrayValue.values.slice()\r\n        : [];\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** A field path and the TransformOperation to perform upon it. */\r\nclass FieldTransform {\r\n    constructor(field, transform) {\r\n        this.field = field;\r\n        this.transform = transform;\r\n    }\r\n}\r\nfunction fieldTransformEquals(left, right) {\r\n    return (left.field.isEqual(right.field) &&\r\n        transformOperationEquals(left.transform, right.transform));\r\n}\r\nfunction fieldTransformsAreEqual(left, right) {\r\n    if (left === undefined && right === undefined) {\r\n        return true;\r\n    }\r\n    if (left && right) {\r\n        return arrayEquals(left, right, (l, r) => fieldTransformEquals(l, r));\r\n    }\r\n    return false;\r\n}\r\n/** The result of successfully applying a mutation to the backend. */\r\nclass MutationResult {\r\n    constructor(\r\n    /**\r\n     * The version at which the mutation was committed:\r\n     *\r\n     * - For most operations, this is the updateTime in the WriteResult.\r\n     * - For deletes, the commitTime of the WriteResponse (because deletes are\r\n     *   not stored and have no updateTime).\r\n     *\r\n     * Note that these versions can be different: No-op writes will not change\r\n     * the updateTime even though the commitTime advances.\r\n     */\r\n    version, \r\n    /**\r\n     * The resulting fields returned from the backend after a mutation\r\n     * containing field transforms has been committed. Contains one FieldValue\r\n     * for each FieldTransform that was in the mutation.\r\n     *\r\n     * Will be empty if the mutation did not contain any field transforms.\r\n     */\r\n    transformResults) {\r\n        this.version = version;\r\n        this.transformResults = transformResults;\r\n    }\r\n}\r\n/**\r\n * Encodes a precondition for a mutation. This follows the model that the\r\n * backend accepts with the special case of an explicit \"empty\" precondition\r\n * (meaning no precondition).\r\n */\r\nclass Precondition {\r\n    constructor(updateTime, exists) {\r\n        this.updateTime = updateTime;\r\n        this.exists = exists;\r\n    }\r\n    /** Creates a new empty Precondition. */\r\n    static none() {\r\n        return new Precondition();\r\n    }\r\n    /** Creates a new Precondition with an exists flag. */\r\n    static exists(exists) {\r\n        return new Precondition(undefined, exists);\r\n    }\r\n    /** Creates a new Precondition based on a version a document exists at. */\r\n    static updateTime(version) {\r\n        return new Precondition(version);\r\n    }\r\n    /** Returns whether this Precondition is empty. */\r\n    get isNone() {\r\n        return this.updateTime === undefined && this.exists === undefined;\r\n    }\r\n    isEqual(other) {\r\n        return (this.exists === other.exists &&\r\n            (this.updateTime\r\n                ? !!other.updateTime && this.updateTime.isEqual(other.updateTime)\r\n                : !other.updateTime));\r\n    }\r\n}\r\n/** Returns true if the preconditions is valid for the given document. */\r\nfunction preconditionIsValidForDocument(precondition, document) {\r\n    if (precondition.updateTime !== undefined) {\r\n        return (document.isFoundDocument() &&\r\n            document.version.isEqual(precondition.updateTime));\r\n    }\r\n    else if (precondition.exists !== undefined) {\r\n        return precondition.exists === document.isFoundDocument();\r\n    }\r\n    else {\r\n        return true;\r\n    }\r\n}\r\n/**\r\n * A mutation describes a self-contained change to a document. Mutations can\r\n * create, replace, delete, and update subsets of documents.\r\n *\r\n * Mutations not only act on the value of the document but also its version.\r\n *\r\n * For local mutations (mutations that haven't been committed yet), we preserve\r\n * the existing version for Set and Patch mutations. For Delete mutations, we\r\n * reset the version to 0.\r\n *\r\n * Here's the expected transition table.\r\n *\r\n * MUTATION           APPLIED TO            RESULTS IN\r\n *\r\n * SetMutation        Document(v3)          Document(v3)\r\n * SetMutation        NoDocument(v3)        Document(v0)\r\n * SetMutation        InvalidDocument(v0)   Document(v0)\r\n * PatchMutation      Document(v3)          Document(v3)\r\n * PatchMutation      NoDocument(v3)        NoDocument(v3)\r\n * PatchMutation      InvalidDocument(v0)   UnknownDocument(v3)\r\n * DeleteMutation     Document(v3)          NoDocument(v0)\r\n * DeleteMutation     NoDocument(v3)        NoDocument(v0)\r\n * DeleteMutation     InvalidDocument(v0)   NoDocument(v0)\r\n *\r\n * For acknowledged mutations, we use the updateTime of the WriteResponse as\r\n * the resulting version for Set and Patch mutations. As deletes have no\r\n * explicit update time, we use the commitTime of the WriteResponse for\r\n * Delete mutations.\r\n *\r\n * If a mutation is acknowledged by the backend but fails the precondition check\r\n * locally, we transition to an `UnknownDocument` and rely on Watch to send us\r\n * the updated version.\r\n *\r\n * Field transforms are used only with Patch and Set Mutations. We use the\r\n * `updateTransforms` message to store transforms, rather than the `transforms`s\r\n * messages.\r\n *\r\n * ## Subclassing Notes\r\n *\r\n * Every type of mutation needs to implement its own applyToRemoteDocument() and\r\n * applyToLocalView() to implement the actual behavior of applying the mutation\r\n * to some source document (see `setMutationApplyToRemoteDocument()` for an\r\n * example).\r\n */\r\nclass Mutation {\r\n}\r\n/**\r\n * Applies this mutation to the given document for the purposes of computing a\r\n * new remote document. If the input document doesn't match the expected state\r\n * (e.g. it is invalid or outdated), the document type may transition to\r\n * unknown.\r\n *\r\n * @param mutation - The mutation to apply.\r\n * @param document - The document to mutate. The input document can be an\r\n *     invalid document if the client has no knowledge of the pre-mutation state\r\n *     of the document.\r\n * @param mutationResult - The result of applying the mutation from the backend.\r\n */\r\nfunction mutationApplyToRemoteDocument(mutation, document, mutationResult) {\r\n    if (mutation instanceof SetMutation) {\r\n        setMutationApplyToRemoteDocument(mutation, document, mutationResult);\r\n    }\r\n    else if (mutation instanceof PatchMutation) {\r\n        patchMutationApplyToRemoteDocument(mutation, document, mutationResult);\r\n    }\r\n    else {\r\n        deleteMutationApplyToRemoteDocument(mutation, document, mutationResult);\r\n    }\r\n}\r\n/**\r\n * Applies this mutation to the given document for the purposes of computing\r\n * the new local view of a document. If the input document doesn't match the\r\n * expected state, the document is not modified.\r\n *\r\n * @param mutation - The mutation to apply.\r\n * @param document - The document to mutate. The input document can be an\r\n *     invalid document if the client has no knowledge of the pre-mutation state\r\n *     of the document.\r\n * @param localWriteTime - A timestamp indicating the local write time of the\r\n *     batch this mutation is a part of.\r\n */\r\nfunction mutationApplyToLocalView(mutation, document, localWriteTime) {\r\n    if (mutation instanceof SetMutation) {\r\n        setMutationApplyToLocalView(mutation, document, localWriteTime);\r\n    }\r\n    else if (mutation instanceof PatchMutation) {\r\n        patchMutationApplyToLocalView(mutation, document, localWriteTime);\r\n    }\r\n    else {\r\n        deleteMutationApplyToLocalView(mutation, document);\r\n    }\r\n}\r\n/**\r\n * If this mutation is not idempotent, returns the base value to persist with\r\n * this mutation. If a base value is returned, the mutation is always applied\r\n * to this base value, even if document has already been updated.\r\n *\r\n * The base value is a sparse object that consists of only the document\r\n * fields for which this mutation contains a non-idempotent transformation\r\n * (e.g. a numeric increment). The provided value guarantees consistent\r\n * behavior for non-idempotent transforms and allow us to return the same\r\n * latency-compensated value even if the backend has already applied the\r\n * mutation. The base value is null for idempotent mutations, as they can be\r\n * re-played even if the backend has already applied them.\r\n *\r\n * @returns a base value to store along with the mutation, or null for\r\n * idempotent mutations.\r\n */\r\nfunction mutationExtractBaseValue(mutation, document) {\r\n    let baseObject = null;\r\n    for (const fieldTransform of mutation.fieldTransforms) {\r\n        const existingValue = document.data.field(fieldTransform.field);\r\n        const coercedValue = computeTransformOperationBaseValue(fieldTransform.transform, existingValue || null);\r\n        if (coercedValue != null) {\r\n            if (baseObject == null) {\r\n                baseObject = ObjectValue.empty();\r\n            }\r\n            baseObject.set(fieldTransform.field, coercedValue);\r\n        }\r\n    }\r\n    return baseObject ? baseObject : null;\r\n}\r\nfunction mutationEquals(left, right) {\r\n    if (left.type !== right.type) {\r\n        return false;\r\n    }\r\n    if (!left.key.isEqual(right.key)) {\r\n        return false;\r\n    }\r\n    if (!left.precondition.isEqual(right.precondition)) {\r\n        return false;\r\n    }\r\n    if (!fieldTransformsAreEqual(left.fieldTransforms, right.fieldTransforms)) {\r\n        return false;\r\n    }\r\n    if (left.type === 0 /* Set */) {\r\n        return left.value.isEqual(right.value);\r\n    }\r\n    if (left.type === 1 /* Patch */) {\r\n        return (left.data.isEqual(right.data) &&\r\n            left.fieldMask.isEqual(right.fieldMask));\r\n    }\r\n    return true;\r\n}\r\n/**\r\n * Returns the version from the given document for use as the result of a\r\n * mutation. Mutations are defined to return the version of the base document\r\n * only if it is an existing document. Deleted and unknown documents have a\r\n * post-mutation version of SnapshotVersion.min().\r\n */\r\nfunction getPostMutationVersion(document) {\r\n    return document.isFoundDocument() ? document.version : SnapshotVersion.min();\r\n}\r\n/**\r\n * A mutation that creates or replaces the document at the given key with the\r\n * object value contents.\r\n */\r\nclass SetMutation extends Mutation {\r\n    constructor(key, value, precondition, fieldTransforms = []) {\r\n        super();\r\n        this.key = key;\r\n        this.value = value;\r\n        this.precondition = precondition;\r\n        this.fieldTransforms = fieldTransforms;\r\n        this.type = 0 /* Set */;\r\n    }\r\n}\r\nfunction setMutationApplyToRemoteDocument(mutation, document, mutationResult) {\r\n    // Unlike setMutationApplyToLocalView, if we're applying a mutation to a\r\n    // remote document the server has accepted the mutation so the precondition\r\n    // must have held.\r\n    const newData = mutation.value.clone();\r\n    const transformResults = serverTransformResults(mutation.fieldTransforms, document, mutationResult.transformResults);\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(mutationResult.version, newData)\r\n        .setHasCommittedMutations();\r\n}\r\nfunction setMutationApplyToLocalView(mutation, document, localWriteTime) {\r\n    if (!preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        // The mutation failed to apply (e.g. a document ID created with add()\r\n        // caused a name collision).\r\n        return;\r\n    }\r\n    const newData = mutation.value.clone();\r\n    const transformResults = localTransformResults(mutation.fieldTransforms, localWriteTime, document);\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(getPostMutationVersion(document), newData)\r\n        .setHasLocalMutations();\r\n}\r\n/**\r\n * A mutation that modifies fields of the document at the given key with the\r\n * given values. The values are applied through a field mask:\r\n *\r\n *  * When a field is in both the mask and the values, the corresponding field\r\n *    is updated.\r\n *  * When a field is in neither the mask nor the values, the corresponding\r\n *    field is unmodified.\r\n *  * When a field is in the mask but not in the values, the corresponding field\r\n *    is deleted.\r\n *  * When a field is not in the mask but is in the values, the values map is\r\n *    ignored.\r\n */\r\nclass PatchMutation extends Mutation {\r\n    constructor(key, data, fieldMask, precondition, fieldTransforms = []) {\r\n        super();\r\n        this.key = key;\r\n        this.data = data;\r\n        this.fieldMask = fieldMask;\r\n        this.precondition = precondition;\r\n        this.fieldTransforms = fieldTransforms;\r\n        this.type = 1 /* Patch */;\r\n    }\r\n}\r\nfunction patchMutationApplyToRemoteDocument(mutation, document, mutationResult) {\r\n    if (!preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        // Since the mutation was not rejected, we know that the precondition\r\n        // matched on the backend. We therefore must not have the expected version\r\n        // of the document in our cache and convert to an UnknownDocument with a\r\n        // known updateTime.\r\n        document.convertToUnknownDocument(mutationResult.version);\r\n        return;\r\n    }\r\n    const transformResults = serverTransformResults(mutation.fieldTransforms, document, mutationResult.transformResults);\r\n    const newData = document.data;\r\n    newData.setAll(getPatch(mutation));\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(mutationResult.version, newData)\r\n        .setHasCommittedMutations();\r\n}\r\nfunction patchMutationApplyToLocalView(mutation, document, localWriteTime) {\r\n    if (!preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        return;\r\n    }\r\n    const transformResults = localTransformResults(mutation.fieldTransforms, localWriteTime, document);\r\n    const newData = document.data;\r\n    newData.setAll(getPatch(mutation));\r\n    newData.setAll(transformResults);\r\n    document\r\n        .convertToFoundDocument(getPostMutationVersion(document), newData)\r\n        .setHasLocalMutations();\r\n}\r\n/**\r\n * Returns a FieldPath/Value map with the content of the PatchMutation.\r\n */\r\nfunction getPatch(mutation) {\r\n    const result = new Map();\r\n    mutation.fieldMask.fields.forEach(fieldPath => {\r\n        if (!fieldPath.isEmpty()) {\r\n            const newValue = mutation.data.field(fieldPath);\r\n            result.set(fieldPath, newValue);\r\n        }\r\n    });\r\n    return result;\r\n}\r\n/**\r\n * Creates a list of \"transform results\" (a transform result is a field value\r\n * representing the result of applying a transform) for use after a mutation\r\n * containing transforms has been acknowledged by the server.\r\n *\r\n * @param fieldTransforms - The field transforms to apply the result to.\r\n * @param mutableDocument - The current state of the document after applying all\r\n * previous mutations.\r\n * @param serverTransformResults - The transform results received by the server.\r\n * @returns The transform results list.\r\n */\r\nfunction serverTransformResults(fieldTransforms, mutableDocument, serverTransformResults) {\r\n    const transformResults = new Map();\r\n    hardAssert(fieldTransforms.length === serverTransformResults.length);\r\n    for (let i = 0; i < serverTransformResults.length; i++) {\r\n        const fieldTransform = fieldTransforms[i];\r\n        const transform = fieldTransform.transform;\r\n        const previousValue = mutableDocument.data.field(fieldTransform.field);\r\n        transformResults.set(fieldTransform.field, applyTransformOperationToRemoteDocument(transform, previousValue, serverTransformResults[i]));\r\n    }\r\n    return transformResults;\r\n}\r\n/**\r\n * Creates a list of \"transform results\" (a transform result is a field value\r\n * representing the result of applying a transform) for use when applying a\r\n * transform locally.\r\n *\r\n * @param fieldTransforms - The field transforms to apply the result to.\r\n * @param localWriteTime - The local time of the mutation (used to\r\n *     generate ServerTimestampValues).\r\n * @param mutableDocument - The current state of the document after applying all\r\n *     previous mutations.\r\n * @returns The transform results list.\r\n */\r\nfunction localTransformResults(fieldTransforms, localWriteTime, mutableDocument) {\r\n    const transformResults = new Map();\r\n    for (const fieldTransform of fieldTransforms) {\r\n        const transform = fieldTransform.transform;\r\n        const previousValue = mutableDocument.data.field(fieldTransform.field);\r\n        transformResults.set(fieldTransform.field, applyTransformOperationToLocalView(transform, previousValue, localWriteTime));\r\n    }\r\n    return transformResults;\r\n}\r\n/** A mutation that deletes the document at the given key. */\r\nclass DeleteMutation extends Mutation {\r\n    constructor(key, precondition) {\r\n        super();\r\n        this.key = key;\r\n        this.precondition = precondition;\r\n        this.type = 2 /* Delete */;\r\n        this.fieldTransforms = [];\r\n    }\r\n}\r\nfunction deleteMutationApplyToRemoteDocument(mutation, document, mutationResult) {\r\n    // Unlike applyToLocalView, if we're applying a mutation to a remote\r\n    // document the server has accepted the mutation so the precondition must\r\n    // have held.\r\n    document\r\n        .convertToNoDocument(mutationResult.version)\r\n        .setHasCommittedMutations();\r\n}\r\nfunction deleteMutationApplyToLocalView(mutation, document) {\r\n    if (preconditionIsValidForDocument(mutation.precondition, document)) {\r\n        // We don't call `setHasLocalMutations()` since we want to be backwards\r\n        // compatible with the existing SDK behavior.\r\n        document.convertToNoDocument(SnapshotVersion.min());\r\n    }\r\n}\r\n/**\r\n * A mutation that verifies the existence of the document at the given key with\r\n * the provided precondition.\r\n *\r\n * The `verify` operation is only used in Transactions, and this class serves\r\n * primarily to facilitate serialization into protos.\r\n */\r\nclass VerifyMutation extends Mutation {\r\n    constructor(key, precondition) {\r\n        super();\r\n        this.key = key;\r\n        this.precondition = precondition;\r\n        this.type = 3 /* Verify */;\r\n        this.fieldTransforms = [];\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A batch of mutations that will be sent as one unit to the backend.\r\n */\r\nclass MutationBatch {\r\n    /**\r\n     * @param batchId - The unique ID of this mutation batch.\r\n     * @param localWriteTime - The original write time of this mutation.\r\n     * @param baseMutations - Mutations that are used to populate the base\r\n     * values when this mutation is applied locally. This can be used to locally\r\n     * overwrite values that are persisted in the remote document cache. Base\r\n     * mutations are never sent to the backend.\r\n     * @param mutations - The user-provided mutations in this mutation batch.\r\n     * User-provided mutations are applied both locally and remotely on the\r\n     * backend.\r\n     */\r\n    constructor(batchId, localWriteTime, baseMutations, mutations) {\r\n        this.batchId = batchId;\r\n        this.localWriteTime = localWriteTime;\r\n        this.baseMutations = baseMutations;\r\n        this.mutations = mutations;\r\n    }\r\n    /**\r\n     * Applies all the mutations in this MutationBatch to the specified document\r\n     * to compute the state of the remote document\r\n     *\r\n     * @param document - The document to apply mutations to.\r\n     * @param batchResult - The result of applying the MutationBatch to the\r\n     * backend.\r\n     */\r\n    applyToRemoteDocument(document, batchResult) {\r\n        const mutationResults = batchResult.mutationResults;\r\n        for (let i = 0; i < this.mutations.length; i++) {\r\n            const mutation = this.mutations[i];\r\n            if (mutation.key.isEqual(document.key)) {\r\n                const mutationResult = mutationResults[i];\r\n                mutationApplyToRemoteDocument(mutation, document, mutationResult);\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Computes the local view of a document given all the mutations in this\r\n     * batch.\r\n     *\r\n     * @param document - The document to apply mutations to.\r\n     */\r\n    applyToLocalView(document) {\r\n        // First, apply the base state. This allows us to apply non-idempotent\r\n        // transform against a consistent set of values.\r\n        for (const mutation of this.baseMutations) {\r\n            if (mutation.key.isEqual(document.key)) {\r\n                mutationApplyToLocalView(mutation, document, this.localWriteTime);\r\n            }\r\n        }\r\n        // Second, apply all user-provided mutations.\r\n        for (const mutation of this.mutations) {\r\n            if (mutation.key.isEqual(document.key)) {\r\n                mutationApplyToLocalView(mutation, document, this.localWriteTime);\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Computes the local view for all provided documents given the mutations in\r\n     * this batch.\r\n     */\r\n    applyToLocalDocumentSet(documentMap) {\r\n        // TODO(mrschmidt): This implementation is O(n^2). If we apply the mutations\r\n        // directly (as done in `applyToLocalView()`), we can reduce the complexity\r\n        // to O(n).\r\n        this.mutations.forEach(m => {\r\n            const document = documentMap.get(m.key);\r\n            // TODO(mutabledocuments): This method should take a MutableDocumentMap\r\n            // and we should remove this cast.\r\n            const mutableDocument = document;\r\n            this.applyToLocalView(mutableDocument);\r\n            if (!document.isValidDocument()) {\r\n                mutableDocument.convertToNoDocument(SnapshotVersion.min());\r\n            }\r\n        });\r\n    }\r\n    keys() {\r\n        return this.mutations.reduce((keys, m) => keys.add(m.key), documentKeySet());\r\n    }\r\n    isEqual(other) {\r\n        return (this.batchId === other.batchId &&\r\n            arrayEquals(this.mutations, other.mutations, (l, r) => mutationEquals(l, r)) &&\r\n            arrayEquals(this.baseMutations, other.baseMutations, (l, r) => mutationEquals(l, r)));\r\n    }\r\n}\r\n/** The result of applying a mutation batch to the backend. */\r\nclass MutationBatchResult {\r\n    constructor(batch, commitVersion, mutationResults, \r\n    /**\r\n     * A pre-computed mapping from each mutated document to the resulting\r\n     * version.\r\n     */\r\n    docVersions) {\r\n        this.batch = batch;\r\n        this.commitVersion = commitVersion;\r\n        this.mutationResults = mutationResults;\r\n        this.docVersions = docVersions;\r\n    }\r\n    /**\r\n     * Creates a new MutationBatchResult for the given batch and results. There\r\n     * must be one result for each mutation in the batch. This static factory\r\n     * caches a document=&gt;version mapping (docVersions).\r\n     */\r\n    static from(batch, commitVersion, results) {\r\n        hardAssert(batch.mutations.length === results.length);\r\n        let versionMap = documentVersionMap();\r\n        const mutations = batch.mutations;\r\n        for (let i = 0; i < mutations.length; i++) {\r\n            versionMap = versionMap.insert(mutations[i].key, results[i].version);\r\n        }\r\n        return new MutationBatchResult(batch, commitVersion, results, versionMap);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass ExistenceFilter {\r\n    // TODO(b/33078163): just use simplest form of existence filter for now\r\n    constructor(count) {\r\n        this.count = count;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Error Codes describing the different ways GRPC can fail. These are copied\r\n * directly from GRPC's sources here:\r\n *\r\n * https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\r\n *\r\n * Important! The names of these identifiers matter because the string forms\r\n * are used for reverse lookups from the webchannel stream. Do NOT change the\r\n * names of these identifiers or change this into a const enum.\r\n */\r\nvar RpcCode;\r\n(function (RpcCode) {\r\n    RpcCode[RpcCode[\"OK\"] = 0] = \"OK\";\r\n    RpcCode[RpcCode[\"CANCELLED\"] = 1] = \"CANCELLED\";\r\n    RpcCode[RpcCode[\"UNKNOWN\"] = 2] = \"UNKNOWN\";\r\n    RpcCode[RpcCode[\"INVALID_ARGUMENT\"] = 3] = \"INVALID_ARGUMENT\";\r\n    RpcCode[RpcCode[\"DEADLINE_EXCEEDED\"] = 4] = \"DEADLINE_EXCEEDED\";\r\n    RpcCode[RpcCode[\"NOT_FOUND\"] = 5] = \"NOT_FOUND\";\r\n    RpcCode[RpcCode[\"ALREADY_EXISTS\"] = 6] = \"ALREADY_EXISTS\";\r\n    RpcCode[RpcCode[\"PERMISSION_DENIED\"] = 7] = \"PERMISSION_DENIED\";\r\n    RpcCode[RpcCode[\"UNAUTHENTICATED\"] = 16] = \"UNAUTHENTICATED\";\r\n    RpcCode[RpcCode[\"RESOURCE_EXHAUSTED\"] = 8] = \"RESOURCE_EXHAUSTED\";\r\n    RpcCode[RpcCode[\"FAILED_PRECONDITION\"] = 9] = \"FAILED_PRECONDITION\";\r\n    RpcCode[RpcCode[\"ABORTED\"] = 10] = \"ABORTED\";\r\n    RpcCode[RpcCode[\"OUT_OF_RANGE\"] = 11] = \"OUT_OF_RANGE\";\r\n    RpcCode[RpcCode[\"UNIMPLEMENTED\"] = 12] = \"UNIMPLEMENTED\";\r\n    RpcCode[RpcCode[\"INTERNAL\"] = 13] = \"INTERNAL\";\r\n    RpcCode[RpcCode[\"UNAVAILABLE\"] = 14] = \"UNAVAILABLE\";\r\n    RpcCode[RpcCode[\"DATA_LOSS\"] = 15] = \"DATA_LOSS\";\r\n})(RpcCode || (RpcCode = {}));\r\n/**\r\n * Determines whether an error code represents a permanent error when received\r\n * in response to a non-write operation.\r\n *\r\n * See isPermanentWriteError for classifying write errors.\r\n */\r\nfunction isPermanentError(code) {\r\n    switch (code) {\r\n        case Code.OK:\r\n            return fail();\r\n        case Code.CANCELLED:\r\n        case Code.UNKNOWN:\r\n        case Code.DEADLINE_EXCEEDED:\r\n        case Code.RESOURCE_EXHAUSTED:\r\n        case Code.INTERNAL:\r\n        case Code.UNAVAILABLE:\r\n        // Unauthenticated means something went wrong with our token and we need\r\n        // to retry with new credentials which will happen automatically.\r\n        case Code.UNAUTHENTICATED:\r\n            return false;\r\n        case Code.INVALID_ARGUMENT:\r\n        case Code.NOT_FOUND:\r\n        case Code.ALREADY_EXISTS:\r\n        case Code.PERMISSION_DENIED:\r\n        case Code.FAILED_PRECONDITION:\r\n        // Aborted might be retried in some scenarios, but that is dependant on\r\n        // the context and should handled individually by the calling code.\r\n        // See https://cloud.google.com/apis/design/errors.\r\n        case Code.ABORTED:\r\n        case Code.OUT_OF_RANGE:\r\n        case Code.UNIMPLEMENTED:\r\n        case Code.DATA_LOSS:\r\n            return true;\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\n/**\r\n * Determines whether an error code represents a permanent error when received\r\n * in response to a write operation.\r\n *\r\n * Write operations must be handled specially because as of b/119437764, ABORTED\r\n * errors on the write stream should be retried too (even though ABORTED errors\r\n * are not generally retryable).\r\n *\r\n * Note that during the initial handshake on the write stream an ABORTED error\r\n * signals that we should discard our stream token (i.e. it is permanent). This\r\n * means a handshake error should be classified with isPermanentError, above.\r\n */\r\nfunction isPermanentWriteError(code) {\r\n    return isPermanentError(code) && code !== Code.ABORTED;\r\n}\r\n/**\r\n * Maps an error Code from GRPC status code number, like 0, 1, or 14. These\r\n * are not the same as HTTP status codes.\r\n *\r\n * @returns The Code equivalent to the given GRPC status code. Fails if there\r\n *     is no match.\r\n */\r\nfunction mapCodeFromRpcCode(code) {\r\n    if (code === undefined) {\r\n        // This shouldn't normally happen, but in certain error cases (like trying\r\n        // to send invalid proto messages) we may get an error with no GRPC code.\r\n        logError('GRPC error has no .code');\r\n        return Code.UNKNOWN;\r\n    }\r\n    switch (code) {\r\n        case RpcCode.OK:\r\n            return Code.OK;\r\n        case RpcCode.CANCELLED:\r\n            return Code.CANCELLED;\r\n        case RpcCode.UNKNOWN:\r\n            return Code.UNKNOWN;\r\n        case RpcCode.DEADLINE_EXCEEDED:\r\n            return Code.DEADLINE_EXCEEDED;\r\n        case RpcCode.RESOURCE_EXHAUSTED:\r\n            return Code.RESOURCE_EXHAUSTED;\r\n        case RpcCode.INTERNAL:\r\n            return Code.INTERNAL;\r\n        case RpcCode.UNAVAILABLE:\r\n            return Code.UNAVAILABLE;\r\n        case RpcCode.UNAUTHENTICATED:\r\n            return Code.UNAUTHENTICATED;\r\n        case RpcCode.INVALID_ARGUMENT:\r\n            return Code.INVALID_ARGUMENT;\r\n        case RpcCode.NOT_FOUND:\r\n            return Code.NOT_FOUND;\r\n        case RpcCode.ALREADY_EXISTS:\r\n            return Code.ALREADY_EXISTS;\r\n        case RpcCode.PERMISSION_DENIED:\r\n            return Code.PERMISSION_DENIED;\r\n        case RpcCode.FAILED_PRECONDITION:\r\n            return Code.FAILED_PRECONDITION;\r\n        case RpcCode.ABORTED:\r\n            return Code.ABORTED;\r\n        case RpcCode.OUT_OF_RANGE:\r\n            return Code.OUT_OF_RANGE;\r\n        case RpcCode.UNIMPLEMENTED:\r\n            return Code.UNIMPLEMENTED;\r\n        case RpcCode.DATA_LOSS:\r\n            return Code.DATA_LOSS;\r\n        default:\r\n            return fail();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An event from the RemoteStore. It is split into targetChanges (changes to the\r\n * state or the set of documents in our watched targets) and documentUpdates\r\n * (changes to the actual documents).\r\n */\r\nclass RemoteEvent {\r\n    constructor(\r\n    /**\r\n     * The snapshot version this event brings us up to, or MIN if not set.\r\n     */\r\n    snapshotVersion, \r\n    /**\r\n     * A map from target to changes to the target. See TargetChange.\r\n     */\r\n    targetChanges, \r\n    /**\r\n     * A set of targets that is known to be inconsistent. Listens for these\r\n     * targets should be re-established without resume tokens.\r\n     */\r\n    targetMismatches, \r\n    /**\r\n     * A set of which documents have changed or been deleted, along with the\r\n     * doc's new values (if not deleted).\r\n     */\r\n    documentUpdates, \r\n    /**\r\n     * A set of which document updates are due only to limbo resolution targets.\r\n     */\r\n    resolvedLimboDocuments) {\r\n        this.snapshotVersion = snapshotVersion;\r\n        this.targetChanges = targetChanges;\r\n        this.targetMismatches = targetMismatches;\r\n        this.documentUpdates = documentUpdates;\r\n        this.resolvedLimboDocuments = resolvedLimboDocuments;\r\n    }\r\n    /**\r\n     * HACK: Views require RemoteEvents in order to determine whether the view is\r\n     * CURRENT, but secondary tabs don't receive remote events. So this method is\r\n     * used to create a synthesized RemoteEvent that can be used to apply a\r\n     * CURRENT status change to a View, for queries executed in a different tab.\r\n     */\r\n    // PORTING NOTE: Multi-tab only\r\n    static createSynthesizedRemoteEventForCurrentChange(targetId, current) {\r\n        const targetChanges = new Map();\r\n        targetChanges.set(targetId, TargetChange.createSynthesizedTargetChangeForCurrentChange(targetId, current));\r\n        return new RemoteEvent(SnapshotVersion.min(), targetChanges, targetIdSet(), mutableDocumentMap(), documentKeySet());\r\n    }\r\n}\r\n/**\r\n * A TargetChange specifies the set of changes for a specific target as part of\r\n * a RemoteEvent. These changes track which documents are added, modified or\r\n * removed, as well as the target's resume token and whether the target is\r\n * marked CURRENT.\r\n * The actual changes *to* documents are not part of the TargetChange since\r\n * documents may be part of multiple targets.\r\n */\r\nclass TargetChange {\r\n    constructor(\r\n    /**\r\n     * An opaque, server-assigned token that allows watching a query to be resumed\r\n     * after disconnecting without retransmitting all the data that matches the\r\n     * query. The resume token essentially identifies a point in time from which\r\n     * the server should resume sending results.\r\n     */\r\n    resumeToken, \r\n    /**\r\n     * The \"current\" (synced) status of this target. Note that \"current\"\r\n     * has special meaning in the RPC protocol that implies that a target is\r\n     * both up-to-date and consistent with the rest of the watch stream.\r\n     */\r\n    current, \r\n    /**\r\n     * The set of documents that were newly assigned to this target as part of\r\n     * this remote event.\r\n     */\r\n    addedDocuments, \r\n    /**\r\n     * The set of documents that were already assigned to this target but received\r\n     * an update during this remote event.\r\n     */\r\n    modifiedDocuments, \r\n    /**\r\n     * The set of documents that were removed from this target as part of this\r\n     * remote event.\r\n     */\r\n    removedDocuments) {\r\n        this.resumeToken = resumeToken;\r\n        this.current = current;\r\n        this.addedDocuments = addedDocuments;\r\n        this.modifiedDocuments = modifiedDocuments;\r\n        this.removedDocuments = removedDocuments;\r\n    }\r\n    /**\r\n     * This method is used to create a synthesized TargetChanges that can be used to\r\n     * apply a CURRENT status change to a View (for queries executed in a different\r\n     * tab) or for new queries (to raise snapshots with correct CURRENT status).\r\n     */\r\n    static createSynthesizedTargetChangeForCurrentChange(targetId, current) {\r\n        return new TargetChange(ByteString.EMPTY_BYTE_STRING, current, documentKeySet(), documentKeySet(), documentKeySet());\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Represents a changed document and a list of target ids to which this change\r\n * applies.\r\n *\r\n * If document has been deleted NoDocument will be provided.\r\n */\r\nclass DocumentWatchChange {\r\n    constructor(\r\n    /** The new document applies to all of these targets. */\r\n    updatedTargetIds, \r\n    /** The new document is removed from all of these targets. */\r\n    removedTargetIds, \r\n    /** The key of the document for this change. */\r\n    key, \r\n    /**\r\n     * The new document or NoDocument if it was deleted. Is null if the\r\n     * document went out of view without the server sending a new document.\r\n     */\r\n    newDoc) {\r\n        this.updatedTargetIds = updatedTargetIds;\r\n        this.removedTargetIds = removedTargetIds;\r\n        this.key = key;\r\n        this.newDoc = newDoc;\r\n    }\r\n}\r\nclass ExistenceFilterChange {\r\n    constructor(targetId, existenceFilter) {\r\n        this.targetId = targetId;\r\n        this.existenceFilter = existenceFilter;\r\n    }\r\n}\r\nclass WatchTargetChange {\r\n    constructor(\r\n    /** What kind of change occurred to the watch target. */\r\n    state, \r\n    /** The target IDs that were added/removed/set. */\r\n    targetIds, \r\n    /**\r\n     * An opaque, server-assigned token that allows watching a target to be\r\n     * resumed after disconnecting without retransmitting all the data that\r\n     * matches the target. The resume token essentially identifies a point in\r\n     * time from which the server should resume sending results.\r\n     */\r\n    resumeToken = ByteString.EMPTY_BYTE_STRING, \r\n    /** An RPC error indicating why the watch failed. */\r\n    cause = null) {\r\n        this.state = state;\r\n        this.targetIds = targetIds;\r\n        this.resumeToken = resumeToken;\r\n        this.cause = cause;\r\n    }\r\n}\r\n/** Tracks the internal state of a Watch target. */\r\nclass TargetState {\r\n    constructor() {\r\n        /**\r\n         * The number of pending responses (adds or removes) that we are waiting on.\r\n         * We only consider targets active that have no pending responses.\r\n         */\r\n        this.pendingResponses = 0;\r\n        /**\r\n         * Keeps track of the document changes since the last raised snapshot.\r\n         *\r\n         * These changes are continuously updated as we receive document updates and\r\n         * always reflect the current set of changes against the last issued snapshot.\r\n         */\r\n        this.documentChanges = snapshotChangesMap();\r\n        /** See public getters for explanations of these fields. */\r\n        this._resumeToken = ByteString.EMPTY_BYTE_STRING;\r\n        this._current = false;\r\n        /**\r\n         * Whether this target state should be included in the next snapshot. We\r\n         * initialize to true so that newly-added targets are included in the next\r\n         * RemoteEvent.\r\n         */\r\n        this._hasPendingChanges = true;\r\n    }\r\n    /**\r\n     * Whether this target has been marked 'current'.\r\n     *\r\n     * 'Current' has special meaning in the RPC protocol: It implies that the\r\n     * Watch backend has sent us all changes up to the point at which the target\r\n     * was added and that the target is consistent with the rest of the watch\r\n     * stream.\r\n     */\r\n    get current() {\r\n        return this._current;\r\n    }\r\n    /** The last resume token sent to us for this target. */\r\n    get resumeToken() {\r\n        return this._resumeToken;\r\n    }\r\n    /** Whether this target has pending target adds or target removes. */\r\n    get isPending() {\r\n        return this.pendingResponses !== 0;\r\n    }\r\n    /** Whether we have modified any state that should trigger a snapshot. */\r\n    get hasPendingChanges() {\r\n        return this._hasPendingChanges;\r\n    }\r\n    /**\r\n     * Applies the resume token to the TargetChange, but only when it has a new\r\n     * value. Empty resumeTokens are discarded.\r\n     */\r\n    updateResumeToken(resumeToken) {\r\n        if (resumeToken.approximateByteSize() > 0) {\r\n            this._hasPendingChanges = true;\r\n            this._resumeToken = resumeToken;\r\n        }\r\n    }\r\n    /**\r\n     * Creates a target change from the current set of changes.\r\n     *\r\n     * To reset the document changes after raising this snapshot, call\r\n     * `clearPendingChanges()`.\r\n     */\r\n    toTargetChange() {\r\n        let addedDocuments = documentKeySet();\r\n        let modifiedDocuments = documentKeySet();\r\n        let removedDocuments = documentKeySet();\r\n        this.documentChanges.forEach((key, changeType) => {\r\n            switch (changeType) {\r\n                case 0 /* Added */:\r\n                    addedDocuments = addedDocuments.add(key);\r\n                    break;\r\n                case 2 /* Modified */:\r\n                    modifiedDocuments = modifiedDocuments.add(key);\r\n                    break;\r\n                case 1 /* Removed */:\r\n                    removedDocuments = removedDocuments.add(key);\r\n                    break;\r\n                default:\r\n                    fail();\r\n            }\r\n        });\r\n        return new TargetChange(this._resumeToken, this._current, addedDocuments, modifiedDocuments, removedDocuments);\r\n    }\r\n    /**\r\n     * Resets the document changes and sets `hasPendingChanges` to false.\r\n     */\r\n    clearPendingChanges() {\r\n        this._hasPendingChanges = false;\r\n        this.documentChanges = snapshotChangesMap();\r\n    }\r\n    addDocumentChange(key, changeType) {\r\n        this._hasPendingChanges = true;\r\n        this.documentChanges = this.documentChanges.insert(key, changeType);\r\n    }\r\n    removeDocumentChange(key) {\r\n        this._hasPendingChanges = true;\r\n        this.documentChanges = this.documentChanges.remove(key);\r\n    }\r\n    recordPendingTargetRequest() {\r\n        this.pendingResponses += 1;\r\n    }\r\n    recordTargetResponse() {\r\n        this.pendingResponses -= 1;\r\n    }\r\n    markCurrent() {\r\n        this._hasPendingChanges = true;\r\n        this._current = true;\r\n    }\r\n}\r\nconst LOG_TAG$f = 'WatchChangeAggregator';\r\n/**\r\n * A helper class to accumulate watch changes into a RemoteEvent.\r\n */\r\nclass WatchChangeAggregator {\r\n    constructor(metadataProvider) {\r\n        this.metadataProvider = metadataProvider;\r\n        /** The internal state of all tracked targets. */\r\n        this.targetStates = new Map();\r\n        /** Keeps track of the documents to update since the last raised snapshot. */\r\n        this.pendingDocumentUpdates = mutableDocumentMap();\r\n        /** A mapping of document keys to their set of target IDs. */\r\n        this.pendingDocumentTargetMapping = documentTargetMap();\r\n        /**\r\n         * A list of targets with existence filter mismatches. These targets are\r\n         * known to be inconsistent and their listens needs to be re-established by\r\n         * RemoteStore.\r\n         */\r\n        this.pendingTargetResets = new SortedSet(primitiveComparator);\r\n    }\r\n    /**\r\n     * Processes and adds the DocumentWatchChange to the current set of changes.\r\n     */\r\n    handleDocumentChange(docChange) {\r\n        for (const targetId of docChange.updatedTargetIds) {\r\n            if (docChange.newDoc && docChange.newDoc.isFoundDocument()) {\r\n                this.addDocumentToTarget(targetId, docChange.newDoc);\r\n            }\r\n            else {\r\n                this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\r\n            }\r\n        }\r\n        for (const targetId of docChange.removedTargetIds) {\r\n            this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\r\n        }\r\n    }\r\n    /** Processes and adds the WatchTargetChange to the current set of changes. */\r\n    handleTargetChange(targetChange) {\r\n        this.forEachTarget(targetChange, targetId => {\r\n            const targetState = this.ensureTargetState(targetId);\r\n            switch (targetChange.state) {\r\n                case 0 /* NoChange */:\r\n                    if (this.isActiveTarget(targetId)) {\r\n                        targetState.updateResumeToken(targetChange.resumeToken);\r\n                    }\r\n                    break;\r\n                case 1 /* Added */:\r\n                    // We need to decrement the number of pending acks needed from watch\r\n                    // for this targetId.\r\n                    targetState.recordTargetResponse();\r\n                    if (!targetState.isPending) {\r\n                        // We have a freshly added target, so we need to reset any state\r\n                        // that we had previously. This can happen e.g. when remove and add\r\n                        // back a target for existence filter mismatches.\r\n                        targetState.clearPendingChanges();\r\n                    }\r\n                    targetState.updateResumeToken(targetChange.resumeToken);\r\n                    break;\r\n                case 2 /* Removed */:\r\n                    // We need to keep track of removed targets to we can post-filter and\r\n                    // remove any target changes.\r\n                    // We need to decrement the number of pending acks needed from watch\r\n                    // for this targetId.\r\n                    targetState.recordTargetResponse();\r\n                    if (!targetState.isPending) {\r\n                        this.removeTarget(targetId);\r\n                    }\r\n                    break;\r\n                case 3 /* Current */:\r\n                    if (this.isActiveTarget(targetId)) {\r\n                        targetState.markCurrent();\r\n                        targetState.updateResumeToken(targetChange.resumeToken);\r\n                    }\r\n                    break;\r\n                case 4 /* Reset */:\r\n                    if (this.isActiveTarget(targetId)) {\r\n                        // Reset the target and synthesizes removes for all existing\r\n                        // documents. The backend will re-add any documents that still\r\n                        // match the target before it sends the next global snapshot.\r\n                        this.resetTarget(targetId);\r\n                        targetState.updateResumeToken(targetChange.resumeToken);\r\n                    }\r\n                    break;\r\n                default:\r\n                    fail();\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Iterates over all targetIds that the watch change applies to: either the\r\n     * targetIds explicitly listed in the change or the targetIds of all currently\r\n     * active targets.\r\n     */\r\n    forEachTarget(targetChange, fn) {\r\n        if (targetChange.targetIds.length > 0) {\r\n            targetChange.targetIds.forEach(fn);\r\n        }\r\n        else {\r\n            this.targetStates.forEach((_, targetId) => {\r\n                if (this.isActiveTarget(targetId)) {\r\n                    fn(targetId);\r\n                }\r\n            });\r\n        }\r\n    }\r\n    /**\r\n     * Handles existence filters and synthesizes deletes for filter mismatches.\r\n     * Targets that are invalidated by filter mismatches are added to\r\n     * `pendingTargetResets`.\r\n     */\r\n    handleExistenceFilter(watchChange) {\r\n        const targetId = watchChange.targetId;\r\n        const expectedCount = watchChange.existenceFilter.count;\r\n        const targetData = this.targetDataForActiveTarget(targetId);\r\n        if (targetData) {\r\n            const target = targetData.target;\r\n            if (isDocumentTarget(target)) {\r\n                if (expectedCount === 0) {\r\n                    // The existence filter told us the document does not exist. We deduce\r\n                    // that this document does not exist and apply a deleted document to\r\n                    // our updates. Without applying this deleted document there might be\r\n                    // another query that will raise this document as part of a snapshot\r\n                    // until it is resolved, essentially exposing inconsistency between\r\n                    // queries.\r\n                    const key = new DocumentKey(target.path);\r\n                    this.removeDocumentFromTarget(targetId, key, MutableDocument.newNoDocument(key, SnapshotVersion.min()));\r\n                }\r\n                else {\r\n                    hardAssert(expectedCount === 1);\r\n                }\r\n            }\r\n            else {\r\n                const currentSize = this.getCurrentDocumentCountForTarget(targetId);\r\n                if (currentSize !== expectedCount) {\r\n                    // Existence filter mismatch: We reset the mapping and raise a new\r\n                    // snapshot with `isFromCache:true`.\r\n                    this.resetTarget(targetId);\r\n                    this.pendingTargetResets = this.pendingTargetResets.add(targetId);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Converts the currently accumulated state into a remote event at the\r\n     * provided snapshot version. Resets the accumulated changes before returning.\r\n     */\r\n    createRemoteEvent(snapshotVersion) {\r\n        const targetChanges = new Map();\r\n        this.targetStates.forEach((targetState, targetId) => {\r\n            const targetData = this.targetDataForActiveTarget(targetId);\r\n            if (targetData) {\r\n                if (targetState.current && isDocumentTarget(targetData.target)) {\r\n                    // Document queries for document that don't exist can produce an empty\r\n                    // result set. To update our local cache, we synthesize a document\r\n                    // delete if we have not previously received the document. This\r\n                    // resolves the limbo state of the document, removing it from\r\n                    // limboDocumentRefs.\r\n                    //\r\n                    // TODO(dimond): Ideally we would have an explicit lookup target\r\n                    // instead resulting in an explicit delete message and we could\r\n                    // remove this special logic.\r\n                    const key = new DocumentKey(targetData.target.path);\r\n                    if (this.pendingDocumentUpdates.get(key) === null &&\r\n                        !this.targetContainsDocument(targetId, key)) {\r\n                        this.removeDocumentFromTarget(targetId, key, MutableDocument.newNoDocument(key, snapshotVersion));\r\n                    }\r\n                }\r\n                if (targetState.hasPendingChanges) {\r\n                    targetChanges.set(targetId, targetState.toTargetChange());\r\n                    targetState.clearPendingChanges();\r\n                }\r\n            }\r\n        });\r\n        let resolvedLimboDocuments = documentKeySet();\r\n        // We extract the set of limbo-only document updates as the GC logic\r\n        // special-cases documents that do not appear in the target cache.\r\n        //\r\n        // TODO(gsoltis): Expand on this comment once GC is available in the JS\r\n        // client.\r\n        this.pendingDocumentTargetMapping.forEach((key, targets) => {\r\n            let isOnlyLimboTarget = true;\r\n            targets.forEachWhile(targetId => {\r\n                const targetData = this.targetDataForActiveTarget(targetId);\r\n                if (targetData &&\r\n                    targetData.purpose !== 2 /* LimboResolution */) {\r\n                    isOnlyLimboTarget = false;\r\n                    return false;\r\n                }\r\n                return true;\r\n            });\r\n            if (isOnlyLimboTarget) {\r\n                resolvedLimboDocuments = resolvedLimboDocuments.add(key);\r\n            }\r\n        });\r\n        const remoteEvent = new RemoteEvent(snapshotVersion, targetChanges, this.pendingTargetResets, this.pendingDocumentUpdates, resolvedLimboDocuments);\r\n        this.pendingDocumentUpdates = mutableDocumentMap();\r\n        this.pendingDocumentTargetMapping = documentTargetMap();\r\n        this.pendingTargetResets = new SortedSet(primitiveComparator);\r\n        return remoteEvent;\r\n    }\r\n    /**\r\n     * Adds the provided document to the internal list of document updates and\r\n     * its document key to the given target's mapping.\r\n     */\r\n    // Visible for testing.\r\n    addDocumentToTarget(targetId, document) {\r\n        if (!this.isActiveTarget(targetId)) {\r\n            return;\r\n        }\r\n        const changeType = this.targetContainsDocument(targetId, document.key)\r\n            ? 2 /* Modified */\r\n            : 0 /* Added */;\r\n        const targetState = this.ensureTargetState(targetId);\r\n        targetState.addDocumentChange(document.key, changeType);\r\n        this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(document.key, document);\r\n        this.pendingDocumentTargetMapping =\r\n            this.pendingDocumentTargetMapping.insert(document.key, this.ensureDocumentTargetMapping(document.key).add(targetId));\r\n    }\r\n    /**\r\n     * Removes the provided document from the target mapping. If the\r\n     * document no longer matches the target, but the document's state is still\r\n     * known (e.g. we know that the document was deleted or we received the change\r\n     * that caused the filter mismatch), the new document can be provided\r\n     * to update the remote document cache.\r\n     */\r\n    // Visible for testing.\r\n    removeDocumentFromTarget(targetId, key, updatedDocument) {\r\n        if (!this.isActiveTarget(targetId)) {\r\n            return;\r\n        }\r\n        const targetState = this.ensureTargetState(targetId);\r\n        if (this.targetContainsDocument(targetId, key)) {\r\n            targetState.addDocumentChange(key, 1 /* Removed */);\r\n        }\r\n        else {\r\n            // The document may have entered and left the target before we raised a\r\n            // snapshot, so we can just ignore the change.\r\n            targetState.removeDocumentChange(key);\r\n        }\r\n        this.pendingDocumentTargetMapping =\r\n            this.pendingDocumentTargetMapping.insert(key, this.ensureDocumentTargetMapping(key).delete(targetId));\r\n        if (updatedDocument) {\r\n            this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(key, updatedDocument);\r\n        }\r\n    }\r\n    removeTarget(targetId) {\r\n        this.targetStates.delete(targetId);\r\n    }\r\n    /**\r\n     * Returns the current count of documents in the target. This includes both\r\n     * the number of documents that the LocalStore considers to be part of the\r\n     * target as well as any accumulated changes.\r\n     */\r\n    getCurrentDocumentCountForTarget(targetId) {\r\n        const targetState = this.ensureTargetState(targetId);\r\n        const targetChange = targetState.toTargetChange();\r\n        return (this.metadataProvider.getRemoteKeysForTarget(targetId).size +\r\n            targetChange.addedDocuments.size -\r\n            targetChange.removedDocuments.size);\r\n    }\r\n    /**\r\n     * Increment the number of acks needed from watch before we can consider the\r\n     * server to be 'in-sync' with the client's active targets.\r\n     */\r\n    recordPendingTargetRequest(targetId) {\r\n        // For each request we get we need to record we need a response for it.\r\n        const targetState = this.ensureTargetState(targetId);\r\n        targetState.recordPendingTargetRequest();\r\n    }\r\n    ensureTargetState(targetId) {\r\n        let result = this.targetStates.get(targetId);\r\n        if (!result) {\r\n            result = new TargetState();\r\n            this.targetStates.set(targetId, result);\r\n        }\r\n        return result;\r\n    }\r\n    ensureDocumentTargetMapping(key) {\r\n        let targetMapping = this.pendingDocumentTargetMapping.get(key);\r\n        if (!targetMapping) {\r\n            targetMapping = new SortedSet(primitiveComparator);\r\n            this.pendingDocumentTargetMapping =\r\n                this.pendingDocumentTargetMapping.insert(key, targetMapping);\r\n        }\r\n        return targetMapping;\r\n    }\r\n    /**\r\n     * Verifies that the user is still interested in this target (by calling\r\n     * `getTargetDataForTarget()`) and that we are not waiting for pending ADDs\r\n     * from watch.\r\n     */\r\n    isActiveTarget(targetId) {\r\n        const targetActive = this.targetDataForActiveTarget(targetId) !== null;\r\n        if (!targetActive) {\r\n            logDebug(LOG_TAG$f, 'Detected inactive target', targetId);\r\n        }\r\n        return targetActive;\r\n    }\r\n    /**\r\n     * Returns the TargetData for an active target (i.e. a target that the user\r\n     * is still interested in that has no outstanding target change requests).\r\n     */\r\n    targetDataForActiveTarget(targetId) {\r\n        const targetState = this.targetStates.get(targetId);\r\n        return targetState && targetState.isPending\r\n            ? null\r\n            : this.metadataProvider.getTargetDataForTarget(targetId);\r\n    }\r\n    /**\r\n     * Resets the state of a Watch target to its initial state (e.g. sets\r\n     * 'current' to false, clears the resume token and removes its target mapping\r\n     * from all documents).\r\n     */\r\n    resetTarget(targetId) {\r\n        this.targetStates.set(targetId, new TargetState());\r\n        // Trigger removal for any documents currently mapped to this target.\r\n        // These removals will be part of the initial snapshot if Watch does not\r\n        // resend these documents.\r\n        const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\r\n        existingKeys.forEach(key => {\r\n            this.removeDocumentFromTarget(targetId, key, /*updatedDocument=*/ null);\r\n        });\r\n    }\r\n    /**\r\n     * Returns whether the LocalStore considers the document to be part of the\r\n     * specified target.\r\n     */\r\n    targetContainsDocument(targetId, key) {\r\n        const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\r\n        return existingKeys.has(key);\r\n    }\r\n}\r\nfunction documentTargetMap() {\r\n    return new SortedMap(DocumentKey.comparator);\r\n}\r\nfunction snapshotChangesMap() {\r\n    return new SortedMap(DocumentKey.comparator);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst DIRECTIONS = (() => {\r\n    const dirs = {};\r\n    dirs[\"asc\" /* ASCENDING */] = 'ASCENDING';\r\n    dirs[\"desc\" /* DESCENDING */] = 'DESCENDING';\r\n    return dirs;\r\n})();\r\nconst OPERATORS = (() => {\r\n    const ops = {};\r\n    ops[\"<\" /* LESS_THAN */] = 'LESS_THAN';\r\n    ops[\"<=\" /* LESS_THAN_OR_EQUAL */] = 'LESS_THAN_OR_EQUAL';\r\n    ops[\">\" /* GREATER_THAN */] = 'GREATER_THAN';\r\n    ops[\">=\" /* GREATER_THAN_OR_EQUAL */] = 'GREATER_THAN_OR_EQUAL';\r\n    ops[\"==\" /* EQUAL */] = 'EQUAL';\r\n    ops[\"!=\" /* NOT_EQUAL */] = 'NOT_EQUAL';\r\n    ops[\"array-contains\" /* ARRAY_CONTAINS */] = 'ARRAY_CONTAINS';\r\n    ops[\"in\" /* IN */] = 'IN';\r\n    ops[\"not-in\" /* NOT_IN */] = 'NOT_IN';\r\n    ops[\"array-contains-any\" /* ARRAY_CONTAINS_ANY */] = 'ARRAY_CONTAINS_ANY';\r\n    return ops;\r\n})();\r\nfunction assertPresent(value, description) {\r\n}\r\n/**\r\n * This class generates JsonObject values for the Datastore API suitable for\r\n * sending to either GRPC stub methods or via the JSON/HTTP REST API.\r\n *\r\n * The serializer supports both Protobuf.js and Proto3 JSON formats. By\r\n * setting `useProto3Json` to true, the serializer will use the Proto3 JSON\r\n * format.\r\n *\r\n * For a description of the Proto3 JSON format check\r\n * https://developers.google.com/protocol-buffers/docs/proto3#json\r\n *\r\n * TODO(klimt): We can remove the databaseId argument if we keep the full\r\n * resource name in documents.\r\n */\r\nclass JsonProtoSerializer {\r\n    constructor(databaseId, useProto3Json) {\r\n        this.databaseId = databaseId;\r\n        this.useProto3Json = useProto3Json;\r\n    }\r\n}\r\nfunction fromRpcStatus(status) {\r\n    const code = status.code === undefined ? Code.UNKNOWN : mapCodeFromRpcCode(status.code);\r\n    return new FirestoreError(code, status.message || '');\r\n}\r\n/**\r\n * Returns a value for a number (or null) that's appropriate to put into\r\n * a google.protobuf.Int32Value proto.\r\n * DO NOT USE THIS FOR ANYTHING ELSE.\r\n * This method cheats. It's typed as returning \"number\" because that's what\r\n * our generated proto interfaces say Int32Value must be. But GRPC actually\r\n * expects a { value: <number> } struct.\r\n */\r\nfunction toInt32Proto(serializer, val) {\r\n    if (serializer.useProto3Json || isNullOrUndefined(val)) {\r\n        return val;\r\n    }\r\n    else {\r\n        return { value: val };\r\n    }\r\n}\r\n/**\r\n * Returns a number (or null) from a google.protobuf.Int32Value proto.\r\n */\r\nfunction fromInt32Proto(val) {\r\n    let result;\r\n    if (typeof val === 'object') {\r\n        result = val.value;\r\n    }\r\n    else {\r\n        result = val;\r\n    }\r\n    return isNullOrUndefined(result) ? null : result;\r\n}\r\n/**\r\n * Returns a value for a Date that's appropriate to put into a proto.\r\n */\r\nfunction toTimestamp(serializer, timestamp) {\r\n    if (serializer.useProto3Json) {\r\n        // Serialize to ISO-8601 date format, but with full nano resolution.\r\n        // Since JS Date has only millis, let's only use it for the seconds and\r\n        // then manually add the fractions to the end.\r\n        const jsDateStr = new Date(timestamp.seconds * 1000).toISOString();\r\n        // Remove .xxx frac part and Z in the end.\r\n        const strUntilSeconds = jsDateStr.replace(/\\.\\d*/, '').replace('Z', '');\r\n        // Pad the fraction out to 9 digits (nanos).\r\n        const nanoStr = ('000000000' + timestamp.nanoseconds).slice(-9);\r\n        return `${strUntilSeconds}.${nanoStr}Z`;\r\n    }\r\n    else {\r\n        return {\r\n            seconds: '' + timestamp.seconds,\r\n            nanos: timestamp.nanoseconds\r\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        };\r\n    }\r\n}\r\nfunction fromTimestamp(date) {\r\n    const timestamp = normalizeTimestamp(date);\r\n    return new Timestamp(timestamp.seconds, timestamp.nanos);\r\n}\r\n/**\r\n * Returns a value for bytes that's appropriate to put in a proto.\r\n *\r\n * Visible for testing.\r\n */\r\nfunction toBytes(serializer, bytes) {\r\n    if (serializer.useProto3Json) {\r\n        return bytes.toBase64();\r\n    }\r\n    else {\r\n        return bytes.toUint8Array();\r\n    }\r\n}\r\n/**\r\n * Returns a ByteString based on the proto string value.\r\n */\r\nfunction fromBytes(serializer, value) {\r\n    if (serializer.useProto3Json) {\r\n        hardAssert(value === undefined || typeof value === 'string');\r\n        return ByteString.fromBase64String(value ? value : '');\r\n    }\r\n    else {\r\n        hardAssert(value === undefined || value instanceof Uint8Array);\r\n        return ByteString.fromUint8Array(value ? value : new Uint8Array());\r\n    }\r\n}\r\nfunction toVersion(serializer, version) {\r\n    return toTimestamp(serializer, version.toTimestamp());\r\n}\r\nfunction fromVersion(version) {\r\n    hardAssert(!!version);\r\n    return SnapshotVersion.fromTimestamp(fromTimestamp(version));\r\n}\r\nfunction toResourceName(databaseId, path) {\r\n    return fullyQualifiedPrefixPath(databaseId)\r\n        .child('documents')\r\n        .child(path)\r\n        .canonicalString();\r\n}\r\nfunction fromResourceName(name) {\r\n    const resource = ResourcePath.fromString(name);\r\n    hardAssert(isValidResourceName(resource));\r\n    return resource;\r\n}\r\nfunction toName(serializer, key) {\r\n    return toResourceName(serializer.databaseId, key.path);\r\n}\r\nfunction fromName(serializer, name) {\r\n    const resource = fromResourceName(name);\r\n    if (resource.get(1) !== serializer.databaseId.projectId) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Tried to deserialize key from different project: ' +\r\n            resource.get(1) +\r\n            ' vs ' +\r\n            serializer.databaseId.projectId);\r\n    }\r\n    if (resource.get(3) !== serializer.databaseId.database) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Tried to deserialize key from different database: ' +\r\n            resource.get(3) +\r\n            ' vs ' +\r\n            serializer.databaseId.database);\r\n    }\r\n    return new DocumentKey(extractLocalPathFromResourceName(resource));\r\n}\r\nfunction toQueryPath(serializer, path) {\r\n    return toResourceName(serializer.databaseId, path);\r\n}\r\nfunction fromQueryPath(name) {\r\n    const resourceName = fromResourceName(name);\r\n    // In v1beta1 queries for collections at the root did not have a trailing\r\n    // \"/documents\". In v1 all resource paths contain \"/documents\". Preserve the\r\n    // ability to read the v1beta1 form for compatibility with queries persisted\r\n    // in the local target cache.\r\n    if (resourceName.length === 4) {\r\n        return ResourcePath.emptyPath();\r\n    }\r\n    return extractLocalPathFromResourceName(resourceName);\r\n}\r\nfunction getEncodedDatabaseId(serializer) {\r\n    const path = new ResourcePath([\r\n        'projects',\r\n        serializer.databaseId.projectId,\r\n        'databases',\r\n        serializer.databaseId.database\r\n    ]);\r\n    return path.canonicalString();\r\n}\r\nfunction fullyQualifiedPrefixPath(databaseId) {\r\n    return new ResourcePath([\r\n        'projects',\r\n        databaseId.projectId,\r\n        'databases',\r\n        databaseId.database\r\n    ]);\r\n}\r\nfunction extractLocalPathFromResourceName(resourceName) {\r\n    hardAssert(resourceName.length > 4 && resourceName.get(4) === 'documents');\r\n    return resourceName.popFirst(5);\r\n}\r\n/** Creates a Document proto from key and fields (but no create/update time) */\r\nfunction toMutationDocument(serializer, key, fields) {\r\n    return {\r\n        name: toName(serializer, key),\r\n        fields: fields.value.mapValue.fields\r\n    };\r\n}\r\nfunction toDocument(serializer, document) {\r\n    return {\r\n        name: toName(serializer, document.key),\r\n        fields: document.data.value.mapValue.fields,\r\n        updateTime: toTimestamp(serializer, document.version.toTimestamp())\r\n    };\r\n}\r\nfunction fromDocument(serializer, document, hasCommittedMutations) {\r\n    const key = fromName(serializer, document.name);\r\n    const version = fromVersion(document.updateTime);\r\n    const data = new ObjectValue({ mapValue: { fields: document.fields } });\r\n    const result = MutableDocument.newFoundDocument(key, version, data);\r\n    if (hasCommittedMutations) {\r\n        result.setHasCommittedMutations();\r\n    }\r\n    return hasCommittedMutations ? result.setHasCommittedMutations() : result;\r\n}\r\nfunction fromFound(serializer, doc) {\r\n    hardAssert(!!doc.found);\r\n    assertPresent(doc.found.name);\r\n    assertPresent(doc.found.updateTime);\r\n    const key = fromName(serializer, doc.found.name);\r\n    const version = fromVersion(doc.found.updateTime);\r\n    const data = new ObjectValue({ mapValue: { fields: doc.found.fields } });\r\n    return MutableDocument.newFoundDocument(key, version, data);\r\n}\r\nfunction fromMissing(serializer, result) {\r\n    hardAssert(!!result.missing);\r\n    hardAssert(!!result.readTime);\r\n    const key = fromName(serializer, result.missing);\r\n    const version = fromVersion(result.readTime);\r\n    return MutableDocument.newNoDocument(key, version);\r\n}\r\nfunction fromBatchGetDocumentsResponse(serializer, result) {\r\n    if ('found' in result) {\r\n        return fromFound(serializer, result);\r\n    }\r\n    else if ('missing' in result) {\r\n        return fromMissing(serializer, result);\r\n    }\r\n    return fail();\r\n}\r\nfunction fromWatchChange(serializer, change) {\r\n    let watchChange;\r\n    if ('targetChange' in change) {\r\n        assertPresent(change.targetChange);\r\n        // proto3 default value is unset in JSON (undefined), so use 'NO_CHANGE'\r\n        // if unset\r\n        const state = fromWatchTargetChangeState(change.targetChange.targetChangeType || 'NO_CHANGE');\r\n        const targetIds = change.targetChange.targetIds || [];\r\n        const resumeToken = fromBytes(serializer, change.targetChange.resumeToken);\r\n        const causeProto = change.targetChange.cause;\r\n        const cause = causeProto && fromRpcStatus(causeProto);\r\n        watchChange = new WatchTargetChange(state, targetIds, resumeToken, cause || null);\r\n    }\r\n    else if ('documentChange' in change) {\r\n        assertPresent(change.documentChange);\r\n        const entityChange = change.documentChange;\r\n        assertPresent(entityChange.document);\r\n        assertPresent(entityChange.document.name);\r\n        assertPresent(entityChange.document.updateTime);\r\n        const key = fromName(serializer, entityChange.document.name);\r\n        const version = fromVersion(entityChange.document.updateTime);\r\n        const data = new ObjectValue({\r\n            mapValue: { fields: entityChange.document.fields }\r\n        });\r\n        const doc = MutableDocument.newFoundDocument(key, version, data);\r\n        const updatedTargetIds = entityChange.targetIds || [];\r\n        const removedTargetIds = entityChange.removedTargetIds || [];\r\n        watchChange = new DocumentWatchChange(updatedTargetIds, removedTargetIds, doc.key, doc);\r\n    }\r\n    else if ('documentDelete' in change) {\r\n        assertPresent(change.documentDelete);\r\n        const docDelete = change.documentDelete;\r\n        assertPresent(docDelete.document);\r\n        const key = fromName(serializer, docDelete.document);\r\n        const version = docDelete.readTime\r\n            ? fromVersion(docDelete.readTime)\r\n            : SnapshotVersion.min();\r\n        const doc = MutableDocument.newNoDocument(key, version);\r\n        const removedTargetIds = docDelete.removedTargetIds || [];\r\n        watchChange = new DocumentWatchChange([], removedTargetIds, doc.key, doc);\r\n    }\r\n    else if ('documentRemove' in change) {\r\n        assertPresent(change.documentRemove);\r\n        const docRemove = change.documentRemove;\r\n        assertPresent(docRemove.document);\r\n        const key = fromName(serializer, docRemove.document);\r\n        const removedTargetIds = docRemove.removedTargetIds || [];\r\n        watchChange = new DocumentWatchChange([], removedTargetIds, key, null);\r\n    }\r\n    else if ('filter' in change) {\r\n        // TODO(dimond): implement existence filter parsing with strategy.\r\n        assertPresent(change.filter);\r\n        const filter = change.filter;\r\n        assertPresent(filter.targetId);\r\n        const count = filter.count || 0;\r\n        const existenceFilter = new ExistenceFilter(count);\r\n        const targetId = filter.targetId;\r\n        watchChange = new ExistenceFilterChange(targetId, existenceFilter);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n    return watchChange;\r\n}\r\nfunction fromWatchTargetChangeState(state) {\r\n    if (state === 'NO_CHANGE') {\r\n        return 0 /* NoChange */;\r\n    }\r\n    else if (state === 'ADD') {\r\n        return 1 /* Added */;\r\n    }\r\n    else if (state === 'REMOVE') {\r\n        return 2 /* Removed */;\r\n    }\r\n    else if (state === 'CURRENT') {\r\n        return 3 /* Current */;\r\n    }\r\n    else if (state === 'RESET') {\r\n        return 4 /* Reset */;\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction versionFromListenResponse(change) {\r\n    // We have only reached a consistent snapshot for the entire stream if there\r\n    // is a read_time set and it applies to all targets (i.e. the list of\r\n    // targets is empty). The backend is guaranteed to send such responses.\r\n    if (!('targetChange' in change)) {\r\n        return SnapshotVersion.min();\r\n    }\r\n    const targetChange = change.targetChange;\r\n    if (targetChange.targetIds && targetChange.targetIds.length) {\r\n        return SnapshotVersion.min();\r\n    }\r\n    if (!targetChange.readTime) {\r\n        return SnapshotVersion.min();\r\n    }\r\n    return fromVersion(targetChange.readTime);\r\n}\r\nfunction toMutation(serializer, mutation) {\r\n    let result;\r\n    if (mutation instanceof SetMutation) {\r\n        result = {\r\n            update: toMutationDocument(serializer, mutation.key, mutation.value)\r\n        };\r\n    }\r\n    else if (mutation instanceof DeleteMutation) {\r\n        result = { delete: toName(serializer, mutation.key) };\r\n    }\r\n    else if (mutation instanceof PatchMutation) {\r\n        result = {\r\n            update: toMutationDocument(serializer, mutation.key, mutation.data),\r\n            updateMask: toDocumentMask(mutation.fieldMask)\r\n        };\r\n    }\r\n    else if (mutation instanceof VerifyMutation) {\r\n        result = {\r\n            verify: toName(serializer, mutation.key)\r\n        };\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n    if (mutation.fieldTransforms.length > 0) {\r\n        result.updateTransforms = mutation.fieldTransforms.map(transform => toFieldTransform(serializer, transform));\r\n    }\r\n    if (!mutation.precondition.isNone) {\r\n        result.currentDocument = toPrecondition(serializer, mutation.precondition);\r\n    }\r\n    return result;\r\n}\r\nfunction fromMutation(serializer, proto) {\r\n    const precondition = proto.currentDocument\r\n        ? fromPrecondition(proto.currentDocument)\r\n        : Precondition.none();\r\n    const fieldTransforms = proto.updateTransforms\r\n        ? proto.updateTransforms.map(transform => fromFieldTransform(serializer, transform))\r\n        : [];\r\n    if (proto.update) {\r\n        assertPresent(proto.update.name);\r\n        const key = fromName(serializer, proto.update.name);\r\n        const value = new ObjectValue({\r\n            mapValue: { fields: proto.update.fields }\r\n        });\r\n        if (proto.updateMask) {\r\n            const fieldMask = fromDocumentMask(proto.updateMask);\r\n            return new PatchMutation(key, value, fieldMask, precondition, fieldTransforms);\r\n        }\r\n        else {\r\n            return new SetMutation(key, value, precondition, fieldTransforms);\r\n        }\r\n    }\r\n    else if (proto.delete) {\r\n        const key = fromName(serializer, proto.delete);\r\n        return new DeleteMutation(key, precondition);\r\n    }\r\n    else if (proto.verify) {\r\n        const key = fromName(serializer, proto.verify);\r\n        return new VerifyMutation(key, precondition);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction toPrecondition(serializer, precondition) {\r\n    if (precondition.updateTime !== undefined) {\r\n        return {\r\n            updateTime: toVersion(serializer, precondition.updateTime)\r\n        };\r\n    }\r\n    else if (precondition.exists !== undefined) {\r\n        return { exists: precondition.exists };\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction fromPrecondition(precondition) {\r\n    if (precondition.updateTime !== undefined) {\r\n        return Precondition.updateTime(fromVersion(precondition.updateTime));\r\n    }\r\n    else if (precondition.exists !== undefined) {\r\n        return Precondition.exists(precondition.exists);\r\n    }\r\n    else {\r\n        return Precondition.none();\r\n    }\r\n}\r\nfunction fromWriteResult(proto, commitTime) {\r\n    // NOTE: Deletes don't have an updateTime.\r\n    let version = proto.updateTime\r\n        ? fromVersion(proto.updateTime)\r\n        : fromVersion(commitTime);\r\n    if (version.isEqual(SnapshotVersion.min())) {\r\n        // The Firestore Emulator currently returns an update time of 0 for\r\n        // deletes of non-existing documents (rather than null). This breaks the\r\n        // test \"get deleted doc while offline with source=cache\" as NoDocuments\r\n        // with version 0 are filtered by IndexedDb's RemoteDocumentCache.\r\n        // TODO(#2149): Remove this when Emulator is fixed\r\n        version = fromVersion(commitTime);\r\n    }\r\n    return new MutationResult(version, proto.transformResults || []);\r\n}\r\nfunction fromWriteResults(protos, commitTime) {\r\n    if (protos && protos.length > 0) {\r\n        hardAssert(commitTime !== undefined);\r\n        return protos.map(proto => fromWriteResult(proto, commitTime));\r\n    }\r\n    else {\r\n        return [];\r\n    }\r\n}\r\nfunction toFieldTransform(serializer, fieldTransform) {\r\n    const transform = fieldTransform.transform;\r\n    if (transform instanceof ServerTimestampTransform) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            setToServerValue: 'REQUEST_TIME'\r\n        };\r\n    }\r\n    else if (transform instanceof ArrayUnionTransformOperation) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            appendMissingElements: {\r\n                values: transform.elements\r\n            }\r\n        };\r\n    }\r\n    else if (transform instanceof ArrayRemoveTransformOperation) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            removeAllFromArray: {\r\n                values: transform.elements\r\n            }\r\n        };\r\n    }\r\n    else if (transform instanceof NumericIncrementTransformOperation) {\r\n        return {\r\n            fieldPath: fieldTransform.field.canonicalString(),\r\n            increment: transform.operand\r\n        };\r\n    }\r\n    else {\r\n        throw fail();\r\n    }\r\n}\r\nfunction fromFieldTransform(serializer, proto) {\r\n    let transform = null;\r\n    if ('setToServerValue' in proto) {\r\n        hardAssert(proto.setToServerValue === 'REQUEST_TIME');\r\n        transform = new ServerTimestampTransform();\r\n    }\r\n    else if ('appendMissingElements' in proto) {\r\n        const values = proto.appendMissingElements.values || [];\r\n        transform = new ArrayUnionTransformOperation(values);\r\n    }\r\n    else if ('removeAllFromArray' in proto) {\r\n        const values = proto.removeAllFromArray.values || [];\r\n        transform = new ArrayRemoveTransformOperation(values);\r\n    }\r\n    else if ('increment' in proto) {\r\n        transform = new NumericIncrementTransformOperation(serializer, proto.increment);\r\n    }\r\n    else {\r\n        fail();\r\n    }\r\n    const fieldPath = FieldPath$1.fromServerFormat(proto.fieldPath);\r\n    return new FieldTransform(fieldPath, transform);\r\n}\r\nfunction toDocumentsTarget(serializer, target) {\r\n    return { documents: [toQueryPath(serializer, target.path)] };\r\n}\r\nfunction fromDocumentsTarget(documentsTarget) {\r\n    const count = documentsTarget.documents.length;\r\n    hardAssert(count === 1);\r\n    const name = documentsTarget.documents[0];\r\n    return queryToTarget(newQueryForPath(fromQueryPath(name)));\r\n}\r\nfunction toQueryTarget(serializer, target) {\r\n    // Dissect the path into parent, collectionId, and optional key filter.\r\n    const result = { structuredQuery: {} };\r\n    const path = target.path;\r\n    if (target.collectionGroup !== null) {\r\n        result.parent = toQueryPath(serializer, path);\r\n        result.structuredQuery.from = [\r\n            {\r\n                collectionId: target.collectionGroup,\r\n                allDescendants: true\r\n            }\r\n        ];\r\n    }\r\n    else {\r\n        result.parent = toQueryPath(serializer, path.popLast());\r\n        result.structuredQuery.from = [{ collectionId: path.lastSegment() }];\r\n    }\r\n    const where = toFilter(target.filters);\r\n    if (where) {\r\n        result.structuredQuery.where = where;\r\n    }\r\n    const orderBy = toOrder(target.orderBy);\r\n    if (orderBy) {\r\n        result.structuredQuery.orderBy = orderBy;\r\n    }\r\n    const limit = toInt32Proto(serializer, target.limit);\r\n    if (limit !== null) {\r\n        result.structuredQuery.limit = limit;\r\n    }\r\n    if (target.startAt) {\r\n        result.structuredQuery.startAt = toCursor(target.startAt);\r\n    }\r\n    if (target.endAt) {\r\n        result.structuredQuery.endAt = toCursor(target.endAt);\r\n    }\r\n    return result;\r\n}\r\nfunction convertQueryTargetToQuery(target) {\r\n    let path = fromQueryPath(target.parent);\r\n    const query = target.structuredQuery;\r\n    const fromCount = query.from ? query.from.length : 0;\r\n    let collectionGroup = null;\r\n    if (fromCount > 0) {\r\n        hardAssert(fromCount === 1);\r\n        const from = query.from[0];\r\n        if (from.allDescendants) {\r\n            collectionGroup = from.collectionId;\r\n        }\r\n        else {\r\n            path = path.child(from.collectionId);\r\n        }\r\n    }\r\n    let filterBy = [];\r\n    if (query.where) {\r\n        filterBy = fromFilter(query.where);\r\n    }\r\n    let orderBy = [];\r\n    if (query.orderBy) {\r\n        orderBy = fromOrder(query.orderBy);\r\n    }\r\n    let limit = null;\r\n    if (query.limit) {\r\n        limit = fromInt32Proto(query.limit);\r\n    }\r\n    let startAt = null;\r\n    if (query.startAt) {\r\n        startAt = fromCursor(query.startAt);\r\n    }\r\n    let endAt = null;\r\n    if (query.endAt) {\r\n        endAt = fromCursor(query.endAt);\r\n    }\r\n    return newQuery(path, collectionGroup, orderBy, filterBy, limit, \"F\" /* First */, startAt, endAt);\r\n}\r\nfunction fromQueryTarget(target) {\r\n    return queryToTarget(convertQueryTargetToQuery(target));\r\n}\r\nfunction toListenRequestLabels(serializer, targetData) {\r\n    const value = toLabel(serializer, targetData.purpose);\r\n    if (value == null) {\r\n        return null;\r\n    }\r\n    else {\r\n        return {\r\n            'goog-listen-tags': value\r\n        };\r\n    }\r\n}\r\nfunction toLabel(serializer, purpose) {\r\n    switch (purpose) {\r\n        case 0 /* Listen */:\r\n            return null;\r\n        case 1 /* ExistenceFilterMismatch */:\r\n            return 'existence-filter-mismatch';\r\n        case 2 /* LimboResolution */:\r\n            return 'limbo-document';\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction toTarget(serializer, targetData) {\r\n    let result;\r\n    const target = targetData.target;\r\n    if (isDocumentTarget(target)) {\r\n        result = { documents: toDocumentsTarget(serializer, target) };\r\n    }\r\n    else {\r\n        result = { query: toQueryTarget(serializer, target) };\r\n    }\r\n    result.targetId = targetData.targetId;\r\n    if (targetData.resumeToken.approximateByteSize() > 0) {\r\n        result.resumeToken = toBytes(serializer, targetData.resumeToken);\r\n    }\r\n    else if (targetData.snapshotVersion.compareTo(SnapshotVersion.min()) > 0) {\r\n        // TODO(wuandy): Consider removing above check because it is most likely true.\r\n        // Right now, many tests depend on this behaviour though (leaving min() out\r\n        // of serialization).\r\n        result.readTime = toTimestamp(serializer, targetData.snapshotVersion.toTimestamp());\r\n    }\r\n    return result;\r\n}\r\nfunction toFilter(filters) {\r\n    if (filters.length === 0) {\r\n        return;\r\n    }\r\n    const protos = filters.map(filter => {\r\n        return toUnaryOrFieldFilter(filter);\r\n    });\r\n    if (protos.length === 1) {\r\n        return protos[0];\r\n    }\r\n    return { compositeFilter: { op: 'AND', filters: protos } };\r\n}\r\nfunction fromFilter(filter) {\r\n    if (!filter) {\r\n        return [];\r\n    }\r\n    else if (filter.unaryFilter !== undefined) {\r\n        return [fromUnaryFilter(filter)];\r\n    }\r\n    else if (filter.fieldFilter !== undefined) {\r\n        return [fromFieldFilter(filter)];\r\n    }\r\n    else if (filter.compositeFilter !== undefined) {\r\n        return filter.compositeFilter\r\n            .filters.map(f => fromFilter(f))\r\n            .reduce((accum, current) => accum.concat(current));\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction toOrder(orderBys) {\r\n    if (orderBys.length === 0) {\r\n        return;\r\n    }\r\n    return orderBys.map(order => toPropertyOrder(order));\r\n}\r\nfunction fromOrder(orderBys) {\r\n    return orderBys.map(order => fromPropertyOrder(order));\r\n}\r\nfunction toCursor(cursor) {\r\n    return {\r\n        before: cursor.before,\r\n        values: cursor.position\r\n    };\r\n}\r\nfunction fromCursor(cursor) {\r\n    const before = !!cursor.before;\r\n    const position = cursor.values || [];\r\n    return new Bound(position, before);\r\n}\r\n// visible for testing\r\nfunction toDirection(dir) {\r\n    return DIRECTIONS[dir];\r\n}\r\n// visible for testing\r\nfunction fromDirection(dir) {\r\n    switch (dir) {\r\n        case 'ASCENDING':\r\n            return \"asc\" /* ASCENDING */;\r\n        case 'DESCENDING':\r\n            return \"desc\" /* DESCENDING */;\r\n        default:\r\n            return undefined;\r\n    }\r\n}\r\n// visible for testing\r\nfunction toOperatorName(op) {\r\n    return OPERATORS[op];\r\n}\r\nfunction fromOperatorName(op) {\r\n    switch (op) {\r\n        case 'EQUAL':\r\n            return \"==\" /* EQUAL */;\r\n        case 'NOT_EQUAL':\r\n            return \"!=\" /* NOT_EQUAL */;\r\n        case 'GREATER_THAN':\r\n            return \">\" /* GREATER_THAN */;\r\n        case 'GREATER_THAN_OR_EQUAL':\r\n            return \">=\" /* GREATER_THAN_OR_EQUAL */;\r\n        case 'LESS_THAN':\r\n            return \"<\" /* LESS_THAN */;\r\n        case 'LESS_THAN_OR_EQUAL':\r\n            return \"<=\" /* LESS_THAN_OR_EQUAL */;\r\n        case 'ARRAY_CONTAINS':\r\n            return \"array-contains\" /* ARRAY_CONTAINS */;\r\n        case 'IN':\r\n            return \"in\" /* IN */;\r\n        case 'NOT_IN':\r\n            return \"not-in\" /* NOT_IN */;\r\n        case 'ARRAY_CONTAINS_ANY':\r\n            return \"array-contains-any\" /* ARRAY_CONTAINS_ANY */;\r\n        case 'OPERATOR_UNSPECIFIED':\r\n            return fail();\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction toFieldPathReference(path) {\r\n    return { fieldPath: path.canonicalString() };\r\n}\r\nfunction fromFieldPathReference(fieldReference) {\r\n    return FieldPath$1.fromServerFormat(fieldReference.fieldPath);\r\n}\r\n// visible for testing\r\nfunction toPropertyOrder(orderBy) {\r\n    return {\r\n        field: toFieldPathReference(orderBy.field),\r\n        direction: toDirection(orderBy.dir)\r\n    };\r\n}\r\nfunction fromPropertyOrder(orderBy) {\r\n    return new OrderBy(fromFieldPathReference(orderBy.field), fromDirection(orderBy.direction));\r\n}\r\nfunction fromFieldFilter(filter) {\r\n    return FieldFilter.create(fromFieldPathReference(filter.fieldFilter.field), fromOperatorName(filter.fieldFilter.op), filter.fieldFilter.value);\r\n}\r\n// visible for testing\r\nfunction toUnaryOrFieldFilter(filter) {\r\n    if (filter.op === \"==\" /* EQUAL */) {\r\n        if (isNanValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NAN'\r\n                }\r\n            };\r\n        }\r\n        else if (isNullValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NULL'\r\n                }\r\n            };\r\n        }\r\n    }\r\n    else if (filter.op === \"!=\" /* NOT_EQUAL */) {\r\n        if (isNanValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NOT_NAN'\r\n                }\r\n            };\r\n        }\r\n        else if (isNullValue(filter.value)) {\r\n            return {\r\n                unaryFilter: {\r\n                    field: toFieldPathReference(filter.field),\r\n                    op: 'IS_NOT_NULL'\r\n                }\r\n            };\r\n        }\r\n    }\r\n    return {\r\n        fieldFilter: {\r\n            field: toFieldPathReference(filter.field),\r\n            op: toOperatorName(filter.op),\r\n            value: filter.value\r\n        }\r\n    };\r\n}\r\nfunction fromUnaryFilter(filter) {\r\n    switch (filter.unaryFilter.op) {\r\n        case 'IS_NAN':\r\n            const nanField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(nanField, \"==\" /* EQUAL */, {\r\n                doubleValue: NaN\r\n            });\r\n        case 'IS_NULL':\r\n            const nullField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(nullField, \"==\" /* EQUAL */, {\r\n                nullValue: 'NULL_VALUE'\r\n            });\r\n        case 'IS_NOT_NAN':\r\n            const notNanField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(notNanField, \"!=\" /* NOT_EQUAL */, {\r\n                doubleValue: NaN\r\n            });\r\n        case 'IS_NOT_NULL':\r\n            const notNullField = fromFieldPathReference(filter.unaryFilter.field);\r\n            return FieldFilter.create(notNullField, \"!=\" /* NOT_EQUAL */, {\r\n                nullValue: 'NULL_VALUE'\r\n            });\r\n        case 'OPERATOR_UNSPECIFIED':\r\n            return fail();\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\nfunction toDocumentMask(fieldMask) {\r\n    const canonicalFields = [];\r\n    fieldMask.fields.forEach(field => canonicalFields.push(field.canonicalString()));\r\n    return {\r\n        fieldPaths: canonicalFields\r\n    };\r\n}\r\nfunction fromDocumentMask(proto) {\r\n    const paths = proto.fieldPaths || [];\r\n    return new FieldMask(paths.map(path => FieldPath$1.fromServerFormat(path)));\r\n}\r\nfunction isValidResourceName(path) {\r\n    // Resource names have at least 4 components (project ID, database ID)\r\n    return (path.length >= 4 &&\r\n        path.get(0) === 'projects' &&\r\n        path.get(2) === 'databases');\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An immutable set of metadata that the local store tracks for each target.\r\n */\r\nclass TargetData {\r\n    constructor(\r\n    /** The target being listened to. */\r\n    target, \r\n    /**\r\n     * The target ID to which the target corresponds; Assigned by the\r\n     * LocalStore for user listens and by the SyncEngine for limbo watches.\r\n     */\r\n    targetId, \r\n    /** The purpose of the target. */\r\n    purpose, \r\n    /**\r\n     * The sequence number of the last transaction during which this target data\r\n     * was modified.\r\n     */\r\n    sequenceNumber, \r\n    /** The latest snapshot version seen for this target. */\r\n    snapshotVersion = SnapshotVersion.min(), \r\n    /**\r\n     * The maximum snapshot version at which the associated view\r\n     * contained no limbo documents.\r\n     */\r\n    lastLimboFreeSnapshotVersion = SnapshotVersion.min(), \r\n    /**\r\n     * An opaque, server-assigned token that allows watching a target to be\r\n     * resumed after disconnecting without retransmitting all the data that\r\n     * matches the target. The resume token essentially identifies a point in\r\n     * time from which the server should resume sending results.\r\n     */\r\n    resumeToken = ByteString.EMPTY_BYTE_STRING) {\r\n        this.target = target;\r\n        this.targetId = targetId;\r\n        this.purpose = purpose;\r\n        this.sequenceNumber = sequenceNumber;\r\n        this.snapshotVersion = snapshotVersion;\r\n        this.lastLimboFreeSnapshotVersion = lastLimboFreeSnapshotVersion;\r\n        this.resumeToken = resumeToken;\r\n    }\r\n    /** Creates a new target data instance with an updated sequence number. */\r\n    withSequenceNumber(sequenceNumber) {\r\n        return new TargetData(this.target, this.targetId, this.purpose, sequenceNumber, this.snapshotVersion, this.lastLimboFreeSnapshotVersion, this.resumeToken);\r\n    }\r\n    /**\r\n     * Creates a new target data instance with an updated resume token and\r\n     * snapshot version.\r\n     */\r\n    withResumeToken(resumeToken, snapshotVersion) {\r\n        return new TargetData(this.target, this.targetId, this.purpose, this.sequenceNumber, snapshotVersion, this.lastLimboFreeSnapshotVersion, resumeToken);\r\n    }\r\n    /**\r\n     * Creates a new target data instance with an updated last limbo free\r\n     * snapshot version number.\r\n     */\r\n    withLastLimboFreeSnapshotVersion(lastLimboFreeSnapshotVersion) {\r\n        return new TargetData(this.target, this.targetId, this.purpose, this.sequenceNumber, this.snapshotVersion, lastLimboFreeSnapshotVersion, this.resumeToken);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Serializer for values stored in the LocalStore. */\r\nclass LocalSerializer {\r\n    constructor(remoteSerializer) {\r\n        this.remoteSerializer = remoteSerializer;\r\n    }\r\n}\r\n/** Decodes a remote document from storage locally to a Document. */\r\nfunction fromDbRemoteDocument(localSerializer, remoteDoc) {\r\n    if (remoteDoc.document) {\r\n        return fromDocument(localSerializer.remoteSerializer, remoteDoc.document, !!remoteDoc.hasCommittedMutations);\r\n    }\r\n    else if (remoteDoc.noDocument) {\r\n        const key = DocumentKey.fromSegments(remoteDoc.noDocument.path);\r\n        const version = fromDbTimestamp(remoteDoc.noDocument.readTime);\r\n        const document = MutableDocument.newNoDocument(key, version);\r\n        return remoteDoc.hasCommittedMutations\r\n            ? document.setHasCommittedMutations()\r\n            : document;\r\n    }\r\n    else if (remoteDoc.unknownDocument) {\r\n        const key = DocumentKey.fromSegments(remoteDoc.unknownDocument.path);\r\n        const version = fromDbTimestamp(remoteDoc.unknownDocument.version);\r\n        return MutableDocument.newUnknownDocument(key, version);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\n/** Encodes a document for storage locally. */\r\nfunction toDbRemoteDocument(localSerializer, document, readTime) {\r\n    const dbReadTime = toDbTimestampKey(readTime);\r\n    const parentPath = document.key.path.popLast().toArray();\r\n    if (document.isFoundDocument()) {\r\n        const doc = toDocument(localSerializer.remoteSerializer, document);\r\n        const hasCommittedMutations = document.hasCommittedMutations;\r\n        return new DbRemoteDocument(\r\n        /* unknownDocument= */ null, \r\n        /* noDocument= */ null, doc, hasCommittedMutations, dbReadTime, parentPath);\r\n    }\r\n    else if (document.isNoDocument()) {\r\n        const path = document.key.path.toArray();\r\n        const readTime = toDbTimestamp(document.version);\r\n        const hasCommittedMutations = document.hasCommittedMutations;\r\n        return new DbRemoteDocument(\r\n        /* unknownDocument= */ null, new DbNoDocument(path, readTime), \r\n        /* document= */ null, hasCommittedMutations, dbReadTime, parentPath);\r\n    }\r\n    else if (document.isUnknownDocument()) {\r\n        const path = document.key.path.toArray();\r\n        const readTime = toDbTimestamp(document.version);\r\n        return new DbRemoteDocument(new DbUnknownDocument(path, readTime), \r\n        /* noDocument= */ null, \r\n        /* document= */ null, \r\n        /* hasCommittedMutations= */ true, dbReadTime, parentPath);\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\nfunction toDbTimestampKey(snapshotVersion) {\r\n    const timestamp = snapshotVersion.toTimestamp();\r\n    return [timestamp.seconds, timestamp.nanoseconds];\r\n}\r\nfunction fromDbTimestampKey(dbTimestampKey) {\r\n    const timestamp = new Timestamp(dbTimestampKey[0], dbTimestampKey[1]);\r\n    return SnapshotVersion.fromTimestamp(timestamp);\r\n}\r\nfunction toDbTimestamp(snapshotVersion) {\r\n    const timestamp = snapshotVersion.toTimestamp();\r\n    return new DbTimestamp(timestamp.seconds, timestamp.nanoseconds);\r\n}\r\nfunction fromDbTimestamp(dbTimestamp) {\r\n    const timestamp = new Timestamp(dbTimestamp.seconds, dbTimestamp.nanoseconds);\r\n    return SnapshotVersion.fromTimestamp(timestamp);\r\n}\r\n/** Encodes a batch of mutations into a DbMutationBatch for local storage. */\r\nfunction toDbMutationBatch(localSerializer, userId, batch) {\r\n    const serializedBaseMutations = batch.baseMutations.map(m => toMutation(localSerializer.remoteSerializer, m));\r\n    const serializedMutations = batch.mutations.map(m => toMutation(localSerializer.remoteSerializer, m));\r\n    return new DbMutationBatch(userId, batch.batchId, batch.localWriteTime.toMillis(), serializedBaseMutations, serializedMutations);\r\n}\r\n/** Decodes a DbMutationBatch into a MutationBatch */\r\nfunction fromDbMutationBatch(localSerializer, dbBatch) {\r\n    const baseMutations = (dbBatch.baseMutations || []).map(m => fromMutation(localSerializer.remoteSerializer, m));\r\n    // Squash old transform mutations into existing patch or set mutations.\r\n    // The replacement of representing `transforms` with `update_transforms`\r\n    // on the SDK means that old `transform` mutations stored in IndexedDB need\r\n    // to be updated to `update_transforms`.\r\n    // TODO(b/174608374): Remove this code once we perform a schema migration.\r\n    for (let i = 0; i < dbBatch.mutations.length - 1; ++i) {\r\n        const currentMutation = dbBatch.mutations[i];\r\n        const hasTransform = i + 1 < dbBatch.mutations.length &&\r\n            dbBatch.mutations[i + 1].transform !== undefined;\r\n        if (hasTransform) {\r\n            const transformMutation = dbBatch.mutations[i + 1];\r\n            currentMutation.updateTransforms =\r\n                transformMutation.transform.fieldTransforms;\r\n            dbBatch.mutations.splice(i + 1, 1);\r\n            ++i;\r\n        }\r\n    }\r\n    const mutations = dbBatch.mutations.map(m => fromMutation(localSerializer.remoteSerializer, m));\r\n    const timestamp = Timestamp.fromMillis(dbBatch.localWriteTimeMs);\r\n    return new MutationBatch(dbBatch.batchId, timestamp, baseMutations, mutations);\r\n}\r\n/** Decodes a DbTarget into TargetData */\r\nfunction fromDbTarget(dbTarget) {\r\n    const version = fromDbTimestamp(dbTarget.readTime);\r\n    const lastLimboFreeSnapshotVersion = dbTarget.lastLimboFreeSnapshotVersion !== undefined\r\n        ? fromDbTimestamp(dbTarget.lastLimboFreeSnapshotVersion)\r\n        : SnapshotVersion.min();\r\n    let target;\r\n    if (isDocumentQuery(dbTarget.query)) {\r\n        target = fromDocumentsTarget(dbTarget.query);\r\n    }\r\n    else {\r\n        target = fromQueryTarget(dbTarget.query);\r\n    }\r\n    return new TargetData(target, dbTarget.targetId, 0 /* Listen */, dbTarget.lastListenSequenceNumber, version, lastLimboFreeSnapshotVersion, ByteString.fromBase64String(dbTarget.resumeToken));\r\n}\r\n/** Encodes TargetData into a DbTarget for storage locally. */\r\nfunction toDbTarget(localSerializer, targetData) {\r\n    const dbTimestamp = toDbTimestamp(targetData.snapshotVersion);\r\n    const dbLastLimboFreeTimestamp = toDbTimestamp(targetData.lastLimboFreeSnapshotVersion);\r\n    let queryProto;\r\n    if (isDocumentTarget(targetData.target)) {\r\n        queryProto = toDocumentsTarget(localSerializer.remoteSerializer, targetData.target);\r\n    }\r\n    else {\r\n        queryProto = toQueryTarget(localSerializer.remoteSerializer, targetData.target);\r\n    }\r\n    // We can't store the resumeToken as a ByteString in IndexedDb, so we\r\n    // convert it to a base64 string for storage.\r\n    const resumeToken = targetData.resumeToken.toBase64();\r\n    // lastListenSequenceNumber is always 0 until we do real GC.\r\n    return new DbTarget(targetData.targetId, canonifyTarget(targetData.target), dbTimestamp, resumeToken, targetData.sequenceNumber, dbLastLimboFreeTimestamp, queryProto);\r\n}\r\n/**\r\n * A helper function for figuring out what kind of query has been stored.\r\n */\r\nfunction isDocumentQuery(dbQuery) {\r\n    return dbQuery.documents !== undefined;\r\n}\r\n/** Encodes a DbBundle to a BundleMetadata object. */\r\nfunction fromDbBundle(dbBundle) {\r\n    return {\r\n        id: dbBundle.bundleId,\r\n        createTime: fromDbTimestamp(dbBundle.createTime),\r\n        version: dbBundle.version\r\n    };\r\n}\r\n/** Encodes a BundleMetadata to a DbBundle. */\r\nfunction toDbBundle(metadata) {\r\n    return {\r\n        bundleId: metadata.id,\r\n        createTime: toDbTimestamp(fromVersion(metadata.createTime)),\r\n        version: metadata.version\r\n    };\r\n}\r\n/** Encodes a DbNamedQuery to a NamedQuery. */\r\nfunction fromDbNamedQuery(dbNamedQuery) {\r\n    return {\r\n        name: dbNamedQuery.name,\r\n        query: fromBundledQuery(dbNamedQuery.bundledQuery),\r\n        readTime: fromDbTimestamp(dbNamedQuery.readTime)\r\n    };\r\n}\r\n/** Encodes a NamedQuery from a bundle proto to a DbNamedQuery. */\r\nfunction toDbNamedQuery(query) {\r\n    return {\r\n        name: query.name,\r\n        readTime: toDbTimestamp(fromVersion(query.readTime)),\r\n        bundledQuery: query.bundledQuery\r\n    };\r\n}\r\n/**\r\n * Encodes a `BundledQuery` from bundle proto to a Query object.\r\n *\r\n * This reconstructs the original query used to build the bundle being loaded,\r\n * including features exists only in SDKs (for example: limit-to-last).\r\n */\r\nfunction fromBundledQuery(bundledQuery) {\r\n    const query = convertQueryTargetToQuery({\r\n        parent: bundledQuery.parent,\r\n        structuredQuery: bundledQuery.structuredQuery\r\n    });\r\n    if (bundledQuery.limitType === 'LAST') {\r\n        return queryWithLimit(query, query.limit, \"L\" /* Last */);\r\n    }\r\n    return query;\r\n}\r\n/** Encodes a NamedQuery proto object to a NamedQuery model object. */\r\nfunction fromProtoNamedQuery(namedQuery) {\r\n    return {\r\n        name: namedQuery.name,\r\n        query: fromBundledQuery(namedQuery.bundledQuery),\r\n        readTime: fromVersion(namedQuery.readTime)\r\n    };\r\n}\r\n/** Decodes a BundleMetadata proto into a BundleMetadata object. */\r\nfunction fromBundleMetadata(metadata) {\r\n    return {\r\n        id: metadata.id,\r\n        version: metadata.version,\r\n        createTime: fromVersion(metadata.createTime)\r\n    };\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass IndexedDbBundleCache {\r\n    getBundleMetadata(transaction, bundleId) {\r\n        return bundlesStore(transaction)\r\n            .get(bundleId)\r\n            .next(bundle => {\r\n            if (bundle) {\r\n                return fromDbBundle(bundle);\r\n            }\r\n            return undefined;\r\n        });\r\n    }\r\n    saveBundleMetadata(transaction, bundleMetadata) {\r\n        return bundlesStore(transaction).put(toDbBundle(bundleMetadata));\r\n    }\r\n    getNamedQuery(transaction, queryName) {\r\n        return namedQueriesStore(transaction)\r\n            .get(queryName)\r\n            .next(query => {\r\n            if (query) {\r\n                return fromDbNamedQuery(query);\r\n            }\r\n            return undefined;\r\n        });\r\n    }\r\n    saveNamedQuery(transaction, query) {\r\n        return namedQueriesStore(transaction).put(toDbNamedQuery(query));\r\n    }\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the bundles object store.\r\n */\r\nfunction bundlesStore(txn) {\r\n    return getStore(txn, DbBundle.store);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the namedQueries object store.\r\n */\r\nfunction namedQueriesStore(txn) {\r\n    return getStore(txn, DbNamedQuery.store);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An in-memory implementation of IndexManager.\r\n */\r\nclass MemoryIndexManager {\r\n    constructor() {\r\n        this.collectionParentIndex = new MemoryCollectionParentIndex();\r\n    }\r\n    addToCollectionParentIndex(transaction, collectionPath) {\r\n        this.collectionParentIndex.add(collectionPath);\r\n        return PersistencePromise.resolve();\r\n    }\r\n    getCollectionParents(transaction, collectionId) {\r\n        return PersistencePromise.resolve(this.collectionParentIndex.getEntries(collectionId));\r\n    }\r\n}\r\n/**\r\n * Internal implementation of the collection-parent index exposed by MemoryIndexManager.\r\n * Also used for in-memory caching by IndexedDbIndexManager and initial index population\r\n * in indexeddb_schema.ts\r\n */\r\nclass MemoryCollectionParentIndex {\r\n    constructor() {\r\n        this.index = {};\r\n    }\r\n    // Returns false if the entry already existed.\r\n    add(collectionPath) {\r\n        const collectionId = collectionPath.lastSegment();\r\n        const parentPath = collectionPath.popLast();\r\n        const existingParents = this.index[collectionId] ||\r\n            new SortedSet(ResourcePath.comparator);\r\n        const added = !existingParents.has(parentPath);\r\n        this.index[collectionId] = existingParents.add(parentPath);\r\n        return added;\r\n    }\r\n    has(collectionPath) {\r\n        const collectionId = collectionPath.lastSegment();\r\n        const parentPath = collectionPath.popLast();\r\n        const existingParents = this.index[collectionId];\r\n        return existingParents && existingParents.has(parentPath);\r\n    }\r\n    getEntries(collectionId) {\r\n        const parentPaths = this.index[collectionId] ||\r\n            new SortedSet(ResourcePath.comparator);\r\n        return parentPaths.toArray();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A persisted implementation of IndexManager.\r\n */\r\nclass IndexedDbIndexManager {\r\n    constructor() {\r\n        /**\r\n         * An in-memory copy of the index entries we've already written since the SDK\r\n         * launched. Used to avoid re-writing the same entry repeatedly.\r\n         *\r\n         * This is *NOT* a complete cache of what's in persistence and so can never be used to\r\n         * satisfy reads.\r\n         */\r\n        this.collectionParentsCache = new MemoryCollectionParentIndex();\r\n    }\r\n    /**\r\n     * Adds a new entry to the collection parent index.\r\n     *\r\n     * Repeated calls for the same collectionPath should be avoided within a\r\n     * transaction as IndexedDbIndexManager only caches writes once a transaction\r\n     * has been committed.\r\n     */\r\n    addToCollectionParentIndex(transaction, collectionPath) {\r\n        if (!this.collectionParentsCache.has(collectionPath)) {\r\n            const collectionId = collectionPath.lastSegment();\r\n            const parentPath = collectionPath.popLast();\r\n            transaction.addOnCommittedListener(() => {\r\n                // Add the collection to the in memory cache only if the transaction was\r\n                // successfully committed.\r\n                this.collectionParentsCache.add(collectionPath);\r\n            });\r\n            const collectionParent = {\r\n                collectionId,\r\n                parent: encodeResourcePath(parentPath)\r\n            };\r\n            return collectionParentsStore(transaction).put(collectionParent);\r\n        }\r\n        return PersistencePromise.resolve();\r\n    }\r\n    getCollectionParents(transaction, collectionId) {\r\n        const parentPaths = [];\r\n        const range = IDBKeyRange.bound([collectionId, ''], [immediateSuccessor(collectionId), ''], \r\n        /*lowerOpen=*/ false, \r\n        /*upperOpen=*/ true);\r\n        return collectionParentsStore(transaction)\r\n            .loadAll(range)\r\n            .next(entries => {\r\n            for (const entry of entries) {\r\n                // This collectionId guard shouldn't be necessary (and isn't as long\r\n                // as we're running in a real browser), but there's a bug in\r\n                // indexeddbshim that breaks our range in our tests running in node:\r\n                // https://github.com/axemclion/IndexedDBShim/issues/334\r\n                if (entry.collectionId !== collectionId) {\r\n                    break;\r\n                }\r\n                parentPaths.push(decodeResourcePath(entry.parent));\r\n            }\r\n            return parentPaths;\r\n        });\r\n    }\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the collectionParents\r\n * document store.\r\n */\r\nfunction collectionParentsStore(txn) {\r\n    return getStore(txn, DbCollectionParent.store);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Delete a mutation batch and the associated document mutations.\r\n * @returns A PersistencePromise of the document mutations that were removed.\r\n */\r\nfunction removeMutationBatch(txn, userId, batch) {\r\n    const mutationStore = txn.store(DbMutationBatch.store);\r\n    const indexTxn = txn.store(DbDocumentMutation.store);\r\n    const promises = [];\r\n    const range = IDBKeyRange.only(batch.batchId);\r\n    let numDeleted = 0;\r\n    const removePromise = mutationStore.iterate({ range }, (key, value, control) => {\r\n        numDeleted++;\r\n        return control.delete();\r\n    });\r\n    promises.push(removePromise.next(() => {\r\n        hardAssert(numDeleted === 1);\r\n    }));\r\n    const removedDocuments = [];\r\n    for (const mutation of batch.mutations) {\r\n        const indexKey = DbDocumentMutation.key(userId, mutation.key.path, batch.batchId);\r\n        promises.push(indexTxn.delete(indexKey));\r\n        removedDocuments.push(mutation.key);\r\n    }\r\n    return PersistencePromise.waitFor(promises).next(() => removedDocuments);\r\n}\r\n/**\r\n * Returns an approximate size for the given document.\r\n */\r\nfunction dbDocumentSize(doc) {\r\n    if (!doc) {\r\n        return 0;\r\n    }\r\n    let value;\r\n    if (doc.document) {\r\n        value = doc.document;\r\n    }\r\n    else if (doc.unknownDocument) {\r\n        value = doc.unknownDocument;\r\n    }\r\n    else if (doc.noDocument) {\r\n        value = doc.noDocument;\r\n    }\r\n    else {\r\n        throw fail();\r\n    }\r\n    return JSON.stringify(value).length;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** A mutation queue for a specific user, backed by IndexedDB. */\r\nclass IndexedDbMutationQueue {\r\n    constructor(\r\n    /**\r\n     * The normalized userId (e.g. null UID => \"\" userId) used to store /\r\n     * retrieve mutations.\r\n     */\r\n    userId, serializer, indexManager, referenceDelegate) {\r\n        this.userId = userId;\r\n        this.serializer = serializer;\r\n        this.indexManager = indexManager;\r\n        this.referenceDelegate = referenceDelegate;\r\n        /**\r\n         * Caches the document keys for pending mutation batches. If the mutation\r\n         * has been removed from IndexedDb, the cached value may continue to\r\n         * be used to retrieve the batch's document keys. To remove a cached value\r\n         * locally, `removeCachedMutationKeys()` should be invoked either directly\r\n         * or through `removeMutationBatches()`.\r\n         *\r\n         * With multi-tab, when the primary client acknowledges or rejects a mutation,\r\n         * this cache is used by secondary clients to invalidate the local\r\n         * view of the documents that were previously affected by the mutation.\r\n         */\r\n        // PORTING NOTE: Multi-tab only.\r\n        this.documentKeysByBatchId = {};\r\n    }\r\n    /**\r\n     * Creates a new mutation queue for the given user.\r\n     * @param user - The user for which to create a mutation queue.\r\n     * @param serializer - The serializer to use when persisting to IndexedDb.\r\n     */\r\n    static forUser(user, serializer, indexManager, referenceDelegate) {\r\n        // TODO(mcg): Figure out what constraints there are on userIDs\r\n        // In particular, are there any reserved characters? are empty ids allowed?\r\n        // For the moment store these together in the same mutations table assuming\r\n        // that empty userIDs aren't allowed.\r\n        hardAssert(user.uid !== '');\r\n        const userId = user.isAuthenticated() ? user.uid : '';\r\n        return new IndexedDbMutationQueue(userId, serializer, indexManager, referenceDelegate);\r\n    }\r\n    checkEmpty(transaction) {\r\n        let empty = true;\r\n        const range = IDBKeyRange.bound([this.userId, Number.NEGATIVE_INFINITY], [this.userId, Number.POSITIVE_INFINITY]);\r\n        return mutationsStore(transaction)\r\n            .iterate({ index: DbMutationBatch.userMutationsIndex, range }, (key, value, control) => {\r\n            empty = false;\r\n            control.done();\r\n        })\r\n            .next(() => empty);\r\n    }\r\n    addMutationBatch(transaction, localWriteTime, baseMutations, mutations) {\r\n        const documentStore = documentMutationsStore(transaction);\r\n        const mutationStore = mutationsStore(transaction);\r\n        // The IndexedDb implementation in Chrome (and Firefox) does not handle\r\n        // compound indices that include auto-generated keys correctly. To ensure\r\n        // that the index entry is added correctly in all browsers, we perform two\r\n        // writes: The first write is used to retrieve the next auto-generated Batch\r\n        // ID, and the second write populates the index and stores the actual\r\n        // mutation batch.\r\n        // See: https://bugs.chromium.org/p/chromium/issues/detail?id=701972\r\n        // We write an empty object to obtain key\r\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        return mutationStore.add({}).next(batchId => {\r\n            hardAssert(typeof batchId === 'number');\r\n            const batch = new MutationBatch(batchId, localWriteTime, baseMutations, mutations);\r\n            const dbBatch = toDbMutationBatch(this.serializer, this.userId, batch);\r\n            const promises = [];\r\n            let collectionParents = new SortedSet((l, r) => primitiveComparator(l.canonicalString(), r.canonicalString()));\r\n            for (const mutation of mutations) {\r\n                const indexKey = DbDocumentMutation.key(this.userId, mutation.key.path, batchId);\r\n                collectionParents = collectionParents.add(mutation.key.path.popLast());\r\n                promises.push(mutationStore.put(dbBatch));\r\n                promises.push(documentStore.put(indexKey, DbDocumentMutation.PLACEHOLDER));\r\n            }\r\n            collectionParents.forEach(parent => {\r\n                promises.push(this.indexManager.addToCollectionParentIndex(transaction, parent));\r\n            });\r\n            transaction.addOnCommittedListener(() => {\r\n                this.documentKeysByBatchId[batchId] = batch.keys();\r\n            });\r\n            return PersistencePromise.waitFor(promises).next(() => batch);\r\n        });\r\n    }\r\n    lookupMutationBatch(transaction, batchId) {\r\n        return mutationsStore(transaction)\r\n            .get(batchId)\r\n            .next(dbBatch => {\r\n            if (dbBatch) {\r\n                hardAssert(dbBatch.userId === this.userId);\r\n                return fromDbMutationBatch(this.serializer, dbBatch);\r\n            }\r\n            return null;\r\n        });\r\n    }\r\n    /**\r\n     * Returns the document keys for the mutation batch with the given batchId.\r\n     * For primary clients, this method returns `null` after\r\n     * `removeMutationBatches()` has been called. Secondary clients return a\r\n     * cached result until `removeCachedMutationKeys()` is invoked.\r\n     */\r\n    // PORTING NOTE: Multi-tab only.\r\n    lookupMutationKeys(transaction, batchId) {\r\n        if (this.documentKeysByBatchId[batchId]) {\r\n            return PersistencePromise.resolve(this.documentKeysByBatchId[batchId]);\r\n        }\r\n        else {\r\n            return this.lookupMutationBatch(transaction, batchId).next(batch => {\r\n                if (batch) {\r\n                    const keys = batch.keys();\r\n                    this.documentKeysByBatchId[batchId] = keys;\r\n                    return keys;\r\n                }\r\n                else {\r\n                    return null;\r\n                }\r\n            });\r\n        }\r\n    }\r\n    getNextMutationBatchAfterBatchId(transaction, batchId) {\r\n        const nextBatchId = batchId + 1;\r\n        const range = IDBKeyRange.lowerBound([this.userId, nextBatchId]);\r\n        let foundBatch = null;\r\n        return mutationsStore(transaction)\r\n            .iterate({ index: DbMutationBatch.userMutationsIndex, range }, (key, dbBatch, control) => {\r\n            if (dbBatch.userId === this.userId) {\r\n                hardAssert(dbBatch.batchId >= nextBatchId);\r\n                foundBatch = fromDbMutationBatch(this.serializer, dbBatch);\r\n            }\r\n            control.done();\r\n        })\r\n            .next(() => foundBatch);\r\n    }\r\n    getHighestUnacknowledgedBatchId(transaction) {\r\n        const range = IDBKeyRange.upperBound([\r\n            this.userId,\r\n            Number.POSITIVE_INFINITY\r\n        ]);\r\n        let batchId = BATCHID_UNKNOWN;\r\n        return mutationsStore(transaction)\r\n            .iterate({ index: DbMutationBatch.userMutationsIndex, range, reverse: true }, (key, dbBatch, control) => {\r\n            batchId = dbBatch.batchId;\r\n            control.done();\r\n        })\r\n            .next(() => batchId);\r\n    }\r\n    getAllMutationBatches(transaction) {\r\n        const range = IDBKeyRange.bound([this.userId, BATCHID_UNKNOWN], [this.userId, Number.POSITIVE_INFINITY]);\r\n        return mutationsStore(transaction)\r\n            .loadAll(DbMutationBatch.userMutationsIndex, range)\r\n            .next(dbBatches => dbBatches.map(dbBatch => fromDbMutationBatch(this.serializer, dbBatch)));\r\n    }\r\n    getAllMutationBatchesAffectingDocumentKey(transaction, documentKey) {\r\n        // Scan the document-mutation index starting with a prefix starting with\r\n        // the given documentKey.\r\n        const indexPrefix = DbDocumentMutation.prefixForPath(this.userId, documentKey.path);\r\n        const indexStart = IDBKeyRange.lowerBound(indexPrefix);\r\n        const results = [];\r\n        return documentMutationsStore(transaction)\r\n            .iterate({ range: indexStart }, (indexKey, _, control) => {\r\n            const [userID, encodedPath, batchId] = indexKey;\r\n            // Only consider rows matching exactly the specific key of\r\n            // interest. Note that because we order by path first, and we\r\n            // order terminators before path separators, we'll encounter all\r\n            // the index rows for documentKey contiguously. In particular, all\r\n            // the rows for documentKey will occur before any rows for\r\n            // documents nested in a subcollection beneath documentKey so we\r\n            // can stop as soon as we hit any such row.\r\n            const path = decodeResourcePath(encodedPath);\r\n            if (userID !== this.userId || !documentKey.path.isEqual(path)) {\r\n                control.done();\r\n                return;\r\n            }\r\n            // Look up the mutation batch in the store.\r\n            return mutationsStore(transaction)\r\n                .get(batchId)\r\n                .next(mutation => {\r\n                if (!mutation) {\r\n                    throw fail();\r\n                }\r\n                hardAssert(mutation.userId === this.userId);\r\n                results.push(fromDbMutationBatch(this.serializer, mutation));\r\n            });\r\n        })\r\n            .next(() => results);\r\n    }\r\n    getAllMutationBatchesAffectingDocumentKeys(transaction, documentKeys) {\r\n        let uniqueBatchIDs = new SortedSet(primitiveComparator);\r\n        const promises = [];\r\n        documentKeys.forEach(documentKey => {\r\n            const indexStart = DbDocumentMutation.prefixForPath(this.userId, documentKey.path);\r\n            const range = IDBKeyRange.lowerBound(indexStart);\r\n            const promise = documentMutationsStore(transaction).iterate({ range }, (indexKey, _, control) => {\r\n                const [userID, encodedPath, batchID] = indexKey;\r\n                // Only consider rows matching exactly the specific key of\r\n                // interest. Note that because we order by path first, and we\r\n                // order terminators before path separators, we'll encounter all\r\n                // the index rows for documentKey contiguously. In particular, all\r\n                // the rows for documentKey will occur before any rows for\r\n                // documents nested in a subcollection beneath documentKey so we\r\n                // can stop as soon as we hit any such row.\r\n                const path = decodeResourcePath(encodedPath);\r\n                if (userID !== this.userId || !documentKey.path.isEqual(path)) {\r\n                    control.done();\r\n                    return;\r\n                }\r\n                uniqueBatchIDs = uniqueBatchIDs.add(batchID);\r\n            });\r\n            promises.push(promise);\r\n        });\r\n        return PersistencePromise.waitFor(promises).next(() => this.lookupMutationBatches(transaction, uniqueBatchIDs));\r\n    }\r\n    getAllMutationBatchesAffectingQuery(transaction, query) {\r\n        const queryPath = query.path;\r\n        const immediateChildrenLength = queryPath.length + 1;\r\n        // TODO(mcg): Actually implement a single-collection query\r\n        //\r\n        // This is actually executing an ancestor query, traversing the whole\r\n        // subtree below the collection which can be horrifically inefficient for\r\n        // some structures. The right way to solve this is to implement the full\r\n        // value index, but that's not in the cards in the near future so this is\r\n        // the best we can do for the moment.\r\n        //\r\n        // Since we don't yet index the actual properties in the mutations, our\r\n        // current approach is to just return all mutation batches that affect\r\n        // documents in the collection being queried.\r\n        const indexPrefix = DbDocumentMutation.prefixForPath(this.userId, queryPath);\r\n        const indexStart = IDBKeyRange.lowerBound(indexPrefix);\r\n        // Collect up unique batchIDs encountered during a scan of the index. Use a\r\n        // SortedSet to accumulate batch IDs so they can be traversed in order in a\r\n        // scan of the main table.\r\n        let uniqueBatchIDs = new SortedSet(primitiveComparator);\r\n        return documentMutationsStore(transaction)\r\n            .iterate({ range: indexStart }, (indexKey, _, control) => {\r\n            const [userID, encodedPath, batchID] = indexKey;\r\n            const path = decodeResourcePath(encodedPath);\r\n            if (userID !== this.userId || !queryPath.isPrefixOf(path)) {\r\n                control.done();\r\n                return;\r\n            }\r\n            // Rows with document keys more than one segment longer than the\r\n            // query path can't be matches. For example, a query on 'rooms'\r\n            // can't match the document /rooms/abc/messages/xyx.\r\n            // TODO(mcg): we'll need a different scanner when we implement\r\n            // ancestor queries.\r\n            if (path.length !== immediateChildrenLength) {\r\n                return;\r\n            }\r\n            uniqueBatchIDs = uniqueBatchIDs.add(batchID);\r\n        })\r\n            .next(() => this.lookupMutationBatches(transaction, uniqueBatchIDs));\r\n    }\r\n    lookupMutationBatches(transaction, batchIDs) {\r\n        const results = [];\r\n        const promises = [];\r\n        // TODO(rockwood): Implement this using iterate.\r\n        batchIDs.forEach(batchId => {\r\n            promises.push(mutationsStore(transaction)\r\n                .get(batchId)\r\n                .next(mutation => {\r\n                if (mutation === null) {\r\n                    throw fail();\r\n                }\r\n                hardAssert(mutation.userId === this.userId);\r\n                results.push(fromDbMutationBatch(this.serializer, mutation));\r\n            }));\r\n        });\r\n        return PersistencePromise.waitFor(promises).next(() => results);\r\n    }\r\n    removeMutationBatch(transaction, batch) {\r\n        return removeMutationBatch(transaction.simpleDbTransaction, this.userId, batch).next(removedDocuments => {\r\n            transaction.addOnCommittedListener(() => {\r\n                this.removeCachedMutationKeys(batch.batchId);\r\n            });\r\n            return PersistencePromise.forEach(removedDocuments, (key) => {\r\n                return this.referenceDelegate.markPotentiallyOrphaned(transaction, key);\r\n            });\r\n        });\r\n    }\r\n    /**\r\n     * Clears the cached keys for a mutation batch. This method should be\r\n     * called by secondary clients after they process mutation updates.\r\n     *\r\n     * Note that this method does not have to be called from primary clients as\r\n     * the corresponding cache entries are cleared when an acknowledged or\r\n     * rejected batch is removed from the mutation queue.\r\n     */\r\n    // PORTING NOTE: Multi-tab only\r\n    removeCachedMutationKeys(batchId) {\r\n        delete this.documentKeysByBatchId[batchId];\r\n    }\r\n    performConsistencyCheck(txn) {\r\n        return this.checkEmpty(txn).next(empty => {\r\n            if (!empty) {\r\n                return PersistencePromise.resolve();\r\n            }\r\n            // Verify that there are no entries in the documentMutations index if\r\n            // the queue is empty.\r\n            const startRange = IDBKeyRange.lowerBound(DbDocumentMutation.prefixForUser(this.userId));\r\n            const danglingMutationReferences = [];\r\n            return documentMutationsStore(txn)\r\n                .iterate({ range: startRange }, (key, _, control) => {\r\n                const userID = key[0];\r\n                if (userID !== this.userId) {\r\n                    control.done();\r\n                    return;\r\n                }\r\n                else {\r\n                    const path = decodeResourcePath(key[1]);\r\n                    danglingMutationReferences.push(path);\r\n                }\r\n            })\r\n                .next(() => {\r\n                hardAssert(danglingMutationReferences.length === 0);\r\n            });\r\n        });\r\n    }\r\n    containsKey(txn, key) {\r\n        return mutationQueueContainsKey(txn, this.userId, key);\r\n    }\r\n    // PORTING NOTE: Multi-tab only (state is held in memory in other clients).\r\n    /** Returns the mutation queue's metadata from IndexedDb. */\r\n    getMutationQueueMetadata(transaction) {\r\n        return mutationQueuesStore(transaction)\r\n            .get(this.userId)\r\n            .next((metadata) => {\r\n            return (metadata ||\r\n                new DbMutationQueue(this.userId, BATCHID_UNKNOWN, \r\n                /*lastStreamToken=*/ ''));\r\n        });\r\n    }\r\n}\r\n/**\r\n * @returns true if the mutation queue for the given user contains a pending\r\n *         mutation for the given key.\r\n */\r\nfunction mutationQueueContainsKey(txn, userId, key) {\r\n    const indexKey = DbDocumentMutation.prefixForPath(userId, key.path);\r\n    const encodedPath = indexKey[1];\r\n    const startRange = IDBKeyRange.lowerBound(indexKey);\r\n    let containsKey = false;\r\n    return documentMutationsStore(txn)\r\n        .iterate({ range: startRange, keysOnly: true }, (key, value, control) => {\r\n        const [userID, keyPath, /*batchID*/ _] = key;\r\n        if (userID === userId && keyPath === encodedPath) {\r\n            containsKey = true;\r\n        }\r\n        control.done();\r\n    })\r\n        .next(() => containsKey);\r\n}\r\n/** Returns true if any mutation queue contains the given document. */\r\nfunction mutationQueuesContainKey(txn, docKey) {\r\n    let found = false;\r\n    return mutationQueuesStore(txn)\r\n        .iterateSerial(userId => {\r\n        return mutationQueueContainsKey(txn, userId, docKey).next(containsKey => {\r\n            if (containsKey) {\r\n                found = true;\r\n            }\r\n            return PersistencePromise.resolve(!containsKey);\r\n        });\r\n    })\r\n        .next(() => found);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the mutations object store.\r\n */\r\nfunction mutationsStore(txn) {\r\n    return getStore(txn, DbMutationBatch.store);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\r\n */\r\nfunction documentMutationsStore(txn) {\r\n    return getStore(txn, DbDocumentMutation.store);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\r\n */\r\nfunction mutationQueuesStore(txn) {\r\n    return getStore(txn, DbMutationQueue.store);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Offset to ensure non-overlapping target ids. */\r\nconst OFFSET = 2;\r\n/**\r\n * Generates monotonically increasing target IDs for sending targets to the\r\n * watch stream.\r\n *\r\n * The client constructs two generators, one for the target cache, and one for\r\n * for the sync engine (to generate limbo documents targets). These\r\n * generators produce non-overlapping IDs (by using even and odd IDs\r\n * respectively).\r\n *\r\n * By separating the target ID space, the query cache can generate target IDs\r\n * that persist across client restarts, while sync engine can independently\r\n * generate in-memory target IDs that are transient and can be reused after a\r\n * restart.\r\n */\r\nclass TargetIdGenerator {\r\n    constructor(lastId) {\r\n        this.lastId = lastId;\r\n    }\r\n    next() {\r\n        this.lastId += OFFSET;\r\n        return this.lastId;\r\n    }\r\n    static forTargetCache() {\r\n        // The target cache generator must return '2' in its first call to `next()`\r\n        // as there is no differentiation in the protocol layer between an unset\r\n        // number and the number '0'. If we were to sent a target with target ID\r\n        // '0', the backend would consider it unset and replace it with its own ID.\r\n        return new TargetIdGenerator(2 - OFFSET);\r\n    }\r\n    static forSyncEngine() {\r\n        // Sync engine assigns target IDs for limbo document detection.\r\n        return new TargetIdGenerator(1 - OFFSET);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass IndexedDbTargetCache {\r\n    constructor(referenceDelegate, serializer) {\r\n        this.referenceDelegate = referenceDelegate;\r\n        this.serializer = serializer;\r\n    }\r\n    // PORTING NOTE: We don't cache global metadata for the target cache, since\r\n    // some of it (in particular `highestTargetId`) can be modified by secondary\r\n    // tabs. We could perhaps be more granular (and e.g. still cache\r\n    // `lastRemoteSnapshotVersion` in memory) but for simplicity we currently go\r\n    // to IndexedDb whenever we need to read metadata. We can revisit if it turns\r\n    // out to have a meaningful performance impact.\r\n    allocateTargetId(transaction) {\r\n        return this.retrieveMetadata(transaction).next(metadata => {\r\n            const targetIdGenerator = new TargetIdGenerator(metadata.highestTargetId);\r\n            metadata.highestTargetId = targetIdGenerator.next();\r\n            return this.saveMetadata(transaction, metadata).next(() => metadata.highestTargetId);\r\n        });\r\n    }\r\n    getLastRemoteSnapshotVersion(transaction) {\r\n        return this.retrieveMetadata(transaction).next(metadata => {\r\n            return SnapshotVersion.fromTimestamp(new Timestamp(metadata.lastRemoteSnapshotVersion.seconds, metadata.lastRemoteSnapshotVersion.nanoseconds));\r\n        });\r\n    }\r\n    getHighestSequenceNumber(transaction) {\r\n        return this.retrieveMetadata(transaction).next(targetGlobal => targetGlobal.highestListenSequenceNumber);\r\n    }\r\n    setTargetsMetadata(transaction, highestListenSequenceNumber, lastRemoteSnapshotVersion) {\r\n        return this.retrieveMetadata(transaction).next(metadata => {\r\n            metadata.highestListenSequenceNumber = highestListenSequenceNumber;\r\n            if (lastRemoteSnapshotVersion) {\r\n                metadata.lastRemoteSnapshotVersion =\r\n                    lastRemoteSnapshotVersion.toTimestamp();\r\n            }\r\n            if (highestListenSequenceNumber > metadata.highestListenSequenceNumber) {\r\n                metadata.highestListenSequenceNumber = highestListenSequenceNumber;\r\n            }\r\n            return this.saveMetadata(transaction, metadata);\r\n        });\r\n    }\r\n    addTargetData(transaction, targetData) {\r\n        return this.saveTargetData(transaction, targetData).next(() => {\r\n            return this.retrieveMetadata(transaction).next(metadata => {\r\n                metadata.targetCount += 1;\r\n                this.updateMetadataFromTargetData(targetData, metadata);\r\n                return this.saveMetadata(transaction, metadata);\r\n            });\r\n        });\r\n    }\r\n    updateTargetData(transaction, targetData) {\r\n        return this.saveTargetData(transaction, targetData);\r\n    }\r\n    removeTargetData(transaction, targetData) {\r\n        return this.removeMatchingKeysForTargetId(transaction, targetData.targetId)\r\n            .next(() => targetsStore(transaction).delete(targetData.targetId))\r\n            .next(() => this.retrieveMetadata(transaction))\r\n            .next(metadata => {\r\n            hardAssert(metadata.targetCount > 0);\r\n            metadata.targetCount -= 1;\r\n            return this.saveMetadata(transaction, metadata);\r\n        });\r\n    }\r\n    /**\r\n     * Drops any targets with sequence number less than or equal to the upper bound, excepting those\r\n     * present in `activeTargetIds`. Document associations for the removed targets are also removed.\r\n     * Returns the number of targets removed.\r\n     */\r\n    removeTargets(txn, upperBound, activeTargetIds) {\r\n        let count = 0;\r\n        const promises = [];\r\n        return targetsStore(txn)\r\n            .iterate((key, value) => {\r\n            const targetData = fromDbTarget(value);\r\n            if (targetData.sequenceNumber <= upperBound &&\r\n                activeTargetIds.get(targetData.targetId) === null) {\r\n                count++;\r\n                promises.push(this.removeTargetData(txn, targetData));\r\n            }\r\n        })\r\n            .next(() => PersistencePromise.waitFor(promises))\r\n            .next(() => count);\r\n    }\r\n    /**\r\n     * Call provided function with each `TargetData` that we have cached.\r\n     */\r\n    forEachTarget(txn, f) {\r\n        return targetsStore(txn).iterate((key, value) => {\r\n            const targetData = fromDbTarget(value);\r\n            f(targetData);\r\n        });\r\n    }\r\n    retrieveMetadata(transaction) {\r\n        return globalTargetStore(transaction)\r\n            .get(DbTargetGlobal.key)\r\n            .next(metadata => {\r\n            hardAssert(metadata !== null);\r\n            return metadata;\r\n        });\r\n    }\r\n    saveMetadata(transaction, metadata) {\r\n        return globalTargetStore(transaction).put(DbTargetGlobal.key, metadata);\r\n    }\r\n    saveTargetData(transaction, targetData) {\r\n        return targetsStore(transaction).put(toDbTarget(this.serializer, targetData));\r\n    }\r\n    /**\r\n     * In-place updates the provided metadata to account for values in the given\r\n     * TargetData. Saving is done separately. Returns true if there were any\r\n     * changes to the metadata.\r\n     */\r\n    updateMetadataFromTargetData(targetData, metadata) {\r\n        let updated = false;\r\n        if (targetData.targetId > metadata.highestTargetId) {\r\n            metadata.highestTargetId = targetData.targetId;\r\n            updated = true;\r\n        }\r\n        if (targetData.sequenceNumber > metadata.highestListenSequenceNumber) {\r\n            metadata.highestListenSequenceNumber = targetData.sequenceNumber;\r\n            updated = true;\r\n        }\r\n        return updated;\r\n    }\r\n    getTargetCount(transaction) {\r\n        return this.retrieveMetadata(transaction).next(metadata => metadata.targetCount);\r\n    }\r\n    getTargetData(transaction, target) {\r\n        // Iterating by the canonicalId may yield more than one result because\r\n        // canonicalId values are not required to be unique per target. This query\r\n        // depends on the queryTargets index to be efficient.\r\n        const canonicalId = canonifyTarget(target);\r\n        const range = IDBKeyRange.bound([canonicalId, Number.NEGATIVE_INFINITY], [canonicalId, Number.POSITIVE_INFINITY]);\r\n        let result = null;\r\n        return targetsStore(transaction)\r\n            .iterate({ range, index: DbTarget.queryTargetsIndexName }, (key, value, control) => {\r\n            const found = fromDbTarget(value);\r\n            // After finding a potential match, check that the target is\r\n            // actually equal to the requested target.\r\n            if (targetEquals(target, found.target)) {\r\n                result = found;\r\n                control.done();\r\n            }\r\n        })\r\n            .next(() => result);\r\n    }\r\n    addMatchingKeys(txn, keys, targetId) {\r\n        // PORTING NOTE: The reverse index (documentsTargets) is maintained by\r\n        // IndexedDb.\r\n        const promises = [];\r\n        const store = documentTargetStore(txn);\r\n        keys.forEach(key => {\r\n            const path = encodeResourcePath(key.path);\r\n            promises.push(store.put(new DbTargetDocument(targetId, path)));\r\n            promises.push(this.referenceDelegate.addReference(txn, targetId, key));\r\n        });\r\n        return PersistencePromise.waitFor(promises);\r\n    }\r\n    removeMatchingKeys(txn, keys, targetId) {\r\n        // PORTING NOTE: The reverse index (documentsTargets) is maintained by\r\n        // IndexedDb.\r\n        const store = documentTargetStore(txn);\r\n        return PersistencePromise.forEach(keys, (key) => {\r\n            const path = encodeResourcePath(key.path);\r\n            return PersistencePromise.waitFor([\r\n                store.delete([targetId, path]),\r\n                this.referenceDelegate.removeReference(txn, targetId, key)\r\n            ]);\r\n        });\r\n    }\r\n    removeMatchingKeysForTargetId(txn, targetId) {\r\n        const store = documentTargetStore(txn);\r\n        const range = IDBKeyRange.bound([targetId], [targetId + 1], \r\n        /*lowerOpen=*/ false, \r\n        /*upperOpen=*/ true);\r\n        return store.delete(range);\r\n    }\r\n    getMatchingKeysForTargetId(txn, targetId) {\r\n        const range = IDBKeyRange.bound([targetId], [targetId + 1], \r\n        /*lowerOpen=*/ false, \r\n        /*upperOpen=*/ true);\r\n        const store = documentTargetStore(txn);\r\n        let result = documentKeySet();\r\n        return store\r\n            .iterate({ range, keysOnly: true }, (key, _, control) => {\r\n            const path = decodeResourcePath(key[1]);\r\n            const docKey = new DocumentKey(path);\r\n            result = result.add(docKey);\r\n        })\r\n            .next(() => result);\r\n    }\r\n    containsKey(txn, key) {\r\n        const path = encodeResourcePath(key.path);\r\n        const range = IDBKeyRange.bound([path], [immediateSuccessor(path)], \r\n        /*lowerOpen=*/ false, \r\n        /*upperOpen=*/ true);\r\n        let count = 0;\r\n        return documentTargetStore(txn)\r\n            .iterate({\r\n            index: DbTargetDocument.documentTargetsIndex,\r\n            keysOnly: true,\r\n            range\r\n        }, ([targetId, path], _, control) => {\r\n            // Having a sentinel row for a document does not count as containing that document;\r\n            // For the target cache, containing the document means the document is part of some\r\n            // target.\r\n            if (targetId !== 0) {\r\n                count++;\r\n                control.done();\r\n            }\r\n        })\r\n            .next(() => count > 0);\r\n    }\r\n    /**\r\n     * Looks up a TargetData entry by target ID.\r\n     *\r\n     * @param targetId - The target ID of the TargetData entry to look up.\r\n     * @returns The cached TargetData entry, or null if the cache has no entry for\r\n     * the target.\r\n     */\r\n    // PORTING NOTE: Multi-tab only.\r\n    getTargetDataForTarget(transaction, targetId) {\r\n        return targetsStore(transaction)\r\n            .get(targetId)\r\n            .next(found => {\r\n            if (found) {\r\n                return fromDbTarget(found);\r\n            }\r\n            else {\r\n                return null;\r\n            }\r\n        });\r\n    }\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the queries object store.\r\n */\r\nfunction targetsStore(txn) {\r\n    return getStore(txn, DbTarget.store);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the target globals object store.\r\n */\r\nfunction globalTargetStore(txn) {\r\n    return getStore(txn, DbTargetGlobal.store);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the document target object store.\r\n */\r\nfunction documentTargetStore(txn) {\r\n    return getStore(txn, DbTargetDocument.store);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Verifies the error thrown by a LocalStore operation. If a LocalStore\r\n * operation fails because the primary lease has been taken by another client,\r\n * we ignore the error (the persistence layer will immediately call\r\n * `applyPrimaryLease` to propagate the primary state change). All other errors\r\n * are re-thrown.\r\n *\r\n * @param err - An error returned by a LocalStore operation.\r\n * @returns A Promise that resolves after we recovered, or the original error.\r\n */\r\nasync function ignoreIfPrimaryLeaseLoss(err) {\r\n    if (err.code === Code.FAILED_PRECONDITION &&\r\n        err.message === PRIMARY_LEASE_LOST_ERROR_MSG) {\r\n        logDebug('LocalStore', 'Unexpectedly lost primary lease');\r\n    }\r\n    else {\r\n        throw err;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst GC_DID_NOT_RUN = {\r\n    didRun: false,\r\n    sequenceNumbersCollected: 0,\r\n    targetsRemoved: 0,\r\n    documentsRemoved: 0\r\n};\r\nconst LRU_COLLECTION_DISABLED = -1;\r\nconst LRU_DEFAULT_CACHE_SIZE_BYTES = 40 * 1024 * 1024;\r\nclass LruParams {\r\n    constructor(\r\n    // When we attempt to collect, we will only do so if the cache size is greater than this\r\n    // threshold. Passing `COLLECTION_DISABLED` here will cause collection to always be skipped.\r\n    cacheSizeCollectionThreshold, \r\n    // The percentage of sequence numbers that we will attempt to collect\r\n    percentileToCollect, \r\n    // A cap on the total number of sequence numbers that will be collected. This prevents\r\n    // us from collecting a huge number of sequence numbers if the cache has grown very large.\r\n    maximumSequenceNumbersToCollect) {\r\n        this.cacheSizeCollectionThreshold = cacheSizeCollectionThreshold;\r\n        this.percentileToCollect = percentileToCollect;\r\n        this.maximumSequenceNumbersToCollect = maximumSequenceNumbersToCollect;\r\n    }\r\n    static withCacheSize(cacheSize) {\r\n        return new LruParams(cacheSize, LruParams.DEFAULT_COLLECTION_PERCENTILE, LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT);\r\n    }\r\n}\r\nLruParams.DEFAULT_COLLECTION_PERCENTILE = 10;\r\nLruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT = 1000;\r\nLruParams.DEFAULT = new LruParams(LRU_DEFAULT_CACHE_SIZE_BYTES, LruParams.DEFAULT_COLLECTION_PERCENTILE, LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT);\r\nLruParams.DISABLED = new LruParams(LRU_COLLECTION_DISABLED, 0, 0);\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$e = 'LruGarbageCollector';\r\nconst LRU_MINIMUM_CACHE_SIZE_BYTES = 1 * 1024 * 1024;\r\n/** How long we wait to try running LRU GC after SDK initialization. */\r\nconst INITIAL_GC_DELAY_MS = 1 * 60 * 1000;\r\n/** Minimum amount of time between GC checks, after the first one. */\r\nconst REGULAR_GC_DELAY_MS = 5 * 60 * 1000;\r\nfunction bufferEntryComparator([aSequence, aIndex], [bSequence, bIndex]) {\r\n    const seqCmp = primitiveComparator(aSequence, bSequence);\r\n    if (seqCmp === 0) {\r\n        // This order doesn't matter, but we can bias against churn by sorting\r\n        // entries created earlier as less than newer entries.\r\n        return primitiveComparator(aIndex, bIndex);\r\n    }\r\n    else {\r\n        return seqCmp;\r\n    }\r\n}\r\n/**\r\n * Used to calculate the nth sequence number. Keeps a rolling buffer of the\r\n * lowest n values passed to `addElement`, and finally reports the largest of\r\n * them in `maxValue`.\r\n */\r\nclass RollingSequenceNumberBuffer {\r\n    constructor(maxElements) {\r\n        this.maxElements = maxElements;\r\n        this.buffer = new SortedSet(bufferEntryComparator);\r\n        this.previousIndex = 0;\r\n    }\r\n    nextIndex() {\r\n        return ++this.previousIndex;\r\n    }\r\n    addElement(sequenceNumber) {\r\n        const entry = [sequenceNumber, this.nextIndex()];\r\n        if (this.buffer.size < this.maxElements) {\r\n            this.buffer = this.buffer.add(entry);\r\n        }\r\n        else {\r\n            const highestValue = this.buffer.last();\r\n            if (bufferEntryComparator(entry, highestValue) < 0) {\r\n                this.buffer = this.buffer.delete(highestValue).add(entry);\r\n            }\r\n        }\r\n    }\r\n    get maxValue() {\r\n        // Guaranteed to be non-empty. If we decide we are not collecting any\r\n        // sequence numbers, nthSequenceNumber below short-circuits. If we have\r\n        // decided that we are collecting n sequence numbers, it's because n is some\r\n        // percentage of the existing sequence numbers. That means we should never\r\n        // be in a situation where we are collecting sequence numbers but don't\r\n        // actually have any.\r\n        return this.buffer.last()[0];\r\n    }\r\n}\r\n/**\r\n * This class is responsible for the scheduling of LRU garbage collection. It handles checking\r\n * whether or not GC is enabled, as well as which delay to use before the next run.\r\n */\r\nclass LruScheduler {\r\n    constructor(garbageCollector, asyncQueue) {\r\n        this.garbageCollector = garbageCollector;\r\n        this.asyncQueue = asyncQueue;\r\n        this.hasRun = false;\r\n        this.gcTask = null;\r\n    }\r\n    start(localStore) {\r\n        if (this.garbageCollector.params.cacheSizeCollectionThreshold !==\r\n            LRU_COLLECTION_DISABLED) {\r\n            this.scheduleGC(localStore);\r\n        }\r\n    }\r\n    stop() {\r\n        if (this.gcTask) {\r\n            this.gcTask.cancel();\r\n            this.gcTask = null;\r\n        }\r\n    }\r\n    get started() {\r\n        return this.gcTask !== null;\r\n    }\r\n    scheduleGC(localStore) {\r\n        const delay = this.hasRun ? REGULAR_GC_DELAY_MS : INITIAL_GC_DELAY_MS;\r\n        logDebug('LruGarbageCollector', `Garbage collection scheduled in ${delay}ms`);\r\n        this.gcTask = this.asyncQueue.enqueueAfterDelay(\"lru_garbage_collection\" /* LruGarbageCollection */, delay, async () => {\r\n            this.gcTask = null;\r\n            this.hasRun = true;\r\n            try {\r\n                await localStore.collectGarbage(this.garbageCollector);\r\n            }\r\n            catch (e) {\r\n                if (isIndexedDbTransactionError(e)) {\r\n                    logDebug(LOG_TAG$e, 'Ignoring IndexedDB error during garbage collection: ', e);\r\n                }\r\n                else {\r\n                    await ignoreIfPrimaryLeaseLoss(e);\r\n                }\r\n            }\r\n            await this.scheduleGC(localStore);\r\n        });\r\n    }\r\n}\r\n/** Implements the steps for LRU garbage collection. */\r\nclass LruGarbageCollectorImpl {\r\n    constructor(delegate, params) {\r\n        this.delegate = delegate;\r\n        this.params = params;\r\n    }\r\n    calculateTargetCount(txn, percentile) {\r\n        return this.delegate.getSequenceNumberCount(txn).next(targetCount => {\r\n            return Math.floor((percentile / 100.0) * targetCount);\r\n        });\r\n    }\r\n    nthSequenceNumber(txn, n) {\r\n        if (n === 0) {\r\n            return PersistencePromise.resolve(ListenSequence.INVALID);\r\n        }\r\n        const buffer = new RollingSequenceNumberBuffer(n);\r\n        return this.delegate\r\n            .forEachTarget(txn, target => buffer.addElement(target.sequenceNumber))\r\n            .next(() => {\r\n            return this.delegate.forEachOrphanedDocumentSequenceNumber(txn, sequenceNumber => buffer.addElement(sequenceNumber));\r\n        })\r\n            .next(() => buffer.maxValue);\r\n    }\r\n    removeTargets(txn, upperBound, activeTargetIds) {\r\n        return this.delegate.removeTargets(txn, upperBound, activeTargetIds);\r\n    }\r\n    removeOrphanedDocuments(txn, upperBound) {\r\n        return this.delegate.removeOrphanedDocuments(txn, upperBound);\r\n    }\r\n    collect(txn, activeTargetIds) {\r\n        if (this.params.cacheSizeCollectionThreshold === LRU_COLLECTION_DISABLED) {\r\n            logDebug('LruGarbageCollector', 'Garbage collection skipped; disabled');\r\n            return PersistencePromise.resolve(GC_DID_NOT_RUN);\r\n        }\r\n        return this.getCacheSize(txn).next(cacheSize => {\r\n            if (cacheSize < this.params.cacheSizeCollectionThreshold) {\r\n                logDebug('LruGarbageCollector', `Garbage collection skipped; Cache size ${cacheSize} ` +\r\n                    `is lower than threshold ${this.params.cacheSizeCollectionThreshold}`);\r\n                return GC_DID_NOT_RUN;\r\n            }\r\n            else {\r\n                return this.runGarbageCollection(txn, activeTargetIds);\r\n            }\r\n        });\r\n    }\r\n    getCacheSize(txn) {\r\n        return this.delegate.getCacheSize(txn);\r\n    }\r\n    runGarbageCollection(txn, activeTargetIds) {\r\n        let upperBoundSequenceNumber;\r\n        let sequenceNumbersToCollect, targetsRemoved;\r\n        // Timestamps for various pieces of the process\r\n        let countedTargetsTs, foundUpperBoundTs, removedTargetsTs, removedDocumentsTs;\r\n        const startTs = Date.now();\r\n        return this.calculateTargetCount(txn, this.params.percentileToCollect)\r\n            .next(sequenceNumbers => {\r\n            // Cap at the configured max\r\n            if (sequenceNumbers > this.params.maximumSequenceNumbersToCollect) {\r\n                logDebug('LruGarbageCollector', 'Capping sequence numbers to collect down ' +\r\n                    `to the maximum of ${this.params.maximumSequenceNumbersToCollect} ` +\r\n                    `from ${sequenceNumbers}`);\r\n                sequenceNumbersToCollect =\r\n                    this.params.maximumSequenceNumbersToCollect;\r\n            }\r\n            else {\r\n                sequenceNumbersToCollect = sequenceNumbers;\r\n            }\r\n            countedTargetsTs = Date.now();\r\n            return this.nthSequenceNumber(txn, sequenceNumbersToCollect);\r\n        })\r\n            .next(upperBound => {\r\n            upperBoundSequenceNumber = upperBound;\r\n            foundUpperBoundTs = Date.now();\r\n            return this.removeTargets(txn, upperBoundSequenceNumber, activeTargetIds);\r\n        })\r\n            .next(numTargetsRemoved => {\r\n            targetsRemoved = numTargetsRemoved;\r\n            removedTargetsTs = Date.now();\r\n            return this.removeOrphanedDocuments(txn, upperBoundSequenceNumber);\r\n        })\r\n            .next(documentsRemoved => {\r\n            removedDocumentsTs = Date.now();\r\n            if (getLogLevel() <= LogLevel.DEBUG) {\r\n                const desc = 'LRU Garbage Collection\\n' +\r\n                    `\\tCounted targets in ${countedTargetsTs - startTs}ms\\n` +\r\n                    `\\tDetermined least recently used ${sequenceNumbersToCollect} in ` +\r\n                    `${foundUpperBoundTs - countedTargetsTs}ms\\n` +\r\n                    `\\tRemoved ${targetsRemoved} targets in ` +\r\n                    `${removedTargetsTs - foundUpperBoundTs}ms\\n` +\r\n                    `\\tRemoved ${documentsRemoved} documents in ` +\r\n                    `${removedDocumentsTs - removedTargetsTs}ms\\n` +\r\n                    `Total Duration: ${removedDocumentsTs - startTs}ms`;\r\n                logDebug('LruGarbageCollector', desc);\r\n            }\r\n            return PersistencePromise.resolve({\r\n                didRun: true,\r\n                sequenceNumbersCollected: sequenceNumbersToCollect,\r\n                targetsRemoved,\r\n                documentsRemoved\r\n            });\r\n        });\r\n    }\r\n}\r\nfunction newLruGarbageCollector(delegate, params) {\r\n    return new LruGarbageCollectorImpl(delegate, params);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Provides LRU functionality for IndexedDB persistence. */\r\nclass IndexedDbLruDelegateImpl {\r\n    constructor(db, params) {\r\n        this.db = db;\r\n        this.garbageCollector = newLruGarbageCollector(this, params);\r\n    }\r\n    getSequenceNumberCount(txn) {\r\n        const docCountPromise = this.orphanedDocumentCount(txn);\r\n        const targetCountPromise = this.db.getTargetCache().getTargetCount(txn);\r\n        return targetCountPromise.next(targetCount => docCountPromise.next(docCount => targetCount + docCount));\r\n    }\r\n    orphanedDocumentCount(txn) {\r\n        let orphanedCount = 0;\r\n        return this.forEachOrphanedDocumentSequenceNumber(txn, _ => {\r\n            orphanedCount++;\r\n        }).next(() => orphanedCount);\r\n    }\r\n    forEachTarget(txn, f) {\r\n        return this.db.getTargetCache().forEachTarget(txn, f);\r\n    }\r\n    forEachOrphanedDocumentSequenceNumber(txn, f) {\r\n        return this.forEachOrphanedDocument(txn, (docKey, sequenceNumber) => f(sequenceNumber));\r\n    }\r\n    addReference(txn, targetId, key) {\r\n        return writeSentinelKey(txn, key);\r\n    }\r\n    removeReference(txn, targetId, key) {\r\n        return writeSentinelKey(txn, key);\r\n    }\r\n    removeTargets(txn, upperBound, activeTargetIds) {\r\n        return this.db.getTargetCache().removeTargets(txn, upperBound, activeTargetIds);\r\n    }\r\n    markPotentiallyOrphaned(txn, key) {\r\n        return writeSentinelKey(txn, key);\r\n    }\r\n    /**\r\n     * Returns true if anything would prevent this document from being garbage\r\n     * collected, given that the document in question is not present in any\r\n     * targets and has a sequence number less than or equal to the upper bound for\r\n     * the collection run.\r\n     */\r\n    isPinned(txn, docKey) {\r\n        return mutationQueuesContainKey(txn, docKey);\r\n    }\r\n    removeOrphanedDocuments(txn, upperBound) {\r\n        const documentCache = this.db.getRemoteDocumentCache();\r\n        const changeBuffer = documentCache.newChangeBuffer();\r\n        const promises = [];\r\n        let documentCount = 0;\r\n        const iteration = this.forEachOrphanedDocument(txn, (docKey, sequenceNumber) => {\r\n            if (sequenceNumber <= upperBound) {\r\n                const p = this.isPinned(txn, docKey).next(isPinned => {\r\n                    if (!isPinned) {\r\n                        documentCount++;\r\n                        // Our size accounting requires us to read all documents before\r\n                        // removing them.\r\n                        return changeBuffer.getEntry(txn, docKey).next(() => {\r\n                            changeBuffer.removeEntry(docKey);\r\n                            return documentTargetStore(txn).delete(sentinelKey$1(docKey));\r\n                        });\r\n                    }\r\n                });\r\n                promises.push(p);\r\n            }\r\n        });\r\n        return iteration\r\n            .next(() => PersistencePromise.waitFor(promises))\r\n            .next(() => changeBuffer.apply(txn))\r\n            .next(() => documentCount);\r\n    }\r\n    removeTarget(txn, targetData) {\r\n        const updated = targetData.withSequenceNumber(txn.currentSequenceNumber);\r\n        return this.db.getTargetCache().updateTargetData(txn, updated);\r\n    }\r\n    updateLimboDocument(txn, key) {\r\n        return writeSentinelKey(txn, key);\r\n    }\r\n    /**\r\n     * Call provided function for each document in the cache that is 'orphaned'. Orphaned\r\n     * means not a part of any target, so the only entry in the target-document index for\r\n     * that document will be the sentinel row (targetId 0), which will also have the sequence\r\n     * number for the last time the document was accessed.\r\n     */\r\n    forEachOrphanedDocument(txn, f) {\r\n        const store = documentTargetStore(txn);\r\n        let nextToReport = ListenSequence.INVALID;\r\n        let nextPath;\r\n        return store\r\n            .iterate({\r\n            index: DbTargetDocument.documentTargetsIndex\r\n        }, ([targetId, docKey], { path, sequenceNumber }) => {\r\n            if (targetId === 0) {\r\n                // if nextToReport is valid, report it, this is a new key so the\r\n                // last one must not be a member of any targets.\r\n                if (nextToReport !== ListenSequence.INVALID) {\r\n                    f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\r\n                }\r\n                // set nextToReport to be this sequence number. It's the next one we\r\n                // might report, if we don't find any targets for this document.\r\n                // Note that the sequence number must be defined when the targetId\r\n                // is 0.\r\n                nextToReport = sequenceNumber;\r\n                nextPath = path;\r\n            }\r\n            else {\r\n                // set nextToReport to be invalid, we know we don't need to report\r\n                // this one since we found a target for it.\r\n                nextToReport = ListenSequence.INVALID;\r\n            }\r\n        })\r\n            .next(() => {\r\n            // Since we report sequence numbers after getting to the next key, we\r\n            // need to check if the last key we iterated over was an orphaned\r\n            // document and report it.\r\n            if (nextToReport !== ListenSequence.INVALID) {\r\n                f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\r\n            }\r\n        });\r\n    }\r\n    getCacheSize(txn) {\r\n        return this.db.getRemoteDocumentCache().getSize(txn);\r\n    }\r\n}\r\nfunction sentinelKey$1(key) {\r\n    return [0, encodeResourcePath(key.path)];\r\n}\r\n/**\r\n * @returns A value suitable for writing a sentinel row in the target-document\r\n * store.\r\n */\r\nfunction sentinelRow(key, sequenceNumber) {\r\n    return new DbTargetDocument(0, encodeResourcePath(key.path), sequenceNumber);\r\n}\r\nfunction writeSentinelKey(txn, key) {\r\n    return documentTargetStore(txn).put(sentinelRow(key, txn.currentSequenceNumber));\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A map implementation that uses objects as keys. Objects must have an\r\n * associated equals function and must be immutable. Entries in the map are\r\n * stored together with the key being produced from the mapKeyFn. This map\r\n * automatically handles collisions of keys.\r\n */\r\nclass ObjectMap {\r\n    constructor(mapKeyFn, equalsFn) {\r\n        this.mapKeyFn = mapKeyFn;\r\n        this.equalsFn = equalsFn;\r\n        /**\r\n         * The inner map for a key/value pair. Due to the possibility of collisions we\r\n         * keep a list of entries that we do a linear search through to find an actual\r\n         * match. Note that collisions should be rare, so we still expect near\r\n         * constant time lookups in practice.\r\n         */\r\n        this.inner = {};\r\n    }\r\n    /** Get a value for this key, or undefined if it does not exist. */\r\n    get(key) {\r\n        const id = this.mapKeyFn(key);\r\n        const matches = this.inner[id];\r\n        if (matches === undefined) {\r\n            return undefined;\r\n        }\r\n        for (const [otherKey, value] of matches) {\r\n            if (this.equalsFn(otherKey, key)) {\r\n                return value;\r\n            }\r\n        }\r\n        return undefined;\r\n    }\r\n    has(key) {\r\n        return this.get(key) !== undefined;\r\n    }\r\n    /** Put this key and value in the map. */\r\n    set(key, value) {\r\n        const id = this.mapKeyFn(key);\r\n        const matches = this.inner[id];\r\n        if (matches === undefined) {\r\n            this.inner[id] = [[key, value]];\r\n            return;\r\n        }\r\n        for (let i = 0; i < matches.length; i++) {\r\n            if (this.equalsFn(matches[i][0], key)) {\r\n                matches[i] = [key, value];\r\n                return;\r\n            }\r\n        }\r\n        matches.push([key, value]);\r\n    }\r\n    /**\r\n     * Remove this key from the map. Returns a boolean if anything was deleted.\r\n     */\r\n    delete(key) {\r\n        const id = this.mapKeyFn(key);\r\n        const matches = this.inner[id];\r\n        if (matches === undefined) {\r\n            return false;\r\n        }\r\n        for (let i = 0; i < matches.length; i++) {\r\n            if (this.equalsFn(matches[i][0], key)) {\r\n                if (matches.length === 1) {\r\n                    delete this.inner[id];\r\n                }\r\n                else {\r\n                    matches.splice(i, 1);\r\n                }\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n    forEach(fn) {\r\n        forEach(this.inner, (_, entries) => {\r\n            for (const [k, v] of entries) {\r\n                fn(k, v);\r\n            }\r\n        });\r\n    }\r\n    isEmpty() {\r\n        return isEmpty(this.inner);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An in-memory buffer of entries to be written to a RemoteDocumentCache.\r\n * It can be used to batch up a set of changes to be written to the cache, but\r\n * additionally supports reading entries back with the `getEntry()` method,\r\n * falling back to the underlying RemoteDocumentCache if no entry is\r\n * buffered.\r\n *\r\n * Entries added to the cache *must* be read first. This is to facilitate\r\n * calculating the size delta of the pending changes.\r\n *\r\n * PORTING NOTE: This class was implemented then removed from other platforms.\r\n * If byte-counting ends up being needed on the other platforms, consider\r\n * porting this class as part of that implementation work.\r\n */\r\nclass RemoteDocumentChangeBuffer {\r\n    constructor() {\r\n        // A mapping of document key to the new cache entry that should be written (or null if any\r\n        // existing cache entry should be removed).\r\n        this.changes = new ObjectMap(key => key.toString(), (l, r) => l.isEqual(r));\r\n        this.changesApplied = false;\r\n    }\r\n    getReadTime(key) {\r\n        const change = this.changes.get(key);\r\n        if (change) {\r\n            return change.readTime;\r\n        }\r\n        return SnapshotVersion.min();\r\n    }\r\n    /**\r\n     * Buffers a `RemoteDocumentCache.addEntry()` call.\r\n     *\r\n     * You can only modify documents that have already been retrieved via\r\n     * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\r\n     */\r\n    addEntry(document, readTime) {\r\n        this.assertNotApplied();\r\n        this.changes.set(document.key, { document, readTime });\r\n    }\r\n    /**\r\n     * Buffers a `RemoteDocumentCache.removeEntry()` call.\r\n     *\r\n     * You can only remove documents that have already been retrieved via\r\n     * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\r\n     */\r\n    removeEntry(key, readTime = null) {\r\n        this.assertNotApplied();\r\n        this.changes.set(key, {\r\n            document: MutableDocument.newInvalidDocument(key),\r\n            readTime\r\n        });\r\n    }\r\n    /**\r\n     * Looks up an entry in the cache. The buffered changes will first be checked,\r\n     * and if no buffered change applies, this will forward to\r\n     * `RemoteDocumentCache.getEntry()`.\r\n     *\r\n     * @param transaction - The transaction in which to perform any persistence\r\n     *     operations.\r\n     * @param documentKey - The key of the entry to look up.\r\n     * @returns The cached document or an invalid document if we have nothing\r\n     * cached.\r\n     */\r\n    getEntry(transaction, documentKey) {\r\n        this.assertNotApplied();\r\n        const bufferedEntry = this.changes.get(documentKey);\r\n        if (bufferedEntry !== undefined) {\r\n            return PersistencePromise.resolve(bufferedEntry.document);\r\n        }\r\n        else {\r\n            return this.getFromCache(transaction, documentKey);\r\n        }\r\n    }\r\n    /**\r\n     * Looks up several entries in the cache, forwarding to\r\n     * `RemoteDocumentCache.getEntry()`.\r\n     *\r\n     * @param transaction - The transaction in which to perform any persistence\r\n     *     operations.\r\n     * @param documentKeys - The keys of the entries to look up.\r\n     * @returns A map of cached documents, indexed by key. If an entry cannot be\r\n     *     found, the corresponding key will be mapped to an invalid document.\r\n     */\r\n    getEntries(transaction, documentKeys) {\r\n        return this.getAllFromCache(transaction, documentKeys);\r\n    }\r\n    /**\r\n     * Applies buffered changes to the underlying RemoteDocumentCache, using\r\n     * the provided transaction.\r\n     */\r\n    apply(transaction) {\r\n        this.assertNotApplied();\r\n        this.changesApplied = true;\r\n        return this.applyChanges(transaction);\r\n    }\r\n    /** Helper to assert this.changes is not null  */\r\n    assertNotApplied() {\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * The RemoteDocumentCache for IndexedDb. To construct, invoke\r\n * `newIndexedDbRemoteDocumentCache()`.\r\n */\r\nclass IndexedDbRemoteDocumentCacheImpl {\r\n    /**\r\n     * @param serializer - The document serializer.\r\n     * @param indexManager - The query indexes that need to be maintained.\r\n     */\r\n    constructor(serializer, indexManager) {\r\n        this.serializer = serializer;\r\n        this.indexManager = indexManager;\r\n    }\r\n    /**\r\n     * Adds the supplied entries to the cache.\r\n     *\r\n     * All calls of `addEntry` are required to go through the RemoteDocumentChangeBuffer\r\n     * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\r\n     */\r\n    addEntry(transaction, key, doc) {\r\n        const documentStore = remoteDocumentsStore(transaction);\r\n        return documentStore.put(dbKey(key), doc);\r\n    }\r\n    /**\r\n     * Removes a document from the cache.\r\n     *\r\n     * All calls of `removeEntry`  are required to go through the RemoteDocumentChangeBuffer\r\n     * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\r\n     */\r\n    removeEntry(transaction, documentKey) {\r\n        const store = remoteDocumentsStore(transaction);\r\n        const key = dbKey(documentKey);\r\n        return store.delete(key);\r\n    }\r\n    /**\r\n     * Updates the current cache size.\r\n     *\r\n     * Callers to `addEntry()` and `removeEntry()` *must* call this afterwards to update the\r\n     * cache's metadata.\r\n     */\r\n    updateMetadata(transaction, sizeDelta) {\r\n        return this.getMetadata(transaction).next(metadata => {\r\n            metadata.byteSize += sizeDelta;\r\n            return this.setMetadata(transaction, metadata);\r\n        });\r\n    }\r\n    getEntry(transaction, documentKey) {\r\n        return remoteDocumentsStore(transaction)\r\n            .get(dbKey(documentKey))\r\n            .next(dbRemoteDoc => {\r\n            return this.maybeDecodeDocument(documentKey, dbRemoteDoc);\r\n        });\r\n    }\r\n    /**\r\n     * Looks up an entry in the cache.\r\n     *\r\n     * @param documentKey - The key of the entry to look up.\r\n     * @returns The cached document entry and its size.\r\n     */\r\n    getSizedEntry(transaction, documentKey) {\r\n        return remoteDocumentsStore(transaction)\r\n            .get(dbKey(documentKey))\r\n            .next(dbRemoteDoc => {\r\n            const doc = this.maybeDecodeDocument(documentKey, dbRemoteDoc);\r\n            return {\r\n                document: doc,\r\n                size: dbDocumentSize(dbRemoteDoc)\r\n            };\r\n        });\r\n    }\r\n    getEntries(transaction, documentKeys) {\r\n        let results = mutableDocumentMap();\r\n        return this.forEachDbEntry(transaction, documentKeys, (key, dbRemoteDoc) => {\r\n            const doc = this.maybeDecodeDocument(key, dbRemoteDoc);\r\n            results = results.insert(key, doc);\r\n        }).next(() => results);\r\n    }\r\n    /**\r\n     * Looks up several entries in the cache.\r\n     *\r\n     * @param documentKeys - The set of keys entries to look up.\r\n     * @returns A map of documents indexed by key and a map of sizes indexed by\r\n     *     key (zero if the document does not exist).\r\n     */\r\n    getSizedEntries(transaction, documentKeys) {\r\n        let results = mutableDocumentMap();\r\n        let sizeMap = new SortedMap(DocumentKey.comparator);\r\n        return this.forEachDbEntry(transaction, documentKeys, (key, dbRemoteDoc) => {\r\n            const doc = this.maybeDecodeDocument(key, dbRemoteDoc);\r\n            results = results.insert(key, doc);\r\n            sizeMap = sizeMap.insert(key, dbDocumentSize(dbRemoteDoc));\r\n        }).next(() => {\r\n            return { documents: results, sizeMap };\r\n        });\r\n    }\r\n    forEachDbEntry(transaction, documentKeys, callback) {\r\n        if (documentKeys.isEmpty()) {\r\n            return PersistencePromise.resolve();\r\n        }\r\n        const range = IDBKeyRange.bound(documentKeys.first().path.toArray(), documentKeys.last().path.toArray());\r\n        const keyIter = documentKeys.getIterator();\r\n        let nextKey = keyIter.getNext();\r\n        return remoteDocumentsStore(transaction)\r\n            .iterate({ range }, (potentialKeyRaw, dbRemoteDoc, control) => {\r\n            const potentialKey = DocumentKey.fromSegments(potentialKeyRaw);\r\n            // Go through keys not found in cache.\r\n            while (nextKey && DocumentKey.comparator(nextKey, potentialKey) < 0) {\r\n                callback(nextKey, null);\r\n                nextKey = keyIter.getNext();\r\n            }\r\n            if (nextKey && nextKey.isEqual(potentialKey)) {\r\n                // Key found in cache.\r\n                callback(nextKey, dbRemoteDoc);\r\n                nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\r\n            }\r\n            // Skip to the next key (if there is one).\r\n            if (nextKey) {\r\n                control.skip(nextKey.path.toArray());\r\n            }\r\n            else {\r\n                control.done();\r\n            }\r\n        })\r\n            .next(() => {\r\n            // The rest of the keys are not in the cache. One case where `iterate`\r\n            // above won't go through them is when the cache is empty.\r\n            while (nextKey) {\r\n                callback(nextKey, null);\r\n                nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\r\n            }\r\n        });\r\n    }\r\n    getDocumentsMatchingQuery(transaction, query, sinceReadTime) {\r\n        let results = mutableDocumentMap();\r\n        const immediateChildrenPathLength = query.path.length + 1;\r\n        const iterationOptions = {};\r\n        if (sinceReadTime.isEqual(SnapshotVersion.min())) {\r\n            // Documents are ordered by key, so we can use a prefix scan to narrow\r\n            // down the documents we need to match the query against.\r\n            const startKey = query.path.toArray();\r\n            iterationOptions.range = IDBKeyRange.lowerBound(startKey);\r\n        }\r\n        else {\r\n            // Execute an index-free query and filter by read time. This is safe\r\n            // since all document changes to queries that have a\r\n            // lastLimboFreeSnapshotVersion (`sinceReadTime`) have a read time set.\r\n            const collectionKey = query.path.toArray();\r\n            const readTimeKey = toDbTimestampKey(sinceReadTime);\r\n            iterationOptions.range = IDBKeyRange.lowerBound([collectionKey, readTimeKey], \r\n            /* open= */ true);\r\n            iterationOptions.index = DbRemoteDocument.collectionReadTimeIndex;\r\n        }\r\n        return remoteDocumentsStore(transaction)\r\n            .iterate(iterationOptions, (key, dbRemoteDoc, control) => {\r\n            // The query is actually returning any path that starts with the query\r\n            // path prefix which may include documents in subcollections. For\r\n            // example, a query on 'rooms' will return rooms/abc/messages/xyx but we\r\n            // shouldn't match it. Fix this by discarding rows with document keys\r\n            // more than one segment longer than the query path.\r\n            if (key.length !== immediateChildrenPathLength) {\r\n                return;\r\n            }\r\n            const document = fromDbRemoteDocument(this.serializer, dbRemoteDoc);\r\n            if (!query.path.isPrefixOf(document.key.path)) {\r\n                control.done();\r\n            }\r\n            else if (queryMatches(query, document)) {\r\n                results = results.insert(document.key, document);\r\n            }\r\n        })\r\n            .next(() => results);\r\n    }\r\n    newChangeBuffer(options) {\r\n        return new IndexedDbRemoteDocumentChangeBuffer(this, !!options && options.trackRemovals);\r\n    }\r\n    getSize(txn) {\r\n        return this.getMetadata(txn).next(metadata => metadata.byteSize);\r\n    }\r\n    getMetadata(txn) {\r\n        return documentGlobalStore(txn)\r\n            .get(DbRemoteDocumentGlobal.key)\r\n            .next(metadata => {\r\n            hardAssert(!!metadata);\r\n            return metadata;\r\n        });\r\n    }\r\n    setMetadata(txn, metadata) {\r\n        return documentGlobalStore(txn).put(DbRemoteDocumentGlobal.key, metadata);\r\n    }\r\n    /**\r\n     * Decodes `remoteDoc` and returns the document (or null, if the document\r\n     * corresponds to the format used for sentinel deletes).\r\n     */\r\n    maybeDecodeDocument(documentKey, dbRemoteDoc) {\r\n        if (dbRemoteDoc) {\r\n            const doc = fromDbRemoteDocument(this.serializer, dbRemoteDoc);\r\n            // Whether the document is a sentinel removal and should only be used in the\r\n            // `getNewDocumentChanges()`\r\n            const isSentinelRemoval = doc.isNoDocument() && doc.version.isEqual(SnapshotVersion.min());\r\n            if (!isSentinelRemoval) {\r\n                return doc;\r\n            }\r\n        }\r\n        return MutableDocument.newInvalidDocument(documentKey);\r\n    }\r\n}\r\n/**\r\n * Creates a new IndexedDbRemoteDocumentCache.\r\n *\r\n * @param serializer - The document serializer.\r\n * @param indexManager - The query indexes that need to be maintained.\r\n */\r\nfunction newIndexedDbRemoteDocumentCache(serializer, indexManager) {\r\n    return new IndexedDbRemoteDocumentCacheImpl(serializer, indexManager);\r\n}\r\n/**\r\n * Returns the set of documents that have changed since the specified read\r\n * time.\r\n */\r\n// PORTING NOTE: This is only used for multi-tab synchronization.\r\nfunction remoteDocumentCacheGetNewDocumentChanges(remoteDocumentCache, transaction, sinceReadTime) {\r\n    const remoteDocumentCacheImpl = debugCast(remoteDocumentCache);\r\n    let changedDocs = mutableDocumentMap();\r\n    let lastReadTime = toDbTimestampKey(sinceReadTime);\r\n    const documentsStore = remoteDocumentsStore(transaction);\r\n    const range = IDBKeyRange.lowerBound(lastReadTime, true);\r\n    return documentsStore\r\n        .iterate({ index: DbRemoteDocument.readTimeIndex, range }, (_, dbRemoteDoc) => {\r\n        // Unlike `getEntry()` and others, `getNewDocumentChanges()` parses\r\n        // the documents directly since we want to keep sentinel deletes.\r\n        const doc = fromDbRemoteDocument(remoteDocumentCacheImpl.serializer, dbRemoteDoc);\r\n        changedDocs = changedDocs.insert(doc.key, doc);\r\n        lastReadTime = dbRemoteDoc.readTime;\r\n    })\r\n        .next(() => {\r\n        return {\r\n            changedDocs,\r\n            readTime: fromDbTimestampKey(lastReadTime)\r\n        };\r\n    });\r\n}\r\n/**\r\n * Returns the read time of the most recently read document in the cache, or\r\n * SnapshotVersion.min() if not available.\r\n */\r\n// PORTING NOTE: This is only used for multi-tab synchronization.\r\nfunction remoteDocumentCacheGetLastReadTime(transaction) {\r\n    const documentsStore = remoteDocumentsStore(transaction);\r\n    // If there are no existing entries, we return SnapshotVersion.min().\r\n    let readTime = SnapshotVersion.min();\r\n    return documentsStore\r\n        .iterate({ index: DbRemoteDocument.readTimeIndex, reverse: true }, (key, dbRemoteDoc, control) => {\r\n        if (dbRemoteDoc.readTime) {\r\n            readTime = fromDbTimestampKey(dbRemoteDoc.readTime);\r\n        }\r\n        control.done();\r\n    })\r\n        .next(() => readTime);\r\n}\r\n/**\r\n * Handles the details of adding and updating documents in the IndexedDbRemoteDocumentCache.\r\n *\r\n * Unlike the MemoryRemoteDocumentChangeBuffer, the IndexedDb implementation computes the size\r\n * delta for all submitted changes. This avoids having to re-read all documents from IndexedDb\r\n * when we apply the changes.\r\n */\r\nclass IndexedDbRemoteDocumentChangeBuffer extends RemoteDocumentChangeBuffer {\r\n    /**\r\n     * @param documentCache - The IndexedDbRemoteDocumentCache to apply the changes to.\r\n     * @param trackRemovals - Whether to create sentinel deletes that can be tracked by\r\n     * `getNewDocumentChanges()`.\r\n     */\r\n    constructor(documentCache, trackRemovals) {\r\n        super();\r\n        this.documentCache = documentCache;\r\n        this.trackRemovals = trackRemovals;\r\n        // A map of document sizes prior to applying the changes in this buffer.\r\n        this.documentSizes = new ObjectMap(key => key.toString(), (l, r) => l.isEqual(r));\r\n    }\r\n    applyChanges(transaction) {\r\n        const promises = [];\r\n        let sizeDelta = 0;\r\n        let collectionParents = new SortedSet((l, r) => primitiveComparator(l.canonicalString(), r.canonicalString()));\r\n        this.changes.forEach((key, documentChange) => {\r\n            const previousSize = this.documentSizes.get(key);\r\n            if (documentChange.document.isValidDocument()) {\r\n                const doc = toDbRemoteDocument(this.documentCache.serializer, documentChange.document, this.getReadTime(key));\r\n                collectionParents = collectionParents.add(key.path.popLast());\r\n                const size = dbDocumentSize(doc);\r\n                sizeDelta += size - previousSize;\r\n                promises.push(this.documentCache.addEntry(transaction, key, doc));\r\n            }\r\n            else {\r\n                sizeDelta -= previousSize;\r\n                if (this.trackRemovals) {\r\n                    // In order to track removals, we store a \"sentinel delete\" in the\r\n                    // RemoteDocumentCache. This entry is represented by a NoDocument\r\n                    // with a version of 0 and ignored by `maybeDecodeDocument()` but\r\n                    // preserved in `getNewDocumentChanges()`.\r\n                    const deletedDoc = toDbRemoteDocument(this.documentCache.serializer, MutableDocument.newNoDocument(key, SnapshotVersion.min()), this.getReadTime(key));\r\n                    promises.push(this.documentCache.addEntry(transaction, key, deletedDoc));\r\n                }\r\n                else {\r\n                    promises.push(this.documentCache.removeEntry(transaction, key));\r\n                }\r\n            }\r\n        });\r\n        collectionParents.forEach(parent => {\r\n            promises.push(this.documentCache.indexManager.addToCollectionParentIndex(transaction, parent));\r\n        });\r\n        promises.push(this.documentCache.updateMetadata(transaction, sizeDelta));\r\n        return PersistencePromise.waitFor(promises);\r\n    }\r\n    getFromCache(transaction, documentKey) {\r\n        // Record the size of everything we load from the cache so we can compute a delta later.\r\n        return this.documentCache\r\n            .getSizedEntry(transaction, documentKey)\r\n            .next(getResult => {\r\n            this.documentSizes.set(documentKey, getResult.size);\r\n            return getResult.document;\r\n        });\r\n    }\r\n    getAllFromCache(transaction, documentKeys) {\r\n        // Record the size of everything we load from the cache so we can compute\r\n        // a delta later.\r\n        return this.documentCache\r\n            .getSizedEntries(transaction, documentKeys)\r\n            .next(({ documents, sizeMap }) => {\r\n            // Note: `getAllFromCache` returns two maps instead of a single map from\r\n            // keys to `DocumentSizeEntry`s. This is to allow returning the\r\n            // `MutableDocumentMap` directly, without a conversion.\r\n            sizeMap.forEach((documentKey, size) => {\r\n                this.documentSizes.set(documentKey, size);\r\n            });\r\n            return documents;\r\n        });\r\n    }\r\n}\r\nfunction documentGlobalStore(txn) {\r\n    return getStore(txn, DbRemoteDocumentGlobal.store);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the remoteDocuments object store.\r\n */\r\nfunction remoteDocumentsStore(txn) {\r\n    return getStore(txn, DbRemoteDocument.store);\r\n}\r\nfunction dbKey(docKey) {\r\n    return docKey.path.toArray();\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Performs database creation and schema upgrades. */\r\nclass SchemaConverter {\r\n    constructor(serializer) {\r\n        this.serializer = serializer;\r\n    }\r\n    /**\r\n     * Performs database creation and schema upgrades.\r\n     *\r\n     * Note that in production, this method is only ever used to upgrade the schema\r\n     * to SCHEMA_VERSION. Different values of toVersion are only used for testing\r\n     * and local feature development.\r\n     */\r\n    createOrUpgrade(db, txn, fromVersion, toVersion) {\r\n        hardAssert(fromVersion < toVersion &&\r\n            fromVersion >= 0 &&\r\n            toVersion <= SCHEMA_VERSION);\r\n        const simpleDbTransaction = new SimpleDbTransaction('createOrUpgrade', txn);\r\n        if (fromVersion < 1 && toVersion >= 1) {\r\n            createPrimaryClientStore(db);\r\n            createMutationQueue(db);\r\n            createQueryCache(db);\r\n            createRemoteDocumentCache(db);\r\n        }\r\n        // Migration 2 to populate the targetGlobal object no longer needed since\r\n        // migration 3 unconditionally clears it.\r\n        let p = PersistencePromise.resolve();\r\n        if (fromVersion < 3 && toVersion >= 3) {\r\n            // Brand new clients don't need to drop and recreate--only clients that\r\n            // potentially have corrupt data.\r\n            if (fromVersion !== 0) {\r\n                dropQueryCache(db);\r\n                createQueryCache(db);\r\n            }\r\n            p = p.next(() => writeEmptyTargetGlobalEntry(simpleDbTransaction));\r\n        }\r\n        if (fromVersion < 4 && toVersion >= 4) {\r\n            if (fromVersion !== 0) {\r\n                // Schema version 3 uses auto-generated keys to generate globally unique\r\n                // mutation batch IDs (this was previously ensured internally by the\r\n                // client). To migrate to the new schema, we have to read all mutations\r\n                // and write them back out. We preserve the existing batch IDs to guarantee\r\n                // consistency with other object stores. Any further mutation batch IDs will\r\n                // be auto-generated.\r\n                p = p.next(() => upgradeMutationBatchSchemaAndMigrateData(db, simpleDbTransaction));\r\n            }\r\n            p = p.next(() => {\r\n                createClientMetadataStore(db);\r\n            });\r\n        }\r\n        if (fromVersion < 5 && toVersion >= 5) {\r\n            p = p.next(() => this.removeAcknowledgedMutations(simpleDbTransaction));\r\n        }\r\n        if (fromVersion < 6 && toVersion >= 6) {\r\n            p = p.next(() => {\r\n                createDocumentGlobalStore(db);\r\n                return this.addDocumentGlobal(simpleDbTransaction);\r\n            });\r\n        }\r\n        if (fromVersion < 7 && toVersion >= 7) {\r\n            p = p.next(() => this.ensureSequenceNumbers(simpleDbTransaction));\r\n        }\r\n        if (fromVersion < 8 && toVersion >= 8) {\r\n            p = p.next(() => this.createCollectionParentIndex(db, simpleDbTransaction));\r\n        }\r\n        if (fromVersion < 9 && toVersion >= 9) {\r\n            p = p.next(() => {\r\n                // Multi-Tab used to manage its own changelog, but this has been moved\r\n                // to the DbRemoteDocument object store itself. Since the previous change\r\n                // log only contained transient data, we can drop its object store.\r\n                dropRemoteDocumentChangesStore(db);\r\n                createRemoteDocumentReadTimeIndex(txn);\r\n            });\r\n        }\r\n        if (fromVersion < 10 && toVersion >= 10) {\r\n            p = p.next(() => this.rewriteCanonicalIds(simpleDbTransaction));\r\n        }\r\n        if (fromVersion < 11 && toVersion >= 11) {\r\n            p = p.next(() => {\r\n                createBundlesStore(db);\r\n                createNamedQueriesStore(db);\r\n            });\r\n        }\r\n        return p;\r\n    }\r\n    addDocumentGlobal(txn) {\r\n        let byteCount = 0;\r\n        return txn\r\n            .store(DbRemoteDocument.store)\r\n            .iterate((_, doc) => {\r\n            byteCount += dbDocumentSize(doc);\r\n        })\r\n            .next(() => {\r\n            const metadata = new DbRemoteDocumentGlobal(byteCount);\r\n            return txn\r\n                .store(DbRemoteDocumentGlobal.store)\r\n                .put(DbRemoteDocumentGlobal.key, metadata);\r\n        });\r\n    }\r\n    removeAcknowledgedMutations(txn) {\r\n        const queuesStore = txn.store(DbMutationQueue.store);\r\n        const mutationsStore = txn.store(DbMutationBatch.store);\r\n        return queuesStore.loadAll().next(queues => {\r\n            return PersistencePromise.forEach(queues, (queue) => {\r\n                const range = IDBKeyRange.bound([queue.userId, BATCHID_UNKNOWN], [queue.userId, queue.lastAcknowledgedBatchId]);\r\n                return mutationsStore\r\n                    .loadAll(DbMutationBatch.userMutationsIndex, range)\r\n                    .next(dbBatches => {\r\n                    return PersistencePromise.forEach(dbBatches, (dbBatch) => {\r\n                        hardAssert(dbBatch.userId === queue.userId);\r\n                        const batch = fromDbMutationBatch(this.serializer, dbBatch);\r\n                        return removeMutationBatch(txn, queue.userId, batch).next(() => { });\r\n                    });\r\n                });\r\n            });\r\n        });\r\n    }\r\n    /**\r\n     * Ensures that every document in the remote document cache has a corresponding sentinel row\r\n     * with a sequence number. Missing rows are given the most recently used sequence number.\r\n     */\r\n    ensureSequenceNumbers(txn) {\r\n        const documentTargetStore = txn.store(DbTargetDocument.store);\r\n        const documentsStore = txn.store(DbRemoteDocument.store);\r\n        const globalTargetStore = txn.store(DbTargetGlobal.store);\r\n        return globalTargetStore.get(DbTargetGlobal.key).next(metadata => {\r\n            const writeSentinelKey = (path) => {\r\n                return documentTargetStore.put(new DbTargetDocument(0, encodeResourcePath(path), metadata.highestListenSequenceNumber));\r\n            };\r\n            const promises = [];\r\n            return documentsStore\r\n                .iterate((key, doc) => {\r\n                const path = new ResourcePath(key);\r\n                const docSentinelKey = sentinelKey(path);\r\n                promises.push(documentTargetStore.get(docSentinelKey).next(maybeSentinel => {\r\n                    if (!maybeSentinel) {\r\n                        return writeSentinelKey(path);\r\n                    }\r\n                    else {\r\n                        return PersistencePromise.resolve();\r\n                    }\r\n                }));\r\n            })\r\n                .next(() => PersistencePromise.waitFor(promises));\r\n        });\r\n    }\r\n    createCollectionParentIndex(db, txn) {\r\n        // Create the index.\r\n        db.createObjectStore(DbCollectionParent.store, {\r\n            keyPath: DbCollectionParent.keyPath\r\n        });\r\n        const collectionParentsStore = txn.store(DbCollectionParent.store);\r\n        // Helper to add an index entry iff we haven't already written it.\r\n        const cache = new MemoryCollectionParentIndex();\r\n        const addEntry = (collectionPath) => {\r\n            if (cache.add(collectionPath)) {\r\n                const collectionId = collectionPath.lastSegment();\r\n                const parentPath = collectionPath.popLast();\r\n                return collectionParentsStore.put({\r\n                    collectionId,\r\n                    parent: encodeResourcePath(parentPath)\r\n                });\r\n            }\r\n        };\r\n        // Index existing remote documents.\r\n        return txn\r\n            .store(DbRemoteDocument.store)\r\n            .iterate({ keysOnly: true }, (pathSegments, _) => {\r\n            const path = new ResourcePath(pathSegments);\r\n            return addEntry(path.popLast());\r\n        })\r\n            .next(() => {\r\n            // Index existing mutations.\r\n            return txn\r\n                .store(DbDocumentMutation.store)\r\n                .iterate({ keysOnly: true }, ([userID, encodedPath, batchId], _) => {\r\n                const path = decodeResourcePath(encodedPath);\r\n                return addEntry(path.popLast());\r\n            });\r\n        });\r\n    }\r\n    rewriteCanonicalIds(txn) {\r\n        const targetStore = txn.store(DbTarget.store);\r\n        return targetStore.iterate((key, originalDbTarget) => {\r\n            const originalTargetData = fromDbTarget(originalDbTarget);\r\n            const updatedDbTarget = toDbTarget(this.serializer, originalTargetData);\r\n            return targetStore.put(updatedDbTarget);\r\n        });\r\n    }\r\n}\r\nfunction sentinelKey(path) {\r\n    return [0, encodeResourcePath(path)];\r\n}\r\nfunction createPrimaryClientStore(db) {\r\n    db.createObjectStore(DbPrimaryClient.store);\r\n}\r\nfunction createMutationQueue(db) {\r\n    db.createObjectStore(DbMutationQueue.store, {\r\n        keyPath: DbMutationQueue.keyPath\r\n    });\r\n    const mutationBatchesStore = db.createObjectStore(DbMutationBatch.store, {\r\n        keyPath: DbMutationBatch.keyPath,\r\n        autoIncrement: true\r\n    });\r\n    mutationBatchesStore.createIndex(DbMutationBatch.userMutationsIndex, DbMutationBatch.userMutationsKeyPath, { unique: true });\r\n    db.createObjectStore(DbDocumentMutation.store);\r\n}\r\n/**\r\n * Upgrade function to migrate the 'mutations' store from V1 to V3. Loads\r\n * and rewrites all data.\r\n */\r\nfunction upgradeMutationBatchSchemaAndMigrateData(db, txn) {\r\n    const v1MutationsStore = txn.store(DbMutationBatch.store);\r\n    return v1MutationsStore.loadAll().next(existingMutations => {\r\n        db.deleteObjectStore(DbMutationBatch.store);\r\n        const mutationsStore = db.createObjectStore(DbMutationBatch.store, {\r\n            keyPath: DbMutationBatch.keyPath,\r\n            autoIncrement: true\r\n        });\r\n        mutationsStore.createIndex(DbMutationBatch.userMutationsIndex, DbMutationBatch.userMutationsKeyPath, { unique: true });\r\n        const v3MutationsStore = txn.store(DbMutationBatch.store);\r\n        const writeAll = existingMutations.map(mutation => v3MutationsStore.put(mutation));\r\n        return PersistencePromise.waitFor(writeAll);\r\n    });\r\n}\r\nfunction createRemoteDocumentCache(db) {\r\n    db.createObjectStore(DbRemoteDocument.store);\r\n}\r\nfunction createDocumentGlobalStore(db) {\r\n    db.createObjectStore(DbRemoteDocumentGlobal.store);\r\n}\r\nfunction createQueryCache(db) {\r\n    const targetDocumentsStore = db.createObjectStore(DbTargetDocument.store, {\r\n        keyPath: DbTargetDocument.keyPath\r\n    });\r\n    targetDocumentsStore.createIndex(DbTargetDocument.documentTargetsIndex, DbTargetDocument.documentTargetsKeyPath, { unique: true });\r\n    const targetStore = db.createObjectStore(DbTarget.store, {\r\n        keyPath: DbTarget.keyPath\r\n    });\r\n    // NOTE: This is unique only because the TargetId is the suffix.\r\n    targetStore.createIndex(DbTarget.queryTargetsIndexName, DbTarget.queryTargetsKeyPath, { unique: true });\r\n    db.createObjectStore(DbTargetGlobal.store);\r\n}\r\nfunction dropQueryCache(db) {\r\n    db.deleteObjectStore(DbTargetDocument.store);\r\n    db.deleteObjectStore(DbTarget.store);\r\n    db.deleteObjectStore(DbTargetGlobal.store);\r\n}\r\nfunction dropRemoteDocumentChangesStore(db) {\r\n    if (db.objectStoreNames.contains('remoteDocumentChanges')) {\r\n        db.deleteObjectStore('remoteDocumentChanges');\r\n    }\r\n}\r\n/**\r\n * Creates the target global singleton row.\r\n *\r\n * @param txn - The version upgrade transaction for indexeddb\r\n */\r\nfunction writeEmptyTargetGlobalEntry(txn) {\r\n    const globalStore = txn.store(DbTargetGlobal.store);\r\n    const metadata = new DbTargetGlobal(\r\n    /*highestTargetId=*/ 0, \r\n    /*lastListenSequenceNumber=*/ 0, SnapshotVersion.min().toTimestamp(), \r\n    /*targetCount=*/ 0);\r\n    return globalStore.put(DbTargetGlobal.key, metadata);\r\n}\r\n/**\r\n * Creates indices on the RemoteDocuments store used for both multi-tab\r\n * and Index-Free queries.\r\n */\r\nfunction createRemoteDocumentReadTimeIndex(txn) {\r\n    const remoteDocumentStore = txn.objectStore(DbRemoteDocument.store);\r\n    remoteDocumentStore.createIndex(DbRemoteDocument.readTimeIndex, DbRemoteDocument.readTimeIndexPath, { unique: false });\r\n    remoteDocumentStore.createIndex(DbRemoteDocument.collectionReadTimeIndex, DbRemoteDocument.collectionReadTimeIndexPath, { unique: false });\r\n}\r\nfunction createClientMetadataStore(db) {\r\n    db.createObjectStore(DbClientMetadata.store, {\r\n        keyPath: DbClientMetadata.keyPath\r\n    });\r\n}\r\nfunction createBundlesStore(db) {\r\n    db.createObjectStore(DbBundle.store, {\r\n        keyPath: DbBundle.keyPath\r\n    });\r\n}\r\nfunction createNamedQueriesStore(db) {\r\n    db.createObjectStore(DbNamedQuery.store, {\r\n        keyPath: DbNamedQuery.keyPath\r\n    });\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$d = 'IndexedDbPersistence';\r\n/**\r\n * Oldest acceptable age in milliseconds for client metadata before the client\r\n * is considered inactive and its associated data is garbage collected.\r\n */\r\nconst MAX_CLIENT_AGE_MS = 30 * 60 * 1000; // 30 minutes\r\n/**\r\n * Oldest acceptable metadata age for clients that may participate in the\r\n * primary lease election. Clients that have not updated their client metadata\r\n * within 5 seconds are not eligible to receive a primary lease.\r\n */\r\nconst MAX_PRIMARY_ELIGIBLE_AGE_MS = 5000;\r\n/**\r\n * The interval at which clients will update their metadata, including\r\n * refreshing their primary lease if held or potentially trying to acquire it if\r\n * not held.\r\n *\r\n * Primary clients may opportunistically refresh their metadata earlier\r\n * if they're already performing an IndexedDB operation.\r\n */\r\nconst CLIENT_METADATA_REFRESH_INTERVAL_MS = 4000;\r\n/** User-facing error when the primary lease is required but not available. */\r\nconst PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG = 'Failed to obtain exclusive access to the persistence layer. To allow ' +\r\n    'shared access, multi-tab synchronization has to be enabled in all tabs. ' +\r\n    'If you are using `experimentalForceOwningTab:true`, make sure that only ' +\r\n    'one tab has persistence enabled at any given time.';\r\nconst UNSUPPORTED_PLATFORM_ERROR_MSG = 'This platform is either missing IndexedDB or is known to have ' +\r\n    'an incomplete implementation. Offline persistence has been disabled.';\r\n// The format of the LocalStorage key that stores zombied client is:\r\n//     firestore_zombie_<persistence_prefix>_<instance_key>\r\nconst ZOMBIED_CLIENTS_KEY_PREFIX = 'firestore_zombie';\r\n/**\r\n * The name of the main (and currently only) IndexedDB database. This name is\r\n * appended to the prefix provided to the IndexedDbPersistence constructor.\r\n */\r\nconst MAIN_DATABASE = 'main';\r\n/**\r\n * An IndexedDB-backed instance of Persistence. Data is stored persistently\r\n * across sessions.\r\n *\r\n * On Web only, the Firestore SDKs support shared access to its persistence\r\n * layer. This allows multiple browser tabs to read and write to IndexedDb and\r\n * to synchronize state even without network connectivity. Shared access is\r\n * currently optional and not enabled unless all clients invoke\r\n * `enablePersistence()` with `{synchronizeTabs:true}`.\r\n *\r\n * In multi-tab mode, if multiple clients are active at the same time, the SDK\r\n * will designate one client as the \u201Cprimary client\u201D. An effort is made to pick\r\n * a visible, network-connected and active client, and this client is\r\n * responsible for letting other clients know about its presence. The primary\r\n * client writes a unique client-generated identifier (the client ID) to\r\n * IndexedDb\u2019s \u201Cowner\u201D store every 4 seconds. If the primary client fails to\r\n * update this entry, another client can acquire the lease and take over as\r\n * primary.\r\n *\r\n * Some persistence operations in the SDK are designated as primary-client only\r\n * operations. This includes the acknowledgment of mutations and all updates of\r\n * remote documents. The effects of these operations are written to persistence\r\n * and then broadcast to other tabs via LocalStorage (see\r\n * `WebStorageSharedClientState`), which then refresh their state from\r\n * persistence.\r\n *\r\n * Similarly, the primary client listens to notifications sent by secondary\r\n * clients to discover persistence changes written by secondary clients, such as\r\n * the addition of new mutations and query targets.\r\n *\r\n * If multi-tab is not enabled and another tab already obtained the primary\r\n * lease, IndexedDbPersistence enters a failed state and all subsequent\r\n * operations will automatically fail.\r\n *\r\n * Additionally, there is an optimization so that when a tab is closed, the\r\n * primary lease is released immediately (this is especially important to make\r\n * sure that a refreshed tab is able to immediately re-acquire the primary\r\n * lease). Unfortunately, IndexedDB cannot be reliably used in window.unload\r\n * since it is an asynchronous API. So in addition to attempting to give up the\r\n * lease, the leaseholder writes its client ID to a \"zombiedClient\" entry in\r\n * LocalStorage which acts as an indicator that another tab should go ahead and\r\n * take the primary lease immediately regardless of the current lease timestamp.\r\n *\r\n * TODO(b/114226234): Remove `synchronizeTabs` section when multi-tab is no\r\n * longer optional.\r\n */\r\nclass IndexedDbPersistence {\r\n    constructor(\r\n    /**\r\n     * Whether to synchronize the in-memory state of multiple tabs and share\r\n     * access to local persistence.\r\n     */\r\n    allowTabSynchronization, persistenceKey, clientId, lruParams, queue, window, document, serializer, sequenceNumberSyncer, \r\n    /**\r\n     * If set to true, forcefully obtains database access. Existing tabs will\r\n     * no longer be able to access IndexedDB.\r\n     */\r\n    forceOwningTab) {\r\n        this.allowTabSynchronization = allowTabSynchronization;\r\n        this.persistenceKey = persistenceKey;\r\n        this.clientId = clientId;\r\n        this.queue = queue;\r\n        this.window = window;\r\n        this.document = document;\r\n        this.sequenceNumberSyncer = sequenceNumberSyncer;\r\n        this.forceOwningTab = forceOwningTab;\r\n        this.listenSequence = null;\r\n        this._started = false;\r\n        this.isPrimary = false;\r\n        this.networkEnabled = true;\r\n        /** Our window.unload handler, if registered. */\r\n        this.windowUnloadHandler = null;\r\n        this.inForeground = false;\r\n        /** Our 'visibilitychange' listener if registered. */\r\n        this.documentVisibilityHandler = null;\r\n        /** The client metadata refresh task. */\r\n        this.clientMetadataRefresher = null;\r\n        /** The last time we garbage collected the client metadata object store. */\r\n        this.lastGarbageCollectionTime = Number.NEGATIVE_INFINITY;\r\n        /** A listener to notify on primary state changes. */\r\n        this.primaryStateListener = _ => Promise.resolve();\r\n        if (!IndexedDbPersistence.isAvailable()) {\r\n            throw new FirestoreError(Code.UNIMPLEMENTED, UNSUPPORTED_PLATFORM_ERROR_MSG);\r\n        }\r\n        this.referenceDelegate = new IndexedDbLruDelegateImpl(this, lruParams);\r\n        this.dbName = persistenceKey + MAIN_DATABASE;\r\n        this.serializer = new LocalSerializer(serializer);\r\n        this.simpleDb = new SimpleDb(this.dbName, SCHEMA_VERSION, new SchemaConverter(this.serializer));\r\n        this.targetCache = new IndexedDbTargetCache(this.referenceDelegate, this.serializer);\r\n        this.indexManager = new IndexedDbIndexManager();\r\n        this.remoteDocumentCache = newIndexedDbRemoteDocumentCache(this.serializer, this.indexManager);\r\n        this.bundleCache = new IndexedDbBundleCache();\r\n        if (this.window && this.window.localStorage) {\r\n            this.webStorage = this.window.localStorage;\r\n        }\r\n        else {\r\n            this.webStorage = null;\r\n            if (forceOwningTab === false) {\r\n                logError(LOG_TAG$d, 'LocalStorage is unavailable. As a result, persistence may not work ' +\r\n                    'reliably. In particular enablePersistence() could fail immediately ' +\r\n                    'after refreshing the page.');\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Attempt to start IndexedDb persistence.\r\n     *\r\n     * @returns Whether persistence was enabled.\r\n     */\r\n    start() {\r\n        // NOTE: This is expected to fail sometimes (in the case of another tab\r\n        // already having the persistence lock), so it's the first thing we should\r\n        // do.\r\n        return this.updateClientMetadataAndTryBecomePrimary()\r\n            .then(() => {\r\n            if (!this.isPrimary && !this.allowTabSynchronization) {\r\n                // Fail `start()` if `synchronizeTabs` is disabled and we cannot\r\n                // obtain the primary lease.\r\n                throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);\r\n            }\r\n            this.attachVisibilityHandler();\r\n            this.attachWindowUnloadHook();\r\n            this.scheduleClientMetadataAndPrimaryLeaseRefreshes();\r\n            return this.runTransaction('getHighestListenSequenceNumber', 'readonly', txn => this.targetCache.getHighestSequenceNumber(txn));\r\n        })\r\n            .then(highestListenSequenceNumber => {\r\n            this.listenSequence = new ListenSequence(highestListenSequenceNumber, this.sequenceNumberSyncer);\r\n        })\r\n            .then(() => {\r\n            this._started = true;\r\n        })\r\n            .catch(reason => {\r\n            this.simpleDb && this.simpleDb.close();\r\n            return Promise.reject(reason);\r\n        });\r\n    }\r\n    /**\r\n     * Registers a listener that gets called when the primary state of the\r\n     * instance changes. Upon registering, this listener is invoked immediately\r\n     * with the current primary state.\r\n     *\r\n     * PORTING NOTE: This is only used for Web multi-tab.\r\n     */\r\n    setPrimaryStateListener(primaryStateListener) {\r\n        this.primaryStateListener = async (primaryState) => {\r\n            if (this.started) {\r\n                return primaryStateListener(primaryState);\r\n            }\r\n        };\r\n        return primaryStateListener(this.isPrimary);\r\n    }\r\n    /**\r\n     * Registers a listener that gets called when the database receives a\r\n     * version change event indicating that it has deleted.\r\n     *\r\n     * PORTING NOTE: This is only used for Web multi-tab.\r\n     */\r\n    setDatabaseDeletedListener(databaseDeletedListener) {\r\n        this.simpleDb.setVersionChangeListener(async (event) => {\r\n            // Check if an attempt is made to delete IndexedDB.\r\n            if (event.newVersion === null) {\r\n                await databaseDeletedListener();\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Adjusts the current network state in the client's metadata, potentially\r\n     * affecting the primary lease.\r\n     *\r\n     * PORTING NOTE: This is only used for Web multi-tab.\r\n     */\r\n    setNetworkEnabled(networkEnabled) {\r\n        if (this.networkEnabled !== networkEnabled) {\r\n            this.networkEnabled = networkEnabled;\r\n            // Schedule a primary lease refresh for immediate execution. The eventual\r\n            // lease update will be propagated via `primaryStateListener`.\r\n            this.queue.enqueueAndForget(async () => {\r\n                if (this.started) {\r\n                    await this.updateClientMetadataAndTryBecomePrimary();\r\n                }\r\n            });\r\n        }\r\n    }\r\n    /**\r\n     * Updates the client metadata in IndexedDb and attempts to either obtain or\r\n     * extend the primary lease for the local client. Asynchronously notifies the\r\n     * primary state listener if the client either newly obtained or released its\r\n     * primary lease.\r\n     */\r\n    updateClientMetadataAndTryBecomePrimary() {\r\n        return this.runTransaction('updateClientMetadataAndTryBecomePrimary', 'readwrite', txn => {\r\n            const metadataStore = clientMetadataStore(txn);\r\n            return metadataStore\r\n                .put(new DbClientMetadata(this.clientId, Date.now(), this.networkEnabled, this.inForeground))\r\n                .next(() => {\r\n                if (this.isPrimary) {\r\n                    return this.verifyPrimaryLease(txn).next(success => {\r\n                        if (!success) {\r\n                            this.isPrimary = false;\r\n                            this.queue.enqueueRetryable(() => this.primaryStateListener(false));\r\n                        }\r\n                    });\r\n                }\r\n            })\r\n                .next(() => this.canActAsPrimary(txn))\r\n                .next(canActAsPrimary => {\r\n                if (this.isPrimary && !canActAsPrimary) {\r\n                    return this.releasePrimaryLeaseIfHeld(txn).next(() => false);\r\n                }\r\n                else if (canActAsPrimary) {\r\n                    return this.acquireOrExtendPrimaryLease(txn).next(() => true);\r\n                }\r\n                else {\r\n                    return /* canActAsPrimary= */ false;\r\n                }\r\n            });\r\n        })\r\n            .catch(e => {\r\n            if (isIndexedDbTransactionError(e)) {\r\n                logDebug(LOG_TAG$d, 'Failed to extend owner lease: ', e);\r\n                // Proceed with the existing state. Any subsequent access to\r\n                // IndexedDB will verify the lease.\r\n                return this.isPrimary;\r\n            }\r\n            if (!this.allowTabSynchronization) {\r\n                throw e;\r\n            }\r\n            logDebug(LOG_TAG$d, 'Releasing owner lease after error during lease refresh', e);\r\n            return /* isPrimary= */ false;\r\n        })\r\n            .then(isPrimary => {\r\n            if (this.isPrimary !== isPrimary) {\r\n                this.queue.enqueueRetryable(() => this.primaryStateListener(isPrimary));\r\n            }\r\n            this.isPrimary = isPrimary;\r\n        });\r\n    }\r\n    verifyPrimaryLease(txn) {\r\n        const store = primaryClientStore(txn);\r\n        return store.get(DbPrimaryClient.key).next(primaryClient => {\r\n            return PersistencePromise.resolve(this.isLocalClient(primaryClient));\r\n        });\r\n    }\r\n    removeClientMetadata(txn) {\r\n        const metadataStore = clientMetadataStore(txn);\r\n        return metadataStore.delete(this.clientId);\r\n    }\r\n    /**\r\n     * If the garbage collection threshold has passed, prunes the\r\n     * RemoteDocumentChanges and the ClientMetadata store based on the last update\r\n     * time of all clients.\r\n     */\r\n    async maybeGarbageCollectMultiClientState() {\r\n        if (this.isPrimary &&\r\n            !this.isWithinAge(this.lastGarbageCollectionTime, MAX_CLIENT_AGE_MS)) {\r\n            this.lastGarbageCollectionTime = Date.now();\r\n            const inactiveClients = await this.runTransaction('maybeGarbageCollectMultiClientState', 'readwrite-primary', txn => {\r\n                const metadataStore = getStore(txn, DbClientMetadata.store);\r\n                return metadataStore.loadAll().next(existingClients => {\r\n                    const active = this.filterActiveClients(existingClients, MAX_CLIENT_AGE_MS);\r\n                    const inactive = existingClients.filter(client => active.indexOf(client) === -1);\r\n                    // Delete metadata for clients that are no longer considered active.\r\n                    return PersistencePromise.forEach(inactive, (inactiveClient) => metadataStore.delete(inactiveClient.clientId)).next(() => inactive);\r\n                });\r\n            }).catch(() => {\r\n                // Ignore primary lease violations or any other type of error. The next\r\n                // primary will run `maybeGarbageCollectMultiClientState()` again.\r\n                // We don't use `ignoreIfPrimaryLeaseLoss()` since we don't want to depend\r\n                // on LocalStore.\r\n                return [];\r\n            });\r\n            // Delete potential leftover entries that may continue to mark the\r\n            // inactive clients as zombied in LocalStorage.\r\n            // Ideally we'd delete the IndexedDb and LocalStorage zombie entries for\r\n            // the client atomically, but we can't. So we opt to delete the IndexedDb\r\n            // entries first to avoid potentially reviving a zombied client.\r\n            if (this.webStorage) {\r\n                for (const inactiveClient of inactiveClients) {\r\n                    this.webStorage.removeItem(this.zombiedClientLocalStorageKey(inactiveClient.clientId));\r\n                }\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Schedules a recurring timer to update the client metadata and to either\r\n     * extend or acquire the primary lease if the client is eligible.\r\n     */\r\n    scheduleClientMetadataAndPrimaryLeaseRefreshes() {\r\n        this.clientMetadataRefresher = this.queue.enqueueAfterDelay(\"client_metadata_refresh\" /* ClientMetadataRefresh */, CLIENT_METADATA_REFRESH_INTERVAL_MS, () => {\r\n            return this.updateClientMetadataAndTryBecomePrimary()\r\n                .then(() => this.maybeGarbageCollectMultiClientState())\r\n                .then(() => this.scheduleClientMetadataAndPrimaryLeaseRefreshes());\r\n        });\r\n    }\r\n    /** Checks whether `client` is the local client. */\r\n    isLocalClient(client) {\r\n        return client ? client.ownerId === this.clientId : false;\r\n    }\r\n    /**\r\n     * Evaluate the state of all active clients and determine whether the local\r\n     * client is or can act as the holder of the primary lease. Returns whether\r\n     * the client is eligible for the lease, but does not actually acquire it.\r\n     * May return 'false' even if there is no active leaseholder and another\r\n     * (foreground) client should become leaseholder instead.\r\n     */\r\n    canActAsPrimary(txn) {\r\n        if (this.forceOwningTab) {\r\n            return PersistencePromise.resolve(true);\r\n        }\r\n        const store = primaryClientStore(txn);\r\n        return store\r\n            .get(DbPrimaryClient.key)\r\n            .next(currentPrimary => {\r\n            const currentLeaseIsValid = currentPrimary !== null &&\r\n                this.isWithinAge(currentPrimary.leaseTimestampMs, MAX_PRIMARY_ELIGIBLE_AGE_MS) &&\r\n                !this.isClientZombied(currentPrimary.ownerId);\r\n            // A client is eligible for the primary lease if:\r\n            // - its network is enabled and the client's tab is in the foreground.\r\n            // - its network is enabled and no other client's tab is in the\r\n            //   foreground.\r\n            // - every clients network is disabled and the client's tab is in the\r\n            //   foreground.\r\n            // - every clients network is disabled and no other client's tab is in\r\n            //   the foreground.\r\n            // - the `forceOwningTab` setting was passed in.\r\n            if (currentLeaseIsValid) {\r\n                if (this.isLocalClient(currentPrimary) && this.networkEnabled) {\r\n                    return true;\r\n                }\r\n                if (!this.isLocalClient(currentPrimary)) {\r\n                    if (!currentPrimary.allowTabSynchronization) {\r\n                        // Fail the `canActAsPrimary` check if the current leaseholder has\r\n                        // not opted into multi-tab synchronization. If this happens at\r\n                        // client startup, we reject the Promise returned by\r\n                        // `enablePersistence()` and the user can continue to use Firestore\r\n                        // with in-memory persistence.\r\n                        // If this fails during a lease refresh, we will instead block the\r\n                        // AsyncQueue from executing further operations. Note that this is\r\n                        // acceptable since mixing & matching different `synchronizeTabs`\r\n                        // settings is not supported.\r\n                        //\r\n                        // TODO(b/114226234): Remove this check when `synchronizeTabs` can\r\n                        // no longer be turned off.\r\n                        throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);\r\n                    }\r\n                    return false;\r\n                }\r\n            }\r\n            if (this.networkEnabled && this.inForeground) {\r\n                return true;\r\n            }\r\n            return clientMetadataStore(txn)\r\n                .loadAll()\r\n                .next(existingClients => {\r\n                // Process all existing clients and determine whether at least one of\r\n                // them is better suited to obtain the primary lease.\r\n                const preferredCandidate = this.filterActiveClients(existingClients, MAX_PRIMARY_ELIGIBLE_AGE_MS).find(otherClient => {\r\n                    if (this.clientId !== otherClient.clientId) {\r\n                        const otherClientHasBetterNetworkState = !this.networkEnabled && otherClient.networkEnabled;\r\n                        const otherClientHasBetterVisibility = !this.inForeground && otherClient.inForeground;\r\n                        const otherClientHasSameNetworkState = this.networkEnabled === otherClient.networkEnabled;\r\n                        if (otherClientHasBetterNetworkState ||\r\n                            (otherClientHasBetterVisibility &&\r\n                                otherClientHasSameNetworkState)) {\r\n                            return true;\r\n                        }\r\n                    }\r\n                    return false;\r\n                });\r\n                return preferredCandidate === undefined;\r\n            });\r\n        })\r\n            .next(canActAsPrimary => {\r\n            if (this.isPrimary !== canActAsPrimary) {\r\n                logDebug(LOG_TAG$d, `Client ${canActAsPrimary ? 'is' : 'is not'} eligible for a primary lease.`);\r\n            }\r\n            return canActAsPrimary;\r\n        });\r\n    }\r\n    async shutdown() {\r\n        // The shutdown() operations are idempotent and can be called even when\r\n        // start() aborted (e.g. because it couldn't acquire the persistence lease).\r\n        this._started = false;\r\n        this.markClientZombied();\r\n        if (this.clientMetadataRefresher) {\r\n            this.clientMetadataRefresher.cancel();\r\n            this.clientMetadataRefresher = null;\r\n        }\r\n        this.detachVisibilityHandler();\r\n        this.detachWindowUnloadHook();\r\n        // Use `SimpleDb.runTransaction` directly to avoid failing if another tab\r\n        // has obtained the primary lease.\r\n        await this.simpleDb.runTransaction('shutdown', 'readwrite', [DbPrimaryClient.store, DbClientMetadata.store], simpleDbTxn => {\r\n            const persistenceTransaction = new IndexedDbTransaction(simpleDbTxn, ListenSequence.INVALID);\r\n            return this.releasePrimaryLeaseIfHeld(persistenceTransaction).next(() => this.removeClientMetadata(persistenceTransaction));\r\n        });\r\n        this.simpleDb.close();\r\n        // Remove the entry marking the client as zombied from LocalStorage since\r\n        // we successfully deleted its metadata from IndexedDb.\r\n        this.removeClientZombiedEntry();\r\n    }\r\n    /**\r\n     * Returns clients that are not zombied and have an updateTime within the\r\n     * provided threshold.\r\n     */\r\n    filterActiveClients(clients, activityThresholdMs) {\r\n        return clients.filter(client => this.isWithinAge(client.updateTimeMs, activityThresholdMs) &&\r\n            !this.isClientZombied(client.clientId));\r\n    }\r\n    /**\r\n     * Returns the IDs of the clients that are currently active. If multi-tab\r\n     * is not supported, returns an array that only contains the local client's\r\n     * ID.\r\n     *\r\n     * PORTING NOTE: This is only used for Web multi-tab.\r\n     */\r\n    getActiveClients() {\r\n        return this.runTransaction('getActiveClients', 'readonly', txn => {\r\n            return clientMetadataStore(txn)\r\n                .loadAll()\r\n                .next(clients => this.filterActiveClients(clients, MAX_CLIENT_AGE_MS).map(clientMetadata => clientMetadata.clientId));\r\n        });\r\n    }\r\n    get started() {\r\n        return this._started;\r\n    }\r\n    getMutationQueue(user) {\r\n        return IndexedDbMutationQueue.forUser(user, this.serializer, this.indexManager, this.referenceDelegate);\r\n    }\r\n    getTargetCache() {\r\n        return this.targetCache;\r\n    }\r\n    getRemoteDocumentCache() {\r\n        return this.remoteDocumentCache;\r\n    }\r\n    getIndexManager() {\r\n        return this.indexManager;\r\n    }\r\n    getBundleCache() {\r\n        return this.bundleCache;\r\n    }\r\n    runTransaction(action, mode, transactionOperation) {\r\n        logDebug(LOG_TAG$d, 'Starting transaction:', action);\r\n        const simpleDbMode = mode === 'readonly' ? 'readonly' : 'readwrite';\r\n        let persistenceTransaction;\r\n        // Do all transactions as readwrite against all object stores, since we\r\n        // are the only reader/writer.\r\n        return this.simpleDb\r\n            .runTransaction(action, simpleDbMode, ALL_STORES, simpleDbTxn => {\r\n            persistenceTransaction = new IndexedDbTransaction(simpleDbTxn, this.listenSequence\r\n                ? this.listenSequence.next()\r\n                : ListenSequence.INVALID);\r\n            if (mode === 'readwrite-primary') {\r\n                // While we merely verify that we have (or can acquire) the lease\r\n                // immediately, we wait to extend the primary lease until after\r\n                // executing transactionOperation(). This ensures that even if the\r\n                // transactionOperation takes a long time, we'll use a recent\r\n                // leaseTimestampMs in the extended (or newly acquired) lease.\r\n                return this.verifyPrimaryLease(persistenceTransaction)\r\n                    .next(holdsPrimaryLease => {\r\n                    if (holdsPrimaryLease) {\r\n                        return /* holdsPrimaryLease= */ true;\r\n                    }\r\n                    return this.canActAsPrimary(persistenceTransaction);\r\n                })\r\n                    .next(holdsPrimaryLease => {\r\n                    if (!holdsPrimaryLease) {\r\n                        logError(`Failed to obtain primary lease for action '${action}'.`);\r\n                        this.isPrimary = false;\r\n                        this.queue.enqueueRetryable(() => this.primaryStateListener(false));\r\n                        throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_LOST_ERROR_MSG);\r\n                    }\r\n                    return transactionOperation(persistenceTransaction);\r\n                })\r\n                    .next(result => {\r\n                    return this.acquireOrExtendPrimaryLease(persistenceTransaction).next(() => result);\r\n                });\r\n            }\r\n            else {\r\n                return this.verifyAllowTabSynchronization(persistenceTransaction).next(() => transactionOperation(persistenceTransaction));\r\n            }\r\n        })\r\n            .then(result => {\r\n            persistenceTransaction.raiseOnCommittedEvent();\r\n            return result;\r\n        });\r\n    }\r\n    /**\r\n     * Verifies that the current tab is the primary leaseholder or alternatively\r\n     * that the leaseholder has opted into multi-tab synchronization.\r\n     */\r\n    // TODO(b/114226234): Remove this check when `synchronizeTabs` can no longer\r\n    // be turned off.\r\n    verifyAllowTabSynchronization(txn) {\r\n        const store = primaryClientStore(txn);\r\n        return store.get(DbPrimaryClient.key).next(currentPrimary => {\r\n            const currentLeaseIsValid = currentPrimary !== null &&\r\n                this.isWithinAge(currentPrimary.leaseTimestampMs, MAX_PRIMARY_ELIGIBLE_AGE_MS) &&\r\n                !this.isClientZombied(currentPrimary.ownerId);\r\n            if (currentLeaseIsValid && !this.isLocalClient(currentPrimary)) {\r\n                if (!this.forceOwningTab &&\r\n                    (!this.allowTabSynchronization ||\r\n                        !currentPrimary.allowTabSynchronization)) {\r\n                    throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);\r\n                }\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Obtains or extends the new primary lease for the local client. This\r\n     * method does not verify that the client is eligible for this lease.\r\n     */\r\n    acquireOrExtendPrimaryLease(txn) {\r\n        const newPrimary = new DbPrimaryClient(this.clientId, this.allowTabSynchronization, Date.now());\r\n        return primaryClientStore(txn).put(DbPrimaryClient.key, newPrimary);\r\n    }\r\n    static isAvailable() {\r\n        return SimpleDb.isAvailable();\r\n    }\r\n    /** Checks the primary lease and removes it if we are the current primary. */\r\n    releasePrimaryLeaseIfHeld(txn) {\r\n        const store = primaryClientStore(txn);\r\n        return store.get(DbPrimaryClient.key).next(primaryClient => {\r\n            if (this.isLocalClient(primaryClient)) {\r\n                logDebug(LOG_TAG$d, 'Releasing primary lease.');\r\n                return store.delete(DbPrimaryClient.key);\r\n            }\r\n            else {\r\n                return PersistencePromise.resolve();\r\n            }\r\n        });\r\n    }\r\n    /** Verifies that `updateTimeMs` is within `maxAgeMs`. */\r\n    isWithinAge(updateTimeMs, maxAgeMs) {\r\n        const now = Date.now();\r\n        const minAcceptable = now - maxAgeMs;\r\n        const maxAcceptable = now;\r\n        if (updateTimeMs < minAcceptable) {\r\n            return false;\r\n        }\r\n        else if (updateTimeMs > maxAcceptable) {\r\n            logError(`Detected an update time that is in the future: ${updateTimeMs} > ${maxAcceptable}`);\r\n            return false;\r\n        }\r\n        return true;\r\n    }\r\n    attachVisibilityHandler() {\r\n        if (this.document !== null &&\r\n            typeof this.document.addEventListener === 'function') {\r\n            this.documentVisibilityHandler = () => {\r\n                this.queue.enqueueAndForget(() => {\r\n                    this.inForeground = this.document.visibilityState === 'visible';\r\n                    return this.updateClientMetadataAndTryBecomePrimary();\r\n                });\r\n            };\r\n            this.document.addEventListener('visibilitychange', this.documentVisibilityHandler);\r\n            this.inForeground = this.document.visibilityState === 'visible';\r\n        }\r\n    }\r\n    detachVisibilityHandler() {\r\n        if (this.documentVisibilityHandler) {\r\n            this.document.removeEventListener('visibilitychange', this.documentVisibilityHandler);\r\n            this.documentVisibilityHandler = null;\r\n        }\r\n    }\r\n    /**\r\n     * Attaches a window.unload handler that will synchronously write our\r\n     * clientId to a \"zombie client id\" location in LocalStorage. This can be used\r\n     * by tabs trying to acquire the primary lease to determine that the lease\r\n     * is no longer valid even if the timestamp is recent. This is particularly\r\n     * important for the refresh case (so the tab correctly re-acquires the\r\n     * primary lease). LocalStorage is used for this rather than IndexedDb because\r\n     * it is a synchronous API and so can be used reliably from  an unload\r\n     * handler.\r\n     */\r\n    attachWindowUnloadHook() {\r\n        var _a;\r\n        if (typeof ((_a = this.window) === null || _a === void 0 ? void 0 : _a.addEventListener) === 'function') {\r\n            this.windowUnloadHandler = () => {\r\n                // Note: In theory, this should be scheduled on the AsyncQueue since it\r\n                // accesses internal state. We execute this code directly during shutdown\r\n                // to make sure it gets a chance to run.\r\n                this.markClientZombied();\r\n                if (isSafari() && navigator.appVersion.match(/Version\\/1[45]/)) {\r\n                    // On Safari 14 and 15, we do not run any cleanup actions as it might\r\n                    // trigger a bug that prevents Safari from re-opening IndexedDB during\r\n                    // the next page load.\r\n                    // See https://bugs.webkit.org/show_bug.cgi?id=226547\r\n                    this.queue.enterRestrictedMode(/* purgeExistingTasks= */ true);\r\n                }\r\n                this.queue.enqueueAndForget(() => {\r\n                    // Attempt graceful shutdown (including releasing our primary lease),\r\n                    // but there's no guarantee it will complete.\r\n                    return this.shutdown();\r\n                });\r\n            };\r\n            this.window.addEventListener('pagehide', this.windowUnloadHandler);\r\n        }\r\n    }\r\n    detachWindowUnloadHook() {\r\n        if (this.windowUnloadHandler) {\r\n            this.window.removeEventListener('pagehide', this.windowUnloadHandler);\r\n            this.windowUnloadHandler = null;\r\n        }\r\n    }\r\n    /**\r\n     * Returns whether a client is \"zombied\" based on its LocalStorage entry.\r\n     * Clients become zombied when their tab closes without running all of the\r\n     * cleanup logic in `shutdown()`.\r\n     */\r\n    isClientZombied(clientId) {\r\n        var _a;\r\n        try {\r\n            const isZombied = ((_a = this.webStorage) === null || _a === void 0 ? void 0 : _a.getItem(this.zombiedClientLocalStorageKey(clientId))) !== null;\r\n            logDebug(LOG_TAG$d, `Client '${clientId}' ${isZombied ? 'is' : 'is not'} zombied in LocalStorage`);\r\n            return isZombied;\r\n        }\r\n        catch (e) {\r\n            // Gracefully handle if LocalStorage isn't working.\r\n            logError(LOG_TAG$d, 'Failed to get zombied client id.', e);\r\n            return false;\r\n        }\r\n    }\r\n    /**\r\n     * Record client as zombied (a client that had its tab closed). Zombied\r\n     * clients are ignored during primary tab selection.\r\n     */\r\n    markClientZombied() {\r\n        if (!this.webStorage) {\r\n            return;\r\n        }\r\n        try {\r\n            this.webStorage.setItem(this.zombiedClientLocalStorageKey(this.clientId), String(Date.now()));\r\n        }\r\n        catch (e) {\r\n            // Gracefully handle if LocalStorage isn't available / working.\r\n            logError('Failed to set zombie client id.', e);\r\n        }\r\n    }\r\n    /** Removes the zombied client entry if it exists. */\r\n    removeClientZombiedEntry() {\r\n        if (!this.webStorage) {\r\n            return;\r\n        }\r\n        try {\r\n            this.webStorage.removeItem(this.zombiedClientLocalStorageKey(this.clientId));\r\n        }\r\n        catch (e) {\r\n            // Ignore\r\n        }\r\n    }\r\n    zombiedClientLocalStorageKey(clientId) {\r\n        return `${ZOMBIED_CLIENTS_KEY_PREFIX}_${this.persistenceKey}_${clientId}`;\r\n    }\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the primary client object store.\r\n */\r\nfunction primaryClientStore(txn) {\r\n    return getStore(txn, DbPrimaryClient.store);\r\n}\r\n/**\r\n * Helper to get a typed SimpleDbStore for the client metadata object store.\r\n */\r\nfunction clientMetadataStore(txn) {\r\n    return getStore(txn, DbClientMetadata.store);\r\n}\r\n/**\r\n * Generates a string used as a prefix when storing data in IndexedDB and\r\n * LocalStorage.\r\n */\r\nfunction indexedDbStoragePrefix(databaseId, persistenceKey) {\r\n    // Use two different prefix formats:\r\n    //\r\n    //   * firestore / persistenceKey / projectID . databaseID / ...\r\n    //   * firestore / persistenceKey / projectID / ...\r\n    //\r\n    // projectIDs are DNS-compatible names and cannot contain dots\r\n    // so there's no danger of collisions.\r\n    let database = databaseId.projectId;\r\n    if (!databaseId.isDefaultDatabase) {\r\n        database += '.' + databaseId.database;\r\n    }\r\n    return 'firestore/' + persistenceKey + '/' + database + '/';\r\n}\r\nasync function indexedDbClearPersistence(persistenceKey) {\r\n    if (!SimpleDb.isAvailable()) {\r\n        return Promise.resolve();\r\n    }\r\n    const dbName = persistenceKey + MAIN_DATABASE;\r\n    await SimpleDb.delete(dbName);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A readonly view of the local state of all documents we're tracking (i.e. we\r\n * have a cached version in remoteDocumentCache or local mutations for the\r\n * document). The view is computed by applying the mutations in the\r\n * MutationQueue to the RemoteDocumentCache.\r\n */\r\nclass LocalDocumentsView {\r\n    constructor(remoteDocumentCache, mutationQueue, indexManager) {\r\n        this.remoteDocumentCache = remoteDocumentCache;\r\n        this.mutationQueue = mutationQueue;\r\n        this.indexManager = indexManager;\r\n    }\r\n    /**\r\n     * Get the local view of the document identified by `key`.\r\n     *\r\n     * @returns Local view of the document or null if we don't have any cached\r\n     * state for it.\r\n     */\r\n    getDocument(transaction, key) {\r\n        return this.mutationQueue\r\n            .getAllMutationBatchesAffectingDocumentKey(transaction, key)\r\n            .next(batches => this.getDocumentInternal(transaction, key, batches));\r\n    }\r\n    /** Internal version of `getDocument` that allows reusing batches. */\r\n    getDocumentInternal(transaction, key, inBatches) {\r\n        return this.remoteDocumentCache.getEntry(transaction, key).next(doc => {\r\n            for (const batch of inBatches) {\r\n                batch.applyToLocalView(doc);\r\n            }\r\n            return doc;\r\n        });\r\n    }\r\n    // Returns the view of the given `docs` as they would appear after applying\r\n    // all mutations in the given `batches`.\r\n    applyLocalMutationsToDocuments(docs, batches) {\r\n        docs.forEach((key, localView) => {\r\n            for (const batch of batches) {\r\n                batch.applyToLocalView(localView);\r\n            }\r\n        });\r\n    }\r\n    /**\r\n     * Gets the local view of the documents identified by `keys`.\r\n     *\r\n     * If we don't have cached state for a document in `keys`, a NoDocument will\r\n     * be stored for that key in the resulting set.\r\n     */\r\n    getDocuments(transaction, keys) {\r\n        return this.remoteDocumentCache\r\n            .getEntries(transaction, keys)\r\n            .next(docs => this.applyLocalViewToDocuments(transaction, docs).next(() => docs));\r\n    }\r\n    /**\r\n     * Applies the local view the given `baseDocs` without retrieving documents\r\n     * from the local store.\r\n     */\r\n    applyLocalViewToDocuments(transaction, baseDocs) {\r\n        return this.mutationQueue\r\n            .getAllMutationBatchesAffectingDocumentKeys(transaction, baseDocs)\r\n            .next(batches => this.applyLocalMutationsToDocuments(baseDocs, batches));\r\n    }\r\n    /**\r\n     * Performs a query against the local view of all documents.\r\n     *\r\n     * @param transaction - The persistence transaction.\r\n     * @param query - The query to match documents against.\r\n     * @param sinceReadTime - If not set to SnapshotVersion.min(), return only\r\n     *     documents that have been read since this snapshot version (exclusive).\r\n     */\r\n    getDocumentsMatchingQuery(transaction, query, sinceReadTime) {\r\n        if (isDocumentQuery$1(query)) {\r\n            return this.getDocumentsMatchingDocumentQuery(transaction, query.path);\r\n        }\r\n        else if (isCollectionGroupQuery(query)) {\r\n            return this.getDocumentsMatchingCollectionGroupQuery(transaction, query, sinceReadTime);\r\n        }\r\n        else {\r\n            return this.getDocumentsMatchingCollectionQuery(transaction, query, sinceReadTime);\r\n        }\r\n    }\r\n    getDocumentsMatchingDocumentQuery(transaction, docPath) {\r\n        // Just do a simple document lookup.\r\n        return this.getDocument(transaction, new DocumentKey(docPath)).next(document => {\r\n            let result = documentMap();\r\n            if (document.isFoundDocument()) {\r\n                result = result.insert(document.key, document);\r\n            }\r\n            return result;\r\n        });\r\n    }\r\n    getDocumentsMatchingCollectionGroupQuery(transaction, query, sinceReadTime) {\r\n        const collectionId = query.collectionGroup;\r\n        let results = documentMap();\r\n        return this.indexManager\r\n            .getCollectionParents(transaction, collectionId)\r\n            .next(parents => {\r\n            // Perform a collection query against each parent that contains the\r\n            // collectionId and aggregate the results.\r\n            return PersistencePromise.forEach(parents, (parent) => {\r\n                const collectionQuery = asCollectionQueryAtPath(query, parent.child(collectionId));\r\n                return this.getDocumentsMatchingCollectionQuery(transaction, collectionQuery, sinceReadTime).next(r => {\r\n                    r.forEach((key, doc) => {\r\n                        results = results.insert(key, doc);\r\n                    });\r\n                });\r\n            }).next(() => results);\r\n        });\r\n    }\r\n    getDocumentsMatchingCollectionQuery(transaction, query, sinceReadTime) {\r\n        // Query the remote documents and overlay mutations.\r\n        let results;\r\n        let mutationBatches;\r\n        return this.remoteDocumentCache\r\n            .getDocumentsMatchingQuery(transaction, query, sinceReadTime)\r\n            .next(queryResults => {\r\n            results = queryResults;\r\n            return this.mutationQueue.getAllMutationBatchesAffectingQuery(transaction, query);\r\n        })\r\n            .next(matchingMutationBatches => {\r\n            mutationBatches = matchingMutationBatches;\r\n            // It is possible that a PatchMutation can make a document match a query, even if\r\n            // the version in the RemoteDocumentCache is not a match yet (waiting for server\r\n            // to ack). To handle this, we find all document keys affected by the PatchMutations\r\n            // that are not in `result` yet, and back fill them via `remoteDocumentCache.getEntries`,\r\n            // otherwise those `PatchMutations` will be ignored because no base document can be found,\r\n            // and lead to missing result for the query.\r\n            return this.addMissingBaseDocuments(transaction, mutationBatches, results).next(mergedDocuments => {\r\n                results = mergedDocuments;\r\n                for (const batch of mutationBatches) {\r\n                    for (const mutation of batch.mutations) {\r\n                        const key = mutation.key;\r\n                        let document = results.get(key);\r\n                        if (document == null) {\r\n                            // Create invalid document to apply mutations on top of\r\n                            document = MutableDocument.newInvalidDocument(key);\r\n                            results = results.insert(key, document);\r\n                        }\r\n                        mutationApplyToLocalView(mutation, document, batch.localWriteTime);\r\n                        if (!document.isFoundDocument()) {\r\n                            results = results.remove(key);\r\n                        }\r\n                    }\r\n                }\r\n            });\r\n        })\r\n            .next(() => {\r\n            // Finally, filter out any documents that don't actually match\r\n            // the query.\r\n            results.forEach((key, doc) => {\r\n                if (!queryMatches(query, doc)) {\r\n                    results = results.remove(key);\r\n                }\r\n            });\r\n            return results;\r\n        });\r\n    }\r\n    addMissingBaseDocuments(transaction, matchingMutationBatches, existingDocuments) {\r\n        let missingBaseDocEntriesForPatching = documentKeySet();\r\n        for (const batch of matchingMutationBatches) {\r\n            for (const mutation of batch.mutations) {\r\n                if (mutation instanceof PatchMutation &&\r\n                    existingDocuments.get(mutation.key) === null) {\r\n                    missingBaseDocEntriesForPatching =\r\n                        missingBaseDocEntriesForPatching.add(mutation.key);\r\n                }\r\n            }\r\n        }\r\n        let mergedDocuments = existingDocuments;\r\n        return this.remoteDocumentCache\r\n            .getEntries(transaction, missingBaseDocEntriesForPatching)\r\n            .next(missingBaseDocs => {\r\n            missingBaseDocs.forEach((key, doc) => {\r\n                if (doc.isFoundDocument()) {\r\n                    mergedDocuments = mergedDocuments.insert(key, doc);\r\n                }\r\n            });\r\n            return mergedDocuments;\r\n        });\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$c = 'LocalStore';\r\n/**\r\n * The maximum time to leave a resume token buffered without writing it out.\r\n * This value is arbitrary: it's long enough to avoid several writes\r\n * (possibly indefinitely if updates come more frequently than this) but\r\n * short enough that restarting after crashing will still have a pretty\r\n * recent resume token.\r\n */\r\nconst RESUME_TOKEN_MAX_AGE_MICROS = 5 * 60 * 1e6;\r\n/**\r\n * Implements `LocalStore` interface.\r\n *\r\n * Note: some field defined in this class might have public access level, but\r\n * the class is not exported so they are only accessible from this module.\r\n * This is useful to implement optional features (like bundles) in free\r\n * functions, such that they are tree-shakeable.\r\n */\r\nclass LocalStoreImpl {\r\n    constructor(\r\n    /** Manages our in-memory or durable persistence. */\r\n    persistence, queryEngine, initialUser, serializer) {\r\n        this.persistence = persistence;\r\n        this.queryEngine = queryEngine;\r\n        this.serializer = serializer;\r\n        /**\r\n         * Maps a targetID to data about its target.\r\n         *\r\n         * PORTING NOTE: We are using an immutable data structure on Web to make re-runs\r\n         * of `applyRemoteEvent()` idempotent.\r\n         */\r\n        this.targetDataByTarget = new SortedMap(primitiveComparator);\r\n        /** Maps a target to its targetID. */\r\n        // TODO(wuandy): Evaluate if TargetId can be part of Target.\r\n        this.targetIdByTarget = new ObjectMap(t => canonifyTarget(t), targetEquals);\r\n        /**\r\n         * The read time of the last entry processed by `getNewDocumentChanges()`.\r\n         *\r\n         * PORTING NOTE: This is only used for multi-tab synchronization.\r\n         */\r\n        this.lastDocumentChangeReadTime = SnapshotVersion.min();\r\n        this.mutationQueue = persistence.getMutationQueue(initialUser);\r\n        this.remoteDocuments = persistence.getRemoteDocumentCache();\r\n        this.targetCache = persistence.getTargetCache();\r\n        this.localDocuments = new LocalDocumentsView(this.remoteDocuments, this.mutationQueue, this.persistence.getIndexManager());\r\n        this.bundleCache = persistence.getBundleCache();\r\n        this.queryEngine.setLocalDocumentsView(this.localDocuments);\r\n    }\r\n    collectGarbage(garbageCollector) {\r\n        return this.persistence.runTransaction('Collect garbage', 'readwrite-primary', txn => garbageCollector.collect(txn, this.targetDataByTarget));\r\n    }\r\n}\r\nfunction newLocalStore(\r\n/** Manages our in-memory or durable persistence. */\r\npersistence, queryEngine, initialUser, serializer) {\r\n    return new LocalStoreImpl(persistence, queryEngine, initialUser, serializer);\r\n}\r\n/**\r\n * Tells the LocalStore that the currently authenticated user has changed.\r\n *\r\n * In response the local store switches the mutation queue to the new user and\r\n * returns any resulting document changes.\r\n */\r\n// PORTING NOTE: Android and iOS only return the documents affected by the\r\n// change.\r\nasync function localStoreHandleUserChange(localStore, user) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    let newMutationQueue = localStoreImpl.mutationQueue;\r\n    let newLocalDocuments = localStoreImpl.localDocuments;\r\n    const result = await localStoreImpl.persistence.runTransaction('Handle user change', 'readonly', txn => {\r\n        // Swap out the mutation queue, grabbing the pending mutation batches\r\n        // before and after.\r\n        let oldBatches;\r\n        return localStoreImpl.mutationQueue\r\n            .getAllMutationBatches(txn)\r\n            .next(promisedOldBatches => {\r\n            oldBatches = promisedOldBatches;\r\n            newMutationQueue = localStoreImpl.persistence.getMutationQueue(user);\r\n            // Recreate our LocalDocumentsView using the new\r\n            // MutationQueue.\r\n            newLocalDocuments = new LocalDocumentsView(localStoreImpl.remoteDocuments, newMutationQueue, localStoreImpl.persistence.getIndexManager());\r\n            return newMutationQueue.getAllMutationBatches(txn);\r\n        })\r\n            .next(newBatches => {\r\n            const removedBatchIds = [];\r\n            const addedBatchIds = [];\r\n            // Union the old/new changed keys.\r\n            let changedKeys = documentKeySet();\r\n            for (const batch of oldBatches) {\r\n                removedBatchIds.push(batch.batchId);\r\n                for (const mutation of batch.mutations) {\r\n                    changedKeys = changedKeys.add(mutation.key);\r\n                }\r\n            }\r\n            for (const batch of newBatches) {\r\n                addedBatchIds.push(batch.batchId);\r\n                for (const mutation of batch.mutations) {\r\n                    changedKeys = changedKeys.add(mutation.key);\r\n                }\r\n            }\r\n            // Return the set of all (potentially) changed documents and the list\r\n            // of mutation batch IDs that were affected by change.\r\n            return newLocalDocuments\r\n                .getDocuments(txn, changedKeys)\r\n                .next(affectedDocuments => {\r\n                return {\r\n                    affectedDocuments,\r\n                    removedBatchIds,\r\n                    addedBatchIds\r\n                };\r\n            });\r\n        });\r\n    });\r\n    localStoreImpl.mutationQueue = newMutationQueue;\r\n    localStoreImpl.localDocuments = newLocalDocuments;\r\n    localStoreImpl.queryEngine.setLocalDocumentsView(localStoreImpl.localDocuments);\r\n    return result;\r\n}\r\n/* Accepts locally generated Mutations and commit them to storage. */\r\nfunction localStoreWriteLocally(localStore, mutations) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    const localWriteTime = Timestamp.now();\r\n    const keys = mutations.reduce((keys, m) => keys.add(m.key), documentKeySet());\r\n    let existingDocs;\r\n    return localStoreImpl.persistence\r\n        .runTransaction('Locally write mutations', 'readwrite', txn => {\r\n        // Load and apply all existing mutations. This lets us compute the\r\n        // current base state for all non-idempotent transforms before applying\r\n        // any additional user-provided writes.\r\n        return localStoreImpl.localDocuments\r\n            .getDocuments(txn, keys)\r\n            .next(docs => {\r\n            existingDocs = docs;\r\n            // For non-idempotent mutations (such as `FieldValue.increment()`),\r\n            // we record the base state in a separate patch mutation. This is\r\n            // later used to guarantee consistent values and prevents flicker\r\n            // even if the backend sends us an update that already includes our\r\n            // transform.\r\n            const baseMutations = [];\r\n            for (const mutation of mutations) {\r\n                const baseValue = mutationExtractBaseValue(mutation, existingDocs.get(mutation.key));\r\n                if (baseValue != null) {\r\n                    // NOTE: The base state should only be applied if there's some\r\n                    // existing document to override, so use a Precondition of\r\n                    // exists=true\r\n                    baseMutations.push(new PatchMutation(mutation.key, baseValue, extractFieldMask(baseValue.value.mapValue), Precondition.exists(true)));\r\n                }\r\n            }\r\n            return localStoreImpl.mutationQueue.addMutationBatch(txn, localWriteTime, baseMutations, mutations);\r\n        });\r\n    })\r\n        .then(batch => {\r\n        batch.applyToLocalDocumentSet(existingDocs);\r\n        return { batchId: batch.batchId, changes: existingDocs };\r\n    });\r\n}\r\n/**\r\n * Acknowledges the given batch.\r\n *\r\n * On the happy path when a batch is acknowledged, the local store will\r\n *\r\n *  + remove the batch from the mutation queue;\r\n *  + apply the changes to the remote document cache;\r\n *  + recalculate the latency compensated view implied by those changes (there\r\n *    may be mutations in the queue that affect the documents but haven't been\r\n *    acknowledged yet); and\r\n *  + give the changed documents back the sync engine\r\n *\r\n * @returns The resulting (modified) documents.\r\n */\r\nfunction localStoreAcknowledgeBatch(localStore, batchResult) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Acknowledge batch', 'readwrite-primary', txn => {\r\n        const affected = batchResult.batch.keys();\r\n        const documentBuffer = localStoreImpl.remoteDocuments.newChangeBuffer({\r\n            trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\r\n        });\r\n        return applyWriteToRemoteDocuments(localStoreImpl, txn, batchResult, documentBuffer)\r\n            .next(() => documentBuffer.apply(txn))\r\n            .next(() => localStoreImpl.mutationQueue.performConsistencyCheck(txn))\r\n            .next(() => localStoreImpl.localDocuments.getDocuments(txn, affected));\r\n    });\r\n}\r\n/**\r\n * Removes mutations from the MutationQueue for the specified batch;\r\n * LocalDocuments will be recalculated.\r\n *\r\n * @returns The resulting modified documents.\r\n */\r\nfunction localStoreRejectBatch(localStore, batchId) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Reject batch', 'readwrite-primary', txn => {\r\n        let affectedKeys;\r\n        return localStoreImpl.mutationQueue\r\n            .lookupMutationBatch(txn, batchId)\r\n            .next((batch) => {\r\n            hardAssert(batch !== null);\r\n            affectedKeys = batch.keys();\r\n            return localStoreImpl.mutationQueue.removeMutationBatch(txn, batch);\r\n        })\r\n            .next(() => localStoreImpl.mutationQueue.performConsistencyCheck(txn))\r\n            .next(() => localStoreImpl.localDocuments.getDocuments(txn, affectedKeys));\r\n    });\r\n}\r\n/**\r\n * Returns the largest (latest) batch id in mutation queue that is pending\r\n * server response.\r\n *\r\n * Returns `BATCHID_UNKNOWN` if the queue is empty.\r\n */\r\nfunction localStoreGetHighestUnacknowledgedBatchId(localStore) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Get highest unacknowledged batch id', 'readonly', txn => localStoreImpl.mutationQueue.getHighestUnacknowledgedBatchId(txn));\r\n}\r\n/**\r\n * Returns the last consistent snapshot processed (used by the RemoteStore to\r\n * determine whether to buffer incoming snapshots from the backend).\r\n */\r\nfunction localStoreGetLastRemoteSnapshotVersion(localStore) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Get last remote snapshot version', 'readonly', txn => localStoreImpl.targetCache.getLastRemoteSnapshotVersion(txn));\r\n}\r\n/**\r\n * Updates the \"ground-state\" (remote) documents. We assume that the remote\r\n * event reflects any write batches that have been acknowledged or rejected\r\n * (i.e. we do not re-apply local mutations to updates from this event).\r\n *\r\n * LocalDocuments are re-calculated if there are remaining mutations in the\r\n * queue.\r\n */\r\nfunction localStoreApplyRemoteEventToLocalCache(localStore, remoteEvent) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    const remoteVersion = remoteEvent.snapshotVersion;\r\n    let newTargetDataByTargetMap = localStoreImpl.targetDataByTarget;\r\n    return localStoreImpl.persistence\r\n        .runTransaction('Apply remote event', 'readwrite-primary', txn => {\r\n        const documentBuffer = localStoreImpl.remoteDocuments.newChangeBuffer({\r\n            trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\r\n        });\r\n        // Reset newTargetDataByTargetMap in case this transaction gets re-run.\r\n        newTargetDataByTargetMap = localStoreImpl.targetDataByTarget;\r\n        const promises = [];\r\n        remoteEvent.targetChanges.forEach((change, targetId) => {\r\n            const oldTargetData = newTargetDataByTargetMap.get(targetId);\r\n            if (!oldTargetData) {\r\n                return;\r\n            }\r\n            // Only update the remote keys if the target is still active. This\r\n            // ensures that we can persist the updated target data along with\r\n            // the updated assignment.\r\n            promises.push(localStoreImpl.targetCache\r\n                .removeMatchingKeys(txn, change.removedDocuments, targetId)\r\n                .next(() => {\r\n                return localStoreImpl.targetCache.addMatchingKeys(txn, change.addedDocuments, targetId);\r\n            }));\r\n            const resumeToken = change.resumeToken;\r\n            // Update the resume token if the change includes one.\r\n            if (resumeToken.approximateByteSize() > 0) {\r\n                const newTargetData = oldTargetData\r\n                    .withResumeToken(resumeToken, remoteVersion)\r\n                    .withSequenceNumber(txn.currentSequenceNumber);\r\n                newTargetDataByTargetMap = newTargetDataByTargetMap.insert(targetId, newTargetData);\r\n                // Update the target data if there are target changes (or if\r\n                // sufficient time has passed since the last update).\r\n                if (shouldPersistTargetData(oldTargetData, newTargetData, change)) {\r\n                    promises.push(localStoreImpl.targetCache.updateTargetData(txn, newTargetData));\r\n                }\r\n            }\r\n        });\r\n        let changedDocs = mutableDocumentMap();\r\n        remoteEvent.documentUpdates.forEach((key, doc) => {\r\n            if (remoteEvent.resolvedLimboDocuments.has(key)) {\r\n                promises.push(localStoreImpl.persistence.referenceDelegate.updateLimboDocument(txn, key));\r\n            }\r\n        });\r\n        // Each loop iteration only affects its \"own\" doc, so it's safe to get all the remote\r\n        // documents in advance in a single call.\r\n        promises.push(populateDocumentChangeBuffer(txn, documentBuffer, remoteEvent.documentUpdates, remoteVersion, undefined).next(result => {\r\n            changedDocs = result;\r\n        }));\r\n        // HACK: The only reason we allow a null snapshot version is so that we\r\n        // can synthesize remote events when we get permission denied errors while\r\n        // trying to resolve the state of a locally cached document that is in\r\n        // limbo.\r\n        if (!remoteVersion.isEqual(SnapshotVersion.min())) {\r\n            const updateRemoteVersion = localStoreImpl.targetCache\r\n                .getLastRemoteSnapshotVersion(txn)\r\n                .next(lastRemoteSnapshotVersion => {\r\n                return localStoreImpl.targetCache.setTargetsMetadata(txn, txn.currentSequenceNumber, remoteVersion);\r\n            });\r\n            promises.push(updateRemoteVersion);\r\n        }\r\n        return PersistencePromise.waitFor(promises)\r\n            .next(() => documentBuffer.apply(txn))\r\n            .next(() => localStoreImpl.localDocuments.applyLocalViewToDocuments(txn, changedDocs))\r\n            .next(() => changedDocs);\r\n    })\r\n        .then(changedDocs => {\r\n        localStoreImpl.targetDataByTarget = newTargetDataByTargetMap;\r\n        return changedDocs;\r\n    });\r\n}\r\n/**\r\n * Populates document change buffer with documents from backend or a bundle.\r\n * Returns the document changes resulting from applying those documents.\r\n *\r\n * @param txn - Transaction to use to read existing documents from storage.\r\n * @param documentBuffer - Document buffer to collect the resulted changes to be\r\n *        applied to storage.\r\n * @param documents - Documents to be applied.\r\n * @param globalVersion - A `SnapshotVersion` representing the read time if all\r\n *        documents have the same read time.\r\n * @param documentVersions - A DocumentKey-to-SnapshotVersion map if documents\r\n *        have their own read time.\r\n *\r\n * Note: this function will use `documentVersions` if it is defined;\r\n * when it is not defined, resorts to `globalVersion`.\r\n */\r\nfunction populateDocumentChangeBuffer(txn, documentBuffer, documents, globalVersion, \r\n// TODO(wuandy): We could add `readTime` to MaybeDocument instead to remove\r\n// this parameter.\r\ndocumentVersions) {\r\n    let updatedKeys = documentKeySet();\r\n    documents.forEach(k => (updatedKeys = updatedKeys.add(k)));\r\n    return documentBuffer.getEntries(txn, updatedKeys).next(existingDocs => {\r\n        let changedDocs = mutableDocumentMap();\r\n        documents.forEach((key, doc) => {\r\n            const existingDoc = existingDocs.get(key);\r\n            const docReadTime = (documentVersions === null || documentVersions === void 0 ? void 0 : documentVersions.get(key)) || globalVersion;\r\n            // Note: The order of the steps below is important, since we want\r\n            // to ensure that rejected limbo resolutions (which fabricate\r\n            // NoDocuments with SnapshotVersion.min()) never add documents to\r\n            // cache.\r\n            if (doc.isNoDocument() && doc.version.isEqual(SnapshotVersion.min())) {\r\n                // NoDocuments with SnapshotVersion.min() are used in manufactured\r\n                // events. We remove these documents from cache since we lost\r\n                // access.\r\n                documentBuffer.removeEntry(key, docReadTime);\r\n                changedDocs = changedDocs.insert(key, doc);\r\n            }\r\n            else if (!existingDoc.isValidDocument() ||\r\n                doc.version.compareTo(existingDoc.version) > 0 ||\r\n                (doc.version.compareTo(existingDoc.version) === 0 &&\r\n                    existingDoc.hasPendingWrites)) {\r\n                documentBuffer.addEntry(doc, docReadTime);\r\n                changedDocs = changedDocs.insert(key, doc);\r\n            }\r\n            else {\r\n                logDebug(LOG_TAG$c, 'Ignoring outdated watch update for ', key, '. Current version:', existingDoc.version, ' Watch version:', doc.version);\r\n            }\r\n        });\r\n        return changedDocs;\r\n    });\r\n}\r\n/**\r\n * Returns true if the newTargetData should be persisted during an update of\r\n * an active target. TargetData should always be persisted when a target is\r\n * being released and should not call this function.\r\n *\r\n * While the target is active, TargetData updates can be omitted when nothing\r\n * about the target has changed except metadata like the resume token or\r\n * snapshot version. Occasionally it's worth the extra write to prevent these\r\n * values from getting too stale after a crash, but this doesn't have to be\r\n * too frequent.\r\n */\r\nfunction shouldPersistTargetData(oldTargetData, newTargetData, change) {\r\n    hardAssert(newTargetData.resumeToken.approximateByteSize() > 0);\r\n    // Always persist target data if we don't already have a resume token.\r\n    if (oldTargetData.resumeToken.approximateByteSize() === 0) {\r\n        return true;\r\n    }\r\n    // Don't allow resume token changes to be buffered indefinitely. This\r\n    // allows us to be reasonably up-to-date after a crash and avoids needing\r\n    // to loop over all active queries on shutdown. Especially in the browser\r\n    // we may not get time to do anything interesting while the current tab is\r\n    // closing.\r\n    const timeDelta = newTargetData.snapshotVersion.toMicroseconds() -\r\n        oldTargetData.snapshotVersion.toMicroseconds();\r\n    if (timeDelta >= RESUME_TOKEN_MAX_AGE_MICROS) {\r\n        return true;\r\n    }\r\n    // Otherwise if the only thing that has changed about a target is its resume\r\n    // token it's not worth persisting. Note that the RemoteStore keeps an\r\n    // in-memory view of the currently active targets which includes the current\r\n    // resume token, so stream failure or user changes will still use an\r\n    // up-to-date resume token regardless of what we do here.\r\n    const changes = change.addedDocuments.size +\r\n        change.modifiedDocuments.size +\r\n        change.removedDocuments.size;\r\n    return changes > 0;\r\n}\r\n/**\r\n * Notifies local store of the changed views to locally pin documents.\r\n */\r\nasync function localStoreNotifyLocalViewChanges(localStore, viewChanges) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    try {\r\n        await localStoreImpl.persistence.runTransaction('notifyLocalViewChanges', 'readwrite', txn => {\r\n            return PersistencePromise.forEach(viewChanges, (viewChange) => {\r\n                return PersistencePromise.forEach(viewChange.addedKeys, (key) => localStoreImpl.persistence.referenceDelegate.addReference(txn, viewChange.targetId, key)).next(() => PersistencePromise.forEach(viewChange.removedKeys, (key) => localStoreImpl.persistence.referenceDelegate.removeReference(txn, viewChange.targetId, key)));\r\n            });\r\n        });\r\n    }\r\n    catch (e) {\r\n        if (isIndexedDbTransactionError(e)) {\r\n            // If `notifyLocalViewChanges` fails, we did not advance the sequence\r\n            // number for the documents that were included in this transaction.\r\n            // This might trigger them to be deleted earlier than they otherwise\r\n            // would have, but it should not invalidate the integrity of the data.\r\n            logDebug(LOG_TAG$c, 'Failed to update sequence numbers: ' + e);\r\n        }\r\n        else {\r\n            throw e;\r\n        }\r\n    }\r\n    for (const viewChange of viewChanges) {\r\n        const targetId = viewChange.targetId;\r\n        if (!viewChange.fromCache) {\r\n            const targetData = localStoreImpl.targetDataByTarget.get(targetId);\r\n            // Advance the last limbo free snapshot version\r\n            const lastLimboFreeSnapshotVersion = targetData.snapshotVersion;\r\n            const updatedTargetData = targetData.withLastLimboFreeSnapshotVersion(lastLimboFreeSnapshotVersion);\r\n            localStoreImpl.targetDataByTarget =\r\n                localStoreImpl.targetDataByTarget.insert(targetId, updatedTargetData);\r\n        }\r\n    }\r\n}\r\n/**\r\n * Gets the mutation batch after the passed in batchId in the mutation queue\r\n * or null if empty.\r\n * @param afterBatchId - If provided, the batch to search after.\r\n * @returns The next mutation or null if there wasn't one.\r\n */\r\nfunction localStoreGetNextMutationBatch(localStore, afterBatchId) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Get next mutation batch', 'readonly', txn => {\r\n        if (afterBatchId === undefined) {\r\n            afterBatchId = BATCHID_UNKNOWN;\r\n        }\r\n        return localStoreImpl.mutationQueue.getNextMutationBatchAfterBatchId(txn, afterBatchId);\r\n    });\r\n}\r\n/**\r\n * Reads the current value of a Document with a given key or null if not\r\n * found - used for testing.\r\n */\r\nfunction localStoreReadDocument(localStore, key) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('read document', 'readonly', txn => localStoreImpl.localDocuments.getDocument(txn, key));\r\n}\r\n/**\r\n * Assigns the given target an internal ID so that its results can be pinned so\r\n * they don't get GC'd. A target must be allocated in the local store before\r\n * the store can be used to manage its view.\r\n *\r\n * Allocating an already allocated `Target` will return the existing `TargetData`\r\n * for that `Target`.\r\n */\r\nfunction localStoreAllocateTarget(localStore, target) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence\r\n        .runTransaction('Allocate target', 'readwrite', txn => {\r\n        let targetData;\r\n        return localStoreImpl.targetCache\r\n            .getTargetData(txn, target)\r\n            .next((cached) => {\r\n            if (cached) {\r\n                // This target has been listened to previously, so reuse the\r\n                // previous targetID.\r\n                // TODO(mcg): freshen last accessed date?\r\n                targetData = cached;\r\n                return PersistencePromise.resolve(targetData);\r\n            }\r\n            else {\r\n                return localStoreImpl.targetCache\r\n                    .allocateTargetId(txn)\r\n                    .next(targetId => {\r\n                    targetData = new TargetData(target, targetId, 0 /* Listen */, txn.currentSequenceNumber);\r\n                    return localStoreImpl.targetCache\r\n                        .addTargetData(txn, targetData)\r\n                        .next(() => targetData);\r\n                });\r\n            }\r\n        });\r\n    })\r\n        .then(targetData => {\r\n        // If Multi-Tab is enabled, the existing target data may be newer than\r\n        // the in-memory data\r\n        const cachedTargetData = localStoreImpl.targetDataByTarget.get(targetData.targetId);\r\n        if (cachedTargetData === null ||\r\n            targetData.snapshotVersion.compareTo(cachedTargetData.snapshotVersion) >\r\n                0) {\r\n            localStoreImpl.targetDataByTarget =\r\n                localStoreImpl.targetDataByTarget.insert(targetData.targetId, targetData);\r\n            localStoreImpl.targetIdByTarget.set(target, targetData.targetId);\r\n        }\r\n        return targetData;\r\n    });\r\n}\r\n/**\r\n * Returns the TargetData as seen by the LocalStore, including updates that may\r\n * have not yet been persisted to the TargetCache.\r\n */\r\n// Visible for testing.\r\nfunction localStoreGetTargetData(localStore, transaction, target) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    const targetId = localStoreImpl.targetIdByTarget.get(target);\r\n    if (targetId !== undefined) {\r\n        return PersistencePromise.resolve(localStoreImpl.targetDataByTarget.get(targetId));\r\n    }\r\n    else {\r\n        return localStoreImpl.targetCache.getTargetData(transaction, target);\r\n    }\r\n}\r\n/**\r\n * Unpins all the documents associated with the given target. If\r\n * `keepPersistedTargetData` is set to false and Eager GC enabled, the method\r\n * directly removes the associated target data from the target cache.\r\n *\r\n * Releasing a non-existing `Target` is a no-op.\r\n */\r\n// PORTING NOTE: `keepPersistedTargetData` is multi-tab only.\r\nasync function localStoreReleaseTarget(localStore, targetId, keepPersistedTargetData) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    const targetData = localStoreImpl.targetDataByTarget.get(targetId);\r\n    const mode = keepPersistedTargetData ? 'readwrite' : 'readwrite-primary';\r\n    try {\r\n        if (!keepPersistedTargetData) {\r\n            await localStoreImpl.persistence.runTransaction('Release target', mode, txn => {\r\n                return localStoreImpl.persistence.referenceDelegate.removeTarget(txn, targetData);\r\n            });\r\n        }\r\n    }\r\n    catch (e) {\r\n        if (isIndexedDbTransactionError(e)) {\r\n            // All `releaseTarget` does is record the final metadata state for the\r\n            // target, but we've been recording this periodically during target\r\n            // activity. If we lose this write this could cause a very slight\r\n            // difference in the order of target deletion during GC, but we\r\n            // don't define exact LRU semantics so this is acceptable.\r\n            logDebug(LOG_TAG$c, `Failed to update sequence numbers for target ${targetId}: ${e}`);\r\n        }\r\n        else {\r\n            throw e;\r\n        }\r\n    }\r\n    localStoreImpl.targetDataByTarget =\r\n        localStoreImpl.targetDataByTarget.remove(targetId);\r\n    localStoreImpl.targetIdByTarget.delete(targetData.target);\r\n}\r\n/**\r\n * Runs the specified query against the local store and returns the results,\r\n * potentially taking advantage of query data from previous executions (such\r\n * as the set of remote keys).\r\n *\r\n * @param usePreviousResults - Whether results from previous executions can\r\n * be used to optimize this query execution.\r\n */\r\nfunction localStoreExecuteQuery(localStore, query, usePreviousResults) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    let lastLimboFreeSnapshotVersion = SnapshotVersion.min();\r\n    let remoteKeys = documentKeySet();\r\n    return localStoreImpl.persistence.runTransaction('Execute query', 'readonly', txn => {\r\n        return localStoreGetTargetData(localStoreImpl, txn, queryToTarget(query))\r\n            .next(targetData => {\r\n            if (targetData) {\r\n                lastLimboFreeSnapshotVersion =\r\n                    targetData.lastLimboFreeSnapshotVersion;\r\n                return localStoreImpl.targetCache\r\n                    .getMatchingKeysForTargetId(txn, targetData.targetId)\r\n                    .next(result => {\r\n                    remoteKeys = result;\r\n                });\r\n            }\r\n        })\r\n            .next(() => localStoreImpl.queryEngine.getDocumentsMatchingQuery(txn, query, usePreviousResults\r\n            ? lastLimboFreeSnapshotVersion\r\n            : SnapshotVersion.min(), usePreviousResults ? remoteKeys : documentKeySet()))\r\n            .next(documents => {\r\n            return { documents, remoteKeys };\r\n        });\r\n    });\r\n}\r\nfunction applyWriteToRemoteDocuments(localStoreImpl, txn, batchResult, documentBuffer) {\r\n    const batch = batchResult.batch;\r\n    const docKeys = batch.keys();\r\n    let promiseChain = PersistencePromise.resolve();\r\n    docKeys.forEach(docKey => {\r\n        promiseChain = promiseChain\r\n            .next(() => documentBuffer.getEntry(txn, docKey))\r\n            .next(doc => {\r\n            const ackVersion = batchResult.docVersions.get(docKey);\r\n            hardAssert(ackVersion !== null);\r\n            if (doc.version.compareTo(ackVersion) < 0) {\r\n                batch.applyToRemoteDocument(doc, batchResult);\r\n                if (doc.isValidDocument()) {\r\n                    // We use the commitVersion as the readTime rather than the\r\n                    // document's updateTime since the updateTime is not advanced\r\n                    // for updates that do not modify the underlying document.\r\n                    documentBuffer.addEntry(doc, batchResult.commitVersion);\r\n                }\r\n            }\r\n        });\r\n    });\r\n    return promiseChain.next(() => localStoreImpl.mutationQueue.removeMutationBatch(txn, batch));\r\n}\r\n/** Returns the local view of the documents affected by a mutation batch. */\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction localStoreLookupMutationDocuments(localStore, batchId) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    const mutationQueueImpl = debugCast(localStoreImpl.mutationQueue);\r\n    return localStoreImpl.persistence.runTransaction('Lookup mutation documents', 'readonly', txn => {\r\n        return mutationQueueImpl.lookupMutationKeys(txn, batchId).next(keys => {\r\n            if (keys) {\r\n                return localStoreImpl.localDocuments.getDocuments(txn, keys);\r\n            }\r\n            else {\r\n                return PersistencePromise.resolve(null);\r\n            }\r\n        });\r\n    });\r\n}\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction localStoreRemoveCachedMutationBatchMetadata(localStore, batchId) {\r\n    const mutationQueueImpl = debugCast(debugCast(localStore, LocalStoreImpl).mutationQueue);\r\n    mutationQueueImpl.removeCachedMutationKeys(batchId);\r\n}\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction localStoreGetActiveClients(localStore) {\r\n    const persistenceImpl = debugCast(debugCast(localStore, LocalStoreImpl).persistence);\r\n    return persistenceImpl.getActiveClients();\r\n}\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction localStoreGetCachedTarget(localStore, targetId) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    const targetCacheImpl = debugCast(localStoreImpl.targetCache);\r\n    const cachedTargetData = localStoreImpl.targetDataByTarget.get(targetId);\r\n    if (cachedTargetData) {\r\n        return Promise.resolve(cachedTargetData.target);\r\n    }\r\n    else {\r\n        return localStoreImpl.persistence.runTransaction('Get target data', 'readonly', txn => {\r\n            return targetCacheImpl\r\n                .getTargetDataForTarget(txn, targetId)\r\n                .next(targetData => (targetData ? targetData.target : null));\r\n        });\r\n    }\r\n}\r\n/**\r\n * Returns the set of documents that have been updated since the last call.\r\n * If this is the first call, returns the set of changes since client\r\n * initialization. Further invocations will return document that have changed\r\n * since the prior call.\r\n */\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction localStoreGetNewDocumentChanges(localStore) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence\r\n        .runTransaction('Get new document changes', 'readonly', txn => remoteDocumentCacheGetNewDocumentChanges(localStoreImpl.remoteDocuments, txn, localStoreImpl.lastDocumentChangeReadTime))\r\n        .then(({ changedDocs, readTime }) => {\r\n        localStoreImpl.lastDocumentChangeReadTime = readTime;\r\n        return changedDocs;\r\n    });\r\n}\r\n/**\r\n * Reads the newest document change from persistence and moves the internal\r\n * synchronization marker forward so that calls to `getNewDocumentChanges()`\r\n * only return changes that happened after client initialization.\r\n */\r\n// PORTING NOTE: Multi-Tab only.\r\nasync function localStoreSynchronizeLastDocumentChangeReadTime(localStore) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence\r\n        .runTransaction('Synchronize last document change read time', 'readonly', txn => remoteDocumentCacheGetLastReadTime(txn))\r\n        .then(readTime => {\r\n        localStoreImpl.lastDocumentChangeReadTime = readTime;\r\n    });\r\n}\r\n/**\r\n * Creates a new target using the given bundle name, which will be used to\r\n * hold the keys of all documents from the bundle in query-document mappings.\r\n * This ensures that the loaded documents do not get garbage collected\r\n * right away.\r\n */\r\nfunction umbrellaTarget(bundleName) {\r\n    // It is OK that the path used for the query is not valid, because this will\r\n    // not be read and queried.\r\n    return queryToTarget(newQueryForPath(ResourcePath.fromString(`__bundle__/docs/${bundleName}`)));\r\n}\r\n/**\r\n * Applies the documents from a bundle to the \"ground-state\" (remote)\r\n * documents.\r\n *\r\n * LocalDocuments are re-calculated if there are remaining mutations in the\r\n * queue.\r\n */\r\nasync function localStoreApplyBundledDocuments(localStore, bundleConverter, documents, bundleName) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    let documentKeys = documentKeySet();\r\n    let documentMap = mutableDocumentMap();\r\n    let versionMap = documentVersionMap();\r\n    for (const bundleDoc of documents) {\r\n        const documentKey = bundleConverter.toDocumentKey(bundleDoc.metadata.name);\r\n        if (bundleDoc.document) {\r\n            documentKeys = documentKeys.add(documentKey);\r\n        }\r\n        documentMap = documentMap.insert(documentKey, bundleConverter.toMutableDocument(bundleDoc));\r\n        versionMap = versionMap.insert(documentKey, bundleConverter.toSnapshotVersion(bundleDoc.metadata.readTime));\r\n    }\r\n    const documentBuffer = localStoreImpl.remoteDocuments.newChangeBuffer({\r\n        trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\r\n    });\r\n    // Allocates a target to hold all document keys from the bundle, such that\r\n    // they will not get garbage collected right away.\r\n    const umbrellaTargetData = await localStoreAllocateTarget(localStoreImpl, umbrellaTarget(bundleName));\r\n    return localStoreImpl.persistence.runTransaction('Apply bundle documents', 'readwrite', txn => {\r\n        return populateDocumentChangeBuffer(txn, documentBuffer, documentMap, SnapshotVersion.min(), versionMap)\r\n            .next(changedDocs => {\r\n            documentBuffer.apply(txn);\r\n            return changedDocs;\r\n        })\r\n            .next(changedDocs => {\r\n            return localStoreImpl.targetCache\r\n                .removeMatchingKeysForTargetId(txn, umbrellaTargetData.targetId)\r\n                .next(() => localStoreImpl.targetCache.addMatchingKeys(txn, documentKeys, umbrellaTargetData.targetId))\r\n                .next(() => localStoreImpl.localDocuments.applyLocalViewToDocuments(txn, changedDocs))\r\n                .next(() => changedDocs);\r\n        });\r\n    });\r\n}\r\n/**\r\n * Returns a promise of a boolean to indicate if the given bundle has already\r\n * been loaded and the create time is newer than the current loading bundle.\r\n */\r\nfunction localStoreHasNewerBundle(localStore, bundleMetadata) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    const currentReadTime = fromVersion(bundleMetadata.createTime);\r\n    return localStoreImpl.persistence\r\n        .runTransaction('hasNewerBundle', 'readonly', transaction => {\r\n        return localStoreImpl.bundleCache.getBundleMetadata(transaction, bundleMetadata.id);\r\n    })\r\n        .then(cached => {\r\n        return !!cached && cached.createTime.compareTo(currentReadTime) >= 0;\r\n    });\r\n}\r\n/**\r\n * Saves the given `BundleMetadata` to local persistence.\r\n */\r\nfunction localStoreSaveBundle(localStore, bundleMetadata) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Save bundle', 'readwrite', transaction => {\r\n        return localStoreImpl.bundleCache.saveBundleMetadata(transaction, bundleMetadata);\r\n    });\r\n}\r\n/**\r\n * Returns a promise of a `NamedQuery` associated with given query name. Promise\r\n * resolves to undefined if no persisted data can be found.\r\n */\r\nfunction localStoreGetNamedQuery(localStore, queryName) {\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Get named query', 'readonly', transaction => localStoreImpl.bundleCache.getNamedQuery(transaction, queryName));\r\n}\r\n/**\r\n * Saves the given `NamedQuery` to local persistence.\r\n */\r\nasync function localStoreSaveNamedQuery(localStore, query, documents = documentKeySet()) {\r\n    // Allocate a target for the named query such that it can be resumed\r\n    // from associated read time if users use it to listen.\r\n    // NOTE: this also means if no corresponding target exists, the new target\r\n    // will remain active and will not get collected, unless users happen to\r\n    // unlisten the query somehow.\r\n    const allocated = await localStoreAllocateTarget(localStore, queryToTarget(fromBundledQuery(query.bundledQuery)));\r\n    const localStoreImpl = debugCast(localStore);\r\n    return localStoreImpl.persistence.runTransaction('Save named query', 'readwrite', transaction => {\r\n        const readTime = fromVersion(query.readTime);\r\n        // Simply save the query itself if it is older than what the SDK already\r\n        // has.\r\n        if (allocated.snapshotVersion.compareTo(readTime) >= 0) {\r\n            return localStoreImpl.bundleCache.saveNamedQuery(transaction, query);\r\n        }\r\n        // Update existing target data because the query from the bundle is newer.\r\n        const newTargetData = allocated.withResumeToken(ByteString.EMPTY_BYTE_STRING, readTime);\r\n        localStoreImpl.targetDataByTarget =\r\n            localStoreImpl.targetDataByTarget.insert(newTargetData.targetId, newTargetData);\r\n        return localStoreImpl.targetCache\r\n            .updateTargetData(transaction, newTargetData)\r\n            .next(() => localStoreImpl.targetCache.removeMatchingKeysForTargetId(transaction, allocated.targetId))\r\n            .next(() => localStoreImpl.targetCache.addMatchingKeys(transaction, documents, allocated.targetId))\r\n            .next(() => localStoreImpl.bundleCache.saveNamedQuery(transaction, query));\r\n    });\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass MemoryBundleCache {\r\n    constructor(serializer) {\r\n        this.serializer = serializer;\r\n        this.bundles = new Map();\r\n        this.namedQueries = new Map();\r\n    }\r\n    getBundleMetadata(transaction, bundleId) {\r\n        return PersistencePromise.resolve(this.bundles.get(bundleId));\r\n    }\r\n    saveBundleMetadata(transaction, bundleMetadata) {\r\n        this.bundles.set(bundleMetadata.id, fromBundleMetadata(bundleMetadata));\r\n        return PersistencePromise.resolve();\r\n    }\r\n    getNamedQuery(transaction, queryName) {\r\n        return PersistencePromise.resolve(this.namedQueries.get(queryName));\r\n    }\r\n    saveNamedQuery(transaction, query) {\r\n        this.namedQueries.set(query.name, fromProtoNamedQuery(query));\r\n        return PersistencePromise.resolve();\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A collection of references to a document from some kind of numbered entity\r\n * (either a target ID or batch ID). As references are added to or removed from\r\n * the set corresponding events are emitted to a registered garbage collector.\r\n *\r\n * Each reference is represented by a DocumentReference object. Each of them\r\n * contains enough information to uniquely identify the reference. They are all\r\n * stored primarily in a set sorted by key. A document is considered garbage if\r\n * there's no references in that set (this can be efficiently checked thanks to\r\n * sorting by key).\r\n *\r\n * ReferenceSet also keeps a secondary set that contains references sorted by\r\n * IDs. This one is used to efficiently implement removal of all references by\r\n * some target ID.\r\n */\r\nclass ReferenceSet {\r\n    constructor() {\r\n        // A set of outstanding references to a document sorted by key.\r\n        this.refsByKey = new SortedSet(DocReference.compareByKey);\r\n        // A set of outstanding references to a document sorted by target id.\r\n        this.refsByTarget = new SortedSet(DocReference.compareByTargetId);\r\n    }\r\n    /** Returns true if the reference set contains no references. */\r\n    isEmpty() {\r\n        return this.refsByKey.isEmpty();\r\n    }\r\n    /** Adds a reference to the given document key for the given ID. */\r\n    addReference(key, id) {\r\n        const ref = new DocReference(key, id);\r\n        this.refsByKey = this.refsByKey.add(ref);\r\n        this.refsByTarget = this.refsByTarget.add(ref);\r\n    }\r\n    /** Add references to the given document keys for the given ID. */\r\n    addReferences(keys, id) {\r\n        keys.forEach(key => this.addReference(key, id));\r\n    }\r\n    /**\r\n     * Removes a reference to the given document key for the given\r\n     * ID.\r\n     */\r\n    removeReference(key, id) {\r\n        this.removeRef(new DocReference(key, id));\r\n    }\r\n    removeReferences(keys, id) {\r\n        keys.forEach(key => this.removeReference(key, id));\r\n    }\r\n    /**\r\n     * Clears all references with a given ID. Calls removeRef() for each key\r\n     * removed.\r\n     */\r\n    removeReferencesForId(id) {\r\n        const emptyKey = new DocumentKey(new ResourcePath([]));\r\n        const startRef = new DocReference(emptyKey, id);\r\n        const endRef = new DocReference(emptyKey, id + 1);\r\n        const keys = [];\r\n        this.refsByTarget.forEachInRange([startRef, endRef], ref => {\r\n            this.removeRef(ref);\r\n            keys.push(ref.key);\r\n        });\r\n        return keys;\r\n    }\r\n    removeAllReferences() {\r\n        this.refsByKey.forEach(ref => this.removeRef(ref));\r\n    }\r\n    removeRef(ref) {\r\n        this.refsByKey = this.refsByKey.delete(ref);\r\n        this.refsByTarget = this.refsByTarget.delete(ref);\r\n    }\r\n    referencesForId(id) {\r\n        const emptyKey = new DocumentKey(new ResourcePath([]));\r\n        const startRef = new DocReference(emptyKey, id);\r\n        const endRef = new DocReference(emptyKey, id + 1);\r\n        let keys = documentKeySet();\r\n        this.refsByTarget.forEachInRange([startRef, endRef], ref => {\r\n            keys = keys.add(ref.key);\r\n        });\r\n        return keys;\r\n    }\r\n    containsKey(key) {\r\n        const ref = new DocReference(key, 0);\r\n        const firstRef = this.refsByKey.firstAfterOrEqual(ref);\r\n        return firstRef !== null && key.isEqual(firstRef.key);\r\n    }\r\n}\r\nclass DocReference {\r\n    constructor(key, targetOrBatchId) {\r\n        this.key = key;\r\n        this.targetOrBatchId = targetOrBatchId;\r\n    }\r\n    /** Compare by key then by ID */\r\n    static compareByKey(left, right) {\r\n        return (DocumentKey.comparator(left.key, right.key) ||\r\n            primitiveComparator(left.targetOrBatchId, right.targetOrBatchId));\r\n    }\r\n    /** Compare by ID then by key */\r\n    static compareByTargetId(left, right) {\r\n        return (primitiveComparator(left.targetOrBatchId, right.targetOrBatchId) ||\r\n            DocumentKey.comparator(left.key, right.key));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass MemoryMutationQueue {\r\n    constructor(indexManager, referenceDelegate) {\r\n        this.indexManager = indexManager;\r\n        this.referenceDelegate = referenceDelegate;\r\n        /**\r\n         * The set of all mutations that have been sent but not yet been applied to\r\n         * the backend.\r\n         */\r\n        this.mutationQueue = [];\r\n        /** Next value to use when assigning sequential IDs to each mutation batch. */\r\n        this.nextBatchId = 1;\r\n        /** An ordered mapping between documents and the mutations batch IDs. */\r\n        this.batchesByDocumentKey = new SortedSet(DocReference.compareByKey);\r\n    }\r\n    checkEmpty(transaction) {\r\n        return PersistencePromise.resolve(this.mutationQueue.length === 0);\r\n    }\r\n    addMutationBatch(transaction, localWriteTime, baseMutations, mutations) {\r\n        const batchId = this.nextBatchId;\r\n        this.nextBatchId++;\r\n        if (this.mutationQueue.length > 0) {\r\n            this.mutationQueue[this.mutationQueue.length - 1];\r\n        }\r\n        const batch = new MutationBatch(batchId, localWriteTime, baseMutations, mutations);\r\n        this.mutationQueue.push(batch);\r\n        // Track references by document key and index collection parents.\r\n        for (const mutation of mutations) {\r\n            this.batchesByDocumentKey = this.batchesByDocumentKey.add(new DocReference(mutation.key, batchId));\r\n            this.indexManager.addToCollectionParentIndex(transaction, mutation.key.path.popLast());\r\n        }\r\n        return PersistencePromise.resolve(batch);\r\n    }\r\n    lookupMutationBatch(transaction, batchId) {\r\n        return PersistencePromise.resolve(this.findMutationBatch(batchId));\r\n    }\r\n    getNextMutationBatchAfterBatchId(transaction, batchId) {\r\n        const nextBatchId = batchId + 1;\r\n        // The requested batchId may still be out of range so normalize it to the\r\n        // start of the queue.\r\n        const rawIndex = this.indexOfBatchId(nextBatchId);\r\n        const index = rawIndex < 0 ? 0 : rawIndex;\r\n        return PersistencePromise.resolve(this.mutationQueue.length > index ? this.mutationQueue[index] : null);\r\n    }\r\n    getHighestUnacknowledgedBatchId() {\r\n        return PersistencePromise.resolve(this.mutationQueue.length === 0 ? BATCHID_UNKNOWN : this.nextBatchId - 1);\r\n    }\r\n    getAllMutationBatches(transaction) {\r\n        return PersistencePromise.resolve(this.mutationQueue.slice());\r\n    }\r\n    getAllMutationBatchesAffectingDocumentKey(transaction, documentKey) {\r\n        const start = new DocReference(documentKey, 0);\r\n        const end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\r\n        const result = [];\r\n        this.batchesByDocumentKey.forEachInRange([start, end], ref => {\r\n            const batch = this.findMutationBatch(ref.targetOrBatchId);\r\n            result.push(batch);\r\n        });\r\n        return PersistencePromise.resolve(result);\r\n    }\r\n    getAllMutationBatchesAffectingDocumentKeys(transaction, documentKeys) {\r\n        let uniqueBatchIDs = new SortedSet(primitiveComparator);\r\n        documentKeys.forEach(documentKey => {\r\n            const start = new DocReference(documentKey, 0);\r\n            const end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\r\n            this.batchesByDocumentKey.forEachInRange([start, end], ref => {\r\n                uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\r\n            });\r\n        });\r\n        return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\r\n    }\r\n    getAllMutationBatchesAffectingQuery(transaction, query) {\r\n        // Use the query path as a prefix for testing if a document matches the\r\n        // query.\r\n        const prefix = query.path;\r\n        const immediateChildrenPathLength = prefix.length + 1;\r\n        // Construct a document reference for actually scanning the index. Unlike\r\n        // the prefix the document key in this reference must have an even number of\r\n        // segments. The empty segment can be used a suffix of the query path\r\n        // because it precedes all other segments in an ordered traversal.\r\n        let startPath = prefix;\r\n        if (!DocumentKey.isDocumentKey(startPath)) {\r\n            startPath = startPath.child('');\r\n        }\r\n        const start = new DocReference(new DocumentKey(startPath), 0);\r\n        // Find unique batchIDs referenced by all documents potentially matching the\r\n        // query.\r\n        let uniqueBatchIDs = new SortedSet(primitiveComparator);\r\n        this.batchesByDocumentKey.forEachWhile(ref => {\r\n            const rowKeyPath = ref.key.path;\r\n            if (!prefix.isPrefixOf(rowKeyPath)) {\r\n                return false;\r\n            }\r\n            else {\r\n                // Rows with document keys more than one segment longer than the query\r\n                // path can't be matches. For example, a query on 'rooms' can't match\r\n                // the document /rooms/abc/messages/xyx.\r\n                // TODO(mcg): we'll need a different scanner when we implement\r\n                // ancestor queries.\r\n                if (rowKeyPath.length === immediateChildrenPathLength) {\r\n                    uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\r\n                }\r\n                return true;\r\n            }\r\n        }, start);\r\n        return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\r\n    }\r\n    findMutationBatches(batchIDs) {\r\n        // Construct an array of matching batches, sorted by batchID to ensure that\r\n        // multiple mutations affecting the same document key are applied in order.\r\n        const result = [];\r\n        batchIDs.forEach(batchId => {\r\n            const batch = this.findMutationBatch(batchId);\r\n            if (batch !== null) {\r\n                result.push(batch);\r\n            }\r\n        });\r\n        return result;\r\n    }\r\n    removeMutationBatch(transaction, batch) {\r\n        // Find the position of the first batch for removal.\r\n        const batchIndex = this.indexOfExistingBatchId(batch.batchId, 'removed');\r\n        hardAssert(batchIndex === 0);\r\n        this.mutationQueue.shift();\r\n        let references = this.batchesByDocumentKey;\r\n        return PersistencePromise.forEach(batch.mutations, (mutation) => {\r\n            const ref = new DocReference(mutation.key, batch.batchId);\r\n            references = references.delete(ref);\r\n            return this.referenceDelegate.markPotentiallyOrphaned(transaction, mutation.key);\r\n        }).next(() => {\r\n            this.batchesByDocumentKey = references;\r\n        });\r\n    }\r\n    removeCachedMutationKeys(batchId) {\r\n        // No-op since the memory mutation queue does not maintain a separate cache.\r\n    }\r\n    containsKey(txn, key) {\r\n        const ref = new DocReference(key, 0);\r\n        const firstRef = this.batchesByDocumentKey.firstAfterOrEqual(ref);\r\n        return PersistencePromise.resolve(key.isEqual(firstRef && firstRef.key));\r\n    }\r\n    performConsistencyCheck(txn) {\r\n        if (this.mutationQueue.length === 0) ;\r\n        return PersistencePromise.resolve();\r\n    }\r\n    /**\r\n     * Finds the index of the given batchId in the mutation queue and asserts that\r\n     * the resulting index is within the bounds of the queue.\r\n     *\r\n     * @param batchId - The batchId to search for\r\n     * @param action - A description of what the caller is doing, phrased in passive\r\n     * form (e.g. \"acknowledged\" in a routine that acknowledges batches).\r\n     */\r\n    indexOfExistingBatchId(batchId, action) {\r\n        const index = this.indexOfBatchId(batchId);\r\n        return index;\r\n    }\r\n    /**\r\n     * Finds the index of the given batchId in the mutation queue. This operation\r\n     * is O(1).\r\n     *\r\n     * @returns The computed index of the batch with the given batchId, based on\r\n     * the state of the queue. Note this index can be negative if the requested\r\n     * batchId has already been remvoed from the queue or past the end of the\r\n     * queue if the batchId is larger than the last added batch.\r\n     */\r\n    indexOfBatchId(batchId) {\r\n        if (this.mutationQueue.length === 0) {\r\n            // As an index this is past the end of the queue\r\n            return 0;\r\n        }\r\n        // Examine the front of the queue to figure out the difference between the\r\n        // batchId and indexes in the array. Note that since the queue is ordered\r\n        // by batchId, if the first batch has a larger batchId then the requested\r\n        // batchId doesn't exist in the queue.\r\n        const firstBatchId = this.mutationQueue[0].batchId;\r\n        return batchId - firstBatchId;\r\n    }\r\n    /**\r\n     * A version of lookupMutationBatch that doesn't return a promise, this makes\r\n     * other functions that uses this code easier to read and more efficent.\r\n     */\r\n    findMutationBatch(batchId) {\r\n        const index = this.indexOfBatchId(batchId);\r\n        if (index < 0 || index >= this.mutationQueue.length) {\r\n            return null;\r\n        }\r\n        const batch = this.mutationQueue[index];\r\n        return batch;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction documentEntryMap() {\r\n    return new SortedMap(DocumentKey.comparator);\r\n}\r\n/**\r\n * The memory-only RemoteDocumentCache for IndexedDb. To construct, invoke\r\n * `newMemoryRemoteDocumentCache()`.\r\n */\r\nclass MemoryRemoteDocumentCacheImpl {\r\n    /**\r\n     * @param sizer - Used to assess the size of a document. For eager GC, this is\r\n     * expected to just return 0 to avoid unnecessarily doing the work of\r\n     * calculating the size.\r\n     */\r\n    constructor(indexManager, sizer) {\r\n        this.indexManager = indexManager;\r\n        this.sizer = sizer;\r\n        /** Underlying cache of documents and their read times. */\r\n        this.docs = documentEntryMap();\r\n        /** Size of all cached documents. */\r\n        this.size = 0;\r\n    }\r\n    /**\r\n     * Adds the supplied entry to the cache and updates the cache size as appropriate.\r\n     *\r\n     * All calls of `addEntry`  are required to go through the RemoteDocumentChangeBuffer\r\n     * returned by `newChangeBuffer()`.\r\n     */\r\n    addEntry(transaction, doc, readTime) {\r\n        const key = doc.key;\r\n        const entry = this.docs.get(key);\r\n        const previousSize = entry ? entry.size : 0;\r\n        const currentSize = this.sizer(doc);\r\n        this.docs = this.docs.insert(key, {\r\n            document: doc.clone(),\r\n            size: currentSize,\r\n            readTime\r\n        });\r\n        this.size += currentSize - previousSize;\r\n        return this.indexManager.addToCollectionParentIndex(transaction, key.path.popLast());\r\n    }\r\n    /**\r\n     * Removes the specified entry from the cache and updates the cache size as appropriate.\r\n     *\r\n     * All calls of `removeEntry` are required to go through the RemoteDocumentChangeBuffer\r\n     * returned by `newChangeBuffer()`.\r\n     */\r\n    removeEntry(documentKey) {\r\n        const entry = this.docs.get(documentKey);\r\n        if (entry) {\r\n            this.docs = this.docs.remove(documentKey);\r\n            this.size -= entry.size;\r\n        }\r\n    }\r\n    getEntry(transaction, documentKey) {\r\n        const entry = this.docs.get(documentKey);\r\n        return PersistencePromise.resolve(entry\r\n            ? entry.document.clone()\r\n            : MutableDocument.newInvalidDocument(documentKey));\r\n    }\r\n    getEntries(transaction, documentKeys) {\r\n        let results = mutableDocumentMap();\r\n        documentKeys.forEach(documentKey => {\r\n            const entry = this.docs.get(documentKey);\r\n            results = results.insert(documentKey, entry\r\n                ? entry.document.clone()\r\n                : MutableDocument.newInvalidDocument(documentKey));\r\n        });\r\n        return PersistencePromise.resolve(results);\r\n    }\r\n    getDocumentsMatchingQuery(transaction, query, sinceReadTime) {\r\n        let results = mutableDocumentMap();\r\n        // Documents are ordered by key, so we can use a prefix scan to narrow down\r\n        // the documents we need to match the query against.\r\n        const prefix = new DocumentKey(query.path.child(''));\r\n        const iterator = this.docs.getIteratorFrom(prefix);\r\n        while (iterator.hasNext()) {\r\n            const { key, value: { document, readTime } } = iterator.getNext();\r\n            if (!query.path.isPrefixOf(key.path)) {\r\n                break;\r\n            }\r\n            if (readTime.compareTo(sinceReadTime) <= 0) {\r\n                continue;\r\n            }\r\n            if (!queryMatches(query, document)) {\r\n                continue;\r\n            }\r\n            results = results.insert(document.key, document.clone());\r\n        }\r\n        return PersistencePromise.resolve(results);\r\n    }\r\n    forEachDocumentKey(transaction, f) {\r\n        return PersistencePromise.forEach(this.docs, (key) => f(key));\r\n    }\r\n    newChangeBuffer(options) {\r\n        // `trackRemovals` is ignores since the MemoryRemoteDocumentCache keeps\r\n        // a separate changelog and does not need special handling for removals.\r\n        return new MemoryRemoteDocumentChangeBuffer(this);\r\n    }\r\n    getSize(txn) {\r\n        return PersistencePromise.resolve(this.size);\r\n    }\r\n}\r\n/**\r\n * Creates a new memory-only RemoteDocumentCache.\r\n *\r\n * @param indexManager - A class that manages collection group indices.\r\n * @param sizer - Used to assess the size of a document. For eager GC, this is\r\n * expected to just return 0 to avoid unnecessarily doing the work of\r\n * calculating the size.\r\n */\r\nfunction newMemoryRemoteDocumentCache(indexManager, sizer) {\r\n    return new MemoryRemoteDocumentCacheImpl(indexManager, sizer);\r\n}\r\n/**\r\n * Handles the details of adding and updating documents in the MemoryRemoteDocumentCache.\r\n */\r\nclass MemoryRemoteDocumentChangeBuffer extends RemoteDocumentChangeBuffer {\r\n    constructor(documentCache) {\r\n        super();\r\n        this.documentCache = documentCache;\r\n    }\r\n    applyChanges(transaction) {\r\n        const promises = [];\r\n        this.changes.forEach((key, doc) => {\r\n            if (doc.document.isValidDocument()) {\r\n                promises.push(this.documentCache.addEntry(transaction, doc.document, this.getReadTime(key)));\r\n            }\r\n            else {\r\n                this.documentCache.removeEntry(key);\r\n            }\r\n        });\r\n        return PersistencePromise.waitFor(promises);\r\n    }\r\n    getFromCache(transaction, documentKey) {\r\n        return this.documentCache.getEntry(transaction, documentKey);\r\n    }\r\n    getAllFromCache(transaction, documentKeys) {\r\n        return this.documentCache.getEntries(transaction, documentKeys);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass MemoryTargetCache {\r\n    constructor(persistence) {\r\n        this.persistence = persistence;\r\n        /**\r\n         * Maps a target to the data about that target\r\n         */\r\n        this.targets = new ObjectMap(t => canonifyTarget(t), targetEquals);\r\n        /** The last received snapshot version. */\r\n        this.lastRemoteSnapshotVersion = SnapshotVersion.min();\r\n        /** The highest numbered target ID encountered. */\r\n        this.highestTargetId = 0;\r\n        /** The highest sequence number encountered. */\r\n        this.highestSequenceNumber = 0;\r\n        /**\r\n         * A ordered bidirectional mapping between documents and the remote target\r\n         * IDs.\r\n         */\r\n        this.references = new ReferenceSet();\r\n        this.targetCount = 0;\r\n        this.targetIdGenerator = TargetIdGenerator.forTargetCache();\r\n    }\r\n    forEachTarget(txn, f) {\r\n        this.targets.forEach((_, targetData) => f(targetData));\r\n        return PersistencePromise.resolve();\r\n    }\r\n    getLastRemoteSnapshotVersion(transaction) {\r\n        return PersistencePromise.resolve(this.lastRemoteSnapshotVersion);\r\n    }\r\n    getHighestSequenceNumber(transaction) {\r\n        return PersistencePromise.resolve(this.highestSequenceNumber);\r\n    }\r\n    allocateTargetId(transaction) {\r\n        this.highestTargetId = this.targetIdGenerator.next();\r\n        return PersistencePromise.resolve(this.highestTargetId);\r\n    }\r\n    setTargetsMetadata(transaction, highestListenSequenceNumber, lastRemoteSnapshotVersion) {\r\n        if (lastRemoteSnapshotVersion) {\r\n            this.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion;\r\n        }\r\n        if (highestListenSequenceNumber > this.highestSequenceNumber) {\r\n            this.highestSequenceNumber = highestListenSequenceNumber;\r\n        }\r\n        return PersistencePromise.resolve();\r\n    }\r\n    saveTargetData(targetData) {\r\n        this.targets.set(targetData.target, targetData);\r\n        const targetId = targetData.targetId;\r\n        if (targetId > this.highestTargetId) {\r\n            this.targetIdGenerator = new TargetIdGenerator(targetId);\r\n            this.highestTargetId = targetId;\r\n        }\r\n        if (targetData.sequenceNumber > this.highestSequenceNumber) {\r\n            this.highestSequenceNumber = targetData.sequenceNumber;\r\n        }\r\n    }\r\n    addTargetData(transaction, targetData) {\r\n        this.saveTargetData(targetData);\r\n        this.targetCount += 1;\r\n        return PersistencePromise.resolve();\r\n    }\r\n    updateTargetData(transaction, targetData) {\r\n        this.saveTargetData(targetData);\r\n        return PersistencePromise.resolve();\r\n    }\r\n    removeTargetData(transaction, targetData) {\r\n        this.targets.delete(targetData.target);\r\n        this.references.removeReferencesForId(targetData.targetId);\r\n        this.targetCount -= 1;\r\n        return PersistencePromise.resolve();\r\n    }\r\n    removeTargets(transaction, upperBound, activeTargetIds) {\r\n        let count = 0;\r\n        const removals = [];\r\n        this.targets.forEach((key, targetData) => {\r\n            if (targetData.sequenceNumber <= upperBound &&\r\n                activeTargetIds.get(targetData.targetId) === null) {\r\n                this.targets.delete(key);\r\n                removals.push(this.removeMatchingKeysForTargetId(transaction, targetData.targetId));\r\n                count++;\r\n            }\r\n        });\r\n        return PersistencePromise.waitFor(removals).next(() => count);\r\n    }\r\n    getTargetCount(transaction) {\r\n        return PersistencePromise.resolve(this.targetCount);\r\n    }\r\n    getTargetData(transaction, target) {\r\n        const targetData = this.targets.get(target) || null;\r\n        return PersistencePromise.resolve(targetData);\r\n    }\r\n    addMatchingKeys(txn, keys, targetId) {\r\n        this.references.addReferences(keys, targetId);\r\n        return PersistencePromise.resolve();\r\n    }\r\n    removeMatchingKeys(txn, keys, targetId) {\r\n        this.references.removeReferences(keys, targetId);\r\n        const referenceDelegate = this.persistence.referenceDelegate;\r\n        const promises = [];\r\n        if (referenceDelegate) {\r\n            keys.forEach(key => {\r\n                promises.push(referenceDelegate.markPotentiallyOrphaned(txn, key));\r\n            });\r\n        }\r\n        return PersistencePromise.waitFor(promises);\r\n    }\r\n    removeMatchingKeysForTargetId(txn, targetId) {\r\n        this.references.removeReferencesForId(targetId);\r\n        return PersistencePromise.resolve();\r\n    }\r\n    getMatchingKeysForTargetId(txn, targetId) {\r\n        const matchingKeys = this.references.referencesForId(targetId);\r\n        return PersistencePromise.resolve(matchingKeys);\r\n    }\r\n    containsKey(txn, key) {\r\n        return PersistencePromise.resolve(this.references.containsKey(key));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$b = 'MemoryPersistence';\r\n/**\r\n * A memory-backed instance of Persistence. Data is stored only in RAM and\r\n * not persisted across sessions.\r\n */\r\nclass MemoryPersistence {\r\n    /**\r\n     * The constructor accepts a factory for creating a reference delegate. This\r\n     * allows both the delegate and this instance to have strong references to\r\n     * each other without having nullable fields that would then need to be\r\n     * checked or asserted on every access.\r\n     */\r\n    constructor(referenceDelegateFactory, serializer) {\r\n        this.mutationQueues = {};\r\n        this.listenSequence = new ListenSequence(0);\r\n        this._started = false;\r\n        this._started = true;\r\n        this.referenceDelegate = referenceDelegateFactory(this);\r\n        this.targetCache = new MemoryTargetCache(this);\r\n        const sizer = (doc) => this.referenceDelegate.documentSize(doc);\r\n        this.indexManager = new MemoryIndexManager();\r\n        this.remoteDocumentCache = newMemoryRemoteDocumentCache(this.indexManager, sizer);\r\n        this.serializer = new LocalSerializer(serializer);\r\n        this.bundleCache = new MemoryBundleCache(this.serializer);\r\n    }\r\n    start() {\r\n        return Promise.resolve();\r\n    }\r\n    shutdown() {\r\n        // No durable state to ensure is closed on shutdown.\r\n        this._started = false;\r\n        return Promise.resolve();\r\n    }\r\n    get started() {\r\n        return this._started;\r\n    }\r\n    setDatabaseDeletedListener() {\r\n        // No op.\r\n    }\r\n    setNetworkEnabled() {\r\n        // No op.\r\n    }\r\n    getIndexManager() {\r\n        return this.indexManager;\r\n    }\r\n    getMutationQueue(user) {\r\n        let queue = this.mutationQueues[user.toKey()];\r\n        if (!queue) {\r\n            queue = new MemoryMutationQueue(this.indexManager, this.referenceDelegate);\r\n            this.mutationQueues[user.toKey()] = queue;\r\n        }\r\n        return queue;\r\n    }\r\n    getTargetCache() {\r\n        return this.targetCache;\r\n    }\r\n    getRemoteDocumentCache() {\r\n        return this.remoteDocumentCache;\r\n    }\r\n    getBundleCache() {\r\n        return this.bundleCache;\r\n    }\r\n    runTransaction(action, mode, transactionOperation) {\r\n        logDebug(LOG_TAG$b, 'Starting transaction:', action);\r\n        const txn = new MemoryTransaction(this.listenSequence.next());\r\n        this.referenceDelegate.onTransactionStarted();\r\n        return transactionOperation(txn)\r\n            .next(result => {\r\n            return this.referenceDelegate\r\n                .onTransactionCommitted(txn)\r\n                .next(() => result);\r\n        })\r\n            .toPromise()\r\n            .then(result => {\r\n            txn.raiseOnCommittedEvent();\r\n            return result;\r\n        });\r\n    }\r\n    mutationQueuesContainKey(transaction, key) {\r\n        return PersistencePromise.or(Object.values(this.mutationQueues).map(queue => () => queue.containsKey(transaction, key)));\r\n    }\r\n}\r\n/**\r\n * Memory persistence is not actually transactional, but future implementations\r\n * may have transaction-scoped state.\r\n */\r\nclass MemoryTransaction extends PersistenceTransaction {\r\n    constructor(currentSequenceNumber) {\r\n        super();\r\n        this.currentSequenceNumber = currentSequenceNumber;\r\n    }\r\n}\r\nclass MemoryEagerDelegate {\r\n    constructor(persistence) {\r\n        this.persistence = persistence;\r\n        /** Tracks all documents that are active in Query views. */\r\n        this.localViewReferences = new ReferenceSet();\r\n        /** The list of documents that are potentially GCed after each transaction. */\r\n        this._orphanedDocuments = null;\r\n    }\r\n    static factory(persistence) {\r\n        return new MemoryEagerDelegate(persistence);\r\n    }\r\n    get orphanedDocuments() {\r\n        if (!this._orphanedDocuments) {\r\n            throw fail();\r\n        }\r\n        else {\r\n            return this._orphanedDocuments;\r\n        }\r\n    }\r\n    addReference(txn, targetId, key) {\r\n        this.localViewReferences.addReference(key, targetId);\r\n        this.orphanedDocuments.delete(key.toString());\r\n        return PersistencePromise.resolve();\r\n    }\r\n    removeReference(txn, targetId, key) {\r\n        this.localViewReferences.removeReference(key, targetId);\r\n        this.orphanedDocuments.add(key.toString());\r\n        return PersistencePromise.resolve();\r\n    }\r\n    markPotentiallyOrphaned(txn, key) {\r\n        this.orphanedDocuments.add(key.toString());\r\n        return PersistencePromise.resolve();\r\n    }\r\n    removeTarget(txn, targetData) {\r\n        const orphaned = this.localViewReferences.removeReferencesForId(targetData.targetId);\r\n        orphaned.forEach(key => this.orphanedDocuments.add(key.toString()));\r\n        const cache = this.persistence.getTargetCache();\r\n        return cache\r\n            .getMatchingKeysForTargetId(txn, targetData.targetId)\r\n            .next(keys => {\r\n            keys.forEach(key => this.orphanedDocuments.add(key.toString()));\r\n        })\r\n            .next(() => cache.removeTargetData(txn, targetData));\r\n    }\r\n    onTransactionStarted() {\r\n        this._orphanedDocuments = new Set();\r\n    }\r\n    onTransactionCommitted(txn) {\r\n        // Remove newly orphaned documents.\r\n        const cache = this.persistence.getRemoteDocumentCache();\r\n        const changeBuffer = cache.newChangeBuffer();\r\n        return PersistencePromise.forEach(this.orphanedDocuments, (path) => {\r\n            const key = DocumentKey.fromPath(path);\r\n            return this.isReferenced(txn, key).next(isReferenced => {\r\n                if (!isReferenced) {\r\n                    changeBuffer.removeEntry(key);\r\n                }\r\n            });\r\n        }).next(() => {\r\n            this._orphanedDocuments = null;\r\n            return changeBuffer.apply(txn);\r\n        });\r\n    }\r\n    updateLimboDocument(txn, key) {\r\n        return this.isReferenced(txn, key).next(isReferenced => {\r\n            if (isReferenced) {\r\n                this.orphanedDocuments.delete(key.toString());\r\n            }\r\n            else {\r\n                this.orphanedDocuments.add(key.toString());\r\n            }\r\n        });\r\n    }\r\n    documentSize(doc) {\r\n        // For eager GC, we don't care about the document size, there are no size thresholds.\r\n        return 0;\r\n    }\r\n    isReferenced(txn, key) {\r\n        return PersistencePromise.or([\r\n            () => PersistencePromise.resolve(this.localViewReferences.containsKey(key)),\r\n            () => this.persistence.getTargetCache().containsKey(txn, key),\r\n            () => this.persistence.mutationQueuesContainKey(txn, key)\r\n        ]);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A query engine that takes advantage of the target document mapping in the\r\n * QueryCache. Query execution is optimized by only reading the documents that\r\n * previously matched a query plus any documents that were edited after the\r\n * query was last listened to.\r\n *\r\n * There are some cases when this optimization is not guaranteed to produce\r\n * the same results as full collection scans. In these cases, query\r\n * processing falls back to full scans. These cases are:\r\n *\r\n * - Limit queries where a document that matched the query previously no longer\r\n *   matches the query.\r\n *\r\n * - Limit queries where a document edit may cause the document to sort below\r\n *   another document that is in the local cache.\r\n *\r\n * - Queries that have never been CURRENT or free of limbo documents.\r\n */\r\nclass QueryEngine {\r\n    /** Sets the document view to query against. */\r\n    setLocalDocumentsView(localDocuments) {\r\n        this.localDocumentsView = localDocuments;\r\n    }\r\n    /** Returns all local documents matching the specified query. */\r\n    getDocumentsMatchingQuery(transaction, query, lastLimboFreeSnapshotVersion, remoteKeys) {\r\n        // Queries that match all documents don't benefit from using\r\n        // key-based lookups. It is more efficient to scan all documents in a\r\n        // collection, rather than to perform individual lookups.\r\n        if (matchesAllDocuments(query)) {\r\n            return this.executeFullCollectionScan(transaction, query);\r\n        }\r\n        // Queries that have never seen a snapshot without limbo free documents\r\n        // should also be run as a full collection scan.\r\n        if (lastLimboFreeSnapshotVersion.isEqual(SnapshotVersion.min())) {\r\n            return this.executeFullCollectionScan(transaction, query);\r\n        }\r\n        return this.localDocumentsView.getDocuments(transaction, remoteKeys).next(documents => {\r\n            const previousResults = this.applyQuery(query, documents);\r\n            if ((hasLimitToFirst(query) || hasLimitToLast(query)) &&\r\n                this.needsRefill(query.limitType, previousResults, remoteKeys, lastLimboFreeSnapshotVersion)) {\r\n                return this.executeFullCollectionScan(transaction, query);\r\n            }\r\n            if (getLogLevel() <= LogLevel.DEBUG) {\r\n                logDebug('QueryEngine', 'Re-using previous result from %s to execute query: %s', lastLimboFreeSnapshotVersion.toString(), stringifyQuery(query));\r\n            }\r\n            // Retrieve all results for documents that were updated since the last\r\n            // limbo-document free remote snapshot.\r\n            return this.localDocumentsView.getDocumentsMatchingQuery(transaction, query, lastLimboFreeSnapshotVersion).next(updatedResults => {\r\n                // We merge `previousResults` into `updateResults`, since\r\n                // `updateResults` is already a DocumentMap. If a document is\r\n                // contained in both lists, then its contents are the same.\r\n                previousResults.forEach(doc => {\r\n                    updatedResults = updatedResults.insert(doc.key, doc);\r\n                });\r\n                return updatedResults;\r\n            });\r\n        });\r\n    }\r\n    /** Applies the query filter and sorting to the provided documents.  */\r\n    applyQuery(query, documents) {\r\n        // Sort the documents and re-apply the query filter since previously\r\n        // matching documents do not necessarily still match the query.\r\n        let queryResults = new SortedSet(newQueryComparator(query));\r\n        documents.forEach((_, maybeDoc) => {\r\n            if (queryMatches(query, maybeDoc)) {\r\n                queryResults = queryResults.add(maybeDoc);\r\n            }\r\n        });\r\n        return queryResults;\r\n    }\r\n    /**\r\n     * Determines if a limit query needs to be refilled from cache, making it\r\n     * ineligible for index-free execution.\r\n     *\r\n     * @param sortedPreviousResults - The documents that matched the query when it\r\n     * was last synchronized, sorted by the query's comparator.\r\n     * @param remoteKeys - The document keys that matched the query at the last\r\n     * snapshot.\r\n     * @param limboFreeSnapshotVersion - The version of the snapshot when the\r\n     * query was last synchronized.\r\n     */\r\n    needsRefill(limitType, sortedPreviousResults, remoteKeys, limboFreeSnapshotVersion) {\r\n        // The query needs to be refilled if a previously matching document no\r\n        // longer matches.\r\n        if (remoteKeys.size !== sortedPreviousResults.size) {\r\n            return true;\r\n        }\r\n        // Limit queries are not eligible for index-free query execution if there is\r\n        // a potential that an older document from cache now sorts before a document\r\n        // that was previously part of the limit. This, however, can only happen if\r\n        // the document at the edge of the limit goes out of limit.\r\n        // If a document that is not the limit boundary sorts differently,\r\n        // the boundary of the limit itself did not change and documents from cache\r\n        // will continue to be \"rejected\" by this boundary. Therefore, we can ignore\r\n        // any modifications that don't affect the last document.\r\n        const docAtLimitEdge = limitType === \"F\" /* First */\r\n            ? sortedPreviousResults.last()\r\n            : sortedPreviousResults.first();\r\n        if (!docAtLimitEdge) {\r\n            // We don't need to refill the query if there were already no documents.\r\n            return false;\r\n        }\r\n        return (docAtLimitEdge.hasPendingWrites ||\r\n            docAtLimitEdge.version.compareTo(limboFreeSnapshotVersion) > 0);\r\n    }\r\n    executeFullCollectionScan(transaction, query) {\r\n        if (getLogLevel() <= LogLevel.DEBUG) {\r\n            logDebug('QueryEngine', 'Using full collection scan to execute query:', stringifyQuery(query));\r\n        }\r\n        return this.localDocumentsView.getDocumentsMatchingQuery(transaction, query, SnapshotVersion.min());\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// The format of the LocalStorage key that stores the client state is:\r\n//     firestore_clients_<persistence_prefix>_<instance_key>\r\nconst CLIENT_STATE_KEY_PREFIX = 'firestore_clients';\r\n/** Assembles the key for a client state in WebStorage */\r\nfunction createWebStorageClientStateKey(persistenceKey, clientId) {\r\n    return `${CLIENT_STATE_KEY_PREFIX}_${persistenceKey}_${clientId}`;\r\n}\r\n// The format of the WebStorage key that stores the mutation state is:\r\n//     firestore_mutations_<persistence_prefix>_<batch_id>\r\n//     (for unauthenticated users)\r\n// or: firestore_mutations_<persistence_prefix>_<batch_id>_<user_uid>\r\n//\r\n// 'user_uid' is last to avoid needing to escape '_' characters that it might\r\n// contain.\r\nconst MUTATION_BATCH_KEY_PREFIX = 'firestore_mutations';\r\n/** Assembles the key for a mutation batch in WebStorage */\r\nfunction createWebStorageMutationBatchKey(persistenceKey, user, batchId) {\r\n    let mutationKey = `${MUTATION_BATCH_KEY_PREFIX}_${persistenceKey}_${batchId}`;\r\n    if (user.isAuthenticated()) {\r\n        mutationKey += `_${user.uid}`;\r\n    }\r\n    return mutationKey;\r\n}\r\n// The format of the WebStorage key that stores a query target's metadata is:\r\n//     firestore_targets_<persistence_prefix>_<target_id>\r\nconst QUERY_TARGET_KEY_PREFIX = 'firestore_targets';\r\n/** Assembles the key for a query state in WebStorage */\r\nfunction createWebStorageQueryTargetMetadataKey(persistenceKey, targetId) {\r\n    return `${QUERY_TARGET_KEY_PREFIX}_${persistenceKey}_${targetId}`;\r\n}\r\n// The WebStorage prefix that stores the primary tab's online state. The\r\n// format of the key is:\r\n//     firestore_online_state_<persistence_prefix>\r\nconst ONLINE_STATE_KEY_PREFIX = 'firestore_online_state';\r\n/** Assembles the key for the online state of the primary tab. */\r\nfunction createWebStorageOnlineStateKey(persistenceKey) {\r\n    return `${ONLINE_STATE_KEY_PREFIX}_${persistenceKey}`;\r\n}\r\n// The WebStorage prefix that plays as a event to indicate the remote documents\r\n// might have changed due to some secondary tabs loading a bundle.\r\n// format of the key is:\r\n//     firestore_bundle_loaded_<persistenceKey>\r\nconst BUNDLE_LOADED_KEY_PREFIX = 'firestore_bundle_loaded';\r\nfunction createBundleLoadedKey(persistenceKey) {\r\n    return `${BUNDLE_LOADED_KEY_PREFIX}_${persistenceKey}`;\r\n}\r\n// The WebStorage key prefix for the key that stores the last sequence number allocated. The key\r\n// looks like 'firestore_sequence_number_<persistence_prefix>'.\r\nconst SEQUENCE_NUMBER_KEY_PREFIX = 'firestore_sequence_number';\r\n/** Assembles the key for the current sequence number. */\r\nfunction createWebStorageSequenceNumberKey(persistenceKey) {\r\n    return `${SEQUENCE_NUMBER_KEY_PREFIX}_${persistenceKey}`;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$a = 'SharedClientState';\r\n/**\r\n * Holds the state of a mutation batch, including its user ID, batch ID and\r\n * whether the batch is 'pending', 'acknowledged' or 'rejected'.\r\n */\r\n// Visible for testing\r\nclass MutationMetadata {\r\n    constructor(user, batchId, state, error) {\r\n        this.user = user;\r\n        this.batchId = batchId;\r\n        this.state = state;\r\n        this.error = error;\r\n    }\r\n    /**\r\n     * Parses a MutationMetadata from its JSON representation in WebStorage.\r\n     * Logs a warning and returns null if the format of the data is not valid.\r\n     */\r\n    static fromWebStorageEntry(user, batchId, value) {\r\n        const mutationBatch = JSON.parse(value);\r\n        let validData = typeof mutationBatch === 'object' &&\r\n            ['pending', 'acknowledged', 'rejected'].indexOf(mutationBatch.state) !==\r\n                -1 &&\r\n            (mutationBatch.error === undefined ||\r\n                typeof mutationBatch.error === 'object');\r\n        let firestoreError = undefined;\r\n        if (validData && mutationBatch.error) {\r\n            validData =\r\n                typeof mutationBatch.error.message === 'string' &&\r\n                    typeof mutationBatch.error.code === 'string';\r\n            if (validData) {\r\n                firestoreError = new FirestoreError(mutationBatch.error.code, mutationBatch.error.message);\r\n            }\r\n        }\r\n        if (validData) {\r\n            return new MutationMetadata(user, batchId, mutationBatch.state, firestoreError);\r\n        }\r\n        else {\r\n            logError(LOG_TAG$a, `Failed to parse mutation state for ID '${batchId}': ${value}`);\r\n            return null;\r\n        }\r\n    }\r\n    toWebStorageJSON() {\r\n        const batchMetadata = {\r\n            state: this.state,\r\n            updateTimeMs: Date.now() // Modify the existing value to trigger update.\r\n        };\r\n        if (this.error) {\r\n            batchMetadata.error = {\r\n                code: this.error.code,\r\n                message: this.error.message\r\n            };\r\n        }\r\n        return JSON.stringify(batchMetadata);\r\n    }\r\n}\r\n/**\r\n * Holds the state of a query target, including its target ID and whether the\r\n * target is 'not-current', 'current' or 'rejected'.\r\n */\r\n// Visible for testing\r\nclass QueryTargetMetadata {\r\n    constructor(targetId, state, error) {\r\n        this.targetId = targetId;\r\n        this.state = state;\r\n        this.error = error;\r\n    }\r\n    /**\r\n     * Parses a QueryTargetMetadata from its JSON representation in WebStorage.\r\n     * Logs a warning and returns null if the format of the data is not valid.\r\n     */\r\n    static fromWebStorageEntry(targetId, value) {\r\n        const targetState = JSON.parse(value);\r\n        let validData = typeof targetState === 'object' &&\r\n            ['not-current', 'current', 'rejected'].indexOf(targetState.state) !==\r\n                -1 &&\r\n            (targetState.error === undefined ||\r\n                typeof targetState.error === 'object');\r\n        let firestoreError = undefined;\r\n        if (validData && targetState.error) {\r\n            validData =\r\n                typeof targetState.error.message === 'string' &&\r\n                    typeof targetState.error.code === 'string';\r\n            if (validData) {\r\n                firestoreError = new FirestoreError(targetState.error.code, targetState.error.message);\r\n            }\r\n        }\r\n        if (validData) {\r\n            return new QueryTargetMetadata(targetId, targetState.state, firestoreError);\r\n        }\r\n        else {\r\n            logError(LOG_TAG$a, `Failed to parse target state for ID '${targetId}': ${value}`);\r\n            return null;\r\n        }\r\n    }\r\n    toWebStorageJSON() {\r\n        const targetState = {\r\n            state: this.state,\r\n            updateTimeMs: Date.now() // Modify the existing value to trigger update.\r\n        };\r\n        if (this.error) {\r\n            targetState.error = {\r\n                code: this.error.code,\r\n                message: this.error.message\r\n            };\r\n        }\r\n        return JSON.stringify(targetState);\r\n    }\r\n}\r\n/**\r\n * This class represents the immutable ClientState for a client read from\r\n * WebStorage, containing the list of active query targets.\r\n */\r\nclass RemoteClientState {\r\n    constructor(clientId, activeTargetIds) {\r\n        this.clientId = clientId;\r\n        this.activeTargetIds = activeTargetIds;\r\n    }\r\n    /**\r\n     * Parses a RemoteClientState from the JSON representation in WebStorage.\r\n     * Logs a warning and returns null if the format of the data is not valid.\r\n     */\r\n    static fromWebStorageEntry(clientId, value) {\r\n        const clientState = JSON.parse(value);\r\n        let validData = typeof clientState === 'object' &&\r\n            clientState.activeTargetIds instanceof Array;\r\n        let activeTargetIdsSet = targetIdSet();\r\n        for (let i = 0; validData && i < clientState.activeTargetIds.length; ++i) {\r\n            validData = isSafeInteger(clientState.activeTargetIds[i]);\r\n            activeTargetIdsSet = activeTargetIdsSet.add(clientState.activeTargetIds[i]);\r\n        }\r\n        if (validData) {\r\n            return new RemoteClientState(clientId, activeTargetIdsSet);\r\n        }\r\n        else {\r\n            logError(LOG_TAG$a, `Failed to parse client data for instance '${clientId}': ${value}`);\r\n            return null;\r\n        }\r\n    }\r\n}\r\n/**\r\n * This class represents the online state for all clients participating in\r\n * multi-tab. The online state is only written to by the primary client, and\r\n * used in secondary clients to update their query views.\r\n */\r\nclass SharedOnlineState {\r\n    constructor(clientId, onlineState) {\r\n        this.clientId = clientId;\r\n        this.onlineState = onlineState;\r\n    }\r\n    /**\r\n     * Parses a SharedOnlineState from its JSON representation in WebStorage.\r\n     * Logs a warning and returns null if the format of the data is not valid.\r\n     */\r\n    static fromWebStorageEntry(value) {\r\n        const onlineState = JSON.parse(value);\r\n        const validData = typeof onlineState === 'object' &&\r\n            ['Unknown', 'Online', 'Offline'].indexOf(onlineState.onlineState) !==\r\n                -1 &&\r\n            typeof onlineState.clientId === 'string';\r\n        if (validData) {\r\n            return new SharedOnlineState(onlineState.clientId, onlineState.onlineState);\r\n        }\r\n        else {\r\n            logError(LOG_TAG$a, `Failed to parse online state: ${value}`);\r\n            return null;\r\n        }\r\n    }\r\n}\r\n/**\r\n * Metadata state of the local client. Unlike `RemoteClientState`, this class is\r\n * mutable and keeps track of all pending mutations, which allows us to\r\n * update the range of pending mutation batch IDs as new mutations are added or\r\n * removed.\r\n *\r\n * The data in `LocalClientState` is not read from WebStorage and instead\r\n * updated via its instance methods. The updated state can be serialized via\r\n * `toWebStorageJSON()`.\r\n */\r\n// Visible for testing.\r\nclass LocalClientState {\r\n    constructor() {\r\n        this.activeTargetIds = targetIdSet();\r\n    }\r\n    addQueryTarget(targetId) {\r\n        this.activeTargetIds = this.activeTargetIds.add(targetId);\r\n    }\r\n    removeQueryTarget(targetId) {\r\n        this.activeTargetIds = this.activeTargetIds.delete(targetId);\r\n    }\r\n    /**\r\n     * Converts this entry into a JSON-encoded format we can use for WebStorage.\r\n     * Does not encode `clientId` as it is part of the key in WebStorage.\r\n     */\r\n    toWebStorageJSON() {\r\n        const data = {\r\n            activeTargetIds: this.activeTargetIds.toArray(),\r\n            updateTimeMs: Date.now() // Modify the existing value to trigger update.\r\n        };\r\n        return JSON.stringify(data);\r\n    }\r\n}\r\n/**\r\n * `WebStorageSharedClientState` uses WebStorage (window.localStorage) as the\r\n * backing store for the SharedClientState. It keeps track of all active\r\n * clients and supports modifications of the local client's data.\r\n */\r\nclass WebStorageSharedClientState {\r\n    constructor(window, queue, persistenceKey, localClientId, initialUser) {\r\n        this.window = window;\r\n        this.queue = queue;\r\n        this.persistenceKey = persistenceKey;\r\n        this.localClientId = localClientId;\r\n        this.syncEngine = null;\r\n        this.onlineStateHandler = null;\r\n        this.sequenceNumberHandler = null;\r\n        this.storageListener = this.handleWebStorageEvent.bind(this);\r\n        this.activeClients = new SortedMap(primitiveComparator);\r\n        this.started = false;\r\n        /**\r\n         * Captures WebStorage events that occur before `start()` is called. These\r\n         * events are replayed once `WebStorageSharedClientState` is started.\r\n         */\r\n        this.earlyEvents = [];\r\n        // Escape the special characters mentioned here:\r\n        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions\r\n        const escapedPersistenceKey = persistenceKey.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\r\n        this.storage = this.window.localStorage;\r\n        this.currentUser = initialUser;\r\n        this.localClientStorageKey = createWebStorageClientStateKey(this.persistenceKey, this.localClientId);\r\n        this.sequenceNumberKey = createWebStorageSequenceNumberKey(this.persistenceKey);\r\n        this.activeClients = this.activeClients.insert(this.localClientId, new LocalClientState());\r\n        this.clientStateKeyRe = new RegExp(`^${CLIENT_STATE_KEY_PREFIX}_${escapedPersistenceKey}_([^_]*)$`);\r\n        this.mutationBatchKeyRe = new RegExp(`^${MUTATION_BATCH_KEY_PREFIX}_${escapedPersistenceKey}_(\\\\d+)(?:_(.*))?$`);\r\n        this.queryTargetKeyRe = new RegExp(`^${QUERY_TARGET_KEY_PREFIX}_${escapedPersistenceKey}_(\\\\d+)$`);\r\n        this.onlineStateKey = createWebStorageOnlineStateKey(this.persistenceKey);\r\n        this.bundleLoadedKey = createBundleLoadedKey(this.persistenceKey);\r\n        // Rather than adding the storage observer during start(), we add the\r\n        // storage observer during initialization. This ensures that we collect\r\n        // events before other components populate their initial state (during their\r\n        // respective start() calls). Otherwise, we might for example miss a\r\n        // mutation that is added after LocalStore's start() processed the existing\r\n        // mutations but before we observe WebStorage events.\r\n        this.window.addEventListener('storage', this.storageListener);\r\n    }\r\n    /** Returns 'true' if WebStorage is available in the current environment. */\r\n    static isAvailable(window) {\r\n        return !!(window && window.localStorage);\r\n    }\r\n    async start() {\r\n        // Retrieve the list of existing clients to backfill the data in\r\n        // SharedClientState.\r\n        const existingClients = await this.syncEngine.getActiveClients();\r\n        for (const clientId of existingClients) {\r\n            if (clientId === this.localClientId) {\r\n                continue;\r\n            }\r\n            const storageItem = this.getItem(createWebStorageClientStateKey(this.persistenceKey, clientId));\r\n            if (storageItem) {\r\n                const clientState = RemoteClientState.fromWebStorageEntry(clientId, storageItem);\r\n                if (clientState) {\r\n                    this.activeClients = this.activeClients.insert(clientState.clientId, clientState);\r\n                }\r\n            }\r\n        }\r\n        this.persistClientState();\r\n        // Check if there is an existing online state and call the callback handler\r\n        // if applicable.\r\n        const onlineStateJSON = this.storage.getItem(this.onlineStateKey);\r\n        if (onlineStateJSON) {\r\n            const onlineState = this.fromWebStorageOnlineState(onlineStateJSON);\r\n            if (onlineState) {\r\n                this.handleOnlineStateEvent(onlineState);\r\n            }\r\n        }\r\n        for (const event of this.earlyEvents) {\r\n            this.handleWebStorageEvent(event);\r\n        }\r\n        this.earlyEvents = [];\r\n        // Register a window unload hook to remove the client metadata entry from\r\n        // WebStorage even if `shutdown()` was not called.\r\n        this.window.addEventListener('pagehide', () => this.shutdown());\r\n        this.started = true;\r\n    }\r\n    writeSequenceNumber(sequenceNumber) {\r\n        this.setItem(this.sequenceNumberKey, JSON.stringify(sequenceNumber));\r\n    }\r\n    getAllActiveQueryTargets() {\r\n        return this.extractActiveQueryTargets(this.activeClients);\r\n    }\r\n    isActiveQueryTarget(targetId) {\r\n        let found = false;\r\n        this.activeClients.forEach((key, value) => {\r\n            if (value.activeTargetIds.has(targetId)) {\r\n                found = true;\r\n            }\r\n        });\r\n        return found;\r\n    }\r\n    addPendingMutation(batchId) {\r\n        this.persistMutationState(batchId, 'pending');\r\n    }\r\n    updateMutationState(batchId, state, error) {\r\n        this.persistMutationState(batchId, state, error);\r\n        // Once a final mutation result is observed by other clients, they no longer\r\n        // access the mutation's metadata entry. Since WebStorage replays events\r\n        // in order, it is safe to delete the entry right after updating it.\r\n        this.removeMutationState(batchId);\r\n    }\r\n    addLocalQueryTarget(targetId) {\r\n        let queryState = 'not-current';\r\n        // Lookup an existing query state if the target ID was already registered\r\n        // by another tab\r\n        if (this.isActiveQueryTarget(targetId)) {\r\n            const storageItem = this.storage.getItem(createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId));\r\n            if (storageItem) {\r\n                const metadata = QueryTargetMetadata.fromWebStorageEntry(targetId, storageItem);\r\n                if (metadata) {\r\n                    queryState = metadata.state;\r\n                }\r\n            }\r\n        }\r\n        this.localClientState.addQueryTarget(targetId);\r\n        this.persistClientState();\r\n        return queryState;\r\n    }\r\n    removeLocalQueryTarget(targetId) {\r\n        this.localClientState.removeQueryTarget(targetId);\r\n        this.persistClientState();\r\n    }\r\n    isLocalQueryTarget(targetId) {\r\n        return this.localClientState.activeTargetIds.has(targetId);\r\n    }\r\n    clearQueryState(targetId) {\r\n        this.removeItem(createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId));\r\n    }\r\n    updateQueryState(targetId, state, error) {\r\n        this.persistQueryTargetState(targetId, state, error);\r\n    }\r\n    handleUserChange(user, removedBatchIds, addedBatchIds) {\r\n        removedBatchIds.forEach(batchId => {\r\n            this.removeMutationState(batchId);\r\n        });\r\n        this.currentUser = user;\r\n        addedBatchIds.forEach(batchId => {\r\n            this.addPendingMutation(batchId);\r\n        });\r\n    }\r\n    setOnlineState(onlineState) {\r\n        this.persistOnlineState(onlineState);\r\n    }\r\n    notifyBundleLoaded() {\r\n        this.persistBundleLoadedState();\r\n    }\r\n    shutdown() {\r\n        if (this.started) {\r\n            this.window.removeEventListener('storage', this.storageListener);\r\n            this.removeItem(this.localClientStorageKey);\r\n            this.started = false;\r\n        }\r\n    }\r\n    getItem(key) {\r\n        const value = this.storage.getItem(key);\r\n        logDebug(LOG_TAG$a, 'READ', key, value);\r\n        return value;\r\n    }\r\n    setItem(key, value) {\r\n        logDebug(LOG_TAG$a, 'SET', key, value);\r\n        this.storage.setItem(key, value);\r\n    }\r\n    removeItem(key) {\r\n        logDebug(LOG_TAG$a, 'REMOVE', key);\r\n        this.storage.removeItem(key);\r\n    }\r\n    handleWebStorageEvent(event) {\r\n        // Note: The function is typed to take Event to be interface-compatible with\r\n        // `Window.addEventListener`.\r\n        const storageEvent = event;\r\n        if (storageEvent.storageArea === this.storage) {\r\n            logDebug(LOG_TAG$a, 'EVENT', storageEvent.key, storageEvent.newValue);\r\n            if (storageEvent.key === this.localClientStorageKey) {\r\n                logError('Received WebStorage notification for local change. Another client might have ' +\r\n                    'garbage-collected our state');\r\n                return;\r\n            }\r\n            this.queue.enqueueRetryable(async () => {\r\n                if (!this.started) {\r\n                    this.earlyEvents.push(storageEvent);\r\n                    return;\r\n                }\r\n                if (storageEvent.key === null) {\r\n                    return;\r\n                }\r\n                if (this.clientStateKeyRe.test(storageEvent.key)) {\r\n                    if (storageEvent.newValue != null) {\r\n                        const clientState = this.fromWebStorageClientState(storageEvent.key, storageEvent.newValue);\r\n                        if (clientState) {\r\n                            return this.handleClientStateEvent(clientState.clientId, clientState);\r\n                        }\r\n                    }\r\n                    else {\r\n                        const clientId = this.fromWebStorageClientStateKey(storageEvent.key);\r\n                        return this.handleClientStateEvent(clientId, null);\r\n                    }\r\n                }\r\n                else if (this.mutationBatchKeyRe.test(storageEvent.key)) {\r\n                    if (storageEvent.newValue !== null) {\r\n                        const mutationMetadata = this.fromWebStorageMutationMetadata(storageEvent.key, storageEvent.newValue);\r\n                        if (mutationMetadata) {\r\n                            return this.handleMutationBatchEvent(mutationMetadata);\r\n                        }\r\n                    }\r\n                }\r\n                else if (this.queryTargetKeyRe.test(storageEvent.key)) {\r\n                    if (storageEvent.newValue !== null) {\r\n                        const queryTargetMetadata = this.fromWebStorageQueryTargetMetadata(storageEvent.key, storageEvent.newValue);\r\n                        if (queryTargetMetadata) {\r\n                            return this.handleQueryTargetEvent(queryTargetMetadata);\r\n                        }\r\n                    }\r\n                }\r\n                else if (storageEvent.key === this.onlineStateKey) {\r\n                    if (storageEvent.newValue !== null) {\r\n                        const onlineState = this.fromWebStorageOnlineState(storageEvent.newValue);\r\n                        if (onlineState) {\r\n                            return this.handleOnlineStateEvent(onlineState);\r\n                        }\r\n                    }\r\n                }\r\n                else if (storageEvent.key === this.sequenceNumberKey) {\r\n                    const sequenceNumber = fromWebStorageSequenceNumber(storageEvent.newValue);\r\n                    if (sequenceNumber !== ListenSequence.INVALID) {\r\n                        this.sequenceNumberHandler(sequenceNumber);\r\n                    }\r\n                }\r\n                else if (storageEvent.key === this.bundleLoadedKey) {\r\n                    return this.syncEngine.synchronizeWithChangedDocuments();\r\n                }\r\n            });\r\n        }\r\n    }\r\n    get localClientState() {\r\n        return this.activeClients.get(this.localClientId);\r\n    }\r\n    persistClientState() {\r\n        this.setItem(this.localClientStorageKey, this.localClientState.toWebStorageJSON());\r\n    }\r\n    persistMutationState(batchId, state, error) {\r\n        const mutationState = new MutationMetadata(this.currentUser, batchId, state, error);\r\n        const mutationKey = createWebStorageMutationBatchKey(this.persistenceKey, this.currentUser, batchId);\r\n        this.setItem(mutationKey, mutationState.toWebStorageJSON());\r\n    }\r\n    removeMutationState(batchId) {\r\n        const mutationKey = createWebStorageMutationBatchKey(this.persistenceKey, this.currentUser, batchId);\r\n        this.removeItem(mutationKey);\r\n    }\r\n    persistOnlineState(onlineState) {\r\n        const entry = {\r\n            clientId: this.localClientId,\r\n            onlineState\r\n        };\r\n        this.storage.setItem(this.onlineStateKey, JSON.stringify(entry));\r\n    }\r\n    persistQueryTargetState(targetId, state, error) {\r\n        const targetKey = createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId);\r\n        const targetMetadata = new QueryTargetMetadata(targetId, state, error);\r\n        this.setItem(targetKey, targetMetadata.toWebStorageJSON());\r\n    }\r\n    persistBundleLoadedState() {\r\n        this.setItem(this.bundleLoadedKey, 'value-not-used');\r\n    }\r\n    /**\r\n     * Parses a client state key in WebStorage. Returns null if the key does not\r\n     * match the expected key format.\r\n     */\r\n    fromWebStorageClientStateKey(key) {\r\n        const match = this.clientStateKeyRe.exec(key);\r\n        return match ? match[1] : null;\r\n    }\r\n    /**\r\n     * Parses a client state in WebStorage. Returns 'null' if the value could not\r\n     * be parsed.\r\n     */\r\n    fromWebStorageClientState(key, value) {\r\n        const clientId = this.fromWebStorageClientStateKey(key);\r\n        return RemoteClientState.fromWebStorageEntry(clientId, value);\r\n    }\r\n    /**\r\n     * Parses a mutation batch state in WebStorage. Returns 'null' if the value\r\n     * could not be parsed.\r\n     */\r\n    fromWebStorageMutationMetadata(key, value) {\r\n        const match = this.mutationBatchKeyRe.exec(key);\r\n        const batchId = Number(match[1]);\r\n        const userId = match[2] !== undefined ? match[2] : null;\r\n        return MutationMetadata.fromWebStorageEntry(new User(userId), batchId, value);\r\n    }\r\n    /**\r\n     * Parses a query target state from WebStorage. Returns 'null' if the value\r\n     * could not be parsed.\r\n     */\r\n    fromWebStorageQueryTargetMetadata(key, value) {\r\n        const match = this.queryTargetKeyRe.exec(key);\r\n        const targetId = Number(match[1]);\r\n        return QueryTargetMetadata.fromWebStorageEntry(targetId, value);\r\n    }\r\n    /**\r\n     * Parses an online state from WebStorage. Returns 'null' if the value\r\n     * could not be parsed.\r\n     */\r\n    fromWebStorageOnlineState(value) {\r\n        return SharedOnlineState.fromWebStorageEntry(value);\r\n    }\r\n    async handleMutationBatchEvent(mutationBatch) {\r\n        if (mutationBatch.user.uid !== this.currentUser.uid) {\r\n            logDebug(LOG_TAG$a, `Ignoring mutation for non-active user ${mutationBatch.user.uid}`);\r\n            return;\r\n        }\r\n        return this.syncEngine.applyBatchState(mutationBatch.batchId, mutationBatch.state, mutationBatch.error);\r\n    }\r\n    handleQueryTargetEvent(targetMetadata) {\r\n        return this.syncEngine.applyTargetState(targetMetadata.targetId, targetMetadata.state, targetMetadata.error);\r\n    }\r\n    handleClientStateEvent(clientId, clientState) {\r\n        const updatedClients = clientState\r\n            ? this.activeClients.insert(clientId, clientState)\r\n            : this.activeClients.remove(clientId);\r\n        const existingTargets = this.extractActiveQueryTargets(this.activeClients);\r\n        const newTargets = this.extractActiveQueryTargets(updatedClients);\r\n        const addedTargets = [];\r\n        const removedTargets = [];\r\n        newTargets.forEach(targetId => {\r\n            if (!existingTargets.has(targetId)) {\r\n                addedTargets.push(targetId);\r\n            }\r\n        });\r\n        existingTargets.forEach(targetId => {\r\n            if (!newTargets.has(targetId)) {\r\n                removedTargets.push(targetId);\r\n            }\r\n        });\r\n        return this.syncEngine.applyActiveTargetsChange(addedTargets, removedTargets).then(() => {\r\n            this.activeClients = updatedClients;\r\n        });\r\n    }\r\n    handleOnlineStateEvent(onlineState) {\r\n        // We check whether the client that wrote this online state is still active\r\n        // by comparing its client ID to the list of clients kept active in\r\n        // IndexedDb. If a client does not update their IndexedDb client state\r\n        // within 5 seconds, it is considered inactive and we don't emit an online\r\n        // state event.\r\n        if (this.activeClients.get(onlineState.clientId)) {\r\n            this.onlineStateHandler(onlineState.onlineState);\r\n        }\r\n    }\r\n    extractActiveQueryTargets(clients) {\r\n        let activeTargets = targetIdSet();\r\n        clients.forEach((kev, value) => {\r\n            activeTargets = activeTargets.unionWith(value.activeTargetIds);\r\n        });\r\n        return activeTargets;\r\n    }\r\n}\r\nfunction fromWebStorageSequenceNumber(seqString) {\r\n    let sequenceNumber = ListenSequence.INVALID;\r\n    if (seqString != null) {\r\n        try {\r\n            const parsed = JSON.parse(seqString);\r\n            hardAssert(typeof parsed === 'number');\r\n            sequenceNumber = parsed;\r\n        }\r\n        catch (e) {\r\n            logError(LOG_TAG$a, 'Failed to read sequence number from WebStorage', e);\r\n        }\r\n    }\r\n    return sequenceNumber;\r\n}\r\n/**\r\n * `MemorySharedClientState` is a simple implementation of SharedClientState for\r\n * clients using memory persistence. The state in this class remains fully\r\n * isolated and no synchronization is performed.\r\n */\r\nclass MemorySharedClientState {\r\n    constructor() {\r\n        this.localState = new LocalClientState();\r\n        this.queryState = {};\r\n        this.onlineStateHandler = null;\r\n        this.sequenceNumberHandler = null;\r\n    }\r\n    addPendingMutation(batchId) {\r\n        // No op.\r\n    }\r\n    updateMutationState(batchId, state, error) {\r\n        // No op.\r\n    }\r\n    addLocalQueryTarget(targetId) {\r\n        this.localState.addQueryTarget(targetId);\r\n        return this.queryState[targetId] || 'not-current';\r\n    }\r\n    updateQueryState(targetId, state, error) {\r\n        this.queryState[targetId] = state;\r\n    }\r\n    removeLocalQueryTarget(targetId) {\r\n        this.localState.removeQueryTarget(targetId);\r\n    }\r\n    isLocalQueryTarget(targetId) {\r\n        return this.localState.activeTargetIds.has(targetId);\r\n    }\r\n    clearQueryState(targetId) {\r\n        delete this.queryState[targetId];\r\n    }\r\n    getAllActiveQueryTargets() {\r\n        return this.localState.activeTargetIds;\r\n    }\r\n    isActiveQueryTarget(targetId) {\r\n        return this.localState.activeTargetIds.has(targetId);\r\n    }\r\n    start() {\r\n        this.localState = new LocalClientState();\r\n        return Promise.resolve();\r\n    }\r\n    handleUserChange(user, removedBatchIds, addedBatchIds) {\r\n        // No op.\r\n    }\r\n    setOnlineState(onlineState) {\r\n        // No op.\r\n    }\r\n    shutdown() { }\r\n    writeSequenceNumber(sequenceNumber) { }\r\n    notifyBundleLoaded() {\r\n        // No op.\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass NoopConnectivityMonitor {\r\n    addCallback(callback) {\r\n        // No-op.\r\n    }\r\n    shutdown() {\r\n        // No-op.\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Provides a simple helper class that implements the Stream interface to\r\n * bridge to other implementations that are streams but do not implement the\r\n * interface. The stream callbacks are invoked with the callOn... methods.\r\n */\r\nclass StreamBridge {\r\n    constructor(args) {\r\n        this.sendFn = args.sendFn;\r\n        this.closeFn = args.closeFn;\r\n    }\r\n    onOpen(callback) {\r\n        this.wrappedOnOpen = callback;\r\n    }\r\n    onClose(callback) {\r\n        this.wrappedOnClose = callback;\r\n    }\r\n    onMessage(callback) {\r\n        this.wrappedOnMessage = callback;\r\n    }\r\n    close() {\r\n        this.closeFn();\r\n    }\r\n    send(msg) {\r\n        this.sendFn(msg);\r\n    }\r\n    callOnOpen() {\r\n        this.wrappedOnOpen();\r\n    }\r\n    callOnClose(err) {\r\n        this.wrappedOnClose(err);\r\n    }\r\n    callOnMessage(msg) {\r\n        this.wrappedOnMessage(msg);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/*\r\n * Utilities for dealing with node.js-style APIs. See nodePromise for more\r\n * details.\r\n */\r\n/**\r\n * Creates a node-style callback that resolves or rejects a new Promise. The\r\n * callback is passed to the given action which can then use the callback as\r\n * a parameter to a node-style function.\r\n *\r\n * The intent is to directly bridge a node-style function (which takes a\r\n * callback) into a Promise without manually converting between the node-style\r\n * callback and the promise at each call.\r\n *\r\n * In effect it allows you to convert:\r\n *\r\n * @example\r\n * new Promise((resolve: (value?: fs.Stats) => void,\r\n *              reject: (error?: any) => void) => {\r\n *   fs.stat(path, (error?: any, stat?: fs.Stats) => {\r\n *     if (error) {\r\n *       reject(error);\r\n *     } else {\r\n *       resolve(stat);\r\n *     }\r\n *   });\r\n * });\r\n *\r\n * Into\r\n * @example\r\n * nodePromise((callback: NodeCallback<fs.Stats>) => {\r\n *   fs.stat(path, callback);\r\n * });\r\n *\r\n * @param action - a function that takes a node-style callback as an argument\r\n *     and then uses that callback to invoke some node-style API.\r\n * @returns a new Promise which will be rejected if the callback is given the\r\n *     first Error parameter or will resolve to the value given otherwise.\r\n */\r\nfunction nodePromise(action) {\r\n    return new Promise((resolve, reject) => {\r\n        action((error, value) => {\r\n            if (error) {\r\n                reject(error);\r\n            }\r\n            else {\r\n                resolve(value);\r\n            }\r\n        });\r\n    });\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// This is a hack fix for Node ES modules to use `require`.\r\n// @ts-ignore To avoid using `--module es2020` flag.\r\nconst require = module.createRequire(import.meta.url);\r\n// eslint-disable-next-line @typescript-eslint/no-require-imports\r\nconst { version: grpcVersion } = require('@grpc/grpc-js/package.json');\r\nconst LOG_TAG$9 = 'Connection';\r\nconst X_GOOG_API_CLIENT_VALUE = `gl-node/${process.versions.node} fire/${SDK_VERSION} grpc/${grpcVersion}`;\r\nfunction createMetadata(databasePath, token, appId) {\r\n    hardAssert(token === null || token.type === 'OAuth');\r\n    const metadata = new Metadata();\r\n    if (token) {\r\n        for (const header in token.authHeaders) {\r\n            if (token.authHeaders.hasOwnProperty(header)) {\r\n                metadata.set(header, token.authHeaders[header]);\r\n            }\r\n        }\r\n    }\r\n    if (appId) {\r\n        metadata.set('X-Firebase-GMPID', appId);\r\n    }\r\n    metadata.set('X-Goog-Api-Client', X_GOOG_API_CLIENT_VALUE);\r\n    // This header is used to improve routing and project isolation by the\r\n    // backend.\r\n    metadata.set('Google-Cloud-Resource-Prefix', databasePath);\r\n    return metadata;\r\n}\r\n/**\r\n * A Connection implemented by GRPC-Node.\r\n */\r\nclass GrpcConnection {\r\n    constructor(protos, databaseInfo) {\r\n        this.databaseInfo = databaseInfo;\r\n        // We cache stubs for the most-recently-used token.\r\n        this.cachedStub = null;\r\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        this.firestore = protos['google']['firestore']['v1'];\r\n        this.databasePath = `projects/${databaseInfo.databaseId.projectId}/databases/${databaseInfo.databaseId.database}`;\r\n    }\r\n    ensureActiveStub() {\r\n        if (!this.cachedStub) {\r\n            logDebug(LOG_TAG$9, 'Creating Firestore stub.');\r\n            const credentials$1 = this.databaseInfo.ssl\r\n                ? credentials.createSsl()\r\n                : credentials.createInsecure();\r\n            this.cachedStub = new this.firestore.Firestore(this.databaseInfo.host, credentials$1);\r\n        }\r\n        return this.cachedStub;\r\n    }\r\n    invokeRPC(rpcName, path, request, token) {\r\n        const stub = this.ensureActiveStub();\r\n        const metadata = createMetadata(this.databasePath, token, this.databaseInfo.appId);\r\n        const jsonRequest = Object.assign({ database: this.databasePath }, request);\r\n        return nodePromise((callback) => {\r\n            logDebug(LOG_TAG$9, `RPC '${rpcName}' invoked with request:`, request);\r\n            return stub[rpcName](jsonRequest, metadata, (grpcError, value) => {\r\n                if (grpcError) {\r\n                    logDebug(LOG_TAG$9, `RPC '${rpcName}' failed with error:`, grpcError);\r\n                    callback(new FirestoreError(mapCodeFromRpcCode(grpcError.code), grpcError.message));\r\n                }\r\n                else {\r\n                    logDebug(LOG_TAG$9, `RPC '${rpcName}' completed with response:`, value);\r\n                    callback(undefined, value);\r\n                }\r\n            });\r\n        });\r\n    }\r\n    invokeStreamingRPC(rpcName, path, request, token) {\r\n        const results = [];\r\n        const responseDeferred = new Deferred();\r\n        logDebug(LOG_TAG$9, `RPC '${rpcName}' invoked (streaming) with request:`, request);\r\n        const stub = this.ensureActiveStub();\r\n        const metadata = createMetadata(this.databasePath, token, this.databaseInfo.appId);\r\n        const jsonRequest = Object.assign(Object.assign({}, request), { database: this.databasePath });\r\n        const stream = stub[rpcName](jsonRequest, metadata);\r\n        stream.on('data', (response) => {\r\n            logDebug(LOG_TAG$9, `RPC ${rpcName} received result:`, response);\r\n            results.push(response);\r\n        });\r\n        stream.on('end', () => {\r\n            logDebug(LOG_TAG$9, `RPC '${rpcName}' completed.`);\r\n            responseDeferred.resolve(results);\r\n        });\r\n        stream.on('error', (grpcError) => {\r\n            logDebug(LOG_TAG$9, `RPC '${rpcName}' failed with error:`, grpcError);\r\n            const code = mapCodeFromRpcCode(grpcError.code);\r\n            responseDeferred.reject(new FirestoreError(code, grpcError.message));\r\n        });\r\n        return responseDeferred.promise;\r\n    }\r\n    // TODO(mikelehen): This \"method\" is a monster. Should be refactored.\r\n    openStream(rpcName, token) {\r\n        const stub = this.ensureActiveStub();\r\n        const metadata = createMetadata(this.databasePath, token, this.databaseInfo.appId);\r\n        const grpcStream = stub[rpcName](metadata);\r\n        let closed = false;\r\n        const close = (err) => {\r\n            if (!closed) {\r\n                closed = true;\r\n                stream.callOnClose(err);\r\n                grpcStream.end();\r\n            }\r\n        };\r\n        const stream = new StreamBridge({\r\n            sendFn: (msg) => {\r\n                if (!closed) {\r\n                    logDebug(LOG_TAG$9, 'GRPC stream sending:', msg);\r\n                    try {\r\n                        grpcStream.write(msg);\r\n                    }\r\n                    catch (e) {\r\n                        // This probably means we didn't conform to the proto.  Make sure to\r\n                        // log the message we sent.\r\n                        logError('Failure sending:', msg);\r\n                        logError('Error:', e);\r\n                        throw e;\r\n                    }\r\n                }\r\n                else {\r\n                    logDebug(LOG_TAG$9, 'Not sending because gRPC stream is closed:', msg);\r\n                }\r\n            },\r\n            closeFn: () => {\r\n                logDebug(LOG_TAG$9, 'GRPC stream closed locally via close().');\r\n                close();\r\n            }\r\n        });\r\n        grpcStream.on('data', (msg) => {\r\n            if (!closed) {\r\n                logDebug(LOG_TAG$9, 'GRPC stream received:', msg);\r\n                stream.callOnMessage(msg);\r\n            }\r\n        });\r\n        grpcStream.on('end', () => {\r\n            logDebug(LOG_TAG$9, 'GRPC stream ended.');\r\n            close();\r\n        });\r\n        grpcStream.on('error', (grpcError) => {\r\n            if (!closed) {\r\n                logWarn(LOG_TAG$9, 'GRPC stream error. Code:', grpcError.code, 'Message:', grpcError.message);\r\n                const code = mapCodeFromRpcCode(grpcError.code);\r\n                close(new FirestoreError(code, grpcError.message));\r\n            }\r\n        });\r\n        logDebug(LOG_TAG$9, 'Opening GRPC stream');\r\n        // TODO(dimond): Since grpc has no explicit open status (or does it?) we\r\n        // simulate an onOpen in the next loop after the stream had it's listeners\r\n        // registered\r\n        setTimeout(() => {\r\n            stream.callOnOpen();\r\n        }, 0);\r\n        return stream;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// __filename and __dirname globals are unavailable in ES modules\r\n// @ts-ignore To avoid using `--module es2020` flag.\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = dirname(__filename);\r\n/** Used by tests so we can match @grpc/proto-loader behavior. */\r\nconst protoLoaderOptions = {\r\n    longs: String,\r\n    enums: String,\r\n    defaults: true,\r\n    oneofs: false\r\n};\r\n/**\r\n * Loads the protocol buffer definitions for Firestore.\r\n *\r\n * @returns The GrpcObject representing our protos.\r\n */\r\nfunction loadProtos() {\r\n    const root = resolve(__dirname, \"src/protos\" );\r\n    const firestoreProtoFile = join(root, 'google/firestore/v1/firestore.proto');\r\n    const packageDefinition = loadSync(firestoreProtoFile, Object.assign(Object.assign({}, protoLoaderOptions), { includeDirs: [root] }));\r\n    return loadPackageDefinition(packageDefinition);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** Loads the GRPC stack */\r\nfunction newConnection(databaseInfo) {\r\n    const protos = loadProtos();\r\n    return new GrpcConnection(protos, databaseInfo);\r\n}\r\n/** Return the Platform-specific connectivity monitor. */\r\nfunction newConnectivityMonitor() {\r\n    return new NoopConnectivityMonitor();\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** The Platform's 'window' implementation or null if not available. */\r\nfunction getWindow() {\r\n    if (process.env.USE_MOCK_PERSISTENCE === 'YES') {\r\n        // eslint-disable-next-line no-restricted-globals\r\n        return window;\r\n    }\r\n    return null;\r\n}\r\n/** The Platform's 'document' implementation or null if not available. */\r\nfunction getDocument() {\r\n    return null;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction newSerializer(databaseId) {\r\n    return new JsonProtoSerializer(databaseId, /* useProto3Json= */ false);\r\n}\r\n/**\r\n * An instance of the Platform's 'TextEncoder' implementation.\r\n */\r\nfunction newTextEncoder() {\r\n    return new TextEncoder();\r\n}\r\n/**\r\n * An instance of the Platform's 'TextDecoder' implementation.\r\n */\r\nfunction newTextDecoder() {\r\n    return new TextDecoder('utf-8');\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$8 = 'ExponentialBackoff';\r\n/**\r\n * Initial backoff time in milliseconds after an error.\r\n * Set to 1s according to https://cloud.google.com/apis/design/errors.\r\n */\r\nconst DEFAULT_BACKOFF_INITIAL_DELAY_MS = 1000;\r\nconst DEFAULT_BACKOFF_FACTOR = 1.5;\r\n/** Maximum backoff time in milliseconds */\r\nconst DEFAULT_BACKOFF_MAX_DELAY_MS = 60 * 1000;\r\n/**\r\n * A helper for running delayed tasks following an exponential backoff curve\r\n * between attempts.\r\n *\r\n * Each delay is made up of a \"base\" delay which follows the exponential\r\n * backoff curve, and a +/- 50% \"jitter\" that is calculated and added to the\r\n * base delay. This prevents clients from accidentally synchronizing their\r\n * delays causing spikes of load to the backend.\r\n */\r\nclass ExponentialBackoff {\r\n    constructor(\r\n    /**\r\n     * The AsyncQueue to run backoff operations on.\r\n     */\r\n    queue, \r\n    /**\r\n     * The ID to use when scheduling backoff operations on the AsyncQueue.\r\n     */\r\n    timerId, \r\n    /**\r\n     * The initial delay (used as the base delay on the first retry attempt).\r\n     * Note that jitter will still be applied, so the actual delay could be as\r\n     * little as 0.5*initialDelayMs.\r\n     */\r\n    initialDelayMs = DEFAULT_BACKOFF_INITIAL_DELAY_MS, \r\n    /**\r\n     * The multiplier to use to determine the extended base delay after each\r\n     * attempt.\r\n     */\r\n    backoffFactor = DEFAULT_BACKOFF_FACTOR, \r\n    /**\r\n     * The maximum base delay after which no further backoff is performed.\r\n     * Note that jitter will still be applied, so the actual delay could be as\r\n     * much as 1.5*maxDelayMs.\r\n     */\r\n    maxDelayMs = DEFAULT_BACKOFF_MAX_DELAY_MS) {\r\n        this.queue = queue;\r\n        this.timerId = timerId;\r\n        this.initialDelayMs = initialDelayMs;\r\n        this.backoffFactor = backoffFactor;\r\n        this.maxDelayMs = maxDelayMs;\r\n        this.currentBaseMs = 0;\r\n        this.timerPromise = null;\r\n        /** The last backoff attempt, as epoch milliseconds. */\r\n        this.lastAttemptTime = Date.now();\r\n        this.reset();\r\n    }\r\n    /**\r\n     * Resets the backoff delay.\r\n     *\r\n     * The very next backoffAndWait() will have no delay. If it is called again\r\n     * (i.e. due to an error), initialDelayMs (plus jitter) will be used, and\r\n     * subsequent ones will increase according to the backoffFactor.\r\n     */\r\n    reset() {\r\n        this.currentBaseMs = 0;\r\n    }\r\n    /**\r\n     * Resets the backoff delay to the maximum delay (e.g. for use after a\r\n     * RESOURCE_EXHAUSTED error).\r\n     */\r\n    resetToMax() {\r\n        this.currentBaseMs = this.maxDelayMs;\r\n    }\r\n    /**\r\n     * Returns a promise that resolves after currentDelayMs, and increases the\r\n     * delay for any subsequent attempts. If there was a pending backoff operation\r\n     * already, it will be canceled.\r\n     */\r\n    backoffAndRun(op) {\r\n        // Cancel any pending backoff operation.\r\n        this.cancel();\r\n        // First schedule using the current base (which may be 0 and should be\r\n        // honored as such).\r\n        const desiredDelayWithJitterMs = Math.floor(this.currentBaseMs + this.jitterDelayMs());\r\n        // Guard against lastAttemptTime being in the future due to a clock change.\r\n        const delaySoFarMs = Math.max(0, Date.now() - this.lastAttemptTime);\r\n        // Guard against the backoff delay already being past.\r\n        const remainingDelayMs = Math.max(0, desiredDelayWithJitterMs - delaySoFarMs);\r\n        if (remainingDelayMs > 0) {\r\n            logDebug(LOG_TAG$8, `Backing off for ${remainingDelayMs} ms ` +\r\n                `(base delay: ${this.currentBaseMs} ms, ` +\r\n                `delay with jitter: ${desiredDelayWithJitterMs} ms, ` +\r\n                `last attempt: ${delaySoFarMs} ms ago)`);\r\n        }\r\n        this.timerPromise = this.queue.enqueueAfterDelay(this.timerId, remainingDelayMs, () => {\r\n            this.lastAttemptTime = Date.now();\r\n            return op();\r\n        });\r\n        // Apply backoff factor to determine next delay and ensure it is within\r\n        // bounds.\r\n        this.currentBaseMs *= this.backoffFactor;\r\n        if (this.currentBaseMs < this.initialDelayMs) {\r\n            this.currentBaseMs = this.initialDelayMs;\r\n        }\r\n        if (this.currentBaseMs > this.maxDelayMs) {\r\n            this.currentBaseMs = this.maxDelayMs;\r\n        }\r\n    }\r\n    skipBackoff() {\r\n        if (this.timerPromise !== null) {\r\n            this.timerPromise.skipDelay();\r\n            this.timerPromise = null;\r\n        }\r\n    }\r\n    cancel() {\r\n        if (this.timerPromise !== null) {\r\n            this.timerPromise.cancel();\r\n            this.timerPromise = null;\r\n        }\r\n    }\r\n    /** Returns a random value in the range [-currentBaseMs/2, currentBaseMs/2] */\r\n    jitterDelayMs() {\r\n        return (Math.random() - 0.5) * this.currentBaseMs;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$7 = 'PersistentStream';\r\n/** The time a stream stays open after it is marked idle. */\r\nconst IDLE_TIMEOUT_MS = 60 * 1000;\r\n/** The time a stream stays open until we consider it healthy. */\r\nconst HEALTHY_TIMEOUT_MS = 10 * 1000;\r\n/**\r\n * A PersistentStream is an abstract base class that represents a streaming RPC\r\n * to the Firestore backend. It's built on top of the connections own support\r\n * for streaming RPCs, and adds several critical features for our clients:\r\n *\r\n *   - Exponential backoff on failure\r\n *   - Authentication via CredentialsProvider\r\n *   - Dispatching all callbacks into the shared worker queue\r\n *   - Closing idle streams after 60 seconds of inactivity\r\n *\r\n * Subclasses of PersistentStream implement serialization of models to and\r\n * from the JSON representation of the protocol buffers for a specific\r\n * streaming RPC.\r\n *\r\n * ## Starting and Stopping\r\n *\r\n * Streaming RPCs are stateful and need to be start()ed before messages can\r\n * be sent and received. The PersistentStream will call the onOpen() function\r\n * of the listener once the stream is ready to accept requests.\r\n *\r\n * Should a start() fail, PersistentStream will call the registered onClose()\r\n * listener with a FirestoreError indicating what went wrong.\r\n *\r\n * A PersistentStream can be started and stopped repeatedly.\r\n *\r\n * Generic types:\r\n *  SendType: The type of the outgoing message of the underlying\r\n *    connection stream\r\n *  ReceiveType: The type of the incoming message of the underlying\r\n *    connection stream\r\n *  ListenerType: The type of the listener that will be used for callbacks\r\n */\r\nclass PersistentStream {\r\n    constructor(queue, connectionTimerId, idleTimerId, healthTimerId, connection, credentialsProvider, listener) {\r\n        this.queue = queue;\r\n        this.idleTimerId = idleTimerId;\r\n        this.healthTimerId = healthTimerId;\r\n        this.connection = connection;\r\n        this.credentialsProvider = credentialsProvider;\r\n        this.listener = listener;\r\n        this.state = 0 /* Initial */;\r\n        /**\r\n         * A close count that's incremented every time the stream is closed; used by\r\n         * getCloseGuardedDispatcher() to invalidate callbacks that happen after\r\n         * close.\r\n         */\r\n        this.closeCount = 0;\r\n        this.idleTimer = null;\r\n        this.healthCheck = null;\r\n        this.stream = null;\r\n        this.backoff = new ExponentialBackoff(queue, connectionTimerId);\r\n    }\r\n    /**\r\n     * Returns true if start() has been called and no error has occurred. True\r\n     * indicates the stream is open or in the process of opening (which\r\n     * encompasses respecting backoff, getting auth tokens, and starting the\r\n     * actual RPC). Use isOpen() to determine if the stream is open and ready for\r\n     * outbound requests.\r\n     */\r\n    isStarted() {\r\n        return (this.state === 1 /* Starting */ ||\r\n            this.state === 5 /* Backoff */ ||\r\n            this.isOpen());\r\n    }\r\n    /**\r\n     * Returns true if the underlying RPC is open (the onOpen() listener has been\r\n     * called) and the stream is ready for outbound requests.\r\n     */\r\n    isOpen() {\r\n        return (this.state === 2 /* Open */ ||\r\n            this.state === 3 /* Healthy */);\r\n    }\r\n    /**\r\n     * Starts the RPC. Only allowed if isStarted() returns false. The stream is\r\n     * not immediately ready for use: onOpen() will be invoked when the RPC is\r\n     * ready for outbound requests, at which point isOpen() will return true.\r\n     *\r\n     * When start returns, isStarted() will return true.\r\n     */\r\n    start() {\r\n        if (this.state === 4 /* Error */) {\r\n            this.performBackoff();\r\n            return;\r\n        }\r\n        this.auth();\r\n    }\r\n    /**\r\n     * Stops the RPC. This call is idempotent and allowed regardless of the\r\n     * current isStarted() state.\r\n     *\r\n     * When stop returns, isStarted() and isOpen() will both return false.\r\n     */\r\n    async stop() {\r\n        if (this.isStarted()) {\r\n            await this.close(0 /* Initial */);\r\n        }\r\n    }\r\n    /**\r\n     * After an error the stream will usually back off on the next attempt to\r\n     * start it. If the error warrants an immediate restart of the stream, the\r\n     * sender can use this to indicate that the receiver should not back off.\r\n     *\r\n     * Each error will call the onClose() listener. That function can decide to\r\n     * inhibit backoff if required.\r\n     */\r\n    inhibitBackoff() {\r\n        this.state = 0 /* Initial */;\r\n        this.backoff.reset();\r\n    }\r\n    /**\r\n     * Marks this stream as idle. If no further actions are performed on the\r\n     * stream for one minute, the stream will automatically close itself and\r\n     * notify the stream's onClose() handler with Status.OK. The stream will then\r\n     * be in a !isStarted() state, requiring the caller to start the stream again\r\n     * before further use.\r\n     *\r\n     * Only streams that are in state 'Open' can be marked idle, as all other\r\n     * states imply pending network operations.\r\n     */\r\n    markIdle() {\r\n        // Starts the idle time if we are in state 'Open' and are not yet already\r\n        // running a timer (in which case the previous idle timeout still applies).\r\n        if (this.isOpen() && this.idleTimer === null) {\r\n            this.idleTimer = this.queue.enqueueAfterDelay(this.idleTimerId, IDLE_TIMEOUT_MS, () => this.handleIdleCloseTimer());\r\n        }\r\n    }\r\n    /** Sends a message to the underlying stream. */\r\n    sendRequest(msg) {\r\n        this.cancelIdleCheck();\r\n        this.stream.send(msg);\r\n    }\r\n    /** Called by the idle timer when the stream should close due to inactivity. */\r\n    async handleIdleCloseTimer() {\r\n        if (this.isOpen()) {\r\n            // When timing out an idle stream there's no reason to force the stream into backoff when\r\n            // it restarts so set the stream state to Initial instead of Error.\r\n            return this.close(0 /* Initial */);\r\n        }\r\n    }\r\n    /** Marks the stream as active again. */\r\n    cancelIdleCheck() {\r\n        if (this.idleTimer) {\r\n            this.idleTimer.cancel();\r\n            this.idleTimer = null;\r\n        }\r\n    }\r\n    /** Cancels the health check delayed operation. */\r\n    cancelHealthCheck() {\r\n        if (this.healthCheck) {\r\n            this.healthCheck.cancel();\r\n            this.healthCheck = null;\r\n        }\r\n    }\r\n    /**\r\n     * Closes the stream and cleans up as necessary:\r\n     *\r\n     * * closes the underlying GRPC stream;\r\n     * * calls the onClose handler with the given 'error';\r\n     * * sets internal stream state to 'finalState';\r\n     * * adjusts the backoff timer based on the error\r\n     *\r\n     * A new stream can be opened by calling start().\r\n     *\r\n     * @param finalState - the intended state of the stream after closing.\r\n     * @param error - the error the connection was closed with.\r\n     */\r\n    async close(finalState, error) {\r\n        // Cancel any outstanding timers (they're guaranteed not to execute).\r\n        this.cancelIdleCheck();\r\n        this.cancelHealthCheck();\r\n        this.backoff.cancel();\r\n        // Invalidates any stream-related callbacks (e.g. from auth or the\r\n        // underlying stream), guaranteeing they won't execute.\r\n        this.closeCount++;\r\n        if (finalState !== 4 /* Error */) {\r\n            // If this is an intentional close ensure we don't delay our next connection attempt.\r\n            this.backoff.reset();\r\n        }\r\n        else if (error && error.code === Code.RESOURCE_EXHAUSTED) {\r\n            // Log the error. (Probably either 'quota exceeded' or 'max queue length reached'.)\r\n            logError(error.toString());\r\n            logError('Using maximum backoff delay to prevent overloading the backend.');\r\n            this.backoff.resetToMax();\r\n        }\r\n        else if (error &&\r\n            error.code === Code.UNAUTHENTICATED &&\r\n            this.state !== 3 /* Healthy */) {\r\n            // \"unauthenticated\" error means the token was rejected. This should rarely\r\n            // happen since both Auth and AppCheck ensure a sufficient TTL when we\r\n            // request a token. If a user manually resets their system clock this can\r\n            // fail, however. In this case, we should get a Code.UNAUTHENTICATED error\r\n            // before we received the first message and we need to invalidate the token\r\n            // to ensure that we fetch a new token.\r\n            this.credentialsProvider.invalidateToken();\r\n        }\r\n        // Clean up the underlying stream because we are no longer interested in events.\r\n        if (this.stream !== null) {\r\n            this.tearDown();\r\n            this.stream.close();\r\n            this.stream = null;\r\n        }\r\n        // This state must be assigned before calling onClose() to allow the callback to\r\n        // inhibit backoff or otherwise manipulate the state in its non-started state.\r\n        this.state = finalState;\r\n        // Notify the listener that the stream closed.\r\n        await this.listener.onClose(error);\r\n    }\r\n    /**\r\n     * Can be overridden to perform additional cleanup before the stream is closed.\r\n     * Calling super.tearDown() is not required.\r\n     */\r\n    tearDown() { }\r\n    auth() {\r\n        this.state = 1 /* Starting */;\r\n        const dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount);\r\n        // TODO(mikelehen): Just use dispatchIfNotClosed, but see TODO below.\r\n        const closeCount = this.closeCount;\r\n        this.credentialsProvider.getToken().then(token => {\r\n            // Stream can be stopped while waiting for authentication.\r\n            // TODO(mikelehen): We really should just use dispatchIfNotClosed\r\n            // and let this dispatch onto the queue, but that opened a spec test can\r\n            // of worms that I don't want to deal with in this PR.\r\n            if (this.closeCount === closeCount) {\r\n                // Normally we'd have to schedule the callback on the AsyncQueue.\r\n                // However, the following calls are safe to be called outside the\r\n                // AsyncQueue since they don't chain asynchronous calls\r\n                this.startStream(token);\r\n            }\r\n        }, (error) => {\r\n            dispatchIfNotClosed(() => {\r\n                const rpcError = new FirestoreError(Code.UNKNOWN, 'Fetching auth token failed: ' + error.message);\r\n                return this.handleStreamClose(rpcError);\r\n            });\r\n        });\r\n    }\r\n    startStream(token) {\r\n        const dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount);\r\n        this.stream = this.startRpc(token);\r\n        this.stream.onOpen(() => {\r\n            dispatchIfNotClosed(() => {\r\n                this.state = 2 /* Open */;\r\n                this.healthCheck = this.queue.enqueueAfterDelay(this.healthTimerId, HEALTHY_TIMEOUT_MS, () => {\r\n                    if (this.isOpen()) {\r\n                        this.state = 3 /* Healthy */;\r\n                    }\r\n                    return Promise.resolve();\r\n                });\r\n                return this.listener.onOpen();\r\n            });\r\n        });\r\n        this.stream.onClose((error) => {\r\n            dispatchIfNotClosed(() => {\r\n                return this.handleStreamClose(error);\r\n            });\r\n        });\r\n        this.stream.onMessage((msg) => {\r\n            dispatchIfNotClosed(() => {\r\n                return this.onMessage(msg);\r\n            });\r\n        });\r\n    }\r\n    performBackoff() {\r\n        this.state = 5 /* Backoff */;\r\n        this.backoff.backoffAndRun(async () => {\r\n            this.state = 0 /* Initial */;\r\n            this.start();\r\n        });\r\n    }\r\n    // Visible for tests\r\n    handleStreamClose(error) {\r\n        logDebug(LOG_TAG$7, `close with error: ${error}`);\r\n        this.stream = null;\r\n        // In theory the stream could close cleanly, however, in our current model\r\n        // we never expect this to happen because if we stop a stream ourselves,\r\n        // this callback will never be called. To prevent cases where we retry\r\n        // without a backoff accidentally, we set the stream to error in all cases.\r\n        return this.close(4 /* Error */, error);\r\n    }\r\n    /**\r\n     * Returns a \"dispatcher\" function that dispatches operations onto the\r\n     * AsyncQueue but only runs them if closeCount remains unchanged. This allows\r\n     * us to turn auth / stream callbacks into no-ops if the stream is closed /\r\n     * re-opened, etc.\r\n     */\r\n    getCloseGuardedDispatcher(startCloseCount) {\r\n        return (fn) => {\r\n            this.queue.enqueueAndForget(() => {\r\n                if (this.closeCount === startCloseCount) {\r\n                    return fn();\r\n                }\r\n                else {\r\n                    logDebug(LOG_TAG$7, 'stream callback skipped by getCloseGuardedDispatcher.');\r\n                    return Promise.resolve();\r\n                }\r\n            });\r\n        };\r\n    }\r\n}\r\n/**\r\n * A PersistentStream that implements the Listen RPC.\r\n *\r\n * Once the Listen stream has called the onOpen() listener, any number of\r\n * listen() and unlisten() calls can be made to control what changes will be\r\n * sent from the server for ListenResponses.\r\n */\r\nclass PersistentListenStream extends PersistentStream {\r\n    constructor(queue, connection, credentials, serializer, listener) {\r\n        super(queue, \"listen_stream_connection_backoff\" /* ListenStreamConnectionBackoff */, \"listen_stream_idle\" /* ListenStreamIdle */, \"health_check_timeout\" /* HealthCheckTimeout */, connection, credentials, listener);\r\n        this.serializer = serializer;\r\n    }\r\n    startRpc(token) {\r\n        return this.connection.openStream('Listen', token);\r\n    }\r\n    onMessage(watchChangeProto) {\r\n        // A successful response means the stream is healthy\r\n        this.backoff.reset();\r\n        const watchChange = fromWatchChange(this.serializer, watchChangeProto);\r\n        const snapshot = versionFromListenResponse(watchChangeProto);\r\n        return this.listener.onWatchChange(watchChange, snapshot);\r\n    }\r\n    /**\r\n     * Registers interest in the results of the given target. If the target\r\n     * includes a resumeToken it will be included in the request. Results that\r\n     * affect the target will be streamed back as WatchChange messages that\r\n     * reference the targetId.\r\n     */\r\n    watch(targetData) {\r\n        const request = {};\r\n        request.database = getEncodedDatabaseId(this.serializer);\r\n        request.addTarget = toTarget(this.serializer, targetData);\r\n        const labels = toListenRequestLabels(this.serializer, targetData);\r\n        if (labels) {\r\n            request.labels = labels;\r\n        }\r\n        this.sendRequest(request);\r\n    }\r\n    /**\r\n     * Unregisters interest in the results of the target associated with the\r\n     * given targetId.\r\n     */\r\n    unwatch(targetId) {\r\n        const request = {};\r\n        request.database = getEncodedDatabaseId(this.serializer);\r\n        request.removeTarget = targetId;\r\n        this.sendRequest(request);\r\n    }\r\n}\r\n/**\r\n * A Stream that implements the Write RPC.\r\n *\r\n * The Write RPC requires the caller to maintain special streamToken\r\n * state in between calls, to help the server understand which responses the\r\n * client has processed by the time the next request is made. Every response\r\n * will contain a streamToken; this value must be passed to the next\r\n * request.\r\n *\r\n * After calling start() on this stream, the next request must be a handshake,\r\n * containing whatever streamToken is on hand. Once a response to this\r\n * request is received, all pending mutations may be submitted. When\r\n * submitting multiple batches of mutations at the same time, it's\r\n * okay to use the same streamToken for the calls to writeMutations.\r\n *\r\n * TODO(b/33271235): Use proto types\r\n */\r\nclass PersistentWriteStream extends PersistentStream {\r\n    constructor(queue, connection, credentials, serializer, listener) {\r\n        super(queue, \"write_stream_connection_backoff\" /* WriteStreamConnectionBackoff */, \"write_stream_idle\" /* WriteStreamIdle */, \"health_check_timeout\" /* HealthCheckTimeout */, connection, credentials, listener);\r\n        this.serializer = serializer;\r\n        this.handshakeComplete_ = false;\r\n    }\r\n    /**\r\n     * Tracks whether or not a handshake has been successfully exchanged and\r\n     * the stream is ready to accept mutations.\r\n     */\r\n    get handshakeComplete() {\r\n        return this.handshakeComplete_;\r\n    }\r\n    // Override of PersistentStream.start\r\n    start() {\r\n        this.handshakeComplete_ = false;\r\n        this.lastStreamToken = undefined;\r\n        super.start();\r\n    }\r\n    tearDown() {\r\n        if (this.handshakeComplete_) {\r\n            this.writeMutations([]);\r\n        }\r\n    }\r\n    startRpc(token) {\r\n        return this.connection.openStream('Write', token);\r\n    }\r\n    onMessage(responseProto) {\r\n        // Always capture the last stream token.\r\n        hardAssert(!!responseProto.streamToken);\r\n        this.lastStreamToken = responseProto.streamToken;\r\n        if (!this.handshakeComplete_) {\r\n            // The first response is always the handshake response\r\n            hardAssert(!responseProto.writeResults || responseProto.writeResults.length === 0);\r\n            this.handshakeComplete_ = true;\r\n            return this.listener.onHandshakeComplete();\r\n        }\r\n        else {\r\n            // A successful first write response means the stream is healthy,\r\n            // Note, that we could consider a successful handshake healthy, however,\r\n            // the write itself might be causing an error we want to back off from.\r\n            this.backoff.reset();\r\n            const results = fromWriteResults(responseProto.writeResults, responseProto.commitTime);\r\n            const commitVersion = fromVersion(responseProto.commitTime);\r\n            return this.listener.onMutationResult(commitVersion, results);\r\n        }\r\n    }\r\n    /**\r\n     * Sends an initial streamToken to the server, performing the handshake\r\n     * required to make the StreamingWrite RPC work. Subsequent\r\n     * calls should wait until onHandshakeComplete was called.\r\n     */\r\n    writeHandshake() {\r\n        // TODO(dimond): Support stream resumption. We intentionally do not set the\r\n        // stream token on the handshake, ignoring any stream token we might have.\r\n        const request = {};\r\n        request.database = getEncodedDatabaseId(this.serializer);\r\n        this.sendRequest(request);\r\n    }\r\n    /** Sends a group of mutations to the Firestore backend to apply. */\r\n    writeMutations(mutations) {\r\n        const request = {\r\n            streamToken: this.lastStreamToken,\r\n            writes: mutations.map(mutation => toMutation(this.serializer, mutation))\r\n        };\r\n        this.sendRequest(request);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Datastore and its related methods are a wrapper around the external Google\r\n * Cloud Datastore grpc API, which provides an interface that is more convenient\r\n * for the rest of the client SDK architecture to consume.\r\n */\r\nclass Datastore {\r\n}\r\n/**\r\n * An implementation of Datastore that exposes additional state for internal\r\n * consumption.\r\n */\r\nclass DatastoreImpl extends Datastore {\r\n    constructor(credentials, connection, serializer) {\r\n        super();\r\n        this.credentials = credentials;\r\n        this.connection = connection;\r\n        this.serializer = serializer;\r\n        this.terminated = false;\r\n    }\r\n    verifyInitialized() {\r\n        if (this.terminated) {\r\n            throw new FirestoreError(Code.FAILED_PRECONDITION, 'The client has already been terminated.');\r\n        }\r\n    }\r\n    /** Gets an auth token and invokes the provided RPC. */\r\n    invokeRPC(rpcName, path, request) {\r\n        this.verifyInitialized();\r\n        return this.credentials\r\n            .getToken()\r\n            .then(token => {\r\n            return this.connection.invokeRPC(rpcName, path, request, token);\r\n        })\r\n            .catch((error) => {\r\n            if (error.name === 'FirebaseError') {\r\n                if (error.code === Code.UNAUTHENTICATED) {\r\n                    this.credentials.invalidateToken();\r\n                }\r\n                throw error;\r\n            }\r\n            else {\r\n                throw new FirestoreError(Code.UNKNOWN, error.toString());\r\n            }\r\n        });\r\n    }\r\n    /** Gets an auth token and invokes the provided RPC with streamed results. */\r\n    invokeStreamingRPC(rpcName, path, request) {\r\n        this.verifyInitialized();\r\n        return this.credentials\r\n            .getToken()\r\n            .then(token => {\r\n            return this.connection.invokeStreamingRPC(rpcName, path, request, token);\r\n        })\r\n            .catch((error) => {\r\n            if (error.name === 'FirebaseError') {\r\n                if (error.code === Code.UNAUTHENTICATED) {\r\n                    this.credentials.invalidateToken();\r\n                }\r\n                throw error;\r\n            }\r\n            else {\r\n                throw new FirestoreError(Code.UNKNOWN, error.toString());\r\n            }\r\n        });\r\n    }\r\n    terminate() {\r\n        this.terminated = true;\r\n    }\r\n}\r\n// TODO(firestorexp): Make sure there is only one Datastore instance per\r\n// firestore-exp client.\r\nfunction newDatastore(credentials, connection, serializer) {\r\n    return new DatastoreImpl(credentials, connection, serializer);\r\n}\r\nasync function invokeCommitRpc(datastore, mutations) {\r\n    const datastoreImpl = debugCast(datastore);\r\n    const path = getEncodedDatabaseId(datastoreImpl.serializer) + '/documents';\r\n    const request = {\r\n        writes: mutations.map(m => toMutation(datastoreImpl.serializer, m))\r\n    };\r\n    await datastoreImpl.invokeRPC('Commit', path, request);\r\n}\r\nasync function invokeBatchGetDocumentsRpc(datastore, keys) {\r\n    const datastoreImpl = debugCast(datastore);\r\n    const path = getEncodedDatabaseId(datastoreImpl.serializer) + '/documents';\r\n    const request = {\r\n        documents: keys.map(k => toName(datastoreImpl.serializer, k))\r\n    };\r\n    const response = await datastoreImpl.invokeStreamingRPC('BatchGetDocuments', path, request);\r\n    const docs = new Map();\r\n    response.forEach(proto => {\r\n        const doc = fromBatchGetDocumentsResponse(datastoreImpl.serializer, proto);\r\n        docs.set(doc.key.toString(), doc);\r\n    });\r\n    const result = [];\r\n    keys.forEach(key => {\r\n        const doc = docs.get(key.toString());\r\n        hardAssert(!!doc);\r\n        result.push(doc);\r\n    });\r\n    return result;\r\n}\r\nfunction newPersistentWriteStream(datastore, queue, listener) {\r\n    const datastoreImpl = debugCast(datastore);\r\n    datastoreImpl.verifyInitialized();\r\n    return new PersistentWriteStream(queue, datastoreImpl.connection, datastoreImpl.credentials, datastoreImpl.serializer, listener);\r\n}\r\nfunction newPersistentWatchStream(datastore, queue, listener) {\r\n    const datastoreImpl = debugCast(datastore);\r\n    datastoreImpl.verifyInitialized();\r\n    return new PersistentListenStream(queue, datastoreImpl.connection, datastoreImpl.credentials, datastoreImpl.serializer, listener);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$6 = 'OnlineStateTracker';\r\n// To deal with transient failures, we allow multiple stream attempts before\r\n// giving up and transitioning from OnlineState.Unknown to Offline.\r\n// TODO(mikelehen): This used to be set to 2 as a mitigation for b/66228394.\r\n// @jdimond thinks that bug is sufficiently fixed so that we can set this back\r\n// to 1. If that works okay, we could potentially remove this logic entirely.\r\nconst MAX_WATCH_STREAM_FAILURES = 1;\r\n// To deal with stream attempts that don't succeed or fail in a timely manner,\r\n// we have a timeout for OnlineState to reach Online or Offline.\r\n// If the timeout is reached, we transition to Offline rather than waiting\r\n// indefinitely.\r\nconst ONLINE_STATE_TIMEOUT_MS = 10 * 1000;\r\n/**\r\n * A component used by the RemoteStore to track the OnlineState (that is,\r\n * whether or not the client as a whole should be considered to be online or\r\n * offline), implementing the appropriate heuristics.\r\n *\r\n * In particular, when the client is trying to connect to the backend, we\r\n * allow up to MAX_WATCH_STREAM_FAILURES within ONLINE_STATE_TIMEOUT_MS for\r\n * a connection to succeed. If we have too many failures or the timeout elapses,\r\n * then we set the OnlineState to Offline, and the client will behave as if\r\n * it is offline (get()s will return cached data, etc.).\r\n */\r\nclass OnlineStateTracker {\r\n    constructor(asyncQueue, onlineStateHandler) {\r\n        this.asyncQueue = asyncQueue;\r\n        this.onlineStateHandler = onlineStateHandler;\r\n        /** The current OnlineState. */\r\n        this.state = \"Unknown\" /* Unknown */;\r\n        /**\r\n         * A count of consecutive failures to open the stream. If it reaches the\r\n         * maximum defined by MAX_WATCH_STREAM_FAILURES, we'll set the OnlineState to\r\n         * Offline.\r\n         */\r\n        this.watchStreamFailures = 0;\r\n        /**\r\n         * A timer that elapses after ONLINE_STATE_TIMEOUT_MS, at which point we\r\n         * transition from OnlineState.Unknown to OnlineState.Offline without waiting\r\n         * for the stream to actually fail (MAX_WATCH_STREAM_FAILURES times).\r\n         */\r\n        this.onlineStateTimer = null;\r\n        /**\r\n         * Whether the client should log a warning message if it fails to connect to\r\n         * the backend (initially true, cleared after a successful stream, or if we've\r\n         * logged the message already).\r\n         */\r\n        this.shouldWarnClientIsOffline = true;\r\n    }\r\n    /**\r\n     * Called by RemoteStore when a watch stream is started (including on each\r\n     * backoff attempt).\r\n     *\r\n     * If this is the first attempt, it sets the OnlineState to Unknown and starts\r\n     * the onlineStateTimer.\r\n     */\r\n    handleWatchStreamStart() {\r\n        if (this.watchStreamFailures === 0) {\r\n            this.setAndBroadcast(\"Unknown\" /* Unknown */);\r\n            this.onlineStateTimer = this.asyncQueue.enqueueAfterDelay(\"online_state_timeout\" /* OnlineStateTimeout */, ONLINE_STATE_TIMEOUT_MS, () => {\r\n                this.onlineStateTimer = null;\r\n                this.logClientOfflineWarningIfNecessary(`Backend didn't respond within ${ONLINE_STATE_TIMEOUT_MS / 1000} ` +\r\n                    `seconds.`);\r\n                this.setAndBroadcast(\"Offline\" /* Offline */);\r\n                // NOTE: handleWatchStreamFailure() will continue to increment\r\n                // watchStreamFailures even though we are already marked Offline,\r\n                // but this is non-harmful.\r\n                return Promise.resolve();\r\n            });\r\n        }\r\n    }\r\n    /**\r\n     * Updates our OnlineState as appropriate after the watch stream reports a\r\n     * failure. The first failure moves us to the 'Unknown' state. We then may\r\n     * allow multiple failures (based on MAX_WATCH_STREAM_FAILURES) before we\r\n     * actually transition to the 'Offline' state.\r\n     */\r\n    handleWatchStreamFailure(error) {\r\n        if (this.state === \"Online\" /* Online */) {\r\n            this.setAndBroadcast(\"Unknown\" /* Unknown */);\r\n        }\r\n        else {\r\n            this.watchStreamFailures++;\r\n            if (this.watchStreamFailures >= MAX_WATCH_STREAM_FAILURES) {\r\n                this.clearOnlineStateTimer();\r\n                this.logClientOfflineWarningIfNecessary(`Connection failed ${MAX_WATCH_STREAM_FAILURES} ` +\r\n                    `times. Most recent error: ${error.toString()}`);\r\n                this.setAndBroadcast(\"Offline\" /* Offline */);\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Explicitly sets the OnlineState to the specified state.\r\n     *\r\n     * Note that this resets our timers / failure counters, etc. used by our\r\n     * Offline heuristics, so must not be used in place of\r\n     * handleWatchStreamStart() and handleWatchStreamFailure().\r\n     */\r\n    set(newState) {\r\n        this.clearOnlineStateTimer();\r\n        this.watchStreamFailures = 0;\r\n        if (newState === \"Online\" /* Online */) {\r\n            // We've connected to watch at least once. Don't warn the developer\r\n            // about being offline going forward.\r\n            this.shouldWarnClientIsOffline = false;\r\n        }\r\n        this.setAndBroadcast(newState);\r\n    }\r\n    setAndBroadcast(newState) {\r\n        if (newState !== this.state) {\r\n            this.state = newState;\r\n            this.onlineStateHandler(newState);\r\n        }\r\n    }\r\n    logClientOfflineWarningIfNecessary(details) {\r\n        const message = `Could not reach Cloud Firestore backend. ${details}\\n` +\r\n            `This typically indicates that your device does not have a healthy ` +\r\n            `Internet connection at the moment. The client will operate in offline ` +\r\n            `mode until it is able to successfully connect to the backend.`;\r\n        if (this.shouldWarnClientIsOffline) {\r\n            logError(message);\r\n            this.shouldWarnClientIsOffline = false;\r\n        }\r\n        else {\r\n            logDebug(LOG_TAG$6, message);\r\n        }\r\n    }\r\n    clearOnlineStateTimer() {\r\n        if (this.onlineStateTimer !== null) {\r\n            this.onlineStateTimer.cancel();\r\n            this.onlineStateTimer = null;\r\n        }\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$5 = 'RemoteStore';\r\n// TODO(b/35853402): Negotiate this with the stream.\r\nconst MAX_PENDING_WRITES = 10;\r\nclass RemoteStoreImpl {\r\n    constructor(\r\n    /**\r\n     * The local store, used to fill the write pipeline with outbound mutations.\r\n     */\r\n    localStore, \r\n    /** The client-side proxy for interacting with the backend. */\r\n    datastore, asyncQueue, onlineStateHandler, connectivityMonitor) {\r\n        this.localStore = localStore;\r\n        this.datastore = datastore;\r\n        this.asyncQueue = asyncQueue;\r\n        this.remoteSyncer = {};\r\n        /**\r\n         * A list of up to MAX_PENDING_WRITES writes that we have fetched from the\r\n         * LocalStore via fillWritePipeline() and have or will send to the write\r\n         * stream.\r\n         *\r\n         * Whenever writePipeline.length > 0 the RemoteStore will attempt to start or\r\n         * restart the write stream. When the stream is established the writes in the\r\n         * pipeline will be sent in order.\r\n         *\r\n         * Writes remain in writePipeline until they are acknowledged by the backend\r\n         * and thus will automatically be re-sent if the stream is interrupted /\r\n         * restarted before they're acknowledged.\r\n         *\r\n         * Write responses from the backend are linked to their originating request\r\n         * purely based on order, and so we can just shift() writes from the front of\r\n         * the writePipeline as we receive responses.\r\n         */\r\n        this.writePipeline = [];\r\n        /**\r\n         * A mapping of watched targets that the client cares about tracking and the\r\n         * user has explicitly called a 'listen' for this target.\r\n         *\r\n         * These targets may or may not have been sent to or acknowledged by the\r\n         * server. On re-establishing the listen stream, these targets should be sent\r\n         * to the server. The targets removed with unlistens are removed eagerly\r\n         * without waiting for confirmation from the listen stream.\r\n         */\r\n        this.listenTargets = new Map();\r\n        /**\r\n         * A set of reasons for why the RemoteStore may be offline. If empty, the\r\n         * RemoteStore may start its network connections.\r\n         */\r\n        this.offlineCauses = new Set();\r\n        /**\r\n         * Event handlers that get called when the network is disabled or enabled.\r\n         *\r\n         * PORTING NOTE: These functions are used on the Web client to create the\r\n         * underlying streams (to support tree-shakeable streams). On Android and iOS,\r\n         * the streams are created during construction of RemoteStore.\r\n         */\r\n        this.onNetworkStatusChange = [];\r\n        this.connectivityMonitor = connectivityMonitor;\r\n        this.connectivityMonitor.addCallback((_) => {\r\n            asyncQueue.enqueueAndForget(async () => {\r\n                // Porting Note: Unlike iOS, `restartNetwork()` is called even when the\r\n                // network becomes unreachable as we don't have any other way to tear\r\n                // down our streams.\r\n                if (canUseNetwork(this)) {\r\n                    logDebug(LOG_TAG$5, 'Restarting streams for network reachability change.');\r\n                    await restartNetwork(this);\r\n                }\r\n            });\r\n        });\r\n        this.onlineStateTracker = new OnlineStateTracker(asyncQueue, onlineStateHandler);\r\n    }\r\n}\r\nfunction newRemoteStore(localStore, datastore, asyncQueue, onlineStateHandler, connectivityMonitor) {\r\n    return new RemoteStoreImpl(localStore, datastore, asyncQueue, onlineStateHandler, connectivityMonitor);\r\n}\r\n/** Re-enables the network. Idempotent. */\r\nfunction remoteStoreEnableNetwork(remoteStore) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    remoteStoreImpl.offlineCauses.delete(0 /* UserDisabled */);\r\n    return enableNetworkInternal(remoteStoreImpl);\r\n}\r\nasync function enableNetworkInternal(remoteStoreImpl) {\r\n    if (canUseNetwork(remoteStoreImpl)) {\r\n        for (const networkStatusHandler of remoteStoreImpl.onNetworkStatusChange) {\r\n            await networkStatusHandler(/* enabled= */ true);\r\n        }\r\n    }\r\n}\r\n/**\r\n * Temporarily disables the network. The network can be re-enabled using\r\n * enableNetwork().\r\n */\r\nasync function remoteStoreDisableNetwork(remoteStore) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    remoteStoreImpl.offlineCauses.add(0 /* UserDisabled */);\r\n    await disableNetworkInternal(remoteStoreImpl);\r\n    // Set the OnlineState to Offline so get()s return from cache, etc.\r\n    remoteStoreImpl.onlineStateTracker.set(\"Offline\" /* Offline */);\r\n}\r\nasync function disableNetworkInternal(remoteStoreImpl) {\r\n    for (const networkStatusHandler of remoteStoreImpl.onNetworkStatusChange) {\r\n        await networkStatusHandler(/* enabled= */ false);\r\n    }\r\n}\r\nasync function remoteStoreShutdown(remoteStore) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    logDebug(LOG_TAG$5, 'RemoteStore shutting down.');\r\n    remoteStoreImpl.offlineCauses.add(5 /* Shutdown */);\r\n    await disableNetworkInternal(remoteStoreImpl);\r\n    remoteStoreImpl.connectivityMonitor.shutdown();\r\n    // Set the OnlineState to Unknown (rather than Offline) to avoid potentially\r\n    // triggering spurious listener events with cached data, etc.\r\n    remoteStoreImpl.onlineStateTracker.set(\"Unknown\" /* Unknown */);\r\n}\r\n/**\r\n * Starts new listen for the given target. Uses resume token if provided. It\r\n * is a no-op if the target of given `TargetData` is already being listened to.\r\n */\r\nfunction remoteStoreListen(remoteStore, targetData) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    if (remoteStoreImpl.listenTargets.has(targetData.targetId)) {\r\n        return;\r\n    }\r\n    // Mark this as something the client is currently listening for.\r\n    remoteStoreImpl.listenTargets.set(targetData.targetId, targetData);\r\n    if (shouldStartWatchStream(remoteStoreImpl)) {\r\n        // The listen will be sent in onWatchStreamOpen\r\n        startWatchStream(remoteStoreImpl);\r\n    }\r\n    else if (ensureWatchStream(remoteStoreImpl).isOpen()) {\r\n        sendWatchRequest(remoteStoreImpl, targetData);\r\n    }\r\n}\r\n/**\r\n * Removes the listen from server. It is a no-op if the given target id is\r\n * not being listened to.\r\n */\r\nfunction remoteStoreUnlisten(remoteStore, targetId) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    const watchStream = ensureWatchStream(remoteStoreImpl);\r\n    remoteStoreImpl.listenTargets.delete(targetId);\r\n    if (watchStream.isOpen()) {\r\n        sendUnwatchRequest(remoteStoreImpl, targetId);\r\n    }\r\n    if (remoteStoreImpl.listenTargets.size === 0) {\r\n        if (watchStream.isOpen()) {\r\n            watchStream.markIdle();\r\n        }\r\n        else if (canUseNetwork(remoteStoreImpl)) {\r\n            // Revert to OnlineState.Unknown if the watch stream is not open and we\r\n            // have no listeners, since without any listens to send we cannot\r\n            // confirm if the stream is healthy and upgrade to OnlineState.Online.\r\n            remoteStoreImpl.onlineStateTracker.set(\"Unknown\" /* Unknown */);\r\n        }\r\n    }\r\n}\r\n/**\r\n * We need to increment the the expected number of pending responses we're due\r\n * from watch so we wait for the ack to process any messages from this target.\r\n */\r\nfunction sendWatchRequest(remoteStoreImpl, targetData) {\r\n    remoteStoreImpl.watchChangeAggregator.recordPendingTargetRequest(targetData.targetId);\r\n    ensureWatchStream(remoteStoreImpl).watch(targetData);\r\n}\r\n/**\r\n * We need to increment the expected number of pending responses we're due\r\n * from watch so we wait for the removal on the server before we process any\r\n * messages from this target.\r\n */\r\nfunction sendUnwatchRequest(remoteStoreImpl, targetId) {\r\n    remoteStoreImpl.watchChangeAggregator.recordPendingTargetRequest(targetId);\r\n    ensureWatchStream(remoteStoreImpl).unwatch(targetId);\r\n}\r\nfunction startWatchStream(remoteStoreImpl) {\r\n    remoteStoreImpl.watchChangeAggregator = new WatchChangeAggregator({\r\n        getRemoteKeysForTarget: targetId => remoteStoreImpl.remoteSyncer.getRemoteKeysForTarget(targetId),\r\n        getTargetDataForTarget: targetId => remoteStoreImpl.listenTargets.get(targetId) || null\r\n    });\r\n    ensureWatchStream(remoteStoreImpl).start();\r\n    remoteStoreImpl.onlineStateTracker.handleWatchStreamStart();\r\n}\r\n/**\r\n * Returns whether the watch stream should be started because it's necessary\r\n * and has not yet been started.\r\n */\r\nfunction shouldStartWatchStream(remoteStoreImpl) {\r\n    return (canUseNetwork(remoteStoreImpl) &&\r\n        !ensureWatchStream(remoteStoreImpl).isStarted() &&\r\n        remoteStoreImpl.listenTargets.size > 0);\r\n}\r\nfunction canUseNetwork(remoteStore) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    return remoteStoreImpl.offlineCauses.size === 0;\r\n}\r\nfunction cleanUpWatchStreamState(remoteStoreImpl) {\r\n    remoteStoreImpl.watchChangeAggregator = undefined;\r\n}\r\nasync function onWatchStreamOpen(remoteStoreImpl) {\r\n    remoteStoreImpl.listenTargets.forEach((targetData, targetId) => {\r\n        sendWatchRequest(remoteStoreImpl, targetData);\r\n    });\r\n}\r\nasync function onWatchStreamClose(remoteStoreImpl, error) {\r\n    cleanUpWatchStreamState(remoteStoreImpl);\r\n    // If we still need the watch stream, retry the connection.\r\n    if (shouldStartWatchStream(remoteStoreImpl)) {\r\n        remoteStoreImpl.onlineStateTracker.handleWatchStreamFailure(error);\r\n        startWatchStream(remoteStoreImpl);\r\n    }\r\n    else {\r\n        // No need to restart watch stream because there are no active targets.\r\n        // The online state is set to unknown because there is no active attempt\r\n        // at establishing a connection\r\n        remoteStoreImpl.onlineStateTracker.set(\"Unknown\" /* Unknown */);\r\n    }\r\n}\r\nasync function onWatchStreamChange(remoteStoreImpl, watchChange, snapshotVersion) {\r\n    // Mark the client as online since we got a message from the server\r\n    remoteStoreImpl.onlineStateTracker.set(\"Online\" /* Online */);\r\n    if (watchChange instanceof WatchTargetChange &&\r\n        watchChange.state === 2 /* Removed */ &&\r\n        watchChange.cause) {\r\n        // There was an error on a target, don't wait for a consistent snapshot\r\n        // to raise events\r\n        try {\r\n            await handleTargetError(remoteStoreImpl, watchChange);\r\n        }\r\n        catch (e) {\r\n            logDebug(LOG_TAG$5, 'Failed to remove targets %s: %s ', watchChange.targetIds.join(','), e);\r\n            await disableNetworkUntilRecovery(remoteStoreImpl, e);\r\n        }\r\n        return;\r\n    }\r\n    if (watchChange instanceof DocumentWatchChange) {\r\n        remoteStoreImpl.watchChangeAggregator.handleDocumentChange(watchChange);\r\n    }\r\n    else if (watchChange instanceof ExistenceFilterChange) {\r\n        remoteStoreImpl.watchChangeAggregator.handleExistenceFilter(watchChange);\r\n    }\r\n    else {\r\n        remoteStoreImpl.watchChangeAggregator.handleTargetChange(watchChange);\r\n    }\r\n    if (!snapshotVersion.isEqual(SnapshotVersion.min())) {\r\n        try {\r\n            const lastRemoteSnapshotVersion = await localStoreGetLastRemoteSnapshotVersion(remoteStoreImpl.localStore);\r\n            if (snapshotVersion.compareTo(lastRemoteSnapshotVersion) >= 0) {\r\n                // We have received a target change with a global snapshot if the snapshot\r\n                // version is not equal to SnapshotVersion.min().\r\n                await raiseWatchSnapshot(remoteStoreImpl, snapshotVersion);\r\n            }\r\n        }\r\n        catch (e) {\r\n            logDebug(LOG_TAG$5, 'Failed to raise snapshot:', e);\r\n            await disableNetworkUntilRecovery(remoteStoreImpl, e);\r\n        }\r\n    }\r\n}\r\n/**\r\n * Recovery logic for IndexedDB errors that takes the network offline until\r\n * `op` succeeds. Retries are scheduled with backoff using\r\n * `enqueueRetryable()`. If `op()` is not provided, IndexedDB access is\r\n * validated via a generic operation.\r\n *\r\n * The returned Promise is resolved once the network is disabled and before\r\n * any retry attempt.\r\n */\r\nasync function disableNetworkUntilRecovery(remoteStoreImpl, e, op) {\r\n    if (isIndexedDbTransactionError(e)) {\r\n        remoteStoreImpl.offlineCauses.add(1 /* IndexedDbFailed */);\r\n        // Disable network and raise offline snapshots\r\n        await disableNetworkInternal(remoteStoreImpl);\r\n        remoteStoreImpl.onlineStateTracker.set(\"Offline\" /* Offline */);\r\n        if (!op) {\r\n            // Use a simple read operation to determine if IndexedDB recovered.\r\n            // Ideally, we would expose a health check directly on SimpleDb, but\r\n            // RemoteStore only has access to persistence through LocalStore.\r\n            op = () => localStoreGetLastRemoteSnapshotVersion(remoteStoreImpl.localStore);\r\n        }\r\n        // Probe IndexedDB periodically and re-enable network\r\n        remoteStoreImpl.asyncQueue.enqueueRetryable(async () => {\r\n            logDebug(LOG_TAG$5, 'Retrying IndexedDB access');\r\n            await op();\r\n            remoteStoreImpl.offlineCauses.delete(1 /* IndexedDbFailed */);\r\n            await enableNetworkInternal(remoteStoreImpl);\r\n        });\r\n    }\r\n    else {\r\n        throw e;\r\n    }\r\n}\r\n/**\r\n * Executes `op`. If `op` fails, takes the network offline until `op`\r\n * succeeds. Returns after the first attempt.\r\n */\r\nfunction executeWithRecovery(remoteStoreImpl, op) {\r\n    return op().catch(e => disableNetworkUntilRecovery(remoteStoreImpl, e, op));\r\n}\r\n/**\r\n * Takes a batch of changes from the Datastore, repackages them as a\r\n * RemoteEvent, and passes that on to the listener, which is typically the\r\n * SyncEngine.\r\n */\r\nfunction raiseWatchSnapshot(remoteStoreImpl, snapshotVersion) {\r\n    const remoteEvent = remoteStoreImpl.watchChangeAggregator.createRemoteEvent(snapshotVersion);\r\n    // Update in-memory resume tokens. LocalStore will update the\r\n    // persistent view of these when applying the completed RemoteEvent.\r\n    remoteEvent.targetChanges.forEach((change, targetId) => {\r\n        if (change.resumeToken.approximateByteSize() > 0) {\r\n            const targetData = remoteStoreImpl.listenTargets.get(targetId);\r\n            // A watched target might have been removed already.\r\n            if (targetData) {\r\n                remoteStoreImpl.listenTargets.set(targetId, targetData.withResumeToken(change.resumeToken, snapshotVersion));\r\n            }\r\n        }\r\n    });\r\n    // Re-establish listens for the targets that have been invalidated by\r\n    // existence filter mismatches.\r\n    remoteEvent.targetMismatches.forEach(targetId => {\r\n        const targetData = remoteStoreImpl.listenTargets.get(targetId);\r\n        if (!targetData) {\r\n            // A watched target might have been removed already.\r\n            return;\r\n        }\r\n        // Clear the resume token for the target, since we're in a known mismatch\r\n        // state.\r\n        remoteStoreImpl.listenTargets.set(targetId, targetData.withResumeToken(ByteString.EMPTY_BYTE_STRING, targetData.snapshotVersion));\r\n        // Cause a hard reset by unwatching and rewatching immediately, but\r\n        // deliberately don't send a resume token so that we get a full update.\r\n        sendUnwatchRequest(remoteStoreImpl, targetId);\r\n        // Mark the target we send as being on behalf of an existence filter\r\n        // mismatch, but don't actually retain that in listenTargets. This ensures\r\n        // that we flag the first re-listen this way without impacting future\r\n        // listens of this target (that might happen e.g. on reconnect).\r\n        const requestTargetData = new TargetData(targetData.target, targetId, 1 /* ExistenceFilterMismatch */, targetData.sequenceNumber);\r\n        sendWatchRequest(remoteStoreImpl, requestTargetData);\r\n    });\r\n    return remoteStoreImpl.remoteSyncer.applyRemoteEvent(remoteEvent);\r\n}\r\n/** Handles an error on a target */\r\nasync function handleTargetError(remoteStoreImpl, watchChange) {\r\n    const error = watchChange.cause;\r\n    for (const targetId of watchChange.targetIds) {\r\n        // A watched target might have been removed already.\r\n        if (remoteStoreImpl.listenTargets.has(targetId)) {\r\n            await remoteStoreImpl.remoteSyncer.rejectListen(targetId, error);\r\n            remoteStoreImpl.listenTargets.delete(targetId);\r\n            remoteStoreImpl.watchChangeAggregator.removeTarget(targetId);\r\n        }\r\n    }\r\n}\r\n/**\r\n * Attempts to fill our write pipeline with writes from the LocalStore.\r\n *\r\n * Called internally to bootstrap or refill the write pipeline and by\r\n * SyncEngine whenever there are new mutations to process.\r\n *\r\n * Starts the write stream if necessary.\r\n */\r\nasync function fillWritePipeline(remoteStore) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    const writeStream = ensureWriteStream(remoteStoreImpl);\r\n    let lastBatchIdRetrieved = remoteStoreImpl.writePipeline.length > 0\r\n        ? remoteStoreImpl.writePipeline[remoteStoreImpl.writePipeline.length - 1]\r\n            .batchId\r\n        : BATCHID_UNKNOWN;\r\n    while (canAddToWritePipeline(remoteStoreImpl)) {\r\n        try {\r\n            const batch = await localStoreGetNextMutationBatch(remoteStoreImpl.localStore, lastBatchIdRetrieved);\r\n            if (batch === null) {\r\n                if (remoteStoreImpl.writePipeline.length === 0) {\r\n                    writeStream.markIdle();\r\n                }\r\n                break;\r\n            }\r\n            else {\r\n                lastBatchIdRetrieved = batch.batchId;\r\n                addToWritePipeline(remoteStoreImpl, batch);\r\n            }\r\n        }\r\n        catch (e) {\r\n            await disableNetworkUntilRecovery(remoteStoreImpl, e);\r\n        }\r\n    }\r\n    if (shouldStartWriteStream(remoteStoreImpl)) {\r\n        startWriteStream(remoteStoreImpl);\r\n    }\r\n}\r\n/**\r\n * Returns true if we can add to the write pipeline (i.e. the network is\r\n * enabled and the write pipeline is not full).\r\n */\r\nfunction canAddToWritePipeline(remoteStoreImpl) {\r\n    return (canUseNetwork(remoteStoreImpl) &&\r\n        remoteStoreImpl.writePipeline.length < MAX_PENDING_WRITES);\r\n}\r\n/**\r\n * Queues additional writes to be sent to the write stream, sending them\r\n * immediately if the write stream is established.\r\n */\r\nfunction addToWritePipeline(remoteStoreImpl, batch) {\r\n    remoteStoreImpl.writePipeline.push(batch);\r\n    const writeStream = ensureWriteStream(remoteStoreImpl);\r\n    if (writeStream.isOpen() && writeStream.handshakeComplete) {\r\n        writeStream.writeMutations(batch.mutations);\r\n    }\r\n}\r\nfunction shouldStartWriteStream(remoteStoreImpl) {\r\n    return (canUseNetwork(remoteStoreImpl) &&\r\n        !ensureWriteStream(remoteStoreImpl).isStarted() &&\r\n        remoteStoreImpl.writePipeline.length > 0);\r\n}\r\nfunction startWriteStream(remoteStoreImpl) {\r\n    ensureWriteStream(remoteStoreImpl).start();\r\n}\r\nasync function onWriteStreamOpen(remoteStoreImpl) {\r\n    ensureWriteStream(remoteStoreImpl).writeHandshake();\r\n}\r\nasync function onWriteHandshakeComplete(remoteStoreImpl) {\r\n    const writeStream = ensureWriteStream(remoteStoreImpl);\r\n    // Send the write pipeline now that the stream is established.\r\n    for (const batch of remoteStoreImpl.writePipeline) {\r\n        writeStream.writeMutations(batch.mutations);\r\n    }\r\n}\r\nasync function onMutationResult(remoteStoreImpl, commitVersion, results) {\r\n    const batch = remoteStoreImpl.writePipeline.shift();\r\n    const success = MutationBatchResult.from(batch, commitVersion, results);\r\n    await executeWithRecovery(remoteStoreImpl, () => remoteStoreImpl.remoteSyncer.applySuccessfulWrite(success));\r\n    // It's possible that with the completion of this mutation another\r\n    // slot has freed up.\r\n    await fillWritePipeline(remoteStoreImpl);\r\n}\r\nasync function onWriteStreamClose(remoteStoreImpl, error) {\r\n    // If the write stream closed after the write handshake completes, a write\r\n    // operation failed and we fail the pending operation.\r\n    if (error && ensureWriteStream(remoteStoreImpl).handshakeComplete) {\r\n        // This error affects the actual write.\r\n        await handleWriteError(remoteStoreImpl, error);\r\n    }\r\n    // The write stream might have been started by refilling the write\r\n    // pipeline for failed writes\r\n    if (shouldStartWriteStream(remoteStoreImpl)) {\r\n        startWriteStream(remoteStoreImpl);\r\n    }\r\n}\r\nasync function handleWriteError(remoteStoreImpl, error) {\r\n    // Only handle permanent errors here. If it's transient, just let the retry\r\n    // logic kick in.\r\n    if (isPermanentWriteError(error.code)) {\r\n        // This was a permanent error, the request itself was the problem\r\n        // so it's not going to succeed if we resend it.\r\n        const batch = remoteStoreImpl.writePipeline.shift();\r\n        // In this case it's also unlikely that the server itself is melting\r\n        // down -- this was just a bad request so inhibit backoff on the next\r\n        // restart.\r\n        ensureWriteStream(remoteStoreImpl).inhibitBackoff();\r\n        await executeWithRecovery(remoteStoreImpl, () => remoteStoreImpl.remoteSyncer.rejectFailedWrite(batch.batchId, error));\r\n        // It's possible that with the completion of this mutation\r\n        // another slot has freed up.\r\n        await fillWritePipeline(remoteStoreImpl);\r\n    }\r\n}\r\nasync function restartNetwork(remoteStore) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    remoteStoreImpl.offlineCauses.add(4 /* ConnectivityChange */);\r\n    await disableNetworkInternal(remoteStoreImpl);\r\n    remoteStoreImpl.onlineStateTracker.set(\"Unknown\" /* Unknown */);\r\n    remoteStoreImpl.offlineCauses.delete(4 /* ConnectivityChange */);\r\n    await enableNetworkInternal(remoteStoreImpl);\r\n}\r\nasync function remoteStoreHandleCredentialChange(remoteStore, user) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    remoteStoreImpl.asyncQueue.verifyOperationInProgress();\r\n    logDebug(LOG_TAG$5, 'RemoteStore received new credentials');\r\n    const usesNetwork = canUseNetwork(remoteStoreImpl);\r\n    // Tear down and re-create our network streams. This will ensure we get a\r\n    // fresh auth token for the new user and re-fill the write pipeline with\r\n    // new mutations from the LocalStore (since mutations are per-user).\r\n    remoteStoreImpl.offlineCauses.add(3 /* CredentialChange */);\r\n    await disableNetworkInternal(remoteStoreImpl);\r\n    if (usesNetwork) {\r\n        // Don't set the network status to Unknown if we are offline.\r\n        remoteStoreImpl.onlineStateTracker.set(\"Unknown\" /* Unknown */);\r\n    }\r\n    await remoteStoreImpl.remoteSyncer.handleCredentialChange(user);\r\n    remoteStoreImpl.offlineCauses.delete(3 /* CredentialChange */);\r\n    await enableNetworkInternal(remoteStoreImpl);\r\n}\r\n/**\r\n * Toggles the network state when the client gains or loses its primary lease.\r\n */\r\nasync function remoteStoreApplyPrimaryState(remoteStore, isPrimary) {\r\n    const remoteStoreImpl = debugCast(remoteStore);\r\n    if (isPrimary) {\r\n        remoteStoreImpl.offlineCauses.delete(2 /* IsSecondary */);\r\n        await enableNetworkInternal(remoteStoreImpl);\r\n    }\r\n    else if (!isPrimary) {\r\n        remoteStoreImpl.offlineCauses.add(2 /* IsSecondary */);\r\n        await disableNetworkInternal(remoteStoreImpl);\r\n        remoteStoreImpl.onlineStateTracker.set(\"Unknown\" /* Unknown */);\r\n    }\r\n}\r\n/**\r\n * If not yet initialized, registers the WatchStream and its network state\r\n * callback with `remoteStoreImpl`. Returns the existing stream if one is\r\n * already available.\r\n *\r\n * PORTING NOTE: On iOS and Android, the WatchStream gets registered on startup.\r\n * This is not done on Web to allow it to be tree-shaken.\r\n */\r\nfunction ensureWatchStream(remoteStoreImpl) {\r\n    if (!remoteStoreImpl.watchStream) {\r\n        // Create stream (but note that it is not started yet).\r\n        remoteStoreImpl.watchStream = newPersistentWatchStream(remoteStoreImpl.datastore, remoteStoreImpl.asyncQueue, {\r\n            onOpen: onWatchStreamOpen.bind(null, remoteStoreImpl),\r\n            onClose: onWatchStreamClose.bind(null, remoteStoreImpl),\r\n            onWatchChange: onWatchStreamChange.bind(null, remoteStoreImpl)\r\n        });\r\n        remoteStoreImpl.onNetworkStatusChange.push(async (enabled) => {\r\n            if (enabled) {\r\n                remoteStoreImpl.watchStream.inhibitBackoff();\r\n                if (shouldStartWatchStream(remoteStoreImpl)) {\r\n                    startWatchStream(remoteStoreImpl);\r\n                }\r\n                else {\r\n                    remoteStoreImpl.onlineStateTracker.set(\"Unknown\" /* Unknown */);\r\n                }\r\n            }\r\n            else {\r\n                await remoteStoreImpl.watchStream.stop();\r\n                cleanUpWatchStreamState(remoteStoreImpl);\r\n            }\r\n        });\r\n    }\r\n    return remoteStoreImpl.watchStream;\r\n}\r\n/**\r\n * If not yet initialized, registers the WriteStream and its network state\r\n * callback with `remoteStoreImpl`. Returns the existing stream if one is\r\n * already available.\r\n *\r\n * PORTING NOTE: On iOS and Android, the WriteStream gets registered on startup.\r\n * This is not done on Web to allow it to be tree-shaken.\r\n */\r\nfunction ensureWriteStream(remoteStoreImpl) {\r\n    if (!remoteStoreImpl.writeStream) {\r\n        // Create stream (but note that it is not started yet).\r\n        remoteStoreImpl.writeStream = newPersistentWriteStream(remoteStoreImpl.datastore, remoteStoreImpl.asyncQueue, {\r\n            onOpen: onWriteStreamOpen.bind(null, remoteStoreImpl),\r\n            onClose: onWriteStreamClose.bind(null, remoteStoreImpl),\r\n            onHandshakeComplete: onWriteHandshakeComplete.bind(null, remoteStoreImpl),\r\n            onMutationResult: onMutationResult.bind(null, remoteStoreImpl)\r\n        });\r\n        remoteStoreImpl.onNetworkStatusChange.push(async (enabled) => {\r\n            if (enabled) {\r\n                remoteStoreImpl.writeStream.inhibitBackoff();\r\n                // This will start the write stream if necessary.\r\n                await fillWritePipeline(remoteStoreImpl);\r\n            }\r\n            else {\r\n                await remoteStoreImpl.writeStream.stop();\r\n                if (remoteStoreImpl.writePipeline.length > 0) {\r\n                    logDebug(LOG_TAG$5, `Stopping write stream with ${remoteStoreImpl.writePipeline.length} pending writes`);\r\n                    remoteStoreImpl.writePipeline = [];\r\n                }\r\n            }\r\n        });\r\n    }\r\n    return remoteStoreImpl.writeStream;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$4 = 'AsyncQueue';\r\n/**\r\n * Represents an operation scheduled to be run in the future on an AsyncQueue.\r\n *\r\n * It is created via DelayedOperation.createAndSchedule().\r\n *\r\n * Supports cancellation (via cancel()) and early execution (via skipDelay()).\r\n *\r\n * Note: We implement `PromiseLike` instead of `Promise`, as the `Promise` type\r\n * in newer versions of TypeScript defines `finally`, which is not available in\r\n * IE.\r\n */\r\nclass DelayedOperation {\r\n    constructor(asyncQueue, timerId, targetTimeMs, op, removalCallback) {\r\n        this.asyncQueue = asyncQueue;\r\n        this.timerId = timerId;\r\n        this.targetTimeMs = targetTimeMs;\r\n        this.op = op;\r\n        this.removalCallback = removalCallback;\r\n        this.deferred = new Deferred();\r\n        this.then = this.deferred.promise.then.bind(this.deferred.promise);\r\n        // It's normal for the deferred promise to be canceled (due to cancellation)\r\n        // and so we attach a dummy catch callback to avoid\r\n        // 'UnhandledPromiseRejectionWarning' log spam.\r\n        this.deferred.promise.catch(err => { });\r\n    }\r\n    /**\r\n     * Creates and returns a DelayedOperation that has been scheduled to be\r\n     * executed on the provided asyncQueue after the provided delayMs.\r\n     *\r\n     * @param asyncQueue - The queue to schedule the operation on.\r\n     * @param id - A Timer ID identifying the type of operation this is.\r\n     * @param delayMs - The delay (ms) before the operation should be scheduled.\r\n     * @param op - The operation to run.\r\n     * @param removalCallback - A callback to be called synchronously once the\r\n     *   operation is executed or canceled, notifying the AsyncQueue to remove it\r\n     *   from its delayedOperations list.\r\n     *   PORTING NOTE: This exists to prevent making removeDelayedOperation() and\r\n     *   the DelayedOperation class public.\r\n     */\r\n    static createAndSchedule(asyncQueue, timerId, delayMs, op, removalCallback) {\r\n        const targetTime = Date.now() + delayMs;\r\n        const delayedOp = new DelayedOperation(asyncQueue, timerId, targetTime, op, removalCallback);\r\n        delayedOp.start(delayMs);\r\n        return delayedOp;\r\n    }\r\n    /**\r\n     * Starts the timer. This is called immediately after construction by\r\n     * createAndSchedule().\r\n     */\r\n    start(delayMs) {\r\n        this.timerHandle = setTimeout(() => this.handleDelayElapsed(), delayMs);\r\n    }\r\n    /**\r\n     * Queues the operation to run immediately (if it hasn't already been run or\r\n     * canceled).\r\n     */\r\n    skipDelay() {\r\n        return this.handleDelayElapsed();\r\n    }\r\n    /**\r\n     * Cancels the operation if it hasn't already been executed or canceled. The\r\n     * promise will be rejected.\r\n     *\r\n     * As long as the operation has not yet been run, calling cancel() provides a\r\n     * guarantee that the operation will not be run.\r\n     */\r\n    cancel(reason) {\r\n        if (this.timerHandle !== null) {\r\n            this.clearTimeout();\r\n            this.deferred.reject(new FirestoreError(Code.CANCELLED, 'Operation cancelled' + (reason ? ': ' + reason : '')));\r\n        }\r\n    }\r\n    handleDelayElapsed() {\r\n        this.asyncQueue.enqueueAndForget(() => {\r\n            if (this.timerHandle !== null) {\r\n                this.clearTimeout();\r\n                return this.op().then(result => {\r\n                    return this.deferred.resolve(result);\r\n                });\r\n            }\r\n            else {\r\n                return Promise.resolve();\r\n            }\r\n        });\r\n    }\r\n    clearTimeout() {\r\n        if (this.timerHandle !== null) {\r\n            this.removalCallback(this);\r\n            clearTimeout(this.timerHandle);\r\n            this.timerHandle = null;\r\n        }\r\n    }\r\n}\r\n/**\r\n * Returns a FirestoreError that can be surfaced to the user if the provided\r\n * error is an IndexedDbTransactionError. Re-throws the error otherwise.\r\n */\r\nfunction wrapInUserErrorIfRecoverable(e, msg) {\r\n    logError(LOG_TAG$4, `${msg}: ${e}`);\r\n    if (isIndexedDbTransactionError(e)) {\r\n        return new FirestoreError(Code.UNAVAILABLE, `${msg}: ${e}`);\r\n    }\r\n    else {\r\n        throw e;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * DocumentSet is an immutable (copy-on-write) collection that holds documents\r\n * in order specified by the provided comparator. We always add a document key\r\n * comparator on top of what is provided to guarantee document equality based on\r\n * the key.\r\n */\r\nclass DocumentSet {\r\n    /** The default ordering is by key if the comparator is omitted */\r\n    constructor(comp) {\r\n        // We are adding document key comparator to the end as it's the only\r\n        // guaranteed unique property of a document.\r\n        if (comp) {\r\n            this.comparator = (d1, d2) => comp(d1, d2) || DocumentKey.comparator(d1.key, d2.key);\r\n        }\r\n        else {\r\n            this.comparator = (d1, d2) => DocumentKey.comparator(d1.key, d2.key);\r\n        }\r\n        this.keyedMap = documentMap();\r\n        this.sortedSet = new SortedMap(this.comparator);\r\n    }\r\n    /**\r\n     * Returns an empty copy of the existing DocumentSet, using the same\r\n     * comparator.\r\n     */\r\n    static emptySet(oldSet) {\r\n        return new DocumentSet(oldSet.comparator);\r\n    }\r\n    has(key) {\r\n        return this.keyedMap.get(key) != null;\r\n    }\r\n    get(key) {\r\n        return this.keyedMap.get(key);\r\n    }\r\n    first() {\r\n        return this.sortedSet.minKey();\r\n    }\r\n    last() {\r\n        return this.sortedSet.maxKey();\r\n    }\r\n    isEmpty() {\r\n        return this.sortedSet.isEmpty();\r\n    }\r\n    /**\r\n     * Returns the index of the provided key in the document set, or -1 if the\r\n     * document key is not present in the set;\r\n     */\r\n    indexOf(key) {\r\n        const doc = this.keyedMap.get(key);\r\n        return doc ? this.sortedSet.indexOf(doc) : -1;\r\n    }\r\n    get size() {\r\n        return this.sortedSet.size;\r\n    }\r\n    /** Iterates documents in order defined by \"comparator\" */\r\n    forEach(cb) {\r\n        this.sortedSet.inorderTraversal((k, v) => {\r\n            cb(k);\r\n            return false;\r\n        });\r\n    }\r\n    /** Inserts or updates a document with the same key */\r\n    add(doc) {\r\n        // First remove the element if we have it.\r\n        const set = this.delete(doc.key);\r\n        return set.copy(set.keyedMap.insert(doc.key, doc), set.sortedSet.insert(doc, null));\r\n    }\r\n    /** Deletes a document with a given key */\r\n    delete(key) {\r\n        const doc = this.get(key);\r\n        if (!doc) {\r\n            return this;\r\n        }\r\n        return this.copy(this.keyedMap.remove(key), this.sortedSet.remove(doc));\r\n    }\r\n    isEqual(other) {\r\n        if (!(other instanceof DocumentSet)) {\r\n            return false;\r\n        }\r\n        if (this.size !== other.size) {\r\n            return false;\r\n        }\r\n        const thisIt = this.sortedSet.getIterator();\r\n        const otherIt = other.sortedSet.getIterator();\r\n        while (thisIt.hasNext()) {\r\n            const thisDoc = thisIt.getNext().key;\r\n            const otherDoc = otherIt.getNext().key;\r\n            if (!thisDoc.isEqual(otherDoc)) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n    toString() {\r\n        const docStrings = [];\r\n        this.forEach(doc => {\r\n            docStrings.push(doc.toString());\r\n        });\r\n        if (docStrings.length === 0) {\r\n            return 'DocumentSet ()';\r\n        }\r\n        else {\r\n            return 'DocumentSet (\\n  ' + docStrings.join('  \\n') + '\\n)';\r\n        }\r\n    }\r\n    copy(keyedMap, sortedSet) {\r\n        const newSet = new DocumentSet();\r\n        newSet.comparator = this.comparator;\r\n        newSet.keyedMap = keyedMap;\r\n        newSet.sortedSet = sortedSet;\r\n        return newSet;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * DocumentChangeSet keeps track of a set of changes to docs in a query, merging\r\n * duplicate events for the same doc.\r\n */\r\nclass DocumentChangeSet {\r\n    constructor() {\r\n        this.changeMap = new SortedMap(DocumentKey.comparator);\r\n    }\r\n    track(change) {\r\n        const key = change.doc.key;\r\n        const oldChange = this.changeMap.get(key);\r\n        if (!oldChange) {\r\n            this.changeMap = this.changeMap.insert(key, change);\r\n            return;\r\n        }\r\n        // Merge the new change with the existing change.\r\n        if (change.type !== 0 /* Added */ &&\r\n            oldChange.type === 3 /* Metadata */) {\r\n            this.changeMap = this.changeMap.insert(key, change);\r\n        }\r\n        else if (change.type === 3 /* Metadata */ &&\r\n            oldChange.type !== 1 /* Removed */) {\r\n            this.changeMap = this.changeMap.insert(key, {\r\n                type: oldChange.type,\r\n                doc: change.doc\r\n            });\r\n        }\r\n        else if (change.type === 2 /* Modified */ &&\r\n            oldChange.type === 2 /* Modified */) {\r\n            this.changeMap = this.changeMap.insert(key, {\r\n                type: 2 /* Modified */,\r\n                doc: change.doc\r\n            });\r\n        }\r\n        else if (change.type === 2 /* Modified */ &&\r\n            oldChange.type === 0 /* Added */) {\r\n            this.changeMap = this.changeMap.insert(key, {\r\n                type: 0 /* Added */,\r\n                doc: change.doc\r\n            });\r\n        }\r\n        else if (change.type === 1 /* Removed */ &&\r\n            oldChange.type === 0 /* Added */) {\r\n            this.changeMap = this.changeMap.remove(key);\r\n        }\r\n        else if (change.type === 1 /* Removed */ &&\r\n            oldChange.type === 2 /* Modified */) {\r\n            this.changeMap = this.changeMap.insert(key, {\r\n                type: 1 /* Removed */,\r\n                doc: oldChange.doc\r\n            });\r\n        }\r\n        else if (change.type === 0 /* Added */ &&\r\n            oldChange.type === 1 /* Removed */) {\r\n            this.changeMap = this.changeMap.insert(key, {\r\n                type: 2 /* Modified */,\r\n                doc: change.doc\r\n            });\r\n        }\r\n        else {\r\n            // This includes these cases, which don't make sense:\r\n            // Added->Added\r\n            // Removed->Removed\r\n            // Modified->Added\r\n            // Removed->Modified\r\n            // Metadata->Added\r\n            // Removed->Metadata\r\n            fail();\r\n        }\r\n    }\r\n    getChanges() {\r\n        const changes = [];\r\n        this.changeMap.inorderTraversal((key, change) => {\r\n            changes.push(change);\r\n        });\r\n        return changes;\r\n    }\r\n}\r\nclass ViewSnapshot {\r\n    constructor(query, docs, oldDocs, docChanges, mutatedKeys, fromCache, syncStateChanged, excludesMetadataChanges) {\r\n        this.query = query;\r\n        this.docs = docs;\r\n        this.oldDocs = oldDocs;\r\n        this.docChanges = docChanges;\r\n        this.mutatedKeys = mutatedKeys;\r\n        this.fromCache = fromCache;\r\n        this.syncStateChanged = syncStateChanged;\r\n        this.excludesMetadataChanges = excludesMetadataChanges;\r\n    }\r\n    /** Returns a view snapshot as if all documents in the snapshot were added. */\r\n    static fromInitialDocuments(query, documents, mutatedKeys, fromCache) {\r\n        const changes = [];\r\n        documents.forEach(doc => {\r\n            changes.push({ type: 0 /* Added */, doc });\r\n        });\r\n        return new ViewSnapshot(query, documents, DocumentSet.emptySet(documents), changes, mutatedKeys, fromCache, \r\n        /* syncStateChanged= */ true, \r\n        /* excludesMetadataChanges= */ false);\r\n    }\r\n    get hasPendingWrites() {\r\n        return !this.mutatedKeys.isEmpty();\r\n    }\r\n    isEqual(other) {\r\n        if (this.fromCache !== other.fromCache ||\r\n            this.syncStateChanged !== other.syncStateChanged ||\r\n            !this.mutatedKeys.isEqual(other.mutatedKeys) ||\r\n            !queryEquals(this.query, other.query) ||\r\n            !this.docs.isEqual(other.docs) ||\r\n            !this.oldDocs.isEqual(other.oldDocs)) {\r\n            return false;\r\n        }\r\n        const changes = this.docChanges;\r\n        const otherChanges = other.docChanges;\r\n        if (changes.length !== otherChanges.length) {\r\n            return false;\r\n        }\r\n        for (let i = 0; i < changes.length; i++) {\r\n            if (changes[i].type !== otherChanges[i].type ||\r\n                !changes[i].doc.isEqual(otherChanges[i].doc)) {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Holds the listeners and the last received ViewSnapshot for a query being\r\n * tracked by EventManager.\r\n */\r\nclass QueryListenersInfo {\r\n    constructor() {\r\n        this.viewSnap = undefined;\r\n        this.listeners = [];\r\n    }\r\n}\r\nfunction newEventManager() {\r\n    return new EventManagerImpl();\r\n}\r\nclass EventManagerImpl {\r\n    constructor() {\r\n        this.queries = new ObjectMap(q => canonifyQuery(q), queryEquals);\r\n        this.onlineState = \"Unknown\" /* Unknown */;\r\n        this.snapshotsInSyncListeners = new Set();\r\n    }\r\n}\r\nasync function eventManagerListen(eventManager, listener) {\r\n    const eventManagerImpl = debugCast(eventManager);\r\n    const query = listener.query;\r\n    let firstListen = false;\r\n    let queryInfo = eventManagerImpl.queries.get(query);\r\n    if (!queryInfo) {\r\n        firstListen = true;\r\n        queryInfo = new QueryListenersInfo();\r\n    }\r\n    if (firstListen) {\r\n        try {\r\n            queryInfo.viewSnap = await eventManagerImpl.onListen(query);\r\n        }\r\n        catch (e) {\r\n            const firestoreError = wrapInUserErrorIfRecoverable(e, `Initialization of query '${stringifyQuery(listener.query)}' failed`);\r\n            listener.onError(firestoreError);\r\n            return;\r\n        }\r\n    }\r\n    eventManagerImpl.queries.set(query, queryInfo);\r\n    queryInfo.listeners.push(listener);\r\n    // Run global snapshot listeners if a consistent snapshot has been emitted.\r\n    listener.applyOnlineStateChange(eventManagerImpl.onlineState);\r\n    if (queryInfo.viewSnap) {\r\n        const raisedEvent = listener.onViewSnapshot(queryInfo.viewSnap);\r\n        if (raisedEvent) {\r\n            raiseSnapshotsInSyncEvent(eventManagerImpl);\r\n        }\r\n    }\r\n}\r\nasync function eventManagerUnlisten(eventManager, listener) {\r\n    const eventManagerImpl = debugCast(eventManager);\r\n    const query = listener.query;\r\n    let lastListen = false;\r\n    const queryInfo = eventManagerImpl.queries.get(query);\r\n    if (queryInfo) {\r\n        const i = queryInfo.listeners.indexOf(listener);\r\n        if (i >= 0) {\r\n            queryInfo.listeners.splice(i, 1);\r\n            lastListen = queryInfo.listeners.length === 0;\r\n        }\r\n    }\r\n    if (lastListen) {\r\n        eventManagerImpl.queries.delete(query);\r\n        return eventManagerImpl.onUnlisten(query);\r\n    }\r\n}\r\nfunction eventManagerOnWatchChange(eventManager, viewSnaps) {\r\n    const eventManagerImpl = debugCast(eventManager);\r\n    let raisedEvent = false;\r\n    for (const viewSnap of viewSnaps) {\r\n        const query = viewSnap.query;\r\n        const queryInfo = eventManagerImpl.queries.get(query);\r\n        if (queryInfo) {\r\n            for (const listener of queryInfo.listeners) {\r\n                if (listener.onViewSnapshot(viewSnap)) {\r\n                    raisedEvent = true;\r\n                }\r\n            }\r\n            queryInfo.viewSnap = viewSnap;\r\n        }\r\n    }\r\n    if (raisedEvent) {\r\n        raiseSnapshotsInSyncEvent(eventManagerImpl);\r\n    }\r\n}\r\nfunction eventManagerOnWatchError(eventManager, query, error) {\r\n    const eventManagerImpl = debugCast(eventManager);\r\n    const queryInfo = eventManagerImpl.queries.get(query);\r\n    if (queryInfo) {\r\n        for (const listener of queryInfo.listeners) {\r\n            listener.onError(error);\r\n        }\r\n    }\r\n    // Remove all listeners. NOTE: We don't need to call syncEngine.unlisten()\r\n    // after an error.\r\n    eventManagerImpl.queries.delete(query);\r\n}\r\nfunction eventManagerOnOnlineStateChange(eventManager, onlineState) {\r\n    const eventManagerImpl = debugCast(eventManager);\r\n    eventManagerImpl.onlineState = onlineState;\r\n    let raisedEvent = false;\r\n    eventManagerImpl.queries.forEach((_, queryInfo) => {\r\n        for (const listener of queryInfo.listeners) {\r\n            // Run global snapshot listeners if a consistent snapshot has been emitted.\r\n            if (listener.applyOnlineStateChange(onlineState)) {\r\n                raisedEvent = true;\r\n            }\r\n        }\r\n    });\r\n    if (raisedEvent) {\r\n        raiseSnapshotsInSyncEvent(eventManagerImpl);\r\n    }\r\n}\r\nfunction addSnapshotsInSyncListener(eventManager, observer) {\r\n    const eventManagerImpl = debugCast(eventManager);\r\n    eventManagerImpl.snapshotsInSyncListeners.add(observer);\r\n    // Immediately fire an initial event, indicating all existing listeners\r\n    // are in-sync.\r\n    observer.next();\r\n}\r\nfunction removeSnapshotsInSyncListener(eventManager, observer) {\r\n    const eventManagerImpl = debugCast(eventManager);\r\n    eventManagerImpl.snapshotsInSyncListeners.delete(observer);\r\n}\r\n// Call all global snapshot listeners that have been set.\r\nfunction raiseSnapshotsInSyncEvent(eventManagerImpl) {\r\n    eventManagerImpl.snapshotsInSyncListeners.forEach(observer => {\r\n        observer.next();\r\n    });\r\n}\r\n/**\r\n * QueryListener takes a series of internal view snapshots and determines\r\n * when to raise the event.\r\n *\r\n * It uses an Observer to dispatch events.\r\n */\r\nclass QueryListener {\r\n    constructor(query, queryObserver, options) {\r\n        this.query = query;\r\n        this.queryObserver = queryObserver;\r\n        /**\r\n         * Initial snapshots (e.g. from cache) may not be propagated to the wrapped\r\n         * observer. This flag is set to true once we've actually raised an event.\r\n         */\r\n        this.raisedInitialEvent = false;\r\n        this.snap = null;\r\n        this.onlineState = \"Unknown\" /* Unknown */;\r\n        this.options = options || {};\r\n    }\r\n    /**\r\n     * Applies the new ViewSnapshot to this listener, raising a user-facing event\r\n     * if applicable (depending on what changed, whether the user has opted into\r\n     * metadata-only changes, etc.). Returns true if a user-facing event was\r\n     * indeed raised.\r\n     */\r\n    onViewSnapshot(snap) {\r\n        if (!this.options.includeMetadataChanges) {\r\n            // Remove the metadata only changes.\r\n            const docChanges = [];\r\n            for (const docChange of snap.docChanges) {\r\n                if (docChange.type !== 3 /* Metadata */) {\r\n                    docChanges.push(docChange);\r\n                }\r\n            }\r\n            snap = new ViewSnapshot(snap.query, snap.docs, snap.oldDocs, docChanges, snap.mutatedKeys, snap.fromCache, snap.syncStateChanged, \r\n            /* excludesMetadataChanges= */ true);\r\n        }\r\n        let raisedEvent = false;\r\n        if (!this.raisedInitialEvent) {\r\n            if (this.shouldRaiseInitialEvent(snap, this.onlineState)) {\r\n                this.raiseInitialEvent(snap);\r\n                raisedEvent = true;\r\n            }\r\n        }\r\n        else if (this.shouldRaiseEvent(snap)) {\r\n            this.queryObserver.next(snap);\r\n            raisedEvent = true;\r\n        }\r\n        this.snap = snap;\r\n        return raisedEvent;\r\n    }\r\n    onError(error) {\r\n        this.queryObserver.error(error);\r\n    }\r\n    /** Returns whether a snapshot was raised. */\r\n    applyOnlineStateChange(onlineState) {\r\n        this.onlineState = onlineState;\r\n        let raisedEvent = false;\r\n        if (this.snap &&\r\n            !this.raisedInitialEvent &&\r\n            this.shouldRaiseInitialEvent(this.snap, onlineState)) {\r\n            this.raiseInitialEvent(this.snap);\r\n            raisedEvent = true;\r\n        }\r\n        return raisedEvent;\r\n    }\r\n    shouldRaiseInitialEvent(snap, onlineState) {\r\n        // Always raise the first event when we're synced\r\n        if (!snap.fromCache) {\r\n            return true;\r\n        }\r\n        // NOTE: We consider OnlineState.Unknown as online (it should become Offline\r\n        // or Online if we wait long enough).\r\n        const maybeOnline = onlineState !== \"Offline\" /* Offline */;\r\n        // Don't raise the event if we're online, aren't synced yet (checked\r\n        // above) and are waiting for a sync.\r\n        if (this.options.waitForSyncWhenOnline && maybeOnline) {\r\n            return false;\r\n        }\r\n        // Raise data from cache if we have any documents or we are offline\r\n        return !snap.docs.isEmpty() || onlineState === \"Offline\" /* Offline */;\r\n    }\r\n    shouldRaiseEvent(snap) {\r\n        // We don't need to handle includeDocumentMetadataChanges here because\r\n        // the Metadata only changes have already been stripped out if needed.\r\n        // At this point the only changes we will see are the ones we should\r\n        // propagate.\r\n        if (snap.docChanges.length > 0) {\r\n            return true;\r\n        }\r\n        const hasPendingWritesChanged = this.snap && this.snap.hasPendingWrites !== snap.hasPendingWrites;\r\n        if (snap.syncStateChanged || hasPendingWritesChanged) {\r\n            return this.options.includeMetadataChanges === true;\r\n        }\r\n        // Generally we should have hit one of the cases above, but it's possible\r\n        // to get here if there were only metadata docChanges and they got\r\n        // stripped out.\r\n        return false;\r\n    }\r\n    raiseInitialEvent(snap) {\r\n        snap = ViewSnapshot.fromInitialDocuments(snap.query, snap.docs, snap.mutatedKeys, snap.fromCache);\r\n        this.raisedInitialEvent = true;\r\n        this.queryObserver.next(snap);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A set of changes to what documents are currently in view and out of view for\r\n * a given query. These changes are sent to the LocalStore by the View (via\r\n * the SyncEngine) and are used to pin / unpin documents as appropriate.\r\n */\r\nclass LocalViewChanges {\r\n    constructor(targetId, fromCache, addedKeys, removedKeys) {\r\n        this.targetId = targetId;\r\n        this.fromCache = fromCache;\r\n        this.addedKeys = addedKeys;\r\n        this.removedKeys = removedKeys;\r\n    }\r\n    static fromSnapshot(targetId, viewSnapshot) {\r\n        let addedKeys = documentKeySet();\r\n        let removedKeys = documentKeySet();\r\n        for (const docChange of viewSnapshot.docChanges) {\r\n            switch (docChange.type) {\r\n                case 0 /* Added */:\r\n                    addedKeys = addedKeys.add(docChange.doc.key);\r\n                    break;\r\n                case 1 /* Removed */:\r\n                    removedKeys = removedKeys.add(docChange.doc.key);\r\n                    break;\r\n                // do nothing\r\n            }\r\n        }\r\n        return new LocalViewChanges(targetId, viewSnapshot.fromCache, addedKeys, removedKeys);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass BundleLoadResult {\r\n    constructor(progress, changedDocs) {\r\n        this.progress = progress;\r\n        this.changedDocs = changedDocs;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Helper to convert objects from bundles to model objects in the SDK.\r\n */\r\nclass BundleConverterImpl {\r\n    constructor(serializer) {\r\n        this.serializer = serializer;\r\n    }\r\n    toDocumentKey(name) {\r\n        return fromName(this.serializer, name);\r\n    }\r\n    /**\r\n     * Converts a BundleDocument to a MutableDocument.\r\n     */\r\n    toMutableDocument(bundledDoc) {\r\n        if (bundledDoc.metadata.exists) {\r\n            return fromDocument(this.serializer, bundledDoc.document, false);\r\n        }\r\n        else {\r\n            return MutableDocument.newNoDocument(this.toDocumentKey(bundledDoc.metadata.name), this.toSnapshotVersion(bundledDoc.metadata.readTime));\r\n        }\r\n    }\r\n    toSnapshotVersion(time) {\r\n        return fromVersion(time);\r\n    }\r\n}\r\n/**\r\n * A class to process the elements from a bundle, load them into local\r\n * storage and provide progress update while loading.\r\n */\r\nclass BundleLoader {\r\n    constructor(bundleMetadata, localStore, serializer) {\r\n        this.bundleMetadata = bundleMetadata;\r\n        this.localStore = localStore;\r\n        this.serializer = serializer;\r\n        /** Batched queries to be saved into storage */\r\n        this.queries = [];\r\n        /** Batched documents to be saved into storage */\r\n        this.documents = [];\r\n        this.progress = bundleInitialProgress(bundleMetadata);\r\n    }\r\n    /**\r\n     * Adds an element from the bundle to the loader.\r\n     *\r\n     * Returns a new progress if adding the element leads to a new progress,\r\n     * otherwise returns null.\r\n     */\r\n    addSizedElement(element) {\r\n        this.progress.bytesLoaded += element.byteLength;\r\n        let documentsLoaded = this.progress.documentsLoaded;\r\n        if (element.payload.namedQuery) {\r\n            this.queries.push(element.payload.namedQuery);\r\n        }\r\n        else if (element.payload.documentMetadata) {\r\n            this.documents.push({ metadata: element.payload.documentMetadata });\r\n            if (!element.payload.documentMetadata.exists) {\r\n                ++documentsLoaded;\r\n            }\r\n        }\r\n        else if (element.payload.document) {\r\n            this.documents[this.documents.length - 1].document =\r\n                element.payload.document;\r\n            ++documentsLoaded;\r\n        }\r\n        if (documentsLoaded !== this.progress.documentsLoaded) {\r\n            this.progress.documentsLoaded = documentsLoaded;\r\n            return Object.assign({}, this.progress);\r\n        }\r\n        return null;\r\n    }\r\n    getQueryDocumentMapping(documents) {\r\n        const queryDocumentMap = new Map();\r\n        const bundleConverter = new BundleConverterImpl(this.serializer);\r\n        for (const bundleDoc of documents) {\r\n            if (bundleDoc.metadata.queries) {\r\n                const documentKey = bundleConverter.toDocumentKey(bundleDoc.metadata.name);\r\n                for (const queryName of bundleDoc.metadata.queries) {\r\n                    const documentKeys = (queryDocumentMap.get(queryName) || documentKeySet()).add(documentKey);\r\n                    queryDocumentMap.set(queryName, documentKeys);\r\n                }\r\n            }\r\n        }\r\n        return queryDocumentMap;\r\n    }\r\n    /**\r\n     * Update the progress to 'Success' and return the updated progress.\r\n     */\r\n    async complete() {\r\n        const changedDocuments = await localStoreApplyBundledDocuments(this.localStore, new BundleConverterImpl(this.serializer), this.documents, this.bundleMetadata.id);\r\n        const queryDocumentMap = this.getQueryDocumentMapping(this.documents);\r\n        for (const q of this.queries) {\r\n            await localStoreSaveNamedQuery(this.localStore, q, queryDocumentMap.get(q.name));\r\n        }\r\n        this.progress.taskState = 'Success';\r\n        return new BundleLoadResult(Object.assign({}, this.progress), changedDocuments);\r\n    }\r\n}\r\n/**\r\n * Returns a `LoadBundleTaskProgress` representing the initial progress of\r\n * loading a bundle.\r\n */\r\nfunction bundleInitialProgress(metadata) {\r\n    return {\r\n        taskState: 'Running',\r\n        documentsLoaded: 0,\r\n        bytesLoaded: 0,\r\n        totalDocuments: metadata.totalDocuments,\r\n        totalBytes: metadata.totalBytes\r\n    };\r\n}\r\n/**\r\n * Returns a `LoadBundleTaskProgress` representing the progress that the loading\r\n * has succeeded.\r\n */\r\nfunction bundleSuccessProgress(metadata) {\r\n    return {\r\n        taskState: 'Success',\r\n        documentsLoaded: metadata.totalDocuments,\r\n        bytesLoaded: metadata.totalBytes,\r\n        totalDocuments: metadata.totalDocuments,\r\n        totalBytes: metadata.totalBytes\r\n    };\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass AddedLimboDocument {\r\n    constructor(key) {\r\n        this.key = key;\r\n    }\r\n}\r\nclass RemovedLimboDocument {\r\n    constructor(key) {\r\n        this.key = key;\r\n    }\r\n}\r\n/**\r\n * View is responsible for computing the final merged truth of what docs are in\r\n * a query. It gets notified of local and remote changes to docs, and applies\r\n * the query filters and limits to determine the most correct possible results.\r\n */\r\nclass View {\r\n    constructor(query, \r\n    /** Documents included in the remote target */\r\n    _syncedDocuments) {\r\n        this.query = query;\r\n        this._syncedDocuments = _syncedDocuments;\r\n        this.syncState = null;\r\n        /**\r\n         * A flag whether the view is current with the backend. A view is considered\r\n         * current after it has seen the current flag from the backend and did not\r\n         * lose consistency within the watch stream (e.g. because of an existence\r\n         * filter mismatch).\r\n         */\r\n        this.current = false;\r\n        /** Documents in the view but not in the remote target */\r\n        this.limboDocuments = documentKeySet();\r\n        /** Document Keys that have local changes */\r\n        this.mutatedKeys = documentKeySet();\r\n        this.docComparator = newQueryComparator(query);\r\n        this.documentSet = new DocumentSet(this.docComparator);\r\n    }\r\n    /**\r\n     * The set of remote documents that the server has told us belongs to the target associated with\r\n     * this view.\r\n     */\r\n    get syncedDocuments() {\r\n        return this._syncedDocuments;\r\n    }\r\n    /**\r\n     * Iterates over a set of doc changes, applies the query limit, and computes\r\n     * what the new results should be, what the changes were, and whether we may\r\n     * need to go back to the local cache for more results. Does not make any\r\n     * changes to the view.\r\n     * @param docChanges - The doc changes to apply to this view.\r\n     * @param previousChanges - If this is being called with a refill, then start\r\n     *        with this set of docs and changes instead of the current view.\r\n     * @returns a new set of docs, changes, and refill flag.\r\n     */\r\n    computeDocChanges(docChanges, previousChanges) {\r\n        const changeSet = previousChanges\r\n            ? previousChanges.changeSet\r\n            : new DocumentChangeSet();\r\n        const oldDocumentSet = previousChanges\r\n            ? previousChanges.documentSet\r\n            : this.documentSet;\r\n        let newMutatedKeys = previousChanges\r\n            ? previousChanges.mutatedKeys\r\n            : this.mutatedKeys;\r\n        let newDocumentSet = oldDocumentSet;\r\n        let needsRefill = false;\r\n        // Track the last doc in a (full) limit. This is necessary, because some\r\n        // update (a delete, or an update moving a doc past the old limit) might\r\n        // mean there is some other document in the local cache that either should\r\n        // come (1) between the old last limit doc and the new last document, in the\r\n        // case of updates, or (2) after the new last document, in the case of\r\n        // deletes. So we keep this doc at the old limit to compare the updates to.\r\n        //\r\n        // Note that this should never get used in a refill (when previousChanges is\r\n        // set), because there will only be adds -- no deletes or updates.\r\n        const lastDocInLimit = hasLimitToFirst(this.query) && oldDocumentSet.size === this.query.limit\r\n            ? oldDocumentSet.last()\r\n            : null;\r\n        const firstDocInLimit = hasLimitToLast(this.query) && oldDocumentSet.size === this.query.limit\r\n            ? oldDocumentSet.first()\r\n            : null;\r\n        docChanges.inorderTraversal((key, entry) => {\r\n            const oldDoc = oldDocumentSet.get(key);\r\n            const newDoc = queryMatches(this.query, entry) ? entry : null;\r\n            const oldDocHadPendingMutations = oldDoc\r\n                ? this.mutatedKeys.has(oldDoc.key)\r\n                : false;\r\n            const newDocHasPendingMutations = newDoc\r\n                ? newDoc.hasLocalMutations ||\r\n                    // We only consider committed mutations for documents that were\r\n                    // mutated during the lifetime of the view.\r\n                    (this.mutatedKeys.has(newDoc.key) && newDoc.hasCommittedMutations)\r\n                : false;\r\n            let changeApplied = false;\r\n            // Calculate change\r\n            if (oldDoc && newDoc) {\r\n                const docsEqual = oldDoc.data.isEqual(newDoc.data);\r\n                if (!docsEqual) {\r\n                    if (!this.shouldWaitForSyncedDocument(oldDoc, newDoc)) {\r\n                        changeSet.track({\r\n                            type: 2 /* Modified */,\r\n                            doc: newDoc\r\n                        });\r\n                        changeApplied = true;\r\n                        if ((lastDocInLimit &&\r\n                            this.docComparator(newDoc, lastDocInLimit) > 0) ||\r\n                            (firstDocInLimit &&\r\n                                this.docComparator(newDoc, firstDocInLimit) < 0)) {\r\n                            // This doc moved from inside the limit to outside the limit.\r\n                            // That means there may be some other doc in the local cache\r\n                            // that should be included instead.\r\n                            needsRefill = true;\r\n                        }\r\n                    }\r\n                }\r\n                else if (oldDocHadPendingMutations !== newDocHasPendingMutations) {\r\n                    changeSet.track({ type: 3 /* Metadata */, doc: newDoc });\r\n                    changeApplied = true;\r\n                }\r\n            }\r\n            else if (!oldDoc && newDoc) {\r\n                changeSet.track({ type: 0 /* Added */, doc: newDoc });\r\n                changeApplied = true;\r\n            }\r\n            else if (oldDoc && !newDoc) {\r\n                changeSet.track({ type: 1 /* Removed */, doc: oldDoc });\r\n                changeApplied = true;\r\n                if (lastDocInLimit || firstDocInLimit) {\r\n                    // A doc was removed from a full limit query. We'll need to\r\n                    // requery from the local cache to see if we know about some other\r\n                    // doc that should be in the results.\r\n                    needsRefill = true;\r\n                }\r\n            }\r\n            if (changeApplied) {\r\n                if (newDoc) {\r\n                    newDocumentSet = newDocumentSet.add(newDoc);\r\n                    if (newDocHasPendingMutations) {\r\n                        newMutatedKeys = newMutatedKeys.add(key);\r\n                    }\r\n                    else {\r\n                        newMutatedKeys = newMutatedKeys.delete(key);\r\n                    }\r\n                }\r\n                else {\r\n                    newDocumentSet = newDocumentSet.delete(key);\r\n                    newMutatedKeys = newMutatedKeys.delete(key);\r\n                }\r\n            }\r\n        });\r\n        // Drop documents out to meet limit/limitToLast requirement.\r\n        if (hasLimitToFirst(this.query) || hasLimitToLast(this.query)) {\r\n            while (newDocumentSet.size > this.query.limit) {\r\n                const oldDoc = hasLimitToFirst(this.query)\r\n                    ? newDocumentSet.last()\r\n                    : newDocumentSet.first();\r\n                newDocumentSet = newDocumentSet.delete(oldDoc.key);\r\n                newMutatedKeys = newMutatedKeys.delete(oldDoc.key);\r\n                changeSet.track({ type: 1 /* Removed */, doc: oldDoc });\r\n            }\r\n        }\r\n        return {\r\n            documentSet: newDocumentSet,\r\n            changeSet,\r\n            needsRefill,\r\n            mutatedKeys: newMutatedKeys\r\n        };\r\n    }\r\n    shouldWaitForSyncedDocument(oldDoc, newDoc) {\r\n        // We suppress the initial change event for documents that were modified as\r\n        // part of a write acknowledgment (e.g. when the value of a server transform\r\n        // is applied) as Watch will send us the same document again.\r\n        // By suppressing the event, we only raise two user visible events (one with\r\n        // `hasPendingWrites` and the final state of the document) instead of three\r\n        // (one with `hasPendingWrites`, the modified document with\r\n        // `hasPendingWrites` and the final state of the document).\r\n        return (oldDoc.hasLocalMutations &&\r\n            newDoc.hasCommittedMutations &&\r\n            !newDoc.hasLocalMutations);\r\n    }\r\n    /**\r\n     * Updates the view with the given ViewDocumentChanges and optionally updates\r\n     * limbo docs and sync state from the provided target change.\r\n     * @param docChanges - The set of changes to make to the view's docs.\r\n     * @param updateLimboDocuments - Whether to update limbo documents based on\r\n     *        this change.\r\n     * @param targetChange - A target change to apply for computing limbo docs and\r\n     *        sync state.\r\n     * @returns A new ViewChange with the given docs, changes, and sync state.\r\n     */\r\n    // PORTING NOTE: The iOS/Android clients always compute limbo document changes.\r\n    applyChanges(docChanges, updateLimboDocuments, targetChange) {\r\n        const oldDocs = this.documentSet;\r\n        this.documentSet = docChanges.documentSet;\r\n        this.mutatedKeys = docChanges.mutatedKeys;\r\n        // Sort changes based on type and query comparator\r\n        const changes = docChanges.changeSet.getChanges();\r\n        changes.sort((c1, c2) => {\r\n            return (compareChangeType(c1.type, c2.type) ||\r\n                this.docComparator(c1.doc, c2.doc));\r\n        });\r\n        this.applyTargetChange(targetChange);\r\n        const limboChanges = updateLimboDocuments\r\n            ? this.updateLimboDocuments()\r\n            : [];\r\n        const synced = this.limboDocuments.size === 0 && this.current;\r\n        const newSyncState = synced ? 1 /* Synced */ : 0 /* Local */;\r\n        const syncStateChanged = newSyncState !== this.syncState;\r\n        this.syncState = newSyncState;\r\n        if (changes.length === 0 && !syncStateChanged) {\r\n            // no changes\r\n            return { limboChanges };\r\n        }\r\n        else {\r\n            const snap = new ViewSnapshot(this.query, docChanges.documentSet, oldDocs, changes, docChanges.mutatedKeys, newSyncState === 0 /* Local */, syncStateChanged, \r\n            /* excludesMetadataChanges= */ false);\r\n            return {\r\n                snapshot: snap,\r\n                limboChanges\r\n            };\r\n        }\r\n    }\r\n    /**\r\n     * Applies an OnlineState change to the view, potentially generating a\r\n     * ViewChange if the view's syncState changes as a result.\r\n     */\r\n    applyOnlineStateChange(onlineState) {\r\n        if (this.current && onlineState === \"Offline\" /* Offline */) {\r\n            // If we're offline, set `current` to false and then call applyChanges()\r\n            // to refresh our syncState and generate a ViewChange as appropriate. We\r\n            // are guaranteed to get a new TargetChange that sets `current` back to\r\n            // true once the client is back online.\r\n            this.current = false;\r\n            return this.applyChanges({\r\n                documentSet: this.documentSet,\r\n                changeSet: new DocumentChangeSet(),\r\n                mutatedKeys: this.mutatedKeys,\r\n                needsRefill: false\r\n            }, \r\n            /* updateLimboDocuments= */ false);\r\n        }\r\n        else {\r\n            // No effect, just return a no-op ViewChange.\r\n            return { limboChanges: [] };\r\n        }\r\n    }\r\n    /**\r\n     * Returns whether the doc for the given key should be in limbo.\r\n     */\r\n    shouldBeInLimbo(key) {\r\n        // If the remote end says it's part of this query, it's not in limbo.\r\n        if (this._syncedDocuments.has(key)) {\r\n            return false;\r\n        }\r\n        // The local store doesn't think it's a result, so it shouldn't be in limbo.\r\n        if (!this.documentSet.has(key)) {\r\n            return false;\r\n        }\r\n        // If there are local changes to the doc, they might explain why the server\r\n        // doesn't know that it's part of the query. So don't put it in limbo.\r\n        // TODO(klimt): Ideally, we would only consider changes that might actually\r\n        // affect this specific query.\r\n        if (this.documentSet.get(key).hasLocalMutations) {\r\n            return false;\r\n        }\r\n        // Everything else is in limbo.\r\n        return true;\r\n    }\r\n    /**\r\n     * Updates syncedDocuments, current, and limbo docs based on the given change.\r\n     * Returns the list of changes to which docs are in limbo.\r\n     */\r\n    applyTargetChange(targetChange) {\r\n        if (targetChange) {\r\n            targetChange.addedDocuments.forEach(key => (this._syncedDocuments = this._syncedDocuments.add(key)));\r\n            targetChange.modifiedDocuments.forEach(key => {\r\n            });\r\n            targetChange.removedDocuments.forEach(key => (this._syncedDocuments = this._syncedDocuments.delete(key)));\r\n            this.current = targetChange.current;\r\n        }\r\n    }\r\n    updateLimboDocuments() {\r\n        // We can only determine limbo documents when we're in-sync with the server.\r\n        if (!this.current) {\r\n            return [];\r\n        }\r\n        // TODO(klimt): Do this incrementally so that it's not quadratic when\r\n        // updating many documents.\r\n        const oldLimboDocuments = this.limboDocuments;\r\n        this.limboDocuments = documentKeySet();\r\n        this.documentSet.forEach(doc => {\r\n            if (this.shouldBeInLimbo(doc.key)) {\r\n                this.limboDocuments = this.limboDocuments.add(doc.key);\r\n            }\r\n        });\r\n        // Diff the new limbo docs with the old limbo docs.\r\n        const changes = [];\r\n        oldLimboDocuments.forEach(key => {\r\n            if (!this.limboDocuments.has(key)) {\r\n                changes.push(new RemovedLimboDocument(key));\r\n            }\r\n        });\r\n        this.limboDocuments.forEach(key => {\r\n            if (!oldLimboDocuments.has(key)) {\r\n                changes.push(new AddedLimboDocument(key));\r\n            }\r\n        });\r\n        return changes;\r\n    }\r\n    /**\r\n     * Update the in-memory state of the current view with the state read from\r\n     * persistence.\r\n     *\r\n     * We update the query view whenever a client's primary status changes:\r\n     * - When a client transitions from primary to secondary, it can miss\r\n     *   LocalStorage updates and its query views may temporarily not be\r\n     *   synchronized with the state on disk.\r\n     * - For secondary to primary transitions, the client needs to update the list\r\n     *   of `syncedDocuments` since secondary clients update their query views\r\n     *   based purely on synthesized RemoteEvents.\r\n     *\r\n     * @param queryResult.documents - The documents that match the query according\r\n     * to the LocalStore.\r\n     * @param queryResult.remoteKeys - The keys of the documents that match the\r\n     * query according to the backend.\r\n     *\r\n     * @returns The ViewChange that resulted from this synchronization.\r\n     */\r\n    // PORTING NOTE: Multi-tab only.\r\n    synchronizeWithPersistedState(queryResult) {\r\n        this._syncedDocuments = queryResult.remoteKeys;\r\n        this.limboDocuments = documentKeySet();\r\n        const docChanges = this.computeDocChanges(queryResult.documents);\r\n        return this.applyChanges(docChanges, /*updateLimboDocuments=*/ true);\r\n    }\r\n    /**\r\n     * Returns a view snapshot as if this query was just listened to. Contains\r\n     * a document add for every existing document and the `fromCache` and\r\n     * `hasPendingWrites` status of the already established view.\r\n     */\r\n    // PORTING NOTE: Multi-tab only.\r\n    computeInitialSnapshot() {\r\n        return ViewSnapshot.fromInitialDocuments(this.query, this.documentSet, this.mutatedKeys, this.syncState === 0 /* Local */);\r\n    }\r\n}\r\nfunction compareChangeType(c1, c2) {\r\n    const order = (change) => {\r\n        switch (change) {\r\n            case 0 /* Added */:\r\n                return 1;\r\n            case 2 /* Modified */:\r\n                return 2;\r\n            case 3 /* Metadata */:\r\n                // A metadata change is converted to a modified change at the public\r\n                // api layer.  Since we sort by document key and then change type,\r\n                // metadata and modified changes must be sorted equivalently.\r\n                return 2;\r\n            case 1 /* Removed */:\r\n                return 0;\r\n            default:\r\n                return fail();\r\n        }\r\n    };\r\n    return order(c1) - order(c2);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$3 = 'SyncEngine';\r\n/**\r\n * QueryView contains all of the data that SyncEngine needs to keep track of for\r\n * a particular query.\r\n */\r\nclass QueryView {\r\n    constructor(\r\n    /**\r\n     * The query itself.\r\n     */\r\n    query, \r\n    /**\r\n     * The target number created by the client that is used in the watch\r\n     * stream to identify this query.\r\n     */\r\n    targetId, \r\n    /**\r\n     * The view is responsible for computing the final merged truth of what\r\n     * docs are in the query. It gets notified of local and remote changes,\r\n     * and applies the query filters and limits to determine the most correct\r\n     * possible results.\r\n     */\r\n    view) {\r\n        this.query = query;\r\n        this.targetId = targetId;\r\n        this.view = view;\r\n    }\r\n}\r\n/** Tracks a limbo resolution. */\r\nclass LimboResolution {\r\n    constructor(key) {\r\n        this.key = key;\r\n        /**\r\n         * Set to true once we've received a document. This is used in\r\n         * getRemoteKeysForTarget() and ultimately used by WatchChangeAggregator to\r\n         * decide whether it needs to manufacture a delete event for the target once\r\n         * the target is CURRENT.\r\n         */\r\n        this.receivedDocument = false;\r\n    }\r\n}\r\n/**\r\n * An implementation of `SyncEngine` coordinating with other parts of SDK.\r\n *\r\n * The parts of SyncEngine that act as a callback to RemoteStore need to be\r\n * registered individually. This is done in `syncEngineWrite()` and\r\n * `syncEngineListen()` (as well as `applyPrimaryState()`) as these methods\r\n * serve as entry points to RemoteStore's functionality.\r\n *\r\n * Note: some field defined in this class might have public access level, but\r\n * the class is not exported so they are only accessible from this module.\r\n * This is useful to implement optional features (like bundles) in free\r\n * functions, such that they are tree-shakeable.\r\n */\r\nclass SyncEngineImpl {\r\n    constructor(localStore, remoteStore, eventManager, \r\n    // PORTING NOTE: Manages state synchronization in multi-tab environments.\r\n    sharedClientState, currentUser, maxConcurrentLimboResolutions) {\r\n        this.localStore = localStore;\r\n        this.remoteStore = remoteStore;\r\n        this.eventManager = eventManager;\r\n        this.sharedClientState = sharedClientState;\r\n        this.currentUser = currentUser;\r\n        this.maxConcurrentLimboResolutions = maxConcurrentLimboResolutions;\r\n        this.syncEngineListener = {};\r\n        this.queryViewsByQuery = new ObjectMap(q => canonifyQuery(q), queryEquals);\r\n        this.queriesByTarget = new Map();\r\n        /**\r\n         * The keys of documents that are in limbo for which we haven't yet started a\r\n         * limbo resolution query. The strings in this set are the result of calling\r\n         * `key.path.canonicalString()` where `key` is a `DocumentKey` object.\r\n         *\r\n         * The `Set` type was chosen because it provides efficient lookup and removal\r\n         * of arbitrary elements and it also maintains insertion order, providing the\r\n         * desired queue-like FIFO semantics.\r\n         */\r\n        this.enqueuedLimboResolutions = new Set();\r\n        /**\r\n         * Keeps track of the target ID for each document that is in limbo with an\r\n         * active target.\r\n         */\r\n        this.activeLimboTargetsByKey = new SortedMap(DocumentKey.comparator);\r\n        /**\r\n         * Keeps track of the information about an active limbo resolution for each\r\n         * active target ID that was started for the purpose of limbo resolution.\r\n         */\r\n        this.activeLimboResolutionsByTarget = new Map();\r\n        this.limboDocumentRefs = new ReferenceSet();\r\n        /** Stores user completion handlers, indexed by User and BatchId. */\r\n        this.mutationUserCallbacks = {};\r\n        /** Stores user callbacks waiting for all pending writes to be acknowledged. */\r\n        this.pendingWritesCallbacks = new Map();\r\n        this.limboTargetIdGenerator = TargetIdGenerator.forSyncEngine();\r\n        this.onlineState = \"Unknown\" /* Unknown */;\r\n        // The primary state is set to `true` or `false` immediately after Firestore\r\n        // startup. In the interim, a client should only be considered primary if\r\n        // `isPrimary` is true.\r\n        this._isPrimaryClient = undefined;\r\n    }\r\n    get isPrimaryClient() {\r\n        return this._isPrimaryClient === true;\r\n    }\r\n}\r\nfunction newSyncEngine(localStore, remoteStore, eventManager, \r\n// PORTING NOTE: Manages state synchronization in multi-tab environments.\r\nsharedClientState, currentUser, maxConcurrentLimboResolutions, isPrimary) {\r\n    const syncEngine = new SyncEngineImpl(localStore, remoteStore, eventManager, sharedClientState, currentUser, maxConcurrentLimboResolutions);\r\n    if (isPrimary) {\r\n        syncEngine._isPrimaryClient = true;\r\n    }\r\n    return syncEngine;\r\n}\r\n/**\r\n * Initiates the new listen, resolves promise when listen enqueued to the\r\n * server. All the subsequent view snapshots or errors are sent to the\r\n * subscribed handlers. Returns the initial snapshot.\r\n */\r\nasync function syncEngineListen(syncEngine, query) {\r\n    const syncEngineImpl = ensureWatchCallbacks(syncEngine);\r\n    let targetId;\r\n    let viewSnapshot;\r\n    const queryView = syncEngineImpl.queryViewsByQuery.get(query);\r\n    if (queryView) {\r\n        // PORTING NOTE: With Multi-Tab Web, it is possible that a query view\r\n        // already exists when EventManager calls us for the first time. This\r\n        // happens when the primary tab is already listening to this query on\r\n        // behalf of another tab and the user of the primary also starts listening\r\n        // to the query. EventManager will not have an assigned target ID in this\r\n        // case and calls `listen` to obtain this ID.\r\n        targetId = queryView.targetId;\r\n        syncEngineImpl.sharedClientState.addLocalQueryTarget(targetId);\r\n        viewSnapshot = queryView.view.computeInitialSnapshot();\r\n    }\r\n    else {\r\n        const targetData = await localStoreAllocateTarget(syncEngineImpl.localStore, queryToTarget(query));\r\n        const status = syncEngineImpl.sharedClientState.addLocalQueryTarget(targetData.targetId);\r\n        targetId = targetData.targetId;\r\n        viewSnapshot = await initializeViewAndComputeSnapshot(syncEngineImpl, query, targetId, status === 'current');\r\n        if (syncEngineImpl.isPrimaryClient) {\r\n            remoteStoreListen(syncEngineImpl.remoteStore, targetData);\r\n        }\r\n    }\r\n    return viewSnapshot;\r\n}\r\n/**\r\n * Registers a view for a previously unknown query and computes its initial\r\n * snapshot.\r\n */\r\nasync function initializeViewAndComputeSnapshot(syncEngineImpl, query, targetId, current) {\r\n    // PORTING NOTE: On Web only, we inject the code that registers new Limbo\r\n    // targets based on view changes. This allows us to only depend on Limbo\r\n    // changes when user code includes queries.\r\n    syncEngineImpl.applyDocChanges = (queryView, changes, remoteEvent) => applyDocChanges(syncEngineImpl, queryView, changes, remoteEvent);\r\n    const queryResult = await localStoreExecuteQuery(syncEngineImpl.localStore, query, \r\n    /* usePreviousResults= */ true);\r\n    const view = new View(query, queryResult.remoteKeys);\r\n    const viewDocChanges = view.computeDocChanges(queryResult.documents);\r\n    const synthesizedTargetChange = TargetChange.createSynthesizedTargetChangeForCurrentChange(targetId, current && syncEngineImpl.onlineState !== \"Offline\" /* Offline */);\r\n    const viewChange = view.applyChanges(viewDocChanges, \r\n    /* updateLimboDocuments= */ syncEngineImpl.isPrimaryClient, synthesizedTargetChange);\r\n    updateTrackedLimbos(syncEngineImpl, targetId, viewChange.limboChanges);\r\n    const data = new QueryView(query, targetId, view);\r\n    syncEngineImpl.queryViewsByQuery.set(query, data);\r\n    if (syncEngineImpl.queriesByTarget.has(targetId)) {\r\n        syncEngineImpl.queriesByTarget.get(targetId).push(query);\r\n    }\r\n    else {\r\n        syncEngineImpl.queriesByTarget.set(targetId, [query]);\r\n    }\r\n    return viewChange.snapshot;\r\n}\r\n/** Stops listening to the query. */\r\nasync function syncEngineUnlisten(syncEngine, query) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const queryView = syncEngineImpl.queryViewsByQuery.get(query);\r\n    // Only clean up the query view and target if this is the only query mapped\r\n    // to the target.\r\n    const queries = syncEngineImpl.queriesByTarget.get(queryView.targetId);\r\n    if (queries.length > 1) {\r\n        syncEngineImpl.queriesByTarget.set(queryView.targetId, queries.filter(q => !queryEquals(q, query)));\r\n        syncEngineImpl.queryViewsByQuery.delete(query);\r\n        return;\r\n    }\r\n    // No other queries are mapped to the target, clean up the query and the target.\r\n    if (syncEngineImpl.isPrimaryClient) {\r\n        // We need to remove the local query target first to allow us to verify\r\n        // whether any other client is still interested in this target.\r\n        syncEngineImpl.sharedClientState.removeLocalQueryTarget(queryView.targetId);\r\n        const targetRemainsActive = syncEngineImpl.sharedClientState.isActiveQueryTarget(queryView.targetId);\r\n        if (!targetRemainsActive) {\r\n            await localStoreReleaseTarget(syncEngineImpl.localStore, queryView.targetId, \r\n            /*keepPersistedTargetData=*/ false)\r\n                .then(() => {\r\n                syncEngineImpl.sharedClientState.clearQueryState(queryView.targetId);\r\n                remoteStoreUnlisten(syncEngineImpl.remoteStore, queryView.targetId);\r\n                removeAndCleanupTarget(syncEngineImpl, queryView.targetId);\r\n            })\r\n                .catch(ignoreIfPrimaryLeaseLoss);\r\n        }\r\n    }\r\n    else {\r\n        removeAndCleanupTarget(syncEngineImpl, queryView.targetId);\r\n        await localStoreReleaseTarget(syncEngineImpl.localStore, queryView.targetId, \r\n        /*keepPersistedTargetData=*/ true);\r\n    }\r\n}\r\n/**\r\n * Initiates the write of local mutation batch which involves adding the\r\n * writes to the mutation queue, notifying the remote store about new\r\n * mutations and raising events for any changes this write caused.\r\n *\r\n * The promise returned by this call is resolved when the above steps\r\n * have completed, *not* when the write was acked by the backend. The\r\n * userCallback is resolved once the write was acked/rejected by the\r\n * backend (or failed locally for any other reason).\r\n */\r\nasync function syncEngineWrite(syncEngine, batch, userCallback) {\r\n    const syncEngineImpl = syncEngineEnsureWriteCallbacks(syncEngine);\r\n    try {\r\n        const result = await localStoreWriteLocally(syncEngineImpl.localStore, batch);\r\n        syncEngineImpl.sharedClientState.addPendingMutation(result.batchId);\r\n        addMutationCallback(syncEngineImpl, result.batchId, userCallback);\r\n        await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, result.changes);\r\n        await fillWritePipeline(syncEngineImpl.remoteStore);\r\n    }\r\n    catch (e) {\r\n        // If we can't persist the mutation, we reject the user callback and\r\n        // don't send the mutation. The user can then retry the write.\r\n        const error = wrapInUserErrorIfRecoverable(e, `Failed to persist write`);\r\n        userCallback.reject(error);\r\n    }\r\n}\r\n/**\r\n * Applies one remote event to the sync engine, notifying any views of the\r\n * changes, and releasing any pending mutation batches that would become\r\n * visible because of the snapshot version the remote event contains.\r\n */\r\nasync function syncEngineApplyRemoteEvent(syncEngine, remoteEvent) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    try {\r\n        const changes = await localStoreApplyRemoteEventToLocalCache(syncEngineImpl.localStore, remoteEvent);\r\n        // Update `receivedDocument` as appropriate for any limbo targets.\r\n        remoteEvent.targetChanges.forEach((targetChange, targetId) => {\r\n            const limboResolution = syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);\r\n            if (limboResolution) {\r\n                // Since this is a limbo resolution lookup, it's for a single document\r\n                // and it could be added, modified, or removed, but not a combination.\r\n                hardAssert(targetChange.addedDocuments.size +\r\n                    targetChange.modifiedDocuments.size +\r\n                    targetChange.removedDocuments.size <=\r\n                    1);\r\n                if (targetChange.addedDocuments.size > 0) {\r\n                    limboResolution.receivedDocument = true;\r\n                }\r\n                else if (targetChange.modifiedDocuments.size > 0) {\r\n                    hardAssert(limboResolution.receivedDocument);\r\n                }\r\n                else if (targetChange.removedDocuments.size > 0) {\r\n                    hardAssert(limboResolution.receivedDocument);\r\n                    limboResolution.receivedDocument = false;\r\n                }\r\n                else {\r\n                    // This was probably just a CURRENT targetChange or similar.\r\n                }\r\n            }\r\n        });\r\n        await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes, remoteEvent);\r\n    }\r\n    catch (error) {\r\n        await ignoreIfPrimaryLeaseLoss(error);\r\n    }\r\n}\r\n/**\r\n * Applies an OnlineState change to the sync engine and notifies any views of\r\n * the change.\r\n */\r\nfunction syncEngineApplyOnlineStateChange(syncEngine, onlineState, source) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    // If we are the secondary client, we explicitly ignore the remote store's\r\n    // online state (the local client may go offline, even though the primary\r\n    // tab remains online) and only apply the primary tab's online state from\r\n    // SharedClientState.\r\n    if ((syncEngineImpl.isPrimaryClient &&\r\n        source === 0 /* RemoteStore */) ||\r\n        (!syncEngineImpl.isPrimaryClient &&\r\n            source === 1 /* SharedClientState */)) {\r\n        const newViewSnapshots = [];\r\n        syncEngineImpl.queryViewsByQuery.forEach((query, queryView) => {\r\n            const viewChange = queryView.view.applyOnlineStateChange(onlineState);\r\n            if (viewChange.snapshot) {\r\n                newViewSnapshots.push(viewChange.snapshot);\r\n            }\r\n        });\r\n        eventManagerOnOnlineStateChange(syncEngineImpl.eventManager, onlineState);\r\n        if (newViewSnapshots.length) {\r\n            syncEngineImpl.syncEngineListener.onWatchChange(newViewSnapshots);\r\n        }\r\n        syncEngineImpl.onlineState = onlineState;\r\n        if (syncEngineImpl.isPrimaryClient) {\r\n            syncEngineImpl.sharedClientState.setOnlineState(onlineState);\r\n        }\r\n    }\r\n}\r\n/**\r\n * Rejects the listen for the given targetID. This can be triggered by the\r\n * backend for any active target.\r\n *\r\n * @param syncEngine - The sync engine implementation.\r\n * @param targetId - The targetID corresponds to one previously initiated by the\r\n * user as part of TargetData passed to listen() on RemoteStore.\r\n * @param err - A description of the condition that has forced the rejection.\r\n * Nearly always this will be an indication that the user is no longer\r\n * authorized to see the data matching the target.\r\n */\r\nasync function syncEngineRejectListen(syncEngine, targetId, err) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    // PORTING NOTE: Multi-tab only.\r\n    syncEngineImpl.sharedClientState.updateQueryState(targetId, 'rejected', err);\r\n    const limboResolution = syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);\r\n    const limboKey = limboResolution && limboResolution.key;\r\n    if (limboKey) {\r\n        // TODO(klimt): We really only should do the following on permission\r\n        // denied errors, but we don't have the cause code here.\r\n        // It's a limbo doc. Create a synthetic event saying it was deleted.\r\n        // This is kind of a hack. Ideally, we would have a method in the local\r\n        // store to purge a document. However, it would be tricky to keep all of\r\n        // the local store's invariants with another method.\r\n        let documentUpdates = new SortedMap(DocumentKey.comparator);\r\n        documentUpdates = documentUpdates.insert(limboKey, MutableDocument.newNoDocument(limboKey, SnapshotVersion.min()));\r\n        const resolvedLimboDocuments = documentKeySet().add(limboKey);\r\n        const event = new RemoteEvent(SnapshotVersion.min(), \r\n        /* targetChanges= */ new Map(), \r\n        /* targetMismatches= */ new SortedSet(primitiveComparator), documentUpdates, resolvedLimboDocuments);\r\n        await syncEngineApplyRemoteEvent(syncEngineImpl, event);\r\n        // Since this query failed, we won't want to manually unlisten to it.\r\n        // We only remove it from bookkeeping after we successfully applied the\r\n        // RemoteEvent. If `applyRemoteEvent()` throws, we want to re-listen to\r\n        // this query when the RemoteStore restarts the Watch stream, which should\r\n        // re-trigger the target failure.\r\n        syncEngineImpl.activeLimboTargetsByKey =\r\n            syncEngineImpl.activeLimboTargetsByKey.remove(limboKey);\r\n        syncEngineImpl.activeLimboResolutionsByTarget.delete(targetId);\r\n        pumpEnqueuedLimboResolutions(syncEngineImpl);\r\n    }\r\n    else {\r\n        await localStoreReleaseTarget(syncEngineImpl.localStore, targetId, \r\n        /* keepPersistedTargetData */ false)\r\n            .then(() => removeAndCleanupTarget(syncEngineImpl, targetId, err))\r\n            .catch(ignoreIfPrimaryLeaseLoss);\r\n    }\r\n}\r\nasync function syncEngineApplySuccessfulWrite(syncEngine, mutationBatchResult) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const batchId = mutationBatchResult.batch.batchId;\r\n    try {\r\n        const changes = await localStoreAcknowledgeBatch(syncEngineImpl.localStore, mutationBatchResult);\r\n        // The local store may or may not be able to apply the write result and\r\n        // raise events immediately (depending on whether the watcher is caught\r\n        // up), so we raise user callbacks first so that they consistently happen\r\n        // before listen events.\r\n        processUserCallback(syncEngineImpl, batchId, /*error=*/ null);\r\n        triggerPendingWritesCallbacks(syncEngineImpl, batchId);\r\n        syncEngineImpl.sharedClientState.updateMutationState(batchId, 'acknowledged');\r\n        await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes);\r\n    }\r\n    catch (error) {\r\n        await ignoreIfPrimaryLeaseLoss(error);\r\n    }\r\n}\r\nasync function syncEngineRejectFailedWrite(syncEngine, batchId, error) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    try {\r\n        const changes = await localStoreRejectBatch(syncEngineImpl.localStore, batchId);\r\n        // The local store may or may not be able to apply the write result and\r\n        // raise events immediately (depending on whether the watcher is caught up),\r\n        // so we raise user callbacks first so that they consistently happen before\r\n        // listen events.\r\n        processUserCallback(syncEngineImpl, batchId, error);\r\n        triggerPendingWritesCallbacks(syncEngineImpl, batchId);\r\n        syncEngineImpl.sharedClientState.updateMutationState(batchId, 'rejected', error);\r\n        await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes);\r\n    }\r\n    catch (error) {\r\n        await ignoreIfPrimaryLeaseLoss(error);\r\n    }\r\n}\r\n/**\r\n * Registers a user callback that resolves when all pending mutations at the moment of calling\r\n * are acknowledged .\r\n */\r\nasync function syncEngineRegisterPendingWritesCallback(syncEngine, callback) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    if (!canUseNetwork(syncEngineImpl.remoteStore)) {\r\n        logDebug(LOG_TAG$3, 'The network is disabled. The task returned by ' +\r\n            \"'awaitPendingWrites()' will not complete until the network is enabled.\");\r\n    }\r\n    try {\r\n        const highestBatchId = await localStoreGetHighestUnacknowledgedBatchId(syncEngineImpl.localStore);\r\n        if (highestBatchId === BATCHID_UNKNOWN) {\r\n            // Trigger the callback right away if there is no pending writes at the moment.\r\n            callback.resolve();\r\n            return;\r\n        }\r\n        const callbacks = syncEngineImpl.pendingWritesCallbacks.get(highestBatchId) || [];\r\n        callbacks.push(callback);\r\n        syncEngineImpl.pendingWritesCallbacks.set(highestBatchId, callbacks);\r\n    }\r\n    catch (e) {\r\n        const firestoreError = wrapInUserErrorIfRecoverable(e, 'Initialization of waitForPendingWrites() operation failed');\r\n        callback.reject(firestoreError);\r\n    }\r\n}\r\n/**\r\n * Triggers the callbacks that are waiting for this batch id to get acknowledged by server,\r\n * if there are any.\r\n */\r\nfunction triggerPendingWritesCallbacks(syncEngineImpl, batchId) {\r\n    (syncEngineImpl.pendingWritesCallbacks.get(batchId) || []).forEach(callback => {\r\n        callback.resolve();\r\n    });\r\n    syncEngineImpl.pendingWritesCallbacks.delete(batchId);\r\n}\r\n/** Reject all outstanding callbacks waiting for pending writes to complete. */\r\nfunction rejectOutstandingPendingWritesCallbacks(syncEngineImpl, errorMessage) {\r\n    syncEngineImpl.pendingWritesCallbacks.forEach(callbacks => {\r\n        callbacks.forEach(callback => {\r\n            callback.reject(new FirestoreError(Code.CANCELLED, errorMessage));\r\n        });\r\n    });\r\n    syncEngineImpl.pendingWritesCallbacks.clear();\r\n}\r\nfunction addMutationCallback(syncEngineImpl, batchId, callback) {\r\n    let newCallbacks = syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()];\r\n    if (!newCallbacks) {\r\n        newCallbacks = new SortedMap(primitiveComparator);\r\n    }\r\n    newCallbacks = newCallbacks.insert(batchId, callback);\r\n    syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()] =\r\n        newCallbacks;\r\n}\r\n/**\r\n * Resolves or rejects the user callback for the given batch and then discards\r\n * it.\r\n */\r\nfunction processUserCallback(syncEngine, batchId, error) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    let newCallbacks = syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()];\r\n    // NOTE: Mutations restored from persistence won't have callbacks, so it's\r\n    // okay for there to be no callback for this ID.\r\n    if (newCallbacks) {\r\n        const callback = newCallbacks.get(batchId);\r\n        if (callback) {\r\n            if (error) {\r\n                callback.reject(error);\r\n            }\r\n            else {\r\n                callback.resolve();\r\n            }\r\n            newCallbacks = newCallbacks.remove(batchId);\r\n        }\r\n        syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()] =\r\n            newCallbacks;\r\n    }\r\n}\r\nfunction removeAndCleanupTarget(syncEngineImpl, targetId, error = null) {\r\n    syncEngineImpl.sharedClientState.removeLocalQueryTarget(targetId);\r\n    for (const query of syncEngineImpl.queriesByTarget.get(targetId)) {\r\n        syncEngineImpl.queryViewsByQuery.delete(query);\r\n        if (error) {\r\n            syncEngineImpl.syncEngineListener.onWatchError(query, error);\r\n        }\r\n    }\r\n    syncEngineImpl.queriesByTarget.delete(targetId);\r\n    if (syncEngineImpl.isPrimaryClient) {\r\n        const limboKeys = syncEngineImpl.limboDocumentRefs.removeReferencesForId(targetId);\r\n        limboKeys.forEach(limboKey => {\r\n            const isReferenced = syncEngineImpl.limboDocumentRefs.containsKey(limboKey);\r\n            if (!isReferenced) {\r\n                // We removed the last reference for this key\r\n                removeLimboTarget(syncEngineImpl, limboKey);\r\n            }\r\n        });\r\n    }\r\n}\r\nfunction removeLimboTarget(syncEngineImpl, key) {\r\n    syncEngineImpl.enqueuedLimboResolutions.delete(key.path.canonicalString());\r\n    // It's possible that the target already got removed because the query failed. In that case,\r\n    // the key won't exist in `limboTargetsByKey`. Only do the cleanup if we still have the target.\r\n    const limboTargetId = syncEngineImpl.activeLimboTargetsByKey.get(key);\r\n    if (limboTargetId === null) {\r\n        // This target already got removed, because the query failed.\r\n        return;\r\n    }\r\n    remoteStoreUnlisten(syncEngineImpl.remoteStore, limboTargetId);\r\n    syncEngineImpl.activeLimboTargetsByKey =\r\n        syncEngineImpl.activeLimboTargetsByKey.remove(key);\r\n    syncEngineImpl.activeLimboResolutionsByTarget.delete(limboTargetId);\r\n    pumpEnqueuedLimboResolutions(syncEngineImpl);\r\n}\r\nfunction updateTrackedLimbos(syncEngineImpl, targetId, limboChanges) {\r\n    for (const limboChange of limboChanges) {\r\n        if (limboChange instanceof AddedLimboDocument) {\r\n            syncEngineImpl.limboDocumentRefs.addReference(limboChange.key, targetId);\r\n            trackLimboChange(syncEngineImpl, limboChange);\r\n        }\r\n        else if (limboChange instanceof RemovedLimboDocument) {\r\n            logDebug(LOG_TAG$3, 'Document no longer in limbo: ' + limboChange.key);\r\n            syncEngineImpl.limboDocumentRefs.removeReference(limboChange.key, targetId);\r\n            const isReferenced = syncEngineImpl.limboDocumentRefs.containsKey(limboChange.key);\r\n            if (!isReferenced) {\r\n                // We removed the last reference for this key\r\n                removeLimboTarget(syncEngineImpl, limboChange.key);\r\n            }\r\n        }\r\n        else {\r\n            fail();\r\n        }\r\n    }\r\n}\r\nfunction trackLimboChange(syncEngineImpl, limboChange) {\r\n    const key = limboChange.key;\r\n    const keyString = key.path.canonicalString();\r\n    if (!syncEngineImpl.activeLimboTargetsByKey.get(key) &&\r\n        !syncEngineImpl.enqueuedLimboResolutions.has(keyString)) {\r\n        logDebug(LOG_TAG$3, 'New document in limbo: ' + key);\r\n        syncEngineImpl.enqueuedLimboResolutions.add(keyString);\r\n        pumpEnqueuedLimboResolutions(syncEngineImpl);\r\n    }\r\n}\r\n/**\r\n * Starts listens for documents in limbo that are enqueued for resolution,\r\n * subject to a maximum number of concurrent resolutions.\r\n *\r\n * Without bounding the number of concurrent resolutions, the server can fail\r\n * with \"resource exhausted\" errors which can lead to pathological client\r\n * behavior as seen in https://github.com/firebase/firebase-js-sdk/issues/2683.\r\n */\r\nfunction pumpEnqueuedLimboResolutions(syncEngineImpl) {\r\n    while (syncEngineImpl.enqueuedLimboResolutions.size > 0 &&\r\n        syncEngineImpl.activeLimboTargetsByKey.size <\r\n            syncEngineImpl.maxConcurrentLimboResolutions) {\r\n        const keyString = syncEngineImpl.enqueuedLimboResolutions\r\n            .values()\r\n            .next().value;\r\n        syncEngineImpl.enqueuedLimboResolutions.delete(keyString);\r\n        const key = new DocumentKey(ResourcePath.fromString(keyString));\r\n        const limboTargetId = syncEngineImpl.limboTargetIdGenerator.next();\r\n        syncEngineImpl.activeLimboResolutionsByTarget.set(limboTargetId, new LimboResolution(key));\r\n        syncEngineImpl.activeLimboTargetsByKey =\r\n            syncEngineImpl.activeLimboTargetsByKey.insert(key, limboTargetId);\r\n        remoteStoreListen(syncEngineImpl.remoteStore, new TargetData(queryToTarget(newQueryForPath(key.path)), limboTargetId, 2 /* LimboResolution */, ListenSequence.INVALID));\r\n    }\r\n}\r\nasync function syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngine, changes, remoteEvent) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const newSnaps = [];\r\n    const docChangesInAllViews = [];\r\n    const queriesProcessed = [];\r\n    if (syncEngineImpl.queryViewsByQuery.isEmpty()) {\r\n        // Return early since `onWatchChange()` might not have been assigned yet.\r\n        return;\r\n    }\r\n    syncEngineImpl.queryViewsByQuery.forEach((_, queryView) => {\r\n        queriesProcessed.push(syncEngineImpl\r\n            .applyDocChanges(queryView, changes, remoteEvent)\r\n            .then(viewSnapshot => {\r\n            if (viewSnapshot) {\r\n                if (syncEngineImpl.isPrimaryClient) {\r\n                    syncEngineImpl.sharedClientState.updateQueryState(queryView.targetId, viewSnapshot.fromCache ? 'not-current' : 'current');\r\n                }\r\n                newSnaps.push(viewSnapshot);\r\n                const docChanges = LocalViewChanges.fromSnapshot(queryView.targetId, viewSnapshot);\r\n                docChangesInAllViews.push(docChanges);\r\n            }\r\n        }));\r\n    });\r\n    await Promise.all(queriesProcessed);\r\n    syncEngineImpl.syncEngineListener.onWatchChange(newSnaps);\r\n    await localStoreNotifyLocalViewChanges(syncEngineImpl.localStore, docChangesInAllViews);\r\n}\r\nasync function applyDocChanges(syncEngineImpl, queryView, changes, remoteEvent) {\r\n    let viewDocChanges = queryView.view.computeDocChanges(changes);\r\n    if (viewDocChanges.needsRefill) {\r\n        // The query has a limit and some docs were removed, so we need\r\n        // to re-run the query against the local store to make sure we\r\n        // didn't lose any good docs that had been past the limit.\r\n        viewDocChanges = await localStoreExecuteQuery(syncEngineImpl.localStore, queryView.query, \r\n        /* usePreviousResults= */ false).then(({ documents }) => {\r\n            return queryView.view.computeDocChanges(documents, viewDocChanges);\r\n        });\r\n    }\r\n    const targetChange = remoteEvent && remoteEvent.targetChanges.get(queryView.targetId);\r\n    const viewChange = queryView.view.applyChanges(viewDocChanges, \r\n    /* updateLimboDocuments= */ syncEngineImpl.isPrimaryClient, targetChange);\r\n    updateTrackedLimbos(syncEngineImpl, queryView.targetId, viewChange.limboChanges);\r\n    return viewChange.snapshot;\r\n}\r\nasync function syncEngineHandleCredentialChange(syncEngine, user) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const userChanged = !syncEngineImpl.currentUser.isEqual(user);\r\n    if (userChanged) {\r\n        logDebug(LOG_TAG$3, 'User change. New user:', user.toKey());\r\n        const result = await localStoreHandleUserChange(syncEngineImpl.localStore, user);\r\n        syncEngineImpl.currentUser = user;\r\n        // Fails tasks waiting for pending writes requested by previous user.\r\n        rejectOutstandingPendingWritesCallbacks(syncEngineImpl, \"'waitForPendingWrites' promise is rejected due to a user change.\");\r\n        // TODO(b/114226417): Consider calling this only in the primary tab.\r\n        syncEngineImpl.sharedClientState.handleUserChange(user, result.removedBatchIds, result.addedBatchIds);\r\n        await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, result.affectedDocuments);\r\n    }\r\n}\r\nfunction syncEngineGetRemoteKeysForTarget(syncEngine, targetId) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const limboResolution = syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);\r\n    if (limboResolution && limboResolution.receivedDocument) {\r\n        return documentKeySet().add(limboResolution.key);\r\n    }\r\n    else {\r\n        let keySet = documentKeySet();\r\n        const queries = syncEngineImpl.queriesByTarget.get(targetId);\r\n        if (!queries) {\r\n            return keySet;\r\n        }\r\n        for (const query of queries) {\r\n            const queryView = syncEngineImpl.queryViewsByQuery.get(query);\r\n            keySet = keySet.unionWith(queryView.view.syncedDocuments);\r\n        }\r\n        return keySet;\r\n    }\r\n}\r\n/**\r\n * Reconcile the list of synced documents in an existing view with those\r\n * from persistence.\r\n */\r\nasync function synchronizeViewAndComputeSnapshot(syncEngine, queryView) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const queryResult = await localStoreExecuteQuery(syncEngineImpl.localStore, queryView.query, \r\n    /* usePreviousResults= */ true);\r\n    const viewSnapshot = queryView.view.synchronizeWithPersistedState(queryResult);\r\n    if (syncEngineImpl.isPrimaryClient) {\r\n        updateTrackedLimbos(syncEngineImpl, queryView.targetId, viewSnapshot.limboChanges);\r\n    }\r\n    return viewSnapshot;\r\n}\r\n/**\r\n * Retrieves newly changed documents from remote document cache and raises\r\n * snapshots if needed.\r\n */\r\n// PORTING NOTE: Multi-Tab only.\r\nasync function syncEngineSynchronizeWithChangedDocuments(syncEngine) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    return localStoreGetNewDocumentChanges(syncEngineImpl.localStore).then(changes => syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes));\r\n}\r\n/** Applies a mutation state to an existing batch.  */\r\n// PORTING NOTE: Multi-Tab only.\r\nasync function syncEngineApplyBatchState(syncEngine, batchId, batchState, error) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const documents = await localStoreLookupMutationDocuments(syncEngineImpl.localStore, batchId);\r\n    if (documents === null) {\r\n        // A throttled tab may not have seen the mutation before it was completed\r\n        // and removed from the mutation queue, in which case we won't have cached\r\n        // the affected documents. In this case we can safely ignore the update\r\n        // since that means we didn't apply the mutation locally at all (if we\r\n        // had, we would have cached the affected documents), and so we will just\r\n        // see any resulting document changes via normal remote document updates\r\n        // as applicable.\r\n        logDebug(LOG_TAG$3, 'Cannot apply mutation batch with id: ' + batchId);\r\n        return;\r\n    }\r\n    if (batchState === 'pending') {\r\n        // If we are the primary client, we need to send this write to the\r\n        // backend. Secondary clients will ignore these writes since their remote\r\n        // connection is disabled.\r\n        await fillWritePipeline(syncEngineImpl.remoteStore);\r\n    }\r\n    else if (batchState === 'acknowledged' || batchState === 'rejected') {\r\n        // NOTE: Both these methods are no-ops for batches that originated from\r\n        // other clients.\r\n        processUserCallback(syncEngineImpl, batchId, error ? error : null);\r\n        triggerPendingWritesCallbacks(syncEngineImpl, batchId);\r\n        localStoreRemoveCachedMutationBatchMetadata(syncEngineImpl.localStore, batchId);\r\n    }\r\n    else {\r\n        fail();\r\n    }\r\n    await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, documents);\r\n}\r\n/** Applies a query target change from a different tab. */\r\n// PORTING NOTE: Multi-Tab only.\r\nasync function syncEngineApplyPrimaryState(syncEngine, isPrimary) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    ensureWatchCallbacks(syncEngineImpl);\r\n    syncEngineEnsureWriteCallbacks(syncEngineImpl);\r\n    if (isPrimary === true && syncEngineImpl._isPrimaryClient !== true) {\r\n        // Secondary tabs only maintain Views for their local listeners and the\r\n        // Views internal state may not be 100% populated (in particular\r\n        // secondary tabs don't track syncedDocuments, the set of documents the\r\n        // server considers to be in the target). So when a secondary becomes\r\n        // primary, we need to need to make sure that all views for all targets\r\n        // match the state on disk.\r\n        const activeTargets = syncEngineImpl.sharedClientState.getAllActiveQueryTargets();\r\n        const activeQueries = await synchronizeQueryViewsAndRaiseSnapshots(syncEngineImpl, activeTargets.toArray());\r\n        syncEngineImpl._isPrimaryClient = true;\r\n        await remoteStoreApplyPrimaryState(syncEngineImpl.remoteStore, true);\r\n        for (const targetData of activeQueries) {\r\n            remoteStoreListen(syncEngineImpl.remoteStore, targetData);\r\n        }\r\n    }\r\n    else if (isPrimary === false && syncEngineImpl._isPrimaryClient !== false) {\r\n        const activeTargets = [];\r\n        let p = Promise.resolve();\r\n        syncEngineImpl.queriesByTarget.forEach((_, targetId) => {\r\n            if (syncEngineImpl.sharedClientState.isLocalQueryTarget(targetId)) {\r\n                activeTargets.push(targetId);\r\n            }\r\n            else {\r\n                p = p.then(() => {\r\n                    removeAndCleanupTarget(syncEngineImpl, targetId);\r\n                    return localStoreReleaseTarget(syncEngineImpl.localStore, targetId, \r\n                    /*keepPersistedTargetData=*/ true);\r\n                });\r\n            }\r\n            remoteStoreUnlisten(syncEngineImpl.remoteStore, targetId);\r\n        });\r\n        await p;\r\n        await synchronizeQueryViewsAndRaiseSnapshots(syncEngineImpl, activeTargets);\r\n        resetLimboDocuments(syncEngineImpl);\r\n        syncEngineImpl._isPrimaryClient = false;\r\n        await remoteStoreApplyPrimaryState(syncEngineImpl.remoteStore, false);\r\n    }\r\n}\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction resetLimboDocuments(syncEngine) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    syncEngineImpl.activeLimboResolutionsByTarget.forEach((_, targetId) => {\r\n        remoteStoreUnlisten(syncEngineImpl.remoteStore, targetId);\r\n    });\r\n    syncEngineImpl.limboDocumentRefs.removeAllReferences();\r\n    syncEngineImpl.activeLimboResolutionsByTarget = new Map();\r\n    syncEngineImpl.activeLimboTargetsByKey = new SortedMap(DocumentKey.comparator);\r\n}\r\n/**\r\n * Reconcile the query views of the provided query targets with the state from\r\n * persistence. Raises snapshots for any changes that affect the local\r\n * client and returns the updated state of all target's query data.\r\n *\r\n * @param syncEngine - The sync engine implementation\r\n * @param targets - the list of targets with views that need to be recomputed\r\n * @param transitionToPrimary - `true` iff the tab transitions from a secondary\r\n * tab to a primary tab\r\n */\r\n// PORTING NOTE: Multi-Tab only.\r\nasync function synchronizeQueryViewsAndRaiseSnapshots(syncEngine, targets, transitionToPrimary) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    const activeQueries = [];\r\n    const newViewSnapshots = [];\r\n    for (const targetId of targets) {\r\n        let targetData;\r\n        const queries = syncEngineImpl.queriesByTarget.get(targetId);\r\n        if (queries && queries.length !== 0) {\r\n            // For queries that have a local View, we fetch their current state\r\n            // from LocalStore (as the resume token and the snapshot version\r\n            // might have changed) and reconcile their views with the persisted\r\n            // state (the list of syncedDocuments may have gotten out of sync).\r\n            targetData = await localStoreAllocateTarget(syncEngineImpl.localStore, queryToTarget(queries[0]));\r\n            for (const query of queries) {\r\n                const queryView = syncEngineImpl.queryViewsByQuery.get(query);\r\n                const viewChange = await synchronizeViewAndComputeSnapshot(syncEngineImpl, queryView);\r\n                if (viewChange.snapshot) {\r\n                    newViewSnapshots.push(viewChange.snapshot);\r\n                }\r\n            }\r\n        }\r\n        else {\r\n            // For queries that never executed on this client, we need to\r\n            // allocate the target in LocalStore and initialize a new View.\r\n            const target = await localStoreGetCachedTarget(syncEngineImpl.localStore, targetId);\r\n            targetData = await localStoreAllocateTarget(syncEngineImpl.localStore, target);\r\n            await initializeViewAndComputeSnapshot(syncEngineImpl, synthesizeTargetToQuery(target), targetId, \r\n            /*current=*/ false);\r\n        }\r\n        activeQueries.push(targetData);\r\n    }\r\n    syncEngineImpl.syncEngineListener.onWatchChange(newViewSnapshots);\r\n    return activeQueries;\r\n}\r\n/**\r\n * Creates a `Query` object from the specified `Target`. There is no way to\r\n * obtain the original `Query`, so we synthesize a `Query` from the `Target`\r\n * object.\r\n *\r\n * The synthesized result might be different from the original `Query`, but\r\n * since the synthesized `Query` should return the same results as the\r\n * original one (only the presentation of results might differ), the potential\r\n * difference will not cause issues.\r\n */\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction synthesizeTargetToQuery(target) {\r\n    return newQuery(target.path, target.collectionGroup, target.orderBy, target.filters, target.limit, \"F\" /* First */, target.startAt, target.endAt);\r\n}\r\n/** Returns the IDs of the clients that are currently active. */\r\n// PORTING NOTE: Multi-Tab only.\r\nfunction syncEngineGetActiveClients(syncEngine) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    return localStoreGetActiveClients(syncEngineImpl.localStore);\r\n}\r\n/** Applies a query target change from a different tab. */\r\n// PORTING NOTE: Multi-Tab only.\r\nasync function syncEngineApplyTargetState(syncEngine, targetId, state, error) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    if (syncEngineImpl._isPrimaryClient) {\r\n        // If we receive a target state notification via WebStorage, we are\r\n        // either already secondary or another tab has taken the primary lease.\r\n        logDebug(LOG_TAG$3, 'Ignoring unexpected query state notification.');\r\n        return;\r\n    }\r\n    if (syncEngineImpl.queriesByTarget.has(targetId)) {\r\n        switch (state) {\r\n            case 'current':\r\n            case 'not-current': {\r\n                const changes = await localStoreGetNewDocumentChanges(syncEngineImpl.localStore);\r\n                const synthesizedRemoteEvent = RemoteEvent.createSynthesizedRemoteEventForCurrentChange(targetId, state === 'current');\r\n                await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes, synthesizedRemoteEvent);\r\n                break;\r\n            }\r\n            case 'rejected': {\r\n                await localStoreReleaseTarget(syncEngineImpl.localStore, targetId, \r\n                /* keepPersistedTargetData */ true);\r\n                removeAndCleanupTarget(syncEngineImpl, targetId, error);\r\n                break;\r\n            }\r\n            default:\r\n                fail();\r\n        }\r\n    }\r\n}\r\n/** Adds or removes Watch targets for queries from different tabs. */\r\nasync function syncEngineApplyActiveTargetsChange(syncEngine, added, removed) {\r\n    const syncEngineImpl = ensureWatchCallbacks(syncEngine);\r\n    if (!syncEngineImpl._isPrimaryClient) {\r\n        return;\r\n    }\r\n    for (const targetId of added) {\r\n        if (syncEngineImpl.queriesByTarget.has(targetId)) {\r\n            // A target might have been added in a previous attempt\r\n            logDebug(LOG_TAG$3, 'Adding an already active target ' + targetId);\r\n            continue;\r\n        }\r\n        const target = await localStoreGetCachedTarget(syncEngineImpl.localStore, targetId);\r\n        const targetData = await localStoreAllocateTarget(syncEngineImpl.localStore, target);\r\n        await initializeViewAndComputeSnapshot(syncEngineImpl, synthesizeTargetToQuery(target), targetData.targetId, \r\n        /*current=*/ false);\r\n        remoteStoreListen(syncEngineImpl.remoteStore, targetData);\r\n    }\r\n    for (const targetId of removed) {\r\n        // Check that the target is still active since the target might have been\r\n        // removed if it has been rejected by the backend.\r\n        if (!syncEngineImpl.queriesByTarget.has(targetId)) {\r\n            continue;\r\n        }\r\n        // Release queries that are still active.\r\n        await localStoreReleaseTarget(syncEngineImpl.localStore, targetId, \r\n        /* keepPersistedTargetData */ false)\r\n            .then(() => {\r\n            remoteStoreUnlisten(syncEngineImpl.remoteStore, targetId);\r\n            removeAndCleanupTarget(syncEngineImpl, targetId);\r\n        })\r\n            .catch(ignoreIfPrimaryLeaseLoss);\r\n    }\r\n}\r\nfunction ensureWatchCallbacks(syncEngine) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    syncEngineImpl.remoteStore.remoteSyncer.applyRemoteEvent =\r\n        syncEngineApplyRemoteEvent.bind(null, syncEngineImpl);\r\n    syncEngineImpl.remoteStore.remoteSyncer.getRemoteKeysForTarget =\r\n        syncEngineGetRemoteKeysForTarget.bind(null, syncEngineImpl);\r\n    syncEngineImpl.remoteStore.remoteSyncer.rejectListen =\r\n        syncEngineRejectListen.bind(null, syncEngineImpl);\r\n    syncEngineImpl.syncEngineListener.onWatchChange =\r\n        eventManagerOnWatchChange.bind(null, syncEngineImpl.eventManager);\r\n    syncEngineImpl.syncEngineListener.onWatchError =\r\n        eventManagerOnWatchError.bind(null, syncEngineImpl.eventManager);\r\n    return syncEngineImpl;\r\n}\r\nfunction syncEngineEnsureWriteCallbacks(syncEngine) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    syncEngineImpl.remoteStore.remoteSyncer.applySuccessfulWrite =\r\n        syncEngineApplySuccessfulWrite.bind(null, syncEngineImpl);\r\n    syncEngineImpl.remoteStore.remoteSyncer.rejectFailedWrite =\r\n        syncEngineRejectFailedWrite.bind(null, syncEngineImpl);\r\n    return syncEngineImpl;\r\n}\r\n/**\r\n * Loads a Firestore bundle into the SDK. The returned promise resolves when\r\n * the bundle finished loading.\r\n *\r\n * @param syncEngine - SyncEngine to use.\r\n * @param bundleReader - Bundle to load into the SDK.\r\n * @param task - LoadBundleTask used to update the loading progress to public API.\r\n */\r\nfunction syncEngineLoadBundle(syncEngine, bundleReader, task) {\r\n    const syncEngineImpl = debugCast(syncEngine);\r\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\r\n    loadBundleImpl(syncEngineImpl, bundleReader, task).then(() => {\r\n        syncEngineImpl.sharedClientState.notifyBundleLoaded();\r\n    });\r\n}\r\nasync function loadBundleImpl(syncEngine, reader, task) {\r\n    try {\r\n        const metadata = await reader.getMetadata();\r\n        const skip = await localStoreHasNewerBundle(syncEngine.localStore, metadata);\r\n        if (skip) {\r\n            await reader.close();\r\n            task._completeWith(bundleSuccessProgress(metadata));\r\n            return;\r\n        }\r\n        task._updateProgress(bundleInitialProgress(metadata));\r\n        const loader = new BundleLoader(metadata, syncEngine.localStore, reader.serializer);\r\n        let element = await reader.nextElement();\r\n        while (element) {\r\n            ;\r\n            const progress = await loader.addSizedElement(element);\r\n            if (progress) {\r\n                task._updateProgress(progress);\r\n            }\r\n            element = await reader.nextElement();\r\n        }\r\n        const result = await loader.complete();\r\n        // TODO(b/160876443): This currently raises snapshots with\r\n        // `fromCache=false` if users already listen to some queries and bundles\r\n        // has newer version.\r\n        await syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngine, result.changedDocs, \r\n        /* remoteEvent */ undefined);\r\n        // Save metadata, so loading the same bundle will skip.\r\n        await localStoreSaveBundle(syncEngine.localStore, metadata);\r\n        task._completeWith(result.progress);\r\n    }\r\n    catch (e) {\r\n        logWarn(LOG_TAG$3, `Loading bundle failed with ${e}`);\r\n        task._failWith(e);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Provides all components needed for Firestore with in-memory persistence.\r\n * Uses EagerGC garbage collection.\r\n */\r\nclass MemoryOfflineComponentProvider {\r\n    constructor() {\r\n        this.synchronizeTabs = false;\r\n    }\r\n    async initialize(cfg) {\r\n        this.serializer = newSerializer(cfg.databaseInfo.databaseId);\r\n        this.sharedClientState = this.createSharedClientState(cfg);\r\n        this.persistence = this.createPersistence(cfg);\r\n        await this.persistence.start();\r\n        this.gcScheduler = this.createGarbageCollectionScheduler(cfg);\r\n        this.localStore = this.createLocalStore(cfg);\r\n    }\r\n    createGarbageCollectionScheduler(cfg) {\r\n        return null;\r\n    }\r\n    createLocalStore(cfg) {\r\n        return newLocalStore(this.persistence, new QueryEngine(), cfg.initialUser, this.serializer);\r\n    }\r\n    createPersistence(cfg) {\r\n        return new MemoryPersistence(MemoryEagerDelegate.factory, this.serializer);\r\n    }\r\n    createSharedClientState(cfg) {\r\n        return new MemorySharedClientState();\r\n    }\r\n    async terminate() {\r\n        if (this.gcScheduler) {\r\n            this.gcScheduler.stop();\r\n        }\r\n        await this.sharedClientState.shutdown();\r\n        await this.persistence.shutdown();\r\n    }\r\n}\r\n/**\r\n * Provides all components needed for Firestore with IndexedDB persistence.\r\n */\r\nclass IndexedDbOfflineComponentProvider extends MemoryOfflineComponentProvider {\r\n    constructor(onlineComponentProvider, cacheSizeBytes, forceOwnership) {\r\n        super();\r\n        this.onlineComponentProvider = onlineComponentProvider;\r\n        this.cacheSizeBytes = cacheSizeBytes;\r\n        this.forceOwnership = forceOwnership;\r\n        this.synchronizeTabs = false;\r\n    }\r\n    async initialize(cfg) {\r\n        await super.initialize(cfg);\r\n        await localStoreSynchronizeLastDocumentChangeReadTime(this.localStore);\r\n        await this.onlineComponentProvider.initialize(this, cfg);\r\n        // Enqueue writes from a previous session\r\n        await syncEngineEnsureWriteCallbacks(this.onlineComponentProvider.syncEngine);\r\n        await fillWritePipeline(this.onlineComponentProvider.remoteStore);\r\n        // NOTE: This will immediately call the listener, so we make sure to\r\n        // set it after localStore / remoteStore are started.\r\n        await this.persistence.setPrimaryStateListener(() => {\r\n            if (this.gcScheduler && !this.gcScheduler.started) {\r\n                this.gcScheduler.start(this.localStore);\r\n            }\r\n            return Promise.resolve();\r\n        });\r\n    }\r\n    createLocalStore(cfg) {\r\n        return newLocalStore(this.persistence, new QueryEngine(), cfg.initialUser, this.serializer);\r\n    }\r\n    createGarbageCollectionScheduler(cfg) {\r\n        const garbageCollector = this.persistence.referenceDelegate.garbageCollector;\r\n        return new LruScheduler(garbageCollector, cfg.asyncQueue);\r\n    }\r\n    createPersistence(cfg) {\r\n        const persistenceKey = indexedDbStoragePrefix(cfg.databaseInfo.databaseId, cfg.databaseInfo.persistenceKey);\r\n        const lruParams = this.cacheSizeBytes !== undefined\r\n            ? LruParams.withCacheSize(this.cacheSizeBytes)\r\n            : LruParams.DEFAULT;\r\n        return new IndexedDbPersistence(this.synchronizeTabs, persistenceKey, cfg.clientId, lruParams, cfg.asyncQueue, getWindow(), getDocument(), this.serializer, this.sharedClientState, !!this.forceOwnership);\r\n    }\r\n    createSharedClientState(cfg) {\r\n        return new MemorySharedClientState();\r\n    }\r\n}\r\n/**\r\n * Provides all components needed for Firestore with multi-tab IndexedDB\r\n * persistence.\r\n *\r\n * In the legacy client, this provider is used to provide both multi-tab and\r\n * non-multi-tab persistence since we cannot tell at build time whether\r\n * `synchronizeTabs` will be enabled.\r\n */\r\nclass MultiTabOfflineComponentProvider extends IndexedDbOfflineComponentProvider {\r\n    constructor(onlineComponentProvider, cacheSizeBytes) {\r\n        super(onlineComponentProvider, cacheSizeBytes, /* forceOwnership= */ false);\r\n        this.onlineComponentProvider = onlineComponentProvider;\r\n        this.cacheSizeBytes = cacheSizeBytes;\r\n        this.synchronizeTabs = true;\r\n    }\r\n    async initialize(cfg) {\r\n        await super.initialize(cfg);\r\n        const syncEngine = this.onlineComponentProvider.syncEngine;\r\n        if (this.sharedClientState instanceof WebStorageSharedClientState) {\r\n            this.sharedClientState.syncEngine = {\r\n                applyBatchState: syncEngineApplyBatchState.bind(null, syncEngine),\r\n                applyTargetState: syncEngineApplyTargetState.bind(null, syncEngine),\r\n                applyActiveTargetsChange: syncEngineApplyActiveTargetsChange.bind(null, syncEngine),\r\n                getActiveClients: syncEngineGetActiveClients.bind(null, syncEngine),\r\n                synchronizeWithChangedDocuments: syncEngineSynchronizeWithChangedDocuments.bind(null, syncEngine)\r\n            };\r\n            await this.sharedClientState.start();\r\n        }\r\n        // NOTE: This will immediately call the listener, so we make sure to\r\n        // set it after localStore / remoteStore are started.\r\n        await this.persistence.setPrimaryStateListener(async (isPrimary) => {\r\n            await syncEngineApplyPrimaryState(this.onlineComponentProvider.syncEngine, isPrimary);\r\n            if (this.gcScheduler) {\r\n                if (isPrimary && !this.gcScheduler.started) {\r\n                    this.gcScheduler.start(this.localStore);\r\n                }\r\n                else if (!isPrimary) {\r\n                    this.gcScheduler.stop();\r\n                }\r\n            }\r\n        });\r\n    }\r\n    createSharedClientState(cfg) {\r\n        const window = getWindow();\r\n        if (!WebStorageSharedClientState.isAvailable(window)) {\r\n            throw new FirestoreError(Code.UNIMPLEMENTED, 'IndexedDB persistence is only available on platforms that support LocalStorage.');\r\n        }\r\n        const persistenceKey = indexedDbStoragePrefix(cfg.databaseInfo.databaseId, cfg.databaseInfo.persistenceKey);\r\n        return new WebStorageSharedClientState(window, cfg.asyncQueue, persistenceKey, cfg.clientId, cfg.initialUser);\r\n    }\r\n}\r\n/**\r\n * Initializes and wires the components that are needed to interface with the\r\n * network.\r\n */\r\nclass OnlineComponentProvider {\r\n    async initialize(offlineComponentProvider, cfg) {\r\n        if (this.localStore) {\r\n            // OnlineComponentProvider may get initialized multiple times if\r\n            // multi-tab persistence is used.\r\n            return;\r\n        }\r\n        this.localStore = offlineComponentProvider.localStore;\r\n        this.sharedClientState = offlineComponentProvider.sharedClientState;\r\n        this.datastore = this.createDatastore(cfg);\r\n        this.remoteStore = this.createRemoteStore(cfg);\r\n        this.eventManager = this.createEventManager(cfg);\r\n        this.syncEngine = this.createSyncEngine(cfg, \r\n        /* startAsPrimary=*/ !offlineComponentProvider.synchronizeTabs);\r\n        this.sharedClientState.onlineStateHandler = onlineState => syncEngineApplyOnlineStateChange(this.syncEngine, onlineState, 1 /* SharedClientState */);\r\n        this.remoteStore.remoteSyncer.handleCredentialChange =\r\n            syncEngineHandleCredentialChange.bind(null, this.syncEngine);\r\n        await remoteStoreApplyPrimaryState(this.remoteStore, this.syncEngine.isPrimaryClient);\r\n    }\r\n    createEventManager(cfg) {\r\n        return newEventManager();\r\n    }\r\n    createDatastore(cfg) {\r\n        const serializer = newSerializer(cfg.databaseInfo.databaseId);\r\n        const connection = newConnection(cfg.databaseInfo);\r\n        return newDatastore(cfg.credentials, connection, serializer);\r\n    }\r\n    createRemoteStore(cfg) {\r\n        return newRemoteStore(this.localStore, this.datastore, cfg.asyncQueue, onlineState => syncEngineApplyOnlineStateChange(this.syncEngine, onlineState, 0 /* RemoteStore */), newConnectivityMonitor());\r\n    }\r\n    createSyncEngine(cfg, startAsPrimary) {\r\n        return newSyncEngine(this.localStore, this.remoteStore, this.eventManager, this.sharedClientState, cfg.initialUser, cfg.maxConcurrentLimboResolutions, startAsPrimary);\r\n    }\r\n    terminate() {\r\n        return remoteStoreShutdown(this.remoteStore);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * How many bytes to read each time when `ReadableStreamReader.read()` is\r\n * called. Only applicable for byte streams that we control (e.g. those backed\r\n * by an UInt8Array).\r\n */\r\nconst DEFAULT_BYTES_PER_READ = 10240;\r\n/**\r\n * Builds a `ByteStreamReader` from a UInt8Array.\r\n * @param source - The data source to use.\r\n * @param bytesPerRead - How many bytes each `read()` from the returned reader\r\n *        will read.\r\n */\r\nfunction toByteStreamReaderHelper(source, bytesPerRead = DEFAULT_BYTES_PER_READ) {\r\n    let readFrom = 0;\r\n    // The TypeScript definition for ReadableStreamReader changed. We use\r\n    // `any` here to allow this code to compile with different versions.\r\n    // See https://github.com/microsoft/TypeScript/issues/42970\r\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n    const reader = {\r\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        async read() {\r\n            if (readFrom < source.byteLength) {\r\n                const result = {\r\n                    value: source.slice(readFrom, readFrom + bytesPerRead),\r\n                    done: false\r\n                };\r\n                readFrom += bytesPerRead;\r\n                return result;\r\n            }\r\n            return { done: true };\r\n        },\r\n        async cancel() { },\r\n        releaseLock() { },\r\n        closed: Promise.reject('unimplemented')\r\n    };\r\n    return reader;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction validateNonEmptyArgument(functionName, argumentName, argument) {\r\n    if (!argument) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Function ${functionName}() cannot be called with an empty ${argumentName}.`);\r\n    }\r\n}\r\n/**\r\n * Validates that two boolean options are not set at the same time.\r\n * @internal\r\n */\r\nfunction validateIsNotUsedTogether(optionName1, argument1, optionName2, argument2) {\r\n    if (argument1 === true && argument2 === true) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `${optionName1} and ${optionName2} cannot be used together.`);\r\n    }\r\n}\r\n/**\r\n * Validates that `path` refers to a document (indicated by the fact it contains\r\n * an even numbers of segments).\r\n */\r\nfunction validateDocumentPath(path) {\r\n    if (!DocumentKey.isDocumentKey(path)) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid document reference. Document references must have an even number of segments, but ${path} has ${path.length}.`);\r\n    }\r\n}\r\n/**\r\n * Validates that `path` refers to a collection (indicated by the fact it\r\n * contains an odd numbers of segments).\r\n */\r\nfunction validateCollectionPath(path) {\r\n    if (DocumentKey.isDocumentKey(path)) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid collection reference. Collection references must have an odd number of segments, but ${path} has ${path.length}.`);\r\n    }\r\n}\r\n/**\r\n * Returns true if it's a non-null object without a custom prototype\r\n * (i.e. excludes Array, Date, etc.).\r\n */\r\nfunction isPlainObject(input) {\r\n    return (typeof input === 'object' &&\r\n        input !== null &&\r\n        (Object.getPrototypeOf(input) === Object.prototype ||\r\n            Object.getPrototypeOf(input) === null));\r\n}\r\n/** Returns a string describing the type / value of the provided input. */\r\nfunction valueDescription(input) {\r\n    if (input === undefined) {\r\n        return 'undefined';\r\n    }\r\n    else if (input === null) {\r\n        return 'null';\r\n    }\r\n    else if (typeof input === 'string') {\r\n        if (input.length > 20) {\r\n            input = `${input.substring(0, 20)}...`;\r\n        }\r\n        return JSON.stringify(input);\r\n    }\r\n    else if (typeof input === 'number' || typeof input === 'boolean') {\r\n        return '' + input;\r\n    }\r\n    else if (typeof input === 'object') {\r\n        if (input instanceof Array) {\r\n            return 'an array';\r\n        }\r\n        else {\r\n            const customObjectName = tryGetCustomObjectType(input);\r\n            if (customObjectName) {\r\n                return `a custom ${customObjectName} object`;\r\n            }\r\n            else {\r\n                return 'an object';\r\n            }\r\n        }\r\n    }\r\n    else if (typeof input === 'function') {\r\n        return 'a function';\r\n    }\r\n    else {\r\n        return fail();\r\n    }\r\n}\r\n/** try to get the constructor name for an object. */\r\nfunction tryGetCustomObjectType(input) {\r\n    if (input.constructor) {\r\n        return input.constructor.name;\r\n    }\r\n    return null;\r\n}\r\n/**\r\n * Casts `obj` to `T`, optionally unwrapping Compat types to expose the\r\n * underlying instance. Throws if  `obj` is not an instance of `T`.\r\n *\r\n * This cast is used in the Lite and Full SDK to verify instance types for\r\n * arguments passed to the public API.\r\n * @internal\r\n */\r\nfunction cast(obj, \r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nconstructor) {\r\n    if ('_delegate' in obj) {\r\n        // Unwrap Compat types\r\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        obj = obj._delegate;\r\n    }\r\n    if (!(obj instanceof constructor)) {\r\n        if (constructor.name === obj.constructor.name) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Type does not match the expected instance. Did you pass a ' +\r\n                `reference from a different Firestore SDK?`);\r\n        }\r\n        else {\r\n            const description = valueDescription(obj);\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, `Expected type '${constructor.name}', but it was: ${description}`);\r\n        }\r\n    }\r\n    return obj;\r\n}\r\nfunction validatePositiveNumber(functionName, n) {\r\n    if (n <= 0) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Function ${functionName}() requires a positive number, but it was: ${n}.`);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * On Node, only supported data source is a `Uint8Array` for now.\r\n */\r\nfunction toByteStreamReader(source, bytesPerRead) {\r\n    if (!(source instanceof Uint8Array)) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `NodePlatform.toByteStreamReader expects source to be Uint8Array, got ${valueDescription(source)}`);\r\n    }\r\n    return toByteStreamReaderHelper(source, bytesPerRead);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/*\r\n * A wrapper implementation of Observer<T> that will dispatch events\r\n * asynchronously. To allow immediate silencing, a mute call is added which\r\n * causes events scheduled to no longer be raised.\r\n */\r\nclass AsyncObserver {\r\n    constructor(observer) {\r\n        this.observer = observer;\r\n        /**\r\n         * When set to true, will not raise future events. Necessary to deal with\r\n         * async detachment of listener.\r\n         */\r\n        this.muted = false;\r\n    }\r\n    next(value) {\r\n        if (this.observer.next) {\r\n            this.scheduleEvent(this.observer.next, value);\r\n        }\r\n    }\r\n    error(error) {\r\n        if (this.observer.error) {\r\n            this.scheduleEvent(this.observer.error, error);\r\n        }\r\n        else {\r\n            console.error('Uncaught Error in snapshot listener:', error);\r\n        }\r\n    }\r\n    mute() {\r\n        this.muted = true;\r\n    }\r\n    scheduleEvent(eventHandler, event) {\r\n        if (!this.muted) {\r\n            setTimeout(() => {\r\n                if (!this.muted) {\r\n                    eventHandler(event);\r\n                }\r\n            }, 0);\r\n        }\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A complete element in the bundle stream, together with the byte length it\r\n * occupies in the stream.\r\n */\r\nclass SizedBundleElement {\r\n    constructor(payload, \r\n    // How many bytes this element takes to store in the bundle.\r\n    byteLength) {\r\n        this.payload = payload;\r\n        this.byteLength = byteLength;\r\n    }\r\n    isBundleMetadata() {\r\n        return 'metadata' in this.payload;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A class representing a bundle.\r\n *\r\n * Takes a bundle stream or buffer, and presents abstractions to read bundled\r\n * elements out of the underlying content.\r\n */\r\nclass BundleReaderImpl {\r\n    constructor(\r\n    /** The reader to read from underlying binary bundle data source. */\r\n    reader, serializer) {\r\n        this.reader = reader;\r\n        this.serializer = serializer;\r\n        /** Cached bundle metadata. */\r\n        this.metadata = new Deferred();\r\n        /**\r\n         * Internal buffer to hold bundle content, accumulating incomplete element\r\n         * content.\r\n         */\r\n        this.buffer = new Uint8Array();\r\n        this.textDecoder = newTextDecoder();\r\n        // Read the metadata (which is the first element).\r\n        this.nextElementImpl().then(element => {\r\n            if (element && element.isBundleMetadata()) {\r\n                this.metadata.resolve(element.payload.metadata);\r\n            }\r\n            else {\r\n                this.metadata.reject(new Error(`The first element of the bundle is not a metadata, it is\n             ${JSON.stringify(element === null || element === void 0 ? void 0 : element.payload)}`));\r\n            }\r\n        }, error => this.metadata.reject(error));\r\n    }\r\n    close() {\r\n        return this.reader.cancel();\r\n    }\r\n    async getMetadata() {\r\n        return this.metadata.promise;\r\n    }\r\n    async nextElement() {\r\n        // Makes sure metadata is read before proceeding.\r\n        await this.getMetadata();\r\n        return this.nextElementImpl();\r\n    }\r\n    /**\r\n     * Reads from the head of internal buffer, and pulling more data from\r\n     * underlying stream if a complete element cannot be found, until an\r\n     * element(including the prefixed length and the JSON string) is found.\r\n     *\r\n     * Once a complete element is read, it is dropped from internal buffer.\r\n     *\r\n     * Returns either the bundled element, or null if we have reached the end of\r\n     * the stream.\r\n     */\r\n    async nextElementImpl() {\r\n        const lengthBuffer = await this.readLength();\r\n        if (lengthBuffer === null) {\r\n            return null;\r\n        }\r\n        const lengthString = this.textDecoder.decode(lengthBuffer);\r\n        const length = Number(lengthString);\r\n        if (isNaN(length)) {\r\n            this.raiseError(`length string (${lengthString}) is not valid number`);\r\n        }\r\n        const jsonString = await this.readJsonString(length);\r\n        return new SizedBundleElement(JSON.parse(jsonString), lengthBuffer.length + length);\r\n    }\r\n    /** First index of '{' from the underlying buffer. */\r\n    indexOfOpenBracket() {\r\n        return this.buffer.findIndex(v => v === '{'.charCodeAt(0));\r\n    }\r\n    /**\r\n     * Reads from the beginning of the internal buffer, until the first '{', and\r\n     * return the content.\r\n     *\r\n     * If reached end of the stream, returns a null.\r\n     */\r\n    async readLength() {\r\n        while (this.indexOfOpenBracket() < 0) {\r\n            const done = await this.pullMoreDataToBuffer();\r\n            if (done) {\r\n                break;\r\n            }\r\n        }\r\n        // Broke out of the loop because underlying stream is closed, and there\r\n        // happens to be no more data to process.\r\n        if (this.buffer.length === 0) {\r\n            return null;\r\n        }\r\n        const position = this.indexOfOpenBracket();\r\n        // Broke out of the loop because underlying stream is closed, but still\r\n        // cannot find an open bracket.\r\n        if (position < 0) {\r\n            this.raiseError('Reached the end of bundle when a length string is expected.');\r\n        }\r\n        const result = this.buffer.slice(0, position);\r\n        // Update the internal buffer to drop the read length.\r\n        this.buffer = this.buffer.slice(position);\r\n        return result;\r\n    }\r\n    /**\r\n     * Reads from a specified position from the internal buffer, for a specified\r\n     * number of bytes, pulling more data from the underlying stream if needed.\r\n     *\r\n     * Returns a string decoded from the read bytes.\r\n     */\r\n    async readJsonString(length) {\r\n        while (this.buffer.length < length) {\r\n            const done = await this.pullMoreDataToBuffer();\r\n            if (done) {\r\n                this.raiseError('Reached the end of bundle when more is expected.');\r\n            }\r\n        }\r\n        const result = this.textDecoder.decode(this.buffer.slice(0, length));\r\n        // Update the internal buffer to drop the read json string.\r\n        this.buffer = this.buffer.slice(length);\r\n        return result;\r\n    }\r\n    raiseError(message) {\r\n        // eslint-disable-next-line @typescript-eslint/no-floating-promises\r\n        this.reader.cancel();\r\n        throw new Error(`Invalid bundle format: ${message}`);\r\n    }\r\n    /**\r\n     * Pulls more data from underlying stream to internal buffer.\r\n     * Returns a boolean indicating whether the stream is finished.\r\n     */\r\n    async pullMoreDataToBuffer() {\r\n        const result = await this.reader.read();\r\n        if (!result.done) {\r\n            const newBuffer = new Uint8Array(this.buffer.length + result.value.length);\r\n            newBuffer.set(this.buffer);\r\n            newBuffer.set(result.value, this.buffer.length);\r\n            this.buffer = newBuffer;\r\n        }\r\n        return result.done;\r\n    }\r\n}\r\nfunction newBundleReader(reader, serializer) {\r\n    return new BundleReaderImpl(reader, serializer);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Internal transaction object responsible for accumulating the mutations to\r\n * perform and the base versions for any documents read.\r\n */\r\nclass Transaction$2 {\r\n    constructor(datastore) {\r\n        this.datastore = datastore;\r\n        // The version of each document that was read during this transaction.\r\n        this.readVersions = new Map();\r\n        this.mutations = [];\r\n        this.committed = false;\r\n        /**\r\n         * A deferred usage error that occurred previously in this transaction that\r\n         * will cause the transaction to fail once it actually commits.\r\n         */\r\n        this.lastWriteError = null;\r\n        /**\r\n         * Set of documents that have been written in the transaction.\r\n         *\r\n         * When there's more than one write to the same key in a transaction, any\r\n         * writes after the first are handled differently.\r\n         */\r\n        this.writtenDocs = new Set();\r\n    }\r\n    async lookup(keys) {\r\n        this.ensureCommitNotCalled();\r\n        if (this.mutations.length > 0) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Firestore transactions require all reads to be executed before all writes.');\r\n        }\r\n        const docs = await invokeBatchGetDocumentsRpc(this.datastore, keys);\r\n        docs.forEach(doc => this.recordVersion(doc));\r\n        return docs;\r\n    }\r\n    set(key, data) {\r\n        this.write(data.toMutation(key, this.precondition(key)));\r\n        this.writtenDocs.add(key.toString());\r\n    }\r\n    update(key, data) {\r\n        try {\r\n            this.write(data.toMutation(key, this.preconditionForUpdate(key)));\r\n        }\r\n        catch (e) {\r\n            this.lastWriteError = e;\r\n        }\r\n        this.writtenDocs.add(key.toString());\r\n    }\r\n    delete(key) {\r\n        this.write(new DeleteMutation(key, this.precondition(key)));\r\n        this.writtenDocs.add(key.toString());\r\n    }\r\n    async commit() {\r\n        this.ensureCommitNotCalled();\r\n        if (this.lastWriteError) {\r\n            throw this.lastWriteError;\r\n        }\r\n        const unwritten = this.readVersions;\r\n        // For each mutation, note that the doc was written.\r\n        this.mutations.forEach(mutation => {\r\n            unwritten.delete(mutation.key.toString());\r\n        });\r\n        // For each document that was read but not written to, we want to perform\r\n        // a `verify` operation.\r\n        unwritten.forEach((_, path) => {\r\n            const key = DocumentKey.fromPath(path);\r\n            this.mutations.push(new VerifyMutation(key, this.precondition(key)));\r\n        });\r\n        await invokeCommitRpc(this.datastore, this.mutations);\r\n        this.committed = true;\r\n    }\r\n    recordVersion(doc) {\r\n        let docVersion;\r\n        if (doc.isFoundDocument()) {\r\n            docVersion = doc.version;\r\n        }\r\n        else if (doc.isNoDocument()) {\r\n            // For deleted docs, we must use baseVersion 0 when we overwrite them.\r\n            docVersion = SnapshotVersion.min();\r\n        }\r\n        else {\r\n            throw fail();\r\n        }\r\n        const existingVersion = this.readVersions.get(doc.key.toString());\r\n        if (existingVersion) {\r\n            if (!docVersion.isEqual(existingVersion)) {\r\n                // This transaction will fail no matter what.\r\n                throw new FirestoreError(Code.ABORTED, 'Document version changed between two reads.');\r\n            }\r\n        }\r\n        else {\r\n            this.readVersions.set(doc.key.toString(), docVersion);\r\n        }\r\n    }\r\n    /**\r\n     * Returns the version of this document when it was read in this transaction,\r\n     * as a precondition, or no precondition if it was not read.\r\n     */\r\n    precondition(key) {\r\n        const version = this.readVersions.get(key.toString());\r\n        if (!this.writtenDocs.has(key.toString()) && version) {\r\n            return Precondition.updateTime(version);\r\n        }\r\n        else {\r\n            return Precondition.none();\r\n        }\r\n    }\r\n    /**\r\n     * Returns the precondition for a document if the operation is an update.\r\n     */\r\n    preconditionForUpdate(key) {\r\n        const version = this.readVersions.get(key.toString());\r\n        // The first time a document is written, we want to take into account the\r\n        // read time and existence\r\n        if (!this.writtenDocs.has(key.toString()) && version) {\r\n            if (version.isEqual(SnapshotVersion.min())) {\r\n                // The document doesn't exist, so fail the transaction.\r\n                // This has to be validated locally because you can't send a\r\n                // precondition that a document does not exist without changing the\r\n                // semantics of the backend write to be an insert. This is the reverse\r\n                // of what we want, since we want to assert that the document doesn't\r\n                // exist but then send the update and have it fail. Since we can't\r\n                // express that to the backend, we have to validate locally.\r\n                // Note: this can change once we can send separate verify writes in the\r\n                // transaction.\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, \"Can't update a document that doesn't exist.\");\r\n            }\r\n            // Document exists, base precondition on document update time.\r\n            return Precondition.updateTime(version);\r\n        }\r\n        else {\r\n            // Document was not read, so we just use the preconditions for a blind\r\n            // update.\r\n            return Precondition.exists(true);\r\n        }\r\n    }\r\n    write(mutation) {\r\n        this.ensureCommitNotCalled();\r\n        this.mutations.push(mutation);\r\n    }\r\n    ensureCommitNotCalled() {\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst DEFAULT_MAX_ATTEMPTS_COUNT = 5;\r\n/**\r\n * TransactionRunner encapsulates the logic needed to run and retry transactions\r\n * with backoff.\r\n */\r\nclass TransactionRunner {\r\n    constructor(asyncQueue, datastore, updateFunction, deferred) {\r\n        this.asyncQueue = asyncQueue;\r\n        this.datastore = datastore;\r\n        this.updateFunction = updateFunction;\r\n        this.deferred = deferred;\r\n        this.attemptsRemaining = DEFAULT_MAX_ATTEMPTS_COUNT;\r\n        this.backoff = new ExponentialBackoff(this.asyncQueue, \"transaction_retry\" /* TransactionRetry */);\r\n    }\r\n    /** Runs the transaction and sets the result on deferred. */\r\n    run() {\r\n        this.attemptsRemaining -= 1;\r\n        this.runWithBackOff();\r\n    }\r\n    runWithBackOff() {\r\n        this.backoff.backoffAndRun(async () => {\r\n            const transaction = new Transaction$2(this.datastore);\r\n            const userPromise = this.tryRunUpdateFunction(transaction);\r\n            if (userPromise) {\r\n                userPromise\r\n                    .then(result => {\r\n                    this.asyncQueue.enqueueAndForget(() => {\r\n                        return transaction\r\n                            .commit()\r\n                            .then(() => {\r\n                            this.deferred.resolve(result);\r\n                        })\r\n                            .catch(commitError => {\r\n                            this.handleTransactionError(commitError);\r\n                        });\r\n                    });\r\n                })\r\n                    .catch(userPromiseError => {\r\n                    this.handleTransactionError(userPromiseError);\r\n                });\r\n            }\r\n        });\r\n    }\r\n    tryRunUpdateFunction(transaction) {\r\n        try {\r\n            const userPromise = this.updateFunction(transaction);\r\n            if (isNullOrUndefined(userPromise) ||\r\n                !userPromise.catch ||\r\n                !userPromise.then) {\r\n                this.deferred.reject(Error('Transaction callback must return a Promise'));\r\n                return null;\r\n            }\r\n            return userPromise;\r\n        }\r\n        catch (error) {\r\n            // Do not retry errors thrown by user provided updateFunction.\r\n            this.deferred.reject(error);\r\n            return null;\r\n        }\r\n    }\r\n    handleTransactionError(error) {\r\n        if (this.attemptsRemaining > 0 && this.isRetryableTransactionError(error)) {\r\n            this.attemptsRemaining -= 1;\r\n            this.asyncQueue.enqueueAndForget(() => {\r\n                this.runWithBackOff();\r\n                return Promise.resolve();\r\n            });\r\n        }\r\n        else {\r\n            this.deferred.reject(error);\r\n        }\r\n    }\r\n    isRetryableTransactionError(error) {\r\n        if (error.name === 'FirebaseError') {\r\n            // In transactions, the backend will fail outdated reads with FAILED_PRECONDITION and\r\n            // non-matching document versions with ABORTED. These errors should be retried.\r\n            const code = error.code;\r\n            return (code === 'aborted' ||\r\n                code === 'failed-precondition' ||\r\n                !isPermanentError(code));\r\n        }\r\n        return false;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$2 = 'FirestoreClient';\r\nconst MAX_CONCURRENT_LIMBO_RESOLUTIONS = 100;\r\n/**\r\n * FirestoreClient is a top-level class that constructs and owns all of the\r\n * pieces of the client SDK architecture. It is responsible for creating the\r\n * async queue that is shared by all of the other components in the system.\r\n */\r\nclass FirestoreClient {\r\n    constructor(credentials, \r\n    /**\r\n     * Asynchronous queue responsible for all of our internal processing. When\r\n     * we get incoming work from the user (via public API) or the network\r\n     * (incoming GRPC messages), we should always schedule onto this queue.\r\n     * This ensures all of our work is properly serialized (e.g. we don't\r\n     * start processing a new operation while the previous one is waiting for\r\n     * an async I/O to complete).\r\n     */\r\n    asyncQueue, databaseInfo) {\r\n        this.credentials = credentials;\r\n        this.asyncQueue = asyncQueue;\r\n        this.databaseInfo = databaseInfo;\r\n        this.user = User.UNAUTHENTICATED;\r\n        this.clientId = AutoId.newId();\r\n        this.credentialListener = () => Promise.resolve();\r\n        this.credentials.start(asyncQueue, async (user) => {\r\n            logDebug(LOG_TAG$2, 'Received user=', user.uid);\r\n            await this.credentialListener(user);\r\n            this.user = user;\r\n        });\r\n    }\r\n    async getConfiguration() {\r\n        return {\r\n            asyncQueue: this.asyncQueue,\r\n            databaseInfo: this.databaseInfo,\r\n            clientId: this.clientId,\r\n            credentials: this.credentials,\r\n            initialUser: this.user,\r\n            maxConcurrentLimboResolutions: MAX_CONCURRENT_LIMBO_RESOLUTIONS\r\n        };\r\n    }\r\n    setCredentialChangeListener(listener) {\r\n        this.credentialListener = listener;\r\n    }\r\n    /**\r\n     * Checks that the client has not been terminated. Ensures that other methods on\r\n     * this class cannot be called after the client is terminated.\r\n     */\r\n    verifyNotTerminated() {\r\n        if (this.asyncQueue.isShuttingDown) {\r\n            throw new FirestoreError(Code.FAILED_PRECONDITION, 'The client has already been terminated.');\r\n        }\r\n    }\r\n    terminate() {\r\n        this.asyncQueue.enterRestrictedMode();\r\n        const deferred = new Deferred();\r\n        this.asyncQueue.enqueueAndForgetEvenWhileRestricted(async () => {\r\n            try {\r\n                if (this.onlineComponents) {\r\n                    await this.onlineComponents.terminate();\r\n                }\r\n                if (this.offlineComponents) {\r\n                    await this.offlineComponents.terminate();\r\n                }\r\n                // The credentials provider must be terminated after shutting down the\r\n                // RemoteStore as it will prevent the RemoteStore from retrieving auth\r\n                // tokens.\r\n                this.credentials.shutdown();\r\n                deferred.resolve();\r\n            }\r\n            catch (e) {\r\n                const firestoreError = wrapInUserErrorIfRecoverable(e, `Failed to shutdown persistence`);\r\n                deferred.reject(firestoreError);\r\n            }\r\n        });\r\n        return deferred.promise;\r\n    }\r\n}\r\nasync function setOfflineComponentProvider(client, offlineComponentProvider) {\r\n    client.asyncQueue.verifyOperationInProgress();\r\n    logDebug(LOG_TAG$2, 'Initializing OfflineComponentProvider');\r\n    const configuration = await client.getConfiguration();\r\n    await offlineComponentProvider.initialize(configuration);\r\n    let currentUser = configuration.initialUser;\r\n    client.setCredentialChangeListener(async (user) => {\r\n        if (!currentUser.isEqual(user)) {\r\n            await localStoreHandleUserChange(offlineComponentProvider.localStore, user);\r\n            currentUser = user;\r\n        }\r\n    });\r\n    // When a user calls clearPersistence() in one client, all other clients\r\n    // need to be terminated to allow the delete to succeed.\r\n    offlineComponentProvider.persistence.setDatabaseDeletedListener(() => client.terminate());\r\n    client.offlineComponents = offlineComponentProvider;\r\n}\r\nasync function setOnlineComponentProvider(client, onlineComponentProvider) {\r\n    client.asyncQueue.verifyOperationInProgress();\r\n    const offlineComponentProvider = await ensureOfflineComponents(client);\r\n    logDebug(LOG_TAG$2, 'Initializing OnlineComponentProvider');\r\n    const configuration = await client.getConfiguration();\r\n    await onlineComponentProvider.initialize(offlineComponentProvider, configuration);\r\n    // The CredentialChangeListener of the online component provider takes\r\n    // precedence over the offline component provider.\r\n    client.setCredentialChangeListener(user => remoteStoreHandleCredentialChange(onlineComponentProvider.remoteStore, user));\r\n    client.onlineComponents = onlineComponentProvider;\r\n}\r\nasync function ensureOfflineComponents(client) {\r\n    if (!client.offlineComponents) {\r\n        logDebug(LOG_TAG$2, 'Using default OfflineComponentProvider');\r\n        await setOfflineComponentProvider(client, new MemoryOfflineComponentProvider());\r\n    }\r\n    return client.offlineComponents;\r\n}\r\nasync function ensureOnlineComponents(client) {\r\n    if (!client.onlineComponents) {\r\n        logDebug(LOG_TAG$2, 'Using default OnlineComponentProvider');\r\n        await setOnlineComponentProvider(client, new OnlineComponentProvider());\r\n    }\r\n    return client.onlineComponents;\r\n}\r\nfunction getPersistence(client) {\r\n    return ensureOfflineComponents(client).then(c => c.persistence);\r\n}\r\nfunction getLocalStore(client) {\r\n    return ensureOfflineComponents(client).then(c => c.localStore);\r\n}\r\nfunction getRemoteStore(client) {\r\n    return ensureOnlineComponents(client).then(c => c.remoteStore);\r\n}\r\nfunction getSyncEngine(client) {\r\n    return ensureOnlineComponents(client).then(c => c.syncEngine);\r\n}\r\nfunction getDatastore(client) {\r\n    return ensureOnlineComponents(client).then(c => c.datastore);\r\n}\r\nasync function getEventManager(client) {\r\n    const onlineComponentProvider = await ensureOnlineComponents(client);\r\n    const eventManager = onlineComponentProvider.eventManager;\r\n    eventManager.onListen = syncEngineListen.bind(null, onlineComponentProvider.syncEngine);\r\n    eventManager.onUnlisten = syncEngineUnlisten.bind(null, onlineComponentProvider.syncEngine);\r\n    return eventManager;\r\n}\r\n/** Enables the network connection and re-enqueues all pending operations. */\r\nfunction firestoreClientEnableNetwork(client) {\r\n    return client.asyncQueue.enqueue(async () => {\r\n        const persistence = await getPersistence(client);\r\n        const remoteStore = await getRemoteStore(client);\r\n        persistence.setNetworkEnabled(true);\r\n        return remoteStoreEnableNetwork(remoteStore);\r\n    });\r\n}\r\n/** Disables the network connection. Pending operations will not complete. */\r\nfunction firestoreClientDisableNetwork(client) {\r\n    return client.asyncQueue.enqueue(async () => {\r\n        const persistence = await getPersistence(client);\r\n        const remoteStore = await getRemoteStore(client);\r\n        persistence.setNetworkEnabled(false);\r\n        return remoteStoreDisableNetwork(remoteStore);\r\n    });\r\n}\r\n/**\r\n * Returns a Promise that resolves when all writes that were pending at the time\r\n * this method was called received server acknowledgement. An acknowledgement\r\n * can be either acceptance or rejection.\r\n */\r\nfunction firestoreClientWaitForPendingWrites(client) {\r\n    const deferred = new Deferred();\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const syncEngine = await getSyncEngine(client);\r\n        return syncEngineRegisterPendingWritesCallback(syncEngine, deferred);\r\n    });\r\n    return deferred.promise;\r\n}\r\nfunction firestoreClientListen(client, query, options, observer) {\r\n    const wrappedObserver = new AsyncObserver(observer);\r\n    const listener = new QueryListener(query, wrappedObserver, options);\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const eventManager = await getEventManager(client);\r\n        return eventManagerListen(eventManager, listener);\r\n    });\r\n    return () => {\r\n        wrappedObserver.mute();\r\n        client.asyncQueue.enqueueAndForget(async () => {\r\n            const eventManager = await getEventManager(client);\r\n            return eventManagerUnlisten(eventManager, listener);\r\n        });\r\n    };\r\n}\r\nfunction firestoreClientGetDocumentFromLocalCache(client, docKey) {\r\n    const deferred = new Deferred();\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const localStore = await getLocalStore(client);\r\n        return readDocumentFromCache(localStore, docKey, deferred);\r\n    });\r\n    return deferred.promise;\r\n}\r\nfunction firestoreClientGetDocumentViaSnapshotListener(client, key, options = {}) {\r\n    const deferred = new Deferred();\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const eventManager = await getEventManager(client);\r\n        return readDocumentViaSnapshotListener(eventManager, client.asyncQueue, key, options, deferred);\r\n    });\r\n    return deferred.promise;\r\n}\r\nfunction firestoreClientGetDocumentsFromLocalCache(client, query) {\r\n    const deferred = new Deferred();\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const localStore = await getLocalStore(client);\r\n        return executeQueryFromCache(localStore, query, deferred);\r\n    });\r\n    return deferred.promise;\r\n}\r\nfunction firestoreClientGetDocumentsViaSnapshotListener(client, query, options = {}) {\r\n    const deferred = new Deferred();\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const eventManager = await getEventManager(client);\r\n        return executeQueryViaSnapshotListener(eventManager, client.asyncQueue, query, options, deferred);\r\n    });\r\n    return deferred.promise;\r\n}\r\nfunction firestoreClientWrite(client, mutations) {\r\n    const deferred = new Deferred();\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const syncEngine = await getSyncEngine(client);\r\n        return syncEngineWrite(syncEngine, mutations, deferred);\r\n    });\r\n    return deferred.promise;\r\n}\r\nfunction firestoreClientAddSnapshotsInSyncListener(client, observer) {\r\n    const wrappedObserver = new AsyncObserver(observer);\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const eventManager = await getEventManager(client);\r\n        return addSnapshotsInSyncListener(eventManager, wrappedObserver);\r\n    });\r\n    return () => {\r\n        wrappedObserver.mute();\r\n        client.asyncQueue.enqueueAndForget(async () => {\r\n            const eventManager = await getEventManager(client);\r\n            return removeSnapshotsInSyncListener(eventManager, wrappedObserver);\r\n        });\r\n    };\r\n}\r\n/**\r\n * Takes an updateFunction in which a set of reads and writes can be performed\r\n * atomically. In the updateFunction, the client can read and write values\r\n * using the supplied transaction object. After the updateFunction, all\r\n * changes will be committed. If a retryable error occurs (ex: some other\r\n * client has changed any of the data referenced), then the updateFunction\r\n * will be called again after a backoff. If the updateFunction still fails\r\n * after all retries, then the transaction will be rejected.\r\n *\r\n * The transaction object passed to the updateFunction contains methods for\r\n * accessing documents and collections. Unlike other datastore access, data\r\n * accessed with the transaction will not reflect local changes that have not\r\n * been committed. For this reason, it is required that all reads are\r\n * performed before any writes. Transactions must be performed while online.\r\n */\r\nfunction firestoreClientTransaction(client, updateFunction) {\r\n    const deferred = new Deferred();\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        const datastore = await getDatastore(client);\r\n        new TransactionRunner(client.asyncQueue, datastore, updateFunction, deferred).run();\r\n    });\r\n    return deferred.promise;\r\n}\r\nasync function readDocumentFromCache(localStore, docKey, result) {\r\n    try {\r\n        const document = await localStoreReadDocument(localStore, docKey);\r\n        if (document.isFoundDocument()) {\r\n            result.resolve(document);\r\n        }\r\n        else if (document.isNoDocument()) {\r\n            result.resolve(null);\r\n        }\r\n        else {\r\n            result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get document from cache. (However, this document may ' +\r\n                \"exist on the server. Run again without setting 'source' in \" +\r\n                'the GetOptions to attempt to retrieve the document from the ' +\r\n                'server.)'));\r\n        }\r\n    }\r\n    catch (e) {\r\n        const firestoreError = wrapInUserErrorIfRecoverable(e, `Failed to get document '${docKey} from cache`);\r\n        result.reject(firestoreError);\r\n    }\r\n}\r\n/**\r\n * Retrieves a latency-compensated document from the backend via a\r\n * SnapshotListener.\r\n */\r\nfunction readDocumentViaSnapshotListener(eventManager, asyncQueue, key, options, result) {\r\n    const wrappedObserver = new AsyncObserver({\r\n        next: (snap) => {\r\n            // Remove query first before passing event to user to avoid\r\n            // user actions affecting the now stale query.\r\n            asyncQueue.enqueueAndForget(() => eventManagerUnlisten(eventManager, listener));\r\n            const exists = snap.docs.has(key);\r\n            if (!exists && snap.fromCache) {\r\n                // TODO(dimond): If we're online and the document doesn't\r\n                // exist then we resolve with a doc.exists set to false. If\r\n                // we're offline however, we reject the Promise in this\r\n                // case. Two options: 1) Cache the negative response from\r\n                // the server so we can deliver that even when you're\r\n                // offline 2) Actually reject the Promise in the online case\r\n                // if the document doesn't exist.\r\n                result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get document because the client is offline.'));\r\n            }\r\n            else if (exists &&\r\n                snap.fromCache &&\r\n                options &&\r\n                options.source === 'server') {\r\n                result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get document from server. (However, this ' +\r\n                    'document does exist in the local cache. Run again ' +\r\n                    'without setting source to \"server\" to ' +\r\n                    'retrieve the cached document.)'));\r\n            }\r\n            else {\r\n                result.resolve(snap);\r\n            }\r\n        },\r\n        error: e => result.reject(e)\r\n    });\r\n    const listener = new QueryListener(newQueryForPath(key.path), wrappedObserver, {\r\n        includeMetadataChanges: true,\r\n        waitForSyncWhenOnline: true\r\n    });\r\n    return eventManagerListen(eventManager, listener);\r\n}\r\nasync function executeQueryFromCache(localStore, query, result) {\r\n    try {\r\n        const queryResult = await localStoreExecuteQuery(localStore, query, \r\n        /* usePreviousResults= */ true);\r\n        const view = new View(query, queryResult.remoteKeys);\r\n        const viewDocChanges = view.computeDocChanges(queryResult.documents);\r\n        const viewChange = view.applyChanges(viewDocChanges, \r\n        /* updateLimboDocuments= */ false);\r\n        result.resolve(viewChange.snapshot);\r\n    }\r\n    catch (e) {\r\n        const firestoreError = wrapInUserErrorIfRecoverable(e, `Failed to execute query '${query} against cache`);\r\n        result.reject(firestoreError);\r\n    }\r\n}\r\n/**\r\n * Retrieves a latency-compensated query snapshot from the backend via a\r\n * SnapshotListener.\r\n */\r\nfunction executeQueryViaSnapshotListener(eventManager, asyncQueue, query, options, result) {\r\n    const wrappedObserver = new AsyncObserver({\r\n        next: snapshot => {\r\n            // Remove query first before passing event to user to avoid\r\n            // user actions affecting the now stale query.\r\n            asyncQueue.enqueueAndForget(() => eventManagerUnlisten(eventManager, listener));\r\n            if (snapshot.fromCache && options.source === 'server') {\r\n                result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get documents from server. (However, these ' +\r\n                    'documents may exist in the local cache. Run again ' +\r\n                    'without setting source to \"server\" to ' +\r\n                    'retrieve the cached documents.)'));\r\n            }\r\n            else {\r\n                result.resolve(snapshot);\r\n            }\r\n        },\r\n        error: e => result.reject(e)\r\n    });\r\n    const listener = new QueryListener(query, wrappedObserver, {\r\n        includeMetadataChanges: true,\r\n        waitForSyncWhenOnline: true\r\n    });\r\n    return eventManagerListen(eventManager, listener);\r\n}\r\nfunction firestoreClientLoadBundle(client, databaseId, data, resultTask) {\r\n    const reader = createBundleReader(data, newSerializer(databaseId));\r\n    client.asyncQueue.enqueueAndForget(async () => {\r\n        syncEngineLoadBundle(await getSyncEngine(client), reader, resultTask);\r\n    });\r\n}\r\nfunction firestoreClientGetNamedQuery(client, queryName) {\r\n    return client.asyncQueue.enqueue(async () => localStoreGetNamedQuery(await getLocalStore(client), queryName));\r\n}\r\nfunction createBundleReader(data, serializer) {\r\n    let content;\r\n    if (typeof data === 'string') {\r\n        content = newTextEncoder().encode(data);\r\n    }\r\n    else {\r\n        content = data;\r\n    }\r\n    return newBundleReader(toByteStreamReader(content), serializer);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nclass DatabaseInfo {\r\n    /**\r\n     * Constructs a DatabaseInfo using the provided host, databaseId and\r\n     * persistenceKey.\r\n     *\r\n     * @param databaseId - The database to use.\r\n     * @param appId - The Firebase App Id.\r\n     * @param persistenceKey - A unique identifier for this Firestore's local\r\n     * storage (used in conjunction with the databaseId).\r\n     * @param host - The Firestore backend host to connect to.\r\n     * @param ssl - Whether to use SSL when connecting.\r\n     * @param forceLongPolling - Whether to use the forceLongPolling option\r\n     * when using WebChannel as the network transport.\r\n     * @param autoDetectLongPolling - Whether to use the detectBufferingProxy\r\n     * option when using WebChannel as the network transport.\r\n     * @param useFetchStreams Whether to use the Fetch API instead of\r\n     * XMLHTTPRequest\r\n     */\r\n    constructor(databaseId, appId, persistenceKey, host, ssl, forceLongPolling, autoDetectLongPolling, useFetchStreams) {\r\n        this.databaseId = databaseId;\r\n        this.appId = appId;\r\n        this.persistenceKey = persistenceKey;\r\n        this.host = host;\r\n        this.ssl = ssl;\r\n        this.forceLongPolling = forceLongPolling;\r\n        this.autoDetectLongPolling = autoDetectLongPolling;\r\n        this.useFetchStreams = useFetchStreams;\r\n    }\r\n}\r\n/** The default database name for a project. */\r\nconst DEFAULT_DATABASE_NAME = '(default)';\r\n/**\r\n * Represents the database ID a Firestore client is associated with.\r\n * @internal\r\n */\r\nclass DatabaseId {\r\n    constructor(projectId, database) {\r\n        this.projectId = projectId;\r\n        this.database = database ? database : DEFAULT_DATABASE_NAME;\r\n    }\r\n    get isDefaultDatabase() {\r\n        return this.database === DEFAULT_DATABASE_NAME;\r\n    }\r\n    isEqual(other) {\r\n        return (other instanceof DatabaseId &&\r\n            other.projectId === this.projectId &&\r\n            other.database === this.database);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG$1 = 'ComponentProvider';\r\n/**\r\n * An instance map that ensures only one Datastore exists per Firestore\r\n * instance.\r\n */\r\nconst datastoreInstances = new Map();\r\n/**\r\n * Removes all components associated with the provided instance. Must be called\r\n * when the `Firestore` instance is terminated.\r\n */\r\nfunction removeComponents(firestore) {\r\n    const datastore = datastoreInstances.get(firestore);\r\n    if (datastore) {\r\n        logDebug(LOG_TAG$1, 'Removing Datastore');\r\n        datastoreInstances.delete(firestore);\r\n        datastore.terminate();\r\n    }\r\n}\r\nfunction makeDatabaseInfo(databaseId, appId, persistenceKey, settings) {\r\n    return new DatabaseInfo(databaseId, appId, persistenceKey, settings.host, settings.ssl, settings.experimentalForceLongPolling, settings.experimentalAutoDetectLongPolling, settings.useFetchStreams);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// settings() defaults:\r\nconst DEFAULT_HOST = 'firestore.googleapis.com';\r\nconst DEFAULT_SSL = true;\r\n/**\r\n * A concrete type describing all the values that can be applied via a\r\n * user-supplied `FirestoreSettings` object. This is a separate type so that\r\n * defaults can be supplied and the value can be checked for equality.\r\n */\r\nclass FirestoreSettingsImpl {\r\n    constructor(settings) {\r\n        var _a;\r\n        if (settings.host === undefined) {\r\n            if (settings.ssl !== undefined) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, \"Can't provide ssl option if host option is not set\");\r\n            }\r\n            this.host = DEFAULT_HOST;\r\n            this.ssl = DEFAULT_SSL;\r\n        }\r\n        else {\r\n            this.host = settings.host;\r\n            this.ssl = (_a = settings.ssl) !== null && _a !== void 0 ? _a : DEFAULT_SSL;\r\n        }\r\n        this.credentials = settings.credentials;\r\n        this.ignoreUndefinedProperties = !!settings.ignoreUndefinedProperties;\r\n        if (settings.cacheSizeBytes === undefined) {\r\n            this.cacheSizeBytes = LRU_DEFAULT_CACHE_SIZE_BYTES;\r\n        }\r\n        else {\r\n            if (settings.cacheSizeBytes !== LRU_COLLECTION_DISABLED &&\r\n                settings.cacheSizeBytes < LRU_MINIMUM_CACHE_SIZE_BYTES) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `cacheSizeBytes must be at least ${LRU_MINIMUM_CACHE_SIZE_BYTES}`);\r\n            }\r\n            else {\r\n                this.cacheSizeBytes = settings.cacheSizeBytes;\r\n            }\r\n        }\r\n        this.experimentalForceLongPolling = !!settings.experimentalForceLongPolling;\r\n        this.experimentalAutoDetectLongPolling =\r\n            !!settings.experimentalAutoDetectLongPolling;\r\n        this.useFetchStreams = !!settings.useFetchStreams;\r\n        validateIsNotUsedTogether('experimentalForceLongPolling', settings.experimentalForceLongPolling, 'experimentalAutoDetectLongPolling', settings.experimentalAutoDetectLongPolling);\r\n    }\r\n    isEqual(other) {\r\n        return (this.host === other.host &&\r\n            this.ssl === other.ssl &&\r\n            this.credentials === other.credentials &&\r\n            this.cacheSizeBytes === other.cacheSizeBytes &&\r\n            this.experimentalForceLongPolling ===\r\n                other.experimentalForceLongPolling &&\r\n            this.experimentalAutoDetectLongPolling ===\r\n                other.experimentalAutoDetectLongPolling &&\r\n            this.ignoreUndefinedProperties === other.ignoreUndefinedProperties &&\r\n            this.useFetchStreams === other.useFetchStreams);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * The Cloud Firestore service interface.\r\n *\r\n * Do not call this constructor directly. Instead, use {@link getFirestore}.\r\n */\r\nclass Firestore$1 {\r\n    /** @hideconstructor */\r\n    constructor(databaseIdOrApp, _credentials) {\r\n        this._credentials = _credentials;\r\n        /**\r\n         * Whether it's a Firestore or Firestore Lite instance.\r\n         */\r\n        this.type = 'firestore-lite';\r\n        this._persistenceKey = '(lite)';\r\n        this._settings = new FirestoreSettingsImpl({});\r\n        this._settingsFrozen = false;\r\n        if (databaseIdOrApp instanceof DatabaseId) {\r\n            this._databaseId = databaseIdOrApp;\r\n        }\r\n        else {\r\n            this._app = databaseIdOrApp;\r\n            this._databaseId = databaseIdFromApp(databaseIdOrApp);\r\n        }\r\n    }\r\n    /**\r\n     * The {@link @firebase/app#FirebaseApp} associated with this `Firestore` service\r\n     * instance.\r\n     */\r\n    get app() {\r\n        if (!this._app) {\r\n            throw new FirestoreError(Code.FAILED_PRECONDITION, \"Firestore was not initialized using the Firebase SDK. 'app' is \" +\r\n                'not available');\r\n        }\r\n        return this._app;\r\n    }\r\n    get _initialized() {\r\n        return this._settingsFrozen;\r\n    }\r\n    get _terminated() {\r\n        return this._terminateTask !== undefined;\r\n    }\r\n    _setSettings(settings) {\r\n        if (this._settingsFrozen) {\r\n            throw new FirestoreError(Code.FAILED_PRECONDITION, 'Firestore has already been started and its settings can no longer ' +\r\n                'be changed. You can only modify settings before calling any other ' +\r\n                'methods on a Firestore object.');\r\n        }\r\n        this._settings = new FirestoreSettingsImpl(settings);\r\n        if (settings.credentials !== undefined) {\r\n            this._credentials = makeCredentialsProvider(settings.credentials);\r\n        }\r\n    }\r\n    _getSettings() {\r\n        return this._settings;\r\n    }\r\n    _freezeSettings() {\r\n        this._settingsFrozen = true;\r\n        return this._settings;\r\n    }\r\n    _delete() {\r\n        if (!this._terminateTask) {\r\n            this._terminateTask = this._terminate();\r\n        }\r\n        return this._terminateTask;\r\n    }\r\n    /** Returns a JSON-serializable representation of this `Firestore` instance. */\r\n    toJSON() {\r\n        return {\r\n            app: this._app,\r\n            databaseId: this._databaseId,\r\n            settings: this._settings\r\n        };\r\n    }\r\n    /**\r\n     * Terminates all components used by this client. Subclasses can override\r\n     * this method to clean up their own dependencies, but must also call this\r\n     * method.\r\n     *\r\n     * Only ever called once.\r\n     */\r\n    _terminate() {\r\n        removeComponents(this);\r\n        return Promise.resolve();\r\n    }\r\n}\r\nfunction databaseIdFromApp(app) {\r\n    if (!Object.prototype.hasOwnProperty.apply(app.options, ['projectId'])) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, '\"projectId\" not provided in firebase.initializeApp.');\r\n    }\r\n    return new DatabaseId(app.options.projectId);\r\n}\r\n/**\r\n * Modify this instance to communicate with the Cloud Firestore emulator.\r\n *\r\n * Note: This must be called before this instance has been used to do any\r\n * operations.\r\n *\r\n * @param firestore - The `Firestore` instance to configure to connect to the\r\n * emulator.\r\n * @param host - the emulator host (ex: localhost).\r\n * @param port - the emulator port (ex: 9000).\r\n * @param options.mockUserToken - the mock auth token to use for unit testing\r\n * Security Rules.\r\n */\r\nfunction connectFirestoreEmulator(firestore, host, port, options = {}) {\r\n    var _a;\r\n    firestore = cast(firestore, Firestore$1);\r\n    const settings = firestore._getSettings();\r\n    if (settings.host !== DEFAULT_HOST && settings.host !== host) {\r\n        logWarn('Host has been set in both settings() and useEmulator(), emulator host ' +\r\n            'will be used');\r\n    }\r\n    firestore._setSettings(Object.assign(Object.assign({}, settings), { host: `${host}:${port}`, ssl: false }));\r\n    if (options.mockUserToken) {\r\n        let token;\r\n        let user;\r\n        if (typeof options.mockUserToken === 'string') {\r\n            token = options.mockUserToken;\r\n            user = User.MOCK_USER;\r\n        }\r\n        else {\r\n            // Let createMockUserToken validate first (catches common mistakes like\r\n            // invalid field \"uid\" and missing field \"sub\" / \"user_id\".)\r\n            token = createMockUserToken(options.mockUserToken, (_a = firestore._app) === null || _a === void 0 ? void 0 : _a.options.projectId);\r\n            const uid = options.mockUserToken.sub || options.mockUserToken.user_id;\r\n            if (!uid) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, \"mockUserToken must contain 'sub' or 'user_id' field!\");\r\n            }\r\n            user = new User(uid);\r\n        }\r\n        firestore._credentials = new EmulatorCredentialsProvider(new OAuthToken(token, user));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A `DocumentReference` refers to a document location in a Firestore database\r\n * and can be used to write, read, or listen to the location. The document at\r\n * the referenced location may or may not exist.\r\n */\r\nclass DocumentReference {\r\n    /** @hideconstructor */\r\n    constructor(firestore, \r\n    /**\r\n     * If provided, the `FirestoreDataConverter` associated with this instance.\r\n     */\r\n    converter, _key) {\r\n        this.converter = converter;\r\n        this._key = _key;\r\n        /** The type of this Firestore reference. */\r\n        this.type = 'document';\r\n        this.firestore = firestore;\r\n    }\r\n    get _path() {\r\n        return this._key.path;\r\n    }\r\n    /**\r\n     * The document's identifier within its collection.\r\n     */\r\n    get id() {\r\n        return this._key.path.lastSegment();\r\n    }\r\n    /**\r\n     * A string representing the path of the referenced document (relative\r\n     * to the root of the database).\r\n     */\r\n    get path() {\r\n        return this._key.path.canonicalString();\r\n    }\r\n    /**\r\n     * The collection this `DocumentReference` belongs to.\r\n     */\r\n    get parent() {\r\n        return new CollectionReference(this.firestore, this.converter, this._key.path.popLast());\r\n    }\r\n    withConverter(converter) {\r\n        return new DocumentReference(this.firestore, converter, this._key);\r\n    }\r\n}\r\n/**\r\n * A `Query` refers to a query which you can read or listen to. You can also\r\n * construct refined `Query` objects by adding filters and ordering.\r\n */\r\nclass Query {\r\n    // This is the lite version of the Query class in the main SDK.\r\n    /** @hideconstructor protected */\r\n    constructor(firestore, \r\n    /**\r\n     * If provided, the `FirestoreDataConverter` associated with this instance.\r\n     */\r\n    converter, _query) {\r\n        this.converter = converter;\r\n        this._query = _query;\r\n        /** The type of this Firestore reference. */\r\n        this.type = 'query';\r\n        this.firestore = firestore;\r\n    }\r\n    withConverter(converter) {\r\n        return new Query(this.firestore, converter, this._query);\r\n    }\r\n}\r\n/**\r\n * A `CollectionReference` object can be used for adding documents, getting\r\n * document references, and querying for documents (using {@link query}).\r\n */\r\nclass CollectionReference extends Query {\r\n    /** @hideconstructor */\r\n    constructor(firestore, converter, _path) {\r\n        super(firestore, converter, newQueryForPath(_path));\r\n        this._path = _path;\r\n        /** The type of this Firestore reference. */\r\n        this.type = 'collection';\r\n    }\r\n    /** The collection's identifier. */\r\n    get id() {\r\n        return this._query.path.lastSegment();\r\n    }\r\n    /**\r\n     * A string representing the path of the referenced collection (relative\r\n     * to the root of the database).\r\n     */\r\n    get path() {\r\n        return this._query.path.canonicalString();\r\n    }\r\n    /**\r\n     * A reference to the containing `DocumentReference` if this is a\r\n     * subcollection. If this isn't a subcollection, the reference is null.\r\n     */\r\n    get parent() {\r\n        const parentPath = this._path.popLast();\r\n        if (parentPath.isEmpty()) {\r\n            return null;\r\n        }\r\n        else {\r\n            return new DocumentReference(this.firestore, \r\n            /* converter= */ null, new DocumentKey(parentPath));\r\n        }\r\n    }\r\n    withConverter(converter) {\r\n        return new CollectionReference(this.firestore, converter, this._path);\r\n    }\r\n}\r\nfunction collection(parent, path, ...pathSegments) {\r\n    parent = getModularInstance(parent);\r\n    validateNonEmptyArgument('collection', 'path', path);\r\n    if (parent instanceof Firestore$1) {\r\n        const absolutePath = ResourcePath.fromString(path, ...pathSegments);\r\n        validateCollectionPath(absolutePath);\r\n        return new CollectionReference(parent, /* converter= */ null, absolutePath);\r\n    }\r\n    else {\r\n        if (!(parent instanceof DocumentReference) &&\r\n            !(parent instanceof CollectionReference)) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Expected first argument to collection() to be a CollectionReference, ' +\r\n                'a DocumentReference or FirebaseFirestore');\r\n        }\r\n        const absolutePath = parent._path.child(ResourcePath.fromString(path, ...pathSegments));\r\n        validateCollectionPath(absolutePath);\r\n        return new CollectionReference(parent.firestore, \r\n        /* converter= */ null, absolutePath);\r\n    }\r\n}\r\n// TODO(firestorelite): Consider using ErrorFactory -\r\n// https://github.com/firebase/firebase-js-sdk/blob/0131e1f/packages/util/src/errors.ts#L106\r\n/**\r\n * Creates and returns a new `Query` instance that includes all documents in the\r\n * database that are contained in a collection or subcollection with the\r\n * given `collectionId`.\r\n *\r\n * @param firestore - A reference to the root `Firestore` instance.\r\n * @param collectionId - Identifies the collections to query over. Every\r\n * collection or subcollection with this ID as the last segment of its path\r\n * will be included. Cannot contain a slash.\r\n * @returns The created `Query`.\r\n */\r\nfunction collectionGroup(firestore, collectionId) {\r\n    firestore = cast(firestore, Firestore$1);\r\n    validateNonEmptyArgument('collectionGroup', 'collection id', collectionId);\r\n    if (collectionId.indexOf('/') >= 0) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid collection ID '${collectionId}' passed to function ` +\r\n            `collectionGroup(). Collection IDs must not contain '/'.`);\r\n    }\r\n    return new Query(firestore, \r\n    /* converter= */ null, newQueryForCollectionGroup(collectionId));\r\n}\r\nfunction doc(parent, path, ...pathSegments) {\r\n    parent = getModularInstance(parent);\r\n    // We allow omission of 'pathString' but explicitly prohibit passing in both\r\n    // 'undefined' and 'null'.\r\n    if (arguments.length === 1) {\r\n        path = AutoId.newId();\r\n    }\r\n    validateNonEmptyArgument('doc', 'path', path);\r\n    if (parent instanceof Firestore$1) {\r\n        const absolutePath = ResourcePath.fromString(path, ...pathSegments);\r\n        validateDocumentPath(absolutePath);\r\n        return new DocumentReference(parent, \r\n        /* converter= */ null, new DocumentKey(absolutePath));\r\n    }\r\n    else {\r\n        if (!(parent instanceof DocumentReference) &&\r\n            !(parent instanceof CollectionReference)) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Expected first argument to collection() to be a CollectionReference, ' +\r\n                'a DocumentReference or FirebaseFirestore');\r\n        }\r\n        const absolutePath = parent._path.child(ResourcePath.fromString(path, ...pathSegments));\r\n        validateDocumentPath(absolutePath);\r\n        return new DocumentReference(parent.firestore, parent instanceof CollectionReference ? parent.converter : null, new DocumentKey(absolutePath));\r\n    }\r\n}\r\n/**\r\n * Returns true if the provided references are equal.\r\n *\r\n * @param left - A reference to compare.\r\n * @param right - A reference to compare.\r\n * @returns true if the references point to the same location in the same\r\n * Firestore database.\r\n */\r\nfunction refEqual(left, right) {\r\n    left = getModularInstance(left);\r\n    right = getModularInstance(right);\r\n    if ((left instanceof DocumentReference ||\r\n        left instanceof CollectionReference) &&\r\n        (right instanceof DocumentReference || right instanceof CollectionReference)) {\r\n        return (left.firestore === right.firestore &&\r\n            left.path === right.path &&\r\n            left.converter === right.converter);\r\n    }\r\n    return false;\r\n}\r\n/**\r\n * Returns true if the provided queries point to the same collection and apply\r\n * the same constraints.\r\n *\r\n * @param left - A `Query` to compare.\r\n * @param right - A `Query` to compare.\r\n * @returns true if the references point to the same location in the same\r\n * Firestore database.\r\n */\r\nfunction queryEqual(left, right) {\r\n    left = getModularInstance(left);\r\n    right = getModularInstance(right);\r\n    if (left instanceof Query && right instanceof Query) {\r\n        return (left.firestore === right.firestore &&\r\n            queryEquals(left._query, right._query) &&\r\n            left.converter === right.converter);\r\n    }\r\n    return false;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst LOG_TAG = 'AsyncQueue';\r\nclass AsyncQueueImpl {\r\n    constructor() {\r\n        // The last promise in the queue.\r\n        this.tail = Promise.resolve();\r\n        // A list of retryable operations. Retryable operations are run in order and\r\n        // retried with backoff.\r\n        this.retryableOps = [];\r\n        // Is this AsyncQueue being shut down? Once it is set to true, it will not\r\n        // be changed again.\r\n        this._isShuttingDown = false;\r\n        // Operations scheduled to be queued in the future. Operations are\r\n        // automatically removed after they are run or canceled.\r\n        this.delayedOperations = [];\r\n        // visible for testing\r\n        this.failure = null;\r\n        // Flag set while there's an outstanding AsyncQueue operation, used for\r\n        // assertion sanity-checks.\r\n        this.operationInProgress = false;\r\n        // Enabled during shutdown on Safari to prevent future access to IndexedDB.\r\n        this.skipNonRestrictedTasks = false;\r\n        // List of TimerIds to fast-forward delays for.\r\n        this.timerIdsToSkip = [];\r\n        // Backoff timer used to schedule retries for retryable operations\r\n        this.backoff = new ExponentialBackoff(this, \"async_queue_retry\" /* AsyncQueueRetry */);\r\n        // Visibility handler that triggers an immediate retry of all retryable\r\n        // operations. Meant to speed up recovery when we regain file system access\r\n        // after page comes into foreground.\r\n        this.visibilityHandler = () => {\r\n            this.backoff.skipBackoff();\r\n        };\r\n    }\r\n    get isShuttingDown() {\r\n        return this._isShuttingDown;\r\n    }\r\n    /**\r\n     * Adds a new operation to the queue without waiting for it to complete (i.e.\r\n     * we ignore the Promise result).\r\n     */\r\n    enqueueAndForget(op) {\r\n        // eslint-disable-next-line @typescript-eslint/no-floating-promises\r\n        this.enqueue(op);\r\n    }\r\n    enqueueAndForgetEvenWhileRestricted(op) {\r\n        this.verifyNotFailed();\r\n        // eslint-disable-next-line @typescript-eslint/no-floating-promises\r\n        this.enqueueInternal(op);\r\n    }\r\n    enterRestrictedMode(purgeExistingTasks) {\r\n        if (!this._isShuttingDown) {\r\n            this._isShuttingDown = true;\r\n            this.skipNonRestrictedTasks = purgeExistingTasks || false;\r\n        }\r\n    }\r\n    enqueue(op) {\r\n        this.verifyNotFailed();\r\n        if (this._isShuttingDown) {\r\n            // Return a Promise which never resolves.\r\n            return new Promise(() => { });\r\n        }\r\n        // Create a deferred Promise that we can return to the callee. This\r\n        // allows us to return a \"hanging Promise\" only to the callee and still\r\n        // advance the queue even when the operation is not run.\r\n        const task = new Deferred();\r\n        return this.enqueueInternal(() => {\r\n            if (this._isShuttingDown && this.skipNonRestrictedTasks) {\r\n                // We do not resolve 'task'\r\n                return Promise.resolve();\r\n            }\r\n            op().then(task.resolve, task.reject);\r\n            return task.promise;\r\n        }).then(() => task.promise);\r\n    }\r\n    enqueueRetryable(op) {\r\n        this.enqueueAndForget(() => {\r\n            this.retryableOps.push(op);\r\n            return this.retryNextOp();\r\n        });\r\n    }\r\n    /**\r\n     * Runs the next operation from the retryable queue. If the operation fails,\r\n     * reschedules with backoff.\r\n     */\r\n    async retryNextOp() {\r\n        if (this.retryableOps.length === 0) {\r\n            return;\r\n        }\r\n        try {\r\n            await this.retryableOps[0]();\r\n            this.retryableOps.shift();\r\n            this.backoff.reset();\r\n        }\r\n        catch (e) {\r\n            if (isIndexedDbTransactionError(e)) {\r\n                logDebug(LOG_TAG, 'Operation failed with retryable error: ' + e);\r\n            }\r\n            else {\r\n                throw e; // Failure will be handled by AsyncQueue\r\n            }\r\n        }\r\n        if (this.retryableOps.length > 0) {\r\n            // If there are additional operations, we re-schedule `retryNextOp()`.\r\n            // This is necessary to run retryable operations that failed during\r\n            // their initial attempt since we don't know whether they are already\r\n            // enqueued. If, for example, `op1`, `op2`, `op3` are enqueued and `op1`\r\n            // needs to  be re-run, we will run `op1`, `op1`, `op2` using the\r\n            // already enqueued calls to `retryNextOp()`. `op3()` will then run in the\r\n            // call scheduled here.\r\n            // Since `backoffAndRun()` cancels an existing backoff and schedules a\r\n            // new backoff on every call, there is only ever a single additional\r\n            // operation in the queue.\r\n            this.backoff.backoffAndRun(() => this.retryNextOp());\r\n        }\r\n    }\r\n    enqueueInternal(op) {\r\n        const newTail = this.tail.then(() => {\r\n            this.operationInProgress = true;\r\n            return op()\r\n                .catch((error) => {\r\n                this.failure = error;\r\n                this.operationInProgress = false;\r\n                const message = getMessageOrStack(error);\r\n                logError('INTERNAL UNHANDLED ERROR: ', message);\r\n                // Re-throw the error so that this.tail becomes a rejected Promise and\r\n                // all further attempts to chain (via .then) will just short-circuit\r\n                // and return the rejected Promise.\r\n                throw error;\r\n            })\r\n                .then(result => {\r\n                this.operationInProgress = false;\r\n                return result;\r\n            });\r\n        });\r\n        this.tail = newTail;\r\n        return newTail;\r\n    }\r\n    enqueueAfterDelay(timerId, delayMs, op) {\r\n        this.verifyNotFailed();\r\n        // Fast-forward delays for timerIds that have been overriden.\r\n        if (this.timerIdsToSkip.indexOf(timerId) > -1) {\r\n            delayMs = 0;\r\n        }\r\n        const delayedOp = DelayedOperation.createAndSchedule(this, timerId, delayMs, op, removedOp => this.removeDelayedOperation(removedOp));\r\n        this.delayedOperations.push(delayedOp);\r\n        return delayedOp;\r\n    }\r\n    verifyNotFailed() {\r\n        if (this.failure) {\r\n            fail();\r\n        }\r\n    }\r\n    verifyOperationInProgress() {\r\n    }\r\n    /**\r\n     * Waits until all currently queued tasks are finished executing. Delayed\r\n     * operations are not run.\r\n     */\r\n    async drain() {\r\n        // Operations in the queue prior to draining may have enqueued additional\r\n        // operations. Keep draining the queue until the tail is no longer advanced,\r\n        // which indicates that no more new operations were enqueued and that all\r\n        // operations were executed.\r\n        let currentTail;\r\n        do {\r\n            currentTail = this.tail;\r\n            await currentTail;\r\n        } while (currentTail !== this.tail);\r\n    }\r\n    /**\r\n     * For Tests: Determine if a delayed operation with a particular TimerId\r\n     * exists.\r\n     */\r\n    containsDelayedOperation(timerId) {\r\n        for (const op of this.delayedOperations) {\r\n            if (op.timerId === timerId) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n    /**\r\n     * For Tests: Runs some or all delayed operations early.\r\n     *\r\n     * @param lastTimerId - Delayed operations up to and including this TimerId\r\n     * will be drained. Pass TimerId.All to run all delayed operations.\r\n     * @returns a Promise that resolves once all operations have been run.\r\n     */\r\n    runAllDelayedOperationsUntil(lastTimerId) {\r\n        // Note that draining may generate more delayed ops, so we do that first.\r\n        return this.drain().then(() => {\r\n            // Run ops in the same order they'd run if they ran naturally.\r\n            this.delayedOperations.sort((a, b) => a.targetTimeMs - b.targetTimeMs);\r\n            for (const op of this.delayedOperations) {\r\n                op.skipDelay();\r\n                if (lastTimerId !== \"all\" /* All */ && op.timerId === lastTimerId) {\r\n                    break;\r\n                }\r\n            }\r\n            return this.drain();\r\n        });\r\n    }\r\n    /**\r\n     * For Tests: Skip all subsequent delays for a timer id.\r\n     */\r\n    skipDelaysForTimerId(timerId) {\r\n        this.timerIdsToSkip.push(timerId);\r\n    }\r\n    /** Called once a DelayedOperation is run or canceled. */\r\n    removeDelayedOperation(op) {\r\n        // NOTE: indexOf / slice are O(n), but delayedOperations is expected to be small.\r\n        const index = this.delayedOperations.indexOf(op);\r\n        this.delayedOperations.splice(index, 1);\r\n    }\r\n}\r\nfunction newAsyncQueue() {\r\n    return new AsyncQueueImpl();\r\n}\r\n/**\r\n * Chrome includes Error.message in Error.stack. Other browsers do not.\r\n * This returns expected output of message + stack when available.\r\n * @param error - Error or FirestoreError\r\n */\r\nfunction getMessageOrStack(error) {\r\n    let message = error.message || '';\r\n    if (error.stack) {\r\n        if (error.stack.includes(error.message)) {\r\n            message = error.stack;\r\n        }\r\n        else {\r\n            message = error.message + '\\n' + error.stack;\r\n        }\r\n    }\r\n    return message;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Represents the task of loading a Firestore bundle. It provides progress of bundle\r\n * loading, as well as task completion and error events.\r\n *\r\n * The API is compatible with `Promise<LoadBundleTaskProgress>`.\r\n */\r\nclass LoadBundleTask {\r\n    constructor() {\r\n        this._progressObserver = {};\r\n        this._taskCompletionResolver = new Deferred();\r\n        this._lastProgress = {\r\n            taskState: 'Running',\r\n            totalBytes: 0,\r\n            totalDocuments: 0,\r\n            bytesLoaded: 0,\r\n            documentsLoaded: 0\r\n        };\r\n    }\r\n    /**\r\n     * Registers functions to listen to bundle loading progress events.\r\n     * @param next - Called when there is a progress update from bundle loading. Typically `next` calls occur\r\n     *   each time a Firestore document is loaded from the bundle.\r\n     * @param error - Called when an error occurs during bundle loading. The task aborts after reporting the\r\n     *   error, and there should be no more updates after this.\r\n     * @param complete - Called when the loading task is complete.\r\n     */\r\n    onProgress(next, error, complete) {\r\n        this._progressObserver = {\r\n            next,\r\n            error,\r\n            complete\r\n        };\r\n    }\r\n    /**\r\n     * Implements the `Promise<LoadBundleTaskProgress>.catch` interface.\r\n     *\r\n     * @param onRejected - Called when an error occurs during bundle loading.\r\n     */\r\n    catch(onRejected) {\r\n        return this._taskCompletionResolver.promise.catch(onRejected);\r\n    }\r\n    /**\r\n     * Implements the `Promise<LoadBundleTaskProgress>.then` interface.\r\n     *\r\n     * @param onFulfilled - Called on the completion of the loading task with a final `LoadBundleTaskProgress` update.\r\n     *   The update will always have its `taskState` set to `\"Success\"`.\r\n     * @param onRejected - Called when an error occurs during bundle loading.\r\n     */\r\n    then(onFulfilled, onRejected) {\r\n        return this._taskCompletionResolver.promise.then(onFulfilled, onRejected);\r\n    }\r\n    /**\r\n     * Notifies all observers that bundle loading has completed, with a provided\r\n     * `LoadBundleTaskProgress` object.\r\n     *\r\n     * @private\r\n     */\r\n    _completeWith(progress) {\r\n        this._updateProgress(progress);\r\n        if (this._progressObserver.complete) {\r\n            this._progressObserver.complete();\r\n        }\r\n        this._taskCompletionResolver.resolve(progress);\r\n    }\r\n    /**\r\n     * Notifies all observers that bundle loading has failed, with a provided\r\n     * `Error` as the reason.\r\n     *\r\n     * @private\r\n     */\r\n    _failWith(error) {\r\n        this._lastProgress.taskState = 'Error';\r\n        if (this._progressObserver.next) {\r\n            this._progressObserver.next(this._lastProgress);\r\n        }\r\n        if (this._progressObserver.error) {\r\n            this._progressObserver.error(error);\r\n        }\r\n        this._taskCompletionResolver.reject(error);\r\n    }\r\n    /**\r\n     * Notifies a progress update of loading a bundle.\r\n     * @param progress - The new progress.\r\n     *\r\n     * @private\r\n     */\r\n    _updateProgress(progress) {\r\n        this._lastProgress = progress;\r\n        if (this._progressObserver.next) {\r\n            this._progressObserver.next(progress);\r\n        }\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/** DOMException error code constants. */\r\nconst DOM_EXCEPTION_INVALID_STATE = 11;\r\nconst DOM_EXCEPTION_ABORTED = 20;\r\nconst DOM_EXCEPTION_QUOTA_EXCEEDED = 22;\r\n/**\r\n * Constant used to indicate the LRU garbage collection should be disabled.\r\n * Set this value as the `cacheSizeBytes` on the settings passed to the\r\n * {@link Firestore} instance.\r\n */\r\nconst CACHE_SIZE_UNLIMITED = LRU_COLLECTION_DISABLED;\r\n/**\r\n * The Cloud Firestore service interface.\r\n *\r\n * Do not call this constructor directly. Instead, use {@link getFirestore}.\r\n */\r\nclass Firestore extends Firestore$1 {\r\n    /** @hideconstructor */\r\n    constructor(databaseIdOrApp, credentialsProvider) {\r\n        super(databaseIdOrApp, credentialsProvider);\r\n        /**\r\n         * Whether it's a {@link Firestore} or Firestore Lite instance.\r\n         */\r\n        this.type = 'firestore';\r\n        this._queue = newAsyncQueue();\r\n        this._persistenceKey =\r\n            'name' in databaseIdOrApp ? databaseIdOrApp.name : '[DEFAULT]';\r\n    }\r\n    _terminate() {\r\n        if (!this._firestoreClient) {\r\n            // The client must be initialized to ensure that all subsequent API\r\n            // usage throws an exception.\r\n            configureFirestore(this);\r\n        }\r\n        return this._firestoreClient.terminate();\r\n    }\r\n}\r\n/**\r\n * Initializes a new instance of {@link Firestore} with the provided settings.\r\n * Can only be called before any other function, including\r\n * {@link getFirestore}. If the custom settings are empty, this function is\r\n * equivalent to calling {@link getFirestore}.\r\n *\r\n * @param app - The {@link @firebase/app#FirebaseApp} with which the {@link Firestore} instance will\r\n * be associated.\r\n * @param settings - A settings object to configure the {@link Firestore} instance.\r\n * @returns A newly initialized {@link Firestore} instance.\r\n */\r\nfunction initializeFirestore(app, settings) {\r\n    const provider = _getProvider(app, 'firestore');\r\n    if (provider.isInitialized()) {\r\n        const existingInstance = provider.getImmediate();\r\n        const initialSettings = provider.getOptions();\r\n        if (deepEqual(initialSettings, settings)) {\r\n            return existingInstance;\r\n        }\r\n        else {\r\n            throw new FirestoreError(Code.FAILED_PRECONDITION, 'initializeFirestore() has already been called with ' +\r\n                'different options. To avoid this error, call initializeFirestore() with the ' +\r\n                'same options as when it was originally called, or call getFirestore() to return the' +\r\n                ' already initialized instance.');\r\n        }\r\n    }\r\n    if (settings.cacheSizeBytes !== undefined &&\r\n        settings.cacheSizeBytes !== CACHE_SIZE_UNLIMITED &&\r\n        settings.cacheSizeBytes < LRU_MINIMUM_CACHE_SIZE_BYTES) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `cacheSizeBytes must be at least ${LRU_MINIMUM_CACHE_SIZE_BYTES}`);\r\n    }\r\n    return provider.initialize({ options: settings });\r\n}\r\n/**\r\n * Returns the existing {@link Firestore} instance that is associated with the\r\n * provided {@link @firebase/app#FirebaseApp}. If no instance exists, initializes a new\r\n * instance with default settings.\r\n *\r\n * @param app - The {@link @firebase/app#FirebaseApp} instance that the returned {@link Firestore}\r\n * instance is associated with.\r\n * @returns The {@link Firestore} instance of the provided app.\r\n */\r\nfunction getFirestore(app = getApp()) {\r\n    return _getProvider(app, 'firestore').getImmediate();\r\n}\r\n/**\r\n * @internal\r\n */\r\nfunction ensureFirestoreConfigured(firestore) {\r\n    if (!firestore._firestoreClient) {\r\n        configureFirestore(firestore);\r\n    }\r\n    firestore._firestoreClient.verifyNotTerminated();\r\n    return firestore._firestoreClient;\r\n}\r\nfunction configureFirestore(firestore) {\r\n    var _a;\r\n    const settings = firestore._freezeSettings();\r\n    const databaseInfo = makeDatabaseInfo(firestore._databaseId, ((_a = firestore._app) === null || _a === void 0 ? void 0 : _a.options.appId) || '', firestore._persistenceKey, settings);\r\n    firestore._firestoreClient = new FirestoreClient(firestore._credentials, firestore._queue, databaseInfo);\r\n}\r\n/**\r\n * Attempts to enable persistent storage, if possible.\r\n *\r\n * Must be called before any other functions (other than\r\n * {@link initializeFirestore}, {@link getFirestore} or\r\n * {@link clearIndexedDbPersistence}.\r\n *\r\n * If this fails, `enableIndexedDbPersistence()` will reject the promise it\r\n * returns. Note that even after this failure, the {@link Firestore} instance will\r\n * remain usable, however offline persistence will be disabled.\r\n *\r\n * There are several reasons why this can fail, which can be identified by\r\n * the `code` on the error.\r\n *\r\n *   * failed-precondition: The app is already open in another browser tab.\r\n *   * unimplemented: The browser is incompatible with the offline\r\n *     persistence implementation.\r\n *\r\n * @param firestore - The {@link Firestore} instance to enable persistence for.\r\n * @param persistenceSettings - Optional settings object to configure\r\n * persistence.\r\n * @returns A `Promise` that represents successfully enabling persistent storage.\r\n */\r\nfunction enableIndexedDbPersistence(firestore, persistenceSettings) {\r\n    firestore = cast(firestore, Firestore);\r\n    verifyNotInitialized(firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const settings = firestore._freezeSettings();\r\n    const onlineComponentProvider = new OnlineComponentProvider();\r\n    const offlineComponentProvider = new IndexedDbOfflineComponentProvider(onlineComponentProvider, settings.cacheSizeBytes, persistenceSettings === null || persistenceSettings === void 0 ? void 0 : persistenceSettings.forceOwnership);\r\n    return setPersistenceProviders(client, onlineComponentProvider, offlineComponentProvider);\r\n}\r\n/**\r\n * Attempts to enable multi-tab persistent storage, if possible. If enabled\r\n * across all tabs, all operations share access to local persistence, including\r\n * shared execution of queries and latency-compensated local document updates\r\n * across all connected instances.\r\n *\r\n * If this fails, `enableMultiTabIndexedDbPersistence()` will reject the promise\r\n * it returns. Note that even after this failure, the {@link Firestore} instance will\r\n * remain usable, however offline persistence will be disabled.\r\n *\r\n * There are several reasons why this can fail, which can be identified by\r\n * the `code` on the error.\r\n *\r\n *   * failed-precondition: The app is already open in another browser tab and\r\n *     multi-tab is not enabled.\r\n *   * unimplemented: The browser is incompatible with the offline\r\n *     persistence implementation.\r\n *\r\n * @param firestore - The {@link Firestore} instance to enable persistence for.\r\n * @returns A `Promise` that represents successfully enabling persistent\r\n * storage.\r\n */\r\nfunction enableMultiTabIndexedDbPersistence(firestore) {\r\n    firestore = cast(firestore, Firestore);\r\n    verifyNotInitialized(firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const settings = firestore._freezeSettings();\r\n    const onlineComponentProvider = new OnlineComponentProvider();\r\n    const offlineComponentProvider = new MultiTabOfflineComponentProvider(onlineComponentProvider, settings.cacheSizeBytes);\r\n    return setPersistenceProviders(client, onlineComponentProvider, offlineComponentProvider);\r\n}\r\n/**\r\n * Registers both the `OfflineComponentProvider` and `OnlineComponentProvider`.\r\n * If the operation fails with a recoverable error (see\r\n * `canRecoverFromIndexedDbError()` below), the returned Promise is rejected\r\n * but the client remains usable.\r\n */\r\nfunction setPersistenceProviders(client, onlineComponentProvider, offlineComponentProvider) {\r\n    const persistenceResult = new Deferred();\r\n    return client.asyncQueue\r\n        .enqueue(async () => {\r\n        try {\r\n            await setOfflineComponentProvider(client, offlineComponentProvider);\r\n            await setOnlineComponentProvider(client, onlineComponentProvider);\r\n            persistenceResult.resolve();\r\n        }\r\n        catch (e) {\r\n            if (!canFallbackFromIndexedDbError(e)) {\r\n                throw e;\r\n            }\r\n            console.warn('Error enabling offline persistence. Falling back to ' +\r\n                'persistence disabled: ' +\r\n                e);\r\n            persistenceResult.reject(e);\r\n        }\r\n    })\r\n        .then(() => persistenceResult.promise);\r\n}\r\n/**\r\n * Decides whether the provided error allows us to gracefully disable\r\n * persistence (as opposed to crashing the client).\r\n */\r\nfunction canFallbackFromIndexedDbError(error) {\r\n    if (error.name === 'FirebaseError') {\r\n        return (error.code === Code.FAILED_PRECONDITION ||\r\n            error.code === Code.UNIMPLEMENTED);\r\n    }\r\n    else if (typeof DOMException !== 'undefined' &&\r\n        error instanceof DOMException) {\r\n        // There are a few known circumstances where we can open IndexedDb but\r\n        // trying to read/write will fail (e.g. quota exceeded). For\r\n        // well-understood cases, we attempt to detect these and then gracefully\r\n        // fall back to memory persistence.\r\n        // NOTE: Rather than continue to add to this list, we could decide to\r\n        // always fall back, with the risk that we might accidentally hide errors\r\n        // representing actual SDK bugs.\r\n        return (\r\n        // When the browser is out of quota we could get either quota exceeded\r\n        // or an aborted error depending on whether the error happened during\r\n        // schema migration.\r\n        error.code === DOM_EXCEPTION_QUOTA_EXCEEDED ||\r\n            error.code === DOM_EXCEPTION_ABORTED ||\r\n            // Firefox Private Browsing mode disables IndexedDb and returns\r\n            // INVALID_STATE for any usage.\r\n            error.code === DOM_EXCEPTION_INVALID_STATE);\r\n    }\r\n    return true;\r\n}\r\n/**\r\n * Clears the persistent storage. This includes pending writes and cached\r\n * documents.\r\n *\r\n * Must be called while the {@link Firestore} instance is not started (after the app is\r\n * terminated or when the app is first initialized). On startup, this function\r\n * must be called before other functions (other than {@link\r\n * initializeFirestore} or {@link getFirestore})). If the {@link Firestore}\r\n * instance is still running, the promise will be rejected with the error code\r\n * of `failed-precondition`.\r\n *\r\n * Note: `clearIndexedDbPersistence()` is primarily intended to help write\r\n * reliable tests that use Cloud Firestore. It uses an efficient mechanism for\r\n * dropping existing data but does not attempt to securely overwrite or\r\n * otherwise make cached data unrecoverable. For applications that are sensitive\r\n * to the disclosure of cached data in between user sessions, we strongly\r\n * recommend not enabling persistence at all.\r\n *\r\n * @param firestore - The {@link Firestore} instance to clear persistence for.\r\n * @returns A `Promise` that is resolved when the persistent storage is\r\n * cleared. Otherwise, the promise is rejected with an error.\r\n */\r\nfunction clearIndexedDbPersistence(firestore) {\r\n    if (firestore._initialized && !firestore._terminated) {\r\n        throw new FirestoreError(Code.FAILED_PRECONDITION, 'Persistence can only be cleared before a Firestore instance is ' +\r\n            'initialized or after it is terminated.');\r\n    }\r\n    const deferred = new Deferred();\r\n    firestore._queue.enqueueAndForgetEvenWhileRestricted(async () => {\r\n        try {\r\n            await indexedDbClearPersistence(indexedDbStoragePrefix(firestore._databaseId, firestore._persistenceKey));\r\n            deferred.resolve();\r\n        }\r\n        catch (e) {\r\n            deferred.reject(e);\r\n        }\r\n    });\r\n    return deferred.promise;\r\n}\r\n/**\r\n * Waits until all currently pending writes for the active user have been\r\n * acknowledged by the backend.\r\n *\r\n * The returned promise resolves immediately if there are no outstanding writes.\r\n * Otherwise, the promise waits for all previously issued writes (including\r\n * those written in a previous app session), but it does not wait for writes\r\n * that were added after the function is called. If you want to wait for\r\n * additional writes, call `waitForPendingWrites()` again.\r\n *\r\n * Any outstanding `waitForPendingWrites()` promises are rejected during user\r\n * changes.\r\n *\r\n * @returns A `Promise` which resolves when all currently pending writes have been\r\n * acknowledged by the backend.\r\n */\r\nfunction waitForPendingWrites(firestore) {\r\n    firestore = cast(firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientWaitForPendingWrites(client);\r\n}\r\n/**\r\n * Re-enables use of the network for this {@link Firestore} instance after a prior\r\n * call to {@link disableNetwork}.\r\n *\r\n * @returns A `Promise` that is resolved once the network has been enabled.\r\n */\r\nfunction enableNetwork(firestore) {\r\n    firestore = cast(firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientEnableNetwork(client);\r\n}\r\n/**\r\n * Disables network usage for this instance. It can be re-enabled via {@link\r\n * enableNetwork}. While the network is disabled, any snapshot listeners,\r\n * `getDoc()` or `getDocs()` calls will return results from cache, and any write\r\n * operations will be queued until the network is restored.\r\n *\r\n * @returns A `Promise` that is resolved once the network has been disabled.\r\n */\r\nfunction disableNetwork(firestore) {\r\n    firestore = cast(firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientDisableNetwork(client);\r\n}\r\n/**\r\n * Terminates the provided {@link Firestore} instance.\r\n *\r\n * After calling `terminate()` only the `clearIndexedDbPersistence()` function\r\n * may be used. Any other function will throw a `FirestoreError`.\r\n *\r\n * To restart after termination, create a new instance of FirebaseFirestore with\r\n * {@link getFirestore}.\r\n *\r\n * Termination does not cancel any pending writes, and any promises that are\r\n * awaiting a response from the server will not be resolved. If you have\r\n * persistence enabled, the next time you start this instance, it will resume\r\n * sending these writes to the server.\r\n *\r\n * Note: Under normal circumstances, calling `terminate()` is not required. This\r\n * function is useful only when you want to force this instance to release all\r\n * of its resources or in combination with `clearIndexedDbPersistence()` to\r\n * ensure that all local state is destroyed between test runs.\r\n *\r\n * @returns A `Promise` that is resolved when the instance has been successfully\r\n * terminated.\r\n */\r\nfunction terminate(firestore) {\r\n    _removeServiceInstance(firestore.app, 'firestore');\r\n    return firestore._delete();\r\n}\r\n/**\r\n * Loads a Firestore bundle into the local cache.\r\n *\r\n * @param firestore - The {@link Firestore} instance to load bundles for for.\r\n * @param bundleData - An object representing the bundle to be loaded. Valid objects are\r\n *   `ArrayBuffer`, `ReadableStream<Uint8Array>` or `string`.\r\n *\r\n * @returns\r\n *   A `LoadBundleTask` object, which notifies callers with progress updates, and completion\r\n *   or error events. It can be used as a `Promise<LoadBundleTaskProgress>`.\r\n */\r\nfunction loadBundle(firestore, bundleData) {\r\n    firestore = cast(firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const resultTask = new LoadBundleTask();\r\n    firestoreClientLoadBundle(client, firestore._databaseId, bundleData, resultTask);\r\n    return resultTask;\r\n}\r\n/**\r\n * Reads a Firestore {@link Query} from local cache, identified by the given name.\r\n *\r\n * The named queries are packaged  into bundles on the server side (along\r\n * with resulting documents), and loaded to local cache using `loadBundle`. Once in local\r\n * cache, use this method to extract a {@link Query} by name.\r\n */\r\nfunction namedQuery(firestore, name) {\r\n    firestore = cast(firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientGetNamedQuery(client, name).then(namedQuery => {\r\n        if (!namedQuery) {\r\n            return null;\r\n        }\r\n        return new Query(firestore, null, namedQuery.query);\r\n    });\r\n}\r\nfunction verifyNotInitialized(firestore) {\r\n    if (firestore._initialized || firestore._terminated) {\r\n        throw new FirestoreError(Code.FAILED_PRECONDITION, 'Firestore has already been started and persistence can no longer be ' +\r\n            'enabled. You can only enable persistence before calling any other ' +\r\n            'methods on a Firestore object.');\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction registerFirestore(variant, useFetchStreams = true) {\r\n    setSDKVersion(SDK_VERSION$1);\r\n    _registerComponent(new Component('firestore', (container, { options: settings }) => {\r\n        const app = container.getProvider('app').getImmediate();\r\n        const firestoreInstance = new Firestore(app, new FirebaseCredentialsProvider(container.getProvider('auth-internal')));\r\n        settings = Object.assign({ useFetchStreams }, settings);\r\n        firestoreInstance._setSettings(settings);\r\n        return firestoreInstance;\r\n    }, \"PUBLIC\" /* PUBLIC */));\r\n    registerVersion(name, version$1, variant);\r\n    // BUILD_TARGET will be replaced by values like esm5, esm2017, cjs5, etc during the compilation\r\n    registerVersion(name, version$1, '__BUILD_TARGET__');\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A `FieldPath` refers to a field in a document. The path may consist of a\r\n * single field name (referring to a top-level field in the document), or a\r\n * list of field names (referring to a nested field in the document).\r\n *\r\n * Create a `FieldPath` by providing field names. If more than one field\r\n * name is provided, the path will point to a nested field in a document.\r\n */\r\nclass FieldPath {\r\n    /**\r\n     * Creates a `FieldPath` from the provided field names. If more than one field\r\n     * name is provided, the path will point to a nested field in a document.\r\n     *\r\n     * @param fieldNames - A list of field names.\r\n     */\r\n    constructor(...fieldNames) {\r\n        for (let i = 0; i < fieldNames.length; ++i) {\r\n            if (fieldNames[i].length === 0) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid field name at argument $(i + 1). ` +\r\n                    'Field names must not be empty.');\r\n            }\r\n        }\r\n        this._internalPath = new FieldPath$1(fieldNames);\r\n    }\r\n    /**\r\n     * Returns true if this `FieldPath` is equal to the provided one.\r\n     *\r\n     * @param other - The `FieldPath` to compare against.\r\n     * @returns true if this `FieldPath` is equal to the provided one.\r\n     */\r\n    isEqual(other) {\r\n        return this._internalPath.isEqual(other._internalPath);\r\n    }\r\n}\r\n/**\r\n * Returns a special sentinel `FieldPath` to refer to the ID of a document.\r\n * It can be used in queries to sort or filter by the document ID.\r\n */\r\nfunction documentId() {\r\n    return new FieldPath(DOCUMENT_KEY_NAME);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An immutable object representing an array of bytes.\r\n */\r\nclass Bytes {\r\n    /** @hideconstructor */\r\n    constructor(byteString) {\r\n        this._byteString = byteString;\r\n    }\r\n    /**\r\n     * Creates a new `Bytes` object from the given Base64 string, converting it to\r\n     * bytes.\r\n     *\r\n     * @param base64 - The Base64 string used to create the `Bytes` object.\r\n     */\r\n    static fromBase64String(base64) {\r\n        try {\r\n            return new Bytes(ByteString.fromBase64String(base64));\r\n        }\r\n        catch (e) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Failed to construct data from Base64 string: ' + e);\r\n        }\r\n    }\r\n    /**\r\n     * Creates a new `Bytes` object from the given Uint8Array.\r\n     *\r\n     * @param array - The Uint8Array used to create the `Bytes` object.\r\n     */\r\n    static fromUint8Array(array) {\r\n        return new Bytes(ByteString.fromUint8Array(array));\r\n    }\r\n    /**\r\n     * Returns the underlying bytes as a Base64-encoded string.\r\n     *\r\n     * @returns The Base64-encoded string created from the `Bytes` object.\r\n     */\r\n    toBase64() {\r\n        return this._byteString.toBase64();\r\n    }\r\n    /**\r\n     * Returns the underlying bytes in a new `Uint8Array`.\r\n     *\r\n     * @returns The Uint8Array created from the `Bytes` object.\r\n     */\r\n    toUint8Array() {\r\n        return this._byteString.toUint8Array();\r\n    }\r\n    /**\r\n     * Returns a string representation of the `Bytes` object.\r\n     *\r\n     * @returns A string representation of the `Bytes` object.\r\n     */\r\n    toString() {\r\n        return 'Bytes(base64: ' + this.toBase64() + ')';\r\n    }\r\n    /**\r\n     * Returns true if this `Bytes` object is equal to the provided one.\r\n     *\r\n     * @param other - The `Bytes` object to compare against.\r\n     * @returns true if this `Bytes` object is equal to the provided one.\r\n     */\r\n    isEqual(other) {\r\n        return this._byteString.isEqual(other._byteString);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Sentinel values that can be used when writing document fields with `set()`\r\n * or `update()`.\r\n */\r\nclass FieldValue {\r\n    /**\r\n     * @param _methodName - The public API endpoint that returns this class.\r\n     * @hideconstructor\r\n     */\r\n    constructor(_methodName) {\r\n        this._methodName = _methodName;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * An immutable object representing a geographic location in Firestore. The\r\n * location is represented as latitude/longitude pair.\r\n *\r\n * Latitude values are in the range of [-90, 90].\r\n * Longitude values are in the range of [-180, 180].\r\n */\r\nclass GeoPoint {\r\n    /**\r\n     * Creates a new immutable `GeoPoint` object with the provided latitude and\r\n     * longitude values.\r\n     * @param latitude - The latitude as number between -90 and 90.\r\n     * @param longitude - The longitude as number between -180 and 180.\r\n     */\r\n    constructor(latitude, longitude) {\r\n        if (!isFinite(latitude) || latitude < -90 || latitude > 90) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Latitude must be a number between -90 and 90, but was: ' + latitude);\r\n        }\r\n        if (!isFinite(longitude) || longitude < -180 || longitude > 180) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Longitude must be a number between -180 and 180, but was: ' + longitude);\r\n        }\r\n        this._lat = latitude;\r\n        this._long = longitude;\r\n    }\r\n    /**\r\n     * The latitude of this `GeoPoint` instance.\r\n     */\r\n    get latitude() {\r\n        return this._lat;\r\n    }\r\n    /**\r\n     * The longitude of this `GeoPoint` instance.\r\n     */\r\n    get longitude() {\r\n        return this._long;\r\n    }\r\n    /**\r\n     * Returns true if this `GeoPoint` is equal to the provided one.\r\n     *\r\n     * @param other - The `GeoPoint` to compare against.\r\n     * @returns true if this `GeoPoint` is equal to the provided one.\r\n     */\r\n    isEqual(other) {\r\n        return this._lat === other._lat && this._long === other._long;\r\n    }\r\n    /** Returns a JSON-serializable representation of this GeoPoint. */\r\n    toJSON() {\r\n        return { latitude: this._lat, longitude: this._long };\r\n    }\r\n    /**\r\n     * Actually private to JS consumers of our API, so this function is prefixed\r\n     * with an underscore.\r\n     */\r\n    _compareTo(other) {\r\n        return (primitiveComparator(this._lat, other._lat) ||\r\n            primitiveComparator(this._long, other._long));\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nconst RESERVED_FIELD_REGEX = /^__.*__$/;\r\n/** The result of parsing document data (e.g. for a setData call). */\r\nclass ParsedSetData {\r\n    constructor(data, fieldMask, fieldTransforms) {\r\n        this.data = data;\r\n        this.fieldMask = fieldMask;\r\n        this.fieldTransforms = fieldTransforms;\r\n    }\r\n    toMutation(key, precondition) {\r\n        if (this.fieldMask !== null) {\r\n            return new PatchMutation(key, this.data, this.fieldMask, precondition, this.fieldTransforms);\r\n        }\r\n        else {\r\n            return new SetMutation(key, this.data, precondition, this.fieldTransforms);\r\n        }\r\n    }\r\n}\r\n/** The result of parsing \"update\" data (i.e. for an updateData call). */\r\nclass ParsedUpdateData {\r\n    constructor(data, \r\n    // The fieldMask does not include document transforms.\r\n    fieldMask, fieldTransforms) {\r\n        this.data = data;\r\n        this.fieldMask = fieldMask;\r\n        this.fieldTransforms = fieldTransforms;\r\n    }\r\n    toMutation(key, precondition) {\r\n        return new PatchMutation(key, this.data, this.fieldMask, precondition, this.fieldTransforms);\r\n    }\r\n}\r\nfunction isWrite(dataSource) {\r\n    switch (dataSource) {\r\n        case 0 /* Set */: // fall through\r\n        case 2 /* MergeSet */: // fall through\r\n        case 1 /* Update */:\r\n            return true;\r\n        case 3 /* Argument */:\r\n        case 4 /* ArrayArgument */:\r\n            return false;\r\n        default:\r\n            throw fail();\r\n    }\r\n}\r\n/** A \"context\" object passed around while parsing user data. */\r\nclass ParseContextImpl {\r\n    /**\r\n     * Initializes a ParseContext with the given source and path.\r\n     *\r\n     * @param settings - The settings for the parser.\r\n     * @param databaseId - The database ID of the Firestore instance.\r\n     * @param serializer - The serializer to use to generate the Value proto.\r\n     * @param ignoreUndefinedProperties - Whether to ignore undefined properties\r\n     * rather than throw.\r\n     * @param fieldTransforms - A mutable list of field transforms encountered\r\n     * while parsing the data.\r\n     * @param fieldMask - A mutable list of field paths encountered while parsing\r\n     * the data.\r\n     *\r\n     * TODO(b/34871131): We don't support array paths right now, so path can be\r\n     * null to indicate the context represents any location within an array (in\r\n     * which case certain features will not work and errors will be somewhat\r\n     * compromised).\r\n     */\r\n    constructor(settings, databaseId, serializer, ignoreUndefinedProperties, fieldTransforms, fieldMask) {\r\n        this.settings = settings;\r\n        this.databaseId = databaseId;\r\n        this.serializer = serializer;\r\n        this.ignoreUndefinedProperties = ignoreUndefinedProperties;\r\n        // Minor hack: If fieldTransforms is undefined, we assume this is an\r\n        // external call and we need to validate the entire path.\r\n        if (fieldTransforms === undefined) {\r\n            this.validatePath();\r\n        }\r\n        this.fieldTransforms = fieldTransforms || [];\r\n        this.fieldMask = fieldMask || [];\r\n    }\r\n    get path() {\r\n        return this.settings.path;\r\n    }\r\n    get dataSource() {\r\n        return this.settings.dataSource;\r\n    }\r\n    /** Returns a new context with the specified settings overwritten. */\r\n    contextWith(configuration) {\r\n        return new ParseContextImpl(Object.assign(Object.assign({}, this.settings), configuration), this.databaseId, this.serializer, this.ignoreUndefinedProperties, this.fieldTransforms, this.fieldMask);\r\n    }\r\n    childContextForField(field) {\r\n        var _a;\r\n        const childPath = (_a = this.path) === null || _a === void 0 ? void 0 : _a.child(field);\r\n        const context = this.contextWith({ path: childPath, arrayElement: false });\r\n        context.validatePathSegment(field);\r\n        return context;\r\n    }\r\n    childContextForFieldPath(field) {\r\n        var _a;\r\n        const childPath = (_a = this.path) === null || _a === void 0 ? void 0 : _a.child(field);\r\n        const context = this.contextWith({ path: childPath, arrayElement: false });\r\n        context.validatePath();\r\n        return context;\r\n    }\r\n    childContextForArray(index) {\r\n        // TODO(b/34871131): We don't support array paths right now; so make path\r\n        // undefined.\r\n        return this.contextWith({ path: undefined, arrayElement: true });\r\n    }\r\n    createError(reason) {\r\n        return createError(reason, this.settings.methodName, this.settings.hasConverter || false, this.path, this.settings.targetDoc);\r\n    }\r\n    /** Returns 'true' if 'fieldPath' was traversed when creating this context. */\r\n    contains(fieldPath) {\r\n        return (this.fieldMask.find(field => fieldPath.isPrefixOf(field)) !== undefined ||\r\n            this.fieldTransforms.find(transform => fieldPath.isPrefixOf(transform.field)) !== undefined);\r\n    }\r\n    validatePath() {\r\n        // TODO(b/34871131): Remove null check once we have proper paths for fields\r\n        // within arrays.\r\n        if (!this.path) {\r\n            return;\r\n        }\r\n        for (let i = 0; i < this.path.length; i++) {\r\n            this.validatePathSegment(this.path.get(i));\r\n        }\r\n    }\r\n    validatePathSegment(segment) {\r\n        if (segment.length === 0) {\r\n            throw this.createError('Document fields must not be empty');\r\n        }\r\n        if (isWrite(this.dataSource) && RESERVED_FIELD_REGEX.test(segment)) {\r\n            throw this.createError('Document fields cannot begin and end with \"__\"');\r\n        }\r\n    }\r\n}\r\n/**\r\n * Helper for parsing raw user input (provided via the API) into internal model\r\n * classes.\r\n */\r\nclass UserDataReader {\r\n    constructor(databaseId, ignoreUndefinedProperties, serializer) {\r\n        this.databaseId = databaseId;\r\n        this.ignoreUndefinedProperties = ignoreUndefinedProperties;\r\n        this.serializer = serializer || newSerializer(databaseId);\r\n    }\r\n    /** Creates a new top-level parse context. */\r\n    createContext(dataSource, methodName, targetDoc, hasConverter = false) {\r\n        return new ParseContextImpl({\r\n            dataSource,\r\n            methodName,\r\n            targetDoc,\r\n            path: FieldPath$1.emptyPath(),\r\n            arrayElement: false,\r\n            hasConverter\r\n        }, this.databaseId, this.serializer, this.ignoreUndefinedProperties);\r\n    }\r\n}\r\nfunction newUserDataReader(firestore) {\r\n    const settings = firestore._freezeSettings();\r\n    const serializer = newSerializer(firestore._databaseId);\r\n    return new UserDataReader(firestore._databaseId, !!settings.ignoreUndefinedProperties, serializer);\r\n}\r\n/** Parse document data from a set() call. */\r\nfunction parseSetData(userDataReader, methodName, targetDoc, input, hasConverter, options = {}) {\r\n    const context = userDataReader.createContext(options.merge || options.mergeFields\r\n        ? 2 /* MergeSet */\r\n        : 0 /* Set */, methodName, targetDoc, hasConverter);\r\n    validatePlainObject('Data must be an object, but it was:', context, input);\r\n    const updateData = parseObject(input, context);\r\n    let fieldMask;\r\n    let fieldTransforms;\r\n    if (options.merge) {\r\n        fieldMask = new FieldMask(context.fieldMask);\r\n        fieldTransforms = context.fieldTransforms;\r\n    }\r\n    else if (options.mergeFields) {\r\n        const validatedFieldPaths = [];\r\n        for (const stringOrFieldPath of options.mergeFields) {\r\n            const fieldPath = fieldPathFromArgument$1(methodName, stringOrFieldPath, targetDoc);\r\n            if (!context.contains(fieldPath)) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Field '${fieldPath}' is specified in your field mask but missing from your input data.`);\r\n            }\r\n            if (!fieldMaskContains(validatedFieldPaths, fieldPath)) {\r\n                validatedFieldPaths.push(fieldPath);\r\n            }\r\n        }\r\n        fieldMask = new FieldMask(validatedFieldPaths);\r\n        fieldTransforms = context.fieldTransforms.filter(transform => fieldMask.covers(transform.field));\r\n    }\r\n    else {\r\n        fieldMask = null;\r\n        fieldTransforms = context.fieldTransforms;\r\n    }\r\n    return new ParsedSetData(new ObjectValue(updateData), fieldMask, fieldTransforms);\r\n}\r\nclass DeleteFieldValueImpl extends FieldValue {\r\n    _toFieldTransform(context) {\r\n        if (context.dataSource === 2 /* MergeSet */) {\r\n            // No transform to add for a delete, but we need to add it to our\r\n            // fieldMask so it gets deleted.\r\n            context.fieldMask.push(context.path);\r\n        }\r\n        else if (context.dataSource === 1 /* Update */) {\r\n            throw context.createError(`${this._methodName}() can only appear at the top level ` +\r\n                'of your update data');\r\n        }\r\n        else {\r\n            // We shouldn't encounter delete sentinels for queries or non-merge set() calls.\r\n            throw context.createError(`${this._methodName}() cannot be used with set() unless you pass ` +\r\n                '{merge:true}');\r\n        }\r\n        return null;\r\n    }\r\n    isEqual(other) {\r\n        return other instanceof DeleteFieldValueImpl;\r\n    }\r\n}\r\n/**\r\n * Creates a child context for parsing SerializableFieldValues.\r\n *\r\n * This is different than calling `ParseContext.contextWith` because it keeps\r\n * the fieldTransforms and fieldMask separate.\r\n *\r\n * The created context has its `dataSource` set to `UserDataSource.Argument`.\r\n * Although these values are used with writes, any elements in these FieldValues\r\n * are not considered writes since they cannot contain any FieldValue sentinels,\r\n * etc.\r\n *\r\n * @param fieldValue - The sentinel FieldValue for which to create a child\r\n *     context.\r\n * @param context - The parent context.\r\n * @param arrayElement - Whether or not the FieldValue has an array.\r\n */\r\nfunction createSentinelChildContext(fieldValue, context, arrayElement) {\r\n    return new ParseContextImpl({\r\n        dataSource: 3 /* Argument */,\r\n        targetDoc: context.settings.targetDoc,\r\n        methodName: fieldValue._methodName,\r\n        arrayElement\r\n    }, context.databaseId, context.serializer, context.ignoreUndefinedProperties);\r\n}\r\nclass ServerTimestampFieldValueImpl extends FieldValue {\r\n    _toFieldTransform(context) {\r\n        return new FieldTransform(context.path, new ServerTimestampTransform());\r\n    }\r\n    isEqual(other) {\r\n        return other instanceof ServerTimestampFieldValueImpl;\r\n    }\r\n}\r\nclass ArrayUnionFieldValueImpl extends FieldValue {\r\n    constructor(methodName, _elements) {\r\n        super(methodName);\r\n        this._elements = _elements;\r\n    }\r\n    _toFieldTransform(context) {\r\n        const parseContext = createSentinelChildContext(this, context, \r\n        /*array=*/ true);\r\n        const parsedElements = this._elements.map(element => parseData(element, parseContext));\r\n        const arrayUnion = new ArrayUnionTransformOperation(parsedElements);\r\n        return new FieldTransform(context.path, arrayUnion);\r\n    }\r\n    isEqual(other) {\r\n        // TODO(mrschmidt): Implement isEquals\r\n        return this === other;\r\n    }\r\n}\r\nclass ArrayRemoveFieldValueImpl extends FieldValue {\r\n    constructor(methodName, _elements) {\r\n        super(methodName);\r\n        this._elements = _elements;\r\n    }\r\n    _toFieldTransform(context) {\r\n        const parseContext = createSentinelChildContext(this, context, \r\n        /*array=*/ true);\r\n        const parsedElements = this._elements.map(element => parseData(element, parseContext));\r\n        const arrayUnion = new ArrayRemoveTransformOperation(parsedElements);\r\n        return new FieldTransform(context.path, arrayUnion);\r\n    }\r\n    isEqual(other) {\r\n        // TODO(mrschmidt): Implement isEquals\r\n        return this === other;\r\n    }\r\n}\r\nclass NumericIncrementFieldValueImpl extends FieldValue {\r\n    constructor(methodName, _operand) {\r\n        super(methodName);\r\n        this._operand = _operand;\r\n    }\r\n    _toFieldTransform(context) {\r\n        const numericIncrement = new NumericIncrementTransformOperation(context.serializer, toNumber(context.serializer, this._operand));\r\n        return new FieldTransform(context.path, numericIncrement);\r\n    }\r\n    isEqual(other) {\r\n        // TODO(mrschmidt): Implement isEquals\r\n        return this === other;\r\n    }\r\n}\r\n/** Parse update data from an update() call. */\r\nfunction parseUpdateData(userDataReader, methodName, targetDoc, input) {\r\n    const context = userDataReader.createContext(1 /* Update */, methodName, targetDoc);\r\n    validatePlainObject('Data must be an object, but it was:', context, input);\r\n    const fieldMaskPaths = [];\r\n    const updateData = ObjectValue.empty();\r\n    forEach(input, (key, value) => {\r\n        const path = fieldPathFromDotSeparatedString(methodName, key, targetDoc);\r\n        // For Compat types, we have to \"extract\" the underlying types before\r\n        // performing validation.\r\n        value = getModularInstance(value);\r\n        const childContext = context.childContextForFieldPath(path);\r\n        if (value instanceof DeleteFieldValueImpl) {\r\n            // Add it to the field mask, but don't add anything to updateData.\r\n            fieldMaskPaths.push(path);\r\n        }\r\n        else {\r\n            const parsedValue = parseData(value, childContext);\r\n            if (parsedValue != null) {\r\n                fieldMaskPaths.push(path);\r\n                updateData.set(path, parsedValue);\r\n            }\r\n        }\r\n    });\r\n    const mask = new FieldMask(fieldMaskPaths);\r\n    return new ParsedUpdateData(updateData, mask, context.fieldTransforms);\r\n}\r\n/** Parse update data from a list of field/value arguments. */\r\nfunction parseUpdateVarargs(userDataReader, methodName, targetDoc, field, value, moreFieldsAndValues) {\r\n    const context = userDataReader.createContext(1 /* Update */, methodName, targetDoc);\r\n    const keys = [fieldPathFromArgument$1(methodName, field, targetDoc)];\r\n    const values = [value];\r\n    if (moreFieldsAndValues.length % 2 !== 0) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Function ${methodName}() needs to be called with an even number ` +\r\n            'of arguments that alternate between field names and values.');\r\n    }\r\n    for (let i = 0; i < moreFieldsAndValues.length; i += 2) {\r\n        keys.push(fieldPathFromArgument$1(methodName, moreFieldsAndValues[i]));\r\n        values.push(moreFieldsAndValues[i + 1]);\r\n    }\r\n    const fieldMaskPaths = [];\r\n    const updateData = ObjectValue.empty();\r\n    // We iterate in reverse order to pick the last value for a field if the\r\n    // user specified the field multiple times.\r\n    for (let i = keys.length - 1; i >= 0; --i) {\r\n        if (!fieldMaskContains(fieldMaskPaths, keys[i])) {\r\n            const path = keys[i];\r\n            let value = values[i];\r\n            // For Compat types, we have to \"extract\" the underlying types before\r\n            // performing validation.\r\n            value = getModularInstance(value);\r\n            const childContext = context.childContextForFieldPath(path);\r\n            if (value instanceof DeleteFieldValueImpl) {\r\n                // Add it to the field mask, but don't add anything to updateData.\r\n                fieldMaskPaths.push(path);\r\n            }\r\n            else {\r\n                const parsedValue = parseData(value, childContext);\r\n                if (parsedValue != null) {\r\n                    fieldMaskPaths.push(path);\r\n                    updateData.set(path, parsedValue);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    const mask = new FieldMask(fieldMaskPaths);\r\n    return new ParsedUpdateData(updateData, mask, context.fieldTransforms);\r\n}\r\n/**\r\n * Parse a \"query value\" (e.g. value in a where filter or a value in a cursor\r\n * bound).\r\n *\r\n * @param allowArrays - Whether the query value is an array that may directly\r\n * contain additional arrays (e.g. the operand of an `in` query).\r\n */\r\nfunction parseQueryValue(userDataReader, methodName, input, allowArrays = false) {\r\n    const context = userDataReader.createContext(allowArrays ? 4 /* ArrayArgument */ : 3 /* Argument */, methodName);\r\n    const parsed = parseData(input, context);\r\n    return parsed;\r\n}\r\n/**\r\n * Parses user data to Protobuf Values.\r\n *\r\n * @param input - Data to be parsed.\r\n * @param context - A context object representing the current path being parsed,\r\n * the source of the data being parsed, etc.\r\n * @returns The parsed value, or null if the value was a FieldValue sentinel\r\n * that should not be included in the resulting parsed data.\r\n */\r\nfunction parseData(input, context) {\r\n    // Unwrap the API type from the Compat SDK. This will return the API type\r\n    // from firestore-exp.\r\n    input = getModularInstance(input);\r\n    if (looksLikeJsonObject(input)) {\r\n        validatePlainObject('Unsupported field value:', context, input);\r\n        return parseObject(input, context);\r\n    }\r\n    else if (input instanceof FieldValue) {\r\n        // FieldValues usually parse into transforms (except FieldValue.delete())\r\n        // in which case we do not want to include this field in our parsed data\r\n        // (as doing so will overwrite the field directly prior to the transform\r\n        // trying to transform it). So we don't add this location to\r\n        // context.fieldMask and we return null as our parsing result.\r\n        parseSentinelFieldValue(input, context);\r\n        return null;\r\n    }\r\n    else if (input === undefined && context.ignoreUndefinedProperties) {\r\n        // If the input is undefined it can never participate in the fieldMask, so\r\n        // don't handle this below. If `ignoreUndefinedProperties` is false,\r\n        // `parseScalarValue` will reject an undefined value.\r\n        return null;\r\n    }\r\n    else {\r\n        // If context.path is null we are inside an array and we don't support\r\n        // field mask paths more granular than the top-level array.\r\n        if (context.path) {\r\n            context.fieldMask.push(context.path);\r\n        }\r\n        if (input instanceof Array) {\r\n            // TODO(b/34871131): Include the path containing the array in the error\r\n            // message.\r\n            // In the case of IN queries, the parsed data is an array (representing\r\n            // the set of values to be included for the IN query) that may directly\r\n            // contain additional arrays (each representing an individual field\r\n            // value), so we disable this validation.\r\n            if (context.settings.arrayElement &&\r\n                context.dataSource !== 4 /* ArrayArgument */) {\r\n                throw context.createError('Nested arrays are not supported');\r\n            }\r\n            return parseArray(input, context);\r\n        }\r\n        else {\r\n            return parseScalarValue(input, context);\r\n        }\r\n    }\r\n}\r\nfunction parseObject(obj, context) {\r\n    const fields = {};\r\n    if (isEmpty(obj)) {\r\n        // If we encounter an empty object, we explicitly add it to the update\r\n        // mask to ensure that the server creates a map entry.\r\n        if (context.path && context.path.length > 0) {\r\n            context.fieldMask.push(context.path);\r\n        }\r\n    }\r\n    else {\r\n        forEach(obj, (key, val) => {\r\n            const parsedValue = parseData(val, context.childContextForField(key));\r\n            if (parsedValue != null) {\r\n                fields[key] = parsedValue;\r\n            }\r\n        });\r\n    }\r\n    return { mapValue: { fields } };\r\n}\r\nfunction parseArray(array, context) {\r\n    const values = [];\r\n    let entryIndex = 0;\r\n    for (const entry of array) {\r\n        let parsedEntry = parseData(entry, context.childContextForArray(entryIndex));\r\n        if (parsedEntry == null) {\r\n            // Just include nulls in the array for fields being replaced with a\r\n            // sentinel.\r\n            parsedEntry = { nullValue: 'NULL_VALUE' };\r\n        }\r\n        values.push(parsedEntry);\r\n        entryIndex++;\r\n    }\r\n    return { arrayValue: { values } };\r\n}\r\n/**\r\n * \"Parses\" the provided FieldValueImpl, adding any necessary transforms to\r\n * context.fieldTransforms.\r\n */\r\nfunction parseSentinelFieldValue(value, context) {\r\n    // Sentinels are only supported with writes, and not within arrays.\r\n    if (!isWrite(context.dataSource)) {\r\n        throw context.createError(`${value._methodName}() can only be used with update() and set()`);\r\n    }\r\n    if (!context.path) {\r\n        throw context.createError(`${value._methodName}() is not currently supported inside arrays`);\r\n    }\r\n    const fieldTransform = value._toFieldTransform(context);\r\n    if (fieldTransform) {\r\n        context.fieldTransforms.push(fieldTransform);\r\n    }\r\n}\r\n/**\r\n * Helper to parse a scalar value (i.e. not an Object, Array, or FieldValue)\r\n *\r\n * @returns The parsed value\r\n */\r\nfunction parseScalarValue(value, context) {\r\n    value = getModularInstance(value);\r\n    if (value === null) {\r\n        return { nullValue: 'NULL_VALUE' };\r\n    }\r\n    else if (typeof value === 'number') {\r\n        return toNumber(context.serializer, value);\r\n    }\r\n    else if (typeof value === 'boolean') {\r\n        return { booleanValue: value };\r\n    }\r\n    else if (typeof value === 'string') {\r\n        return { stringValue: value };\r\n    }\r\n    else if (value instanceof Date) {\r\n        const timestamp = Timestamp.fromDate(value);\r\n        return {\r\n            timestampValue: toTimestamp(context.serializer, timestamp)\r\n        };\r\n    }\r\n    else if (value instanceof Timestamp) {\r\n        // Firestore backend truncates precision down to microseconds. To ensure\r\n        // offline mode works the same with regards to truncation, perform the\r\n        // truncation immediately without waiting for the backend to do that.\r\n        const timestamp = new Timestamp(value.seconds, Math.floor(value.nanoseconds / 1000) * 1000);\r\n        return {\r\n            timestampValue: toTimestamp(context.serializer, timestamp)\r\n        };\r\n    }\r\n    else if (value instanceof GeoPoint) {\r\n        return {\r\n            geoPointValue: {\r\n                latitude: value.latitude,\r\n                longitude: value.longitude\r\n            }\r\n        };\r\n    }\r\n    else if (value instanceof Bytes) {\r\n        return { bytesValue: toBytes(context.serializer, value._byteString) };\r\n    }\r\n    else if (value instanceof DocumentReference) {\r\n        const thisDb = context.databaseId;\r\n        const otherDb = value.firestore._databaseId;\r\n        if (!otherDb.isEqual(thisDb)) {\r\n            throw context.createError('Document reference is for database ' +\r\n                `${otherDb.projectId}/${otherDb.database} but should be ` +\r\n                `for database ${thisDb.projectId}/${thisDb.database}`);\r\n        }\r\n        return {\r\n            referenceValue: toResourceName(value.firestore._databaseId || context.databaseId, value._key.path)\r\n        };\r\n    }\r\n    else {\r\n        throw context.createError(`Unsupported field value: ${valueDescription(value)}`);\r\n    }\r\n}\r\n/**\r\n * Checks whether an object looks like a JSON object that should be converted\r\n * into a struct. Normal class/prototype instances are considered to look like\r\n * JSON objects since they should be converted to a struct value. Arrays, Dates,\r\n * GeoPoints, etc. are not considered to look like JSON objects since they map\r\n * to specific FieldValue types other than ObjectValue.\r\n */\r\nfunction looksLikeJsonObject(input) {\r\n    return (typeof input === 'object' &&\r\n        input !== null &&\r\n        !(input instanceof Array) &&\r\n        !(input instanceof Date) &&\r\n        !(input instanceof Timestamp) &&\r\n        !(input instanceof GeoPoint) &&\r\n        !(input instanceof Bytes) &&\r\n        !(input instanceof DocumentReference) &&\r\n        !(input instanceof FieldValue));\r\n}\r\nfunction validatePlainObject(message, context, input) {\r\n    if (!looksLikeJsonObject(input) || !isPlainObject(input)) {\r\n        const description = valueDescription(input);\r\n        if (description === 'an object') {\r\n            // Massage the error if it was an object.\r\n            throw context.createError(message + ' a custom object');\r\n        }\r\n        else {\r\n            throw context.createError(message + ' ' + description);\r\n        }\r\n    }\r\n}\r\n/**\r\n * Helper that calls fromDotSeparatedString() but wraps any error thrown.\r\n */\r\nfunction fieldPathFromArgument$1(methodName, path, targetDoc) {\r\n    // If required, replace the FieldPath Compat class with with the firestore-exp\r\n    // FieldPath.\r\n    path = getModularInstance(path);\r\n    if (path instanceof FieldPath) {\r\n        return path._internalPath;\r\n    }\r\n    else if (typeof path === 'string') {\r\n        return fieldPathFromDotSeparatedString(methodName, path);\r\n    }\r\n    else {\r\n        const message = 'Field path arguments must be of type string or FieldPath.';\r\n        throw createError(message, methodName, \r\n        /* hasConverter= */ false, \r\n        /* path= */ undefined, targetDoc);\r\n    }\r\n}\r\n/**\r\n * Matches any characters in a field path string that are reserved.\r\n */\r\nconst FIELD_PATH_RESERVED = new RegExp('[~\\\\*/\\\\[\\\\]]');\r\n/**\r\n * Wraps fromDotSeparatedString with an error message about the method that\r\n * was thrown.\r\n * @param methodName - The publicly visible method name\r\n * @param path - The dot-separated string form of a field path which will be\r\n * split on dots.\r\n * @param targetDoc - The document against which the field path will be\r\n * evaluated.\r\n */\r\nfunction fieldPathFromDotSeparatedString(methodName, path, targetDoc) {\r\n    const found = path.search(FIELD_PATH_RESERVED);\r\n    if (found >= 0) {\r\n        throw createError(`Invalid field path (${path}). Paths must not contain ` +\r\n            `'~', '*', '/', '[', or ']'`, methodName, \r\n        /* hasConverter= */ false, \r\n        /* path= */ undefined, targetDoc);\r\n    }\r\n    try {\r\n        return new FieldPath(...path.split('.'))._internalPath;\r\n    }\r\n    catch (e) {\r\n        throw createError(`Invalid field path (${path}). Paths must not be empty, ` +\r\n            `begin with '.', end with '.', or contain '..'`, methodName, \r\n        /* hasConverter= */ false, \r\n        /* path= */ undefined, targetDoc);\r\n    }\r\n}\r\nfunction createError(reason, methodName, hasConverter, path, targetDoc) {\r\n    const hasPath = path && !path.isEmpty();\r\n    const hasDocument = targetDoc !== undefined;\r\n    let message = `Function ${methodName}() called with invalid data`;\r\n    if (hasConverter) {\r\n        message += ' (via `toFirestore()`)';\r\n    }\r\n    message += '. ';\r\n    let description = '';\r\n    if (hasPath || hasDocument) {\r\n        description += ' (found';\r\n        if (hasPath) {\r\n            description += ` in field ${path}`;\r\n        }\r\n        if (hasDocument) {\r\n            description += ` in document ${targetDoc}`;\r\n        }\r\n        description += ')';\r\n    }\r\n    return new FirestoreError(Code.INVALID_ARGUMENT, message + reason + description);\r\n}\r\n/** Checks `haystack` if FieldPath `needle` is present. Runs in O(n). */\r\nfunction fieldMaskContains(haystack, needle) {\r\n    return haystack.some(v => v.isEqual(needle));\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A `DocumentSnapshot` contains data read from a document in your Firestore\r\n * database. The data can be extracted with `.data()` or `.get(<field>)` to\r\n * get a specific field.\r\n *\r\n * For a `DocumentSnapshot` that points to a non-existing document, any data\r\n * access will return 'undefined'. You can use the `exists()` method to\r\n * explicitly verify a document's existence.\r\n */\r\nclass DocumentSnapshot$1 {\r\n    // Note: This class is stripped down version of the DocumentSnapshot in\r\n    // the legacy SDK. The changes are:\r\n    // - No support for SnapshotMetadata.\r\n    // - No support for SnapshotOptions.\r\n    /** @hideconstructor protected */\r\n    constructor(_firestore, _userDataWriter, _key, _document, _converter) {\r\n        this._firestore = _firestore;\r\n        this._userDataWriter = _userDataWriter;\r\n        this._key = _key;\r\n        this._document = _document;\r\n        this._converter = _converter;\r\n    }\r\n    /** Property of the `DocumentSnapshot` that provides the document's ID. */\r\n    get id() {\r\n        return this._key.path.lastSegment();\r\n    }\r\n    /**\r\n     * The `DocumentReference` for the document included in the `DocumentSnapshot`.\r\n     */\r\n    get ref() {\r\n        return new DocumentReference(this._firestore, this._converter, this._key);\r\n    }\r\n    /**\r\n     * Signals whether or not the document at the snapshot's location exists.\r\n     *\r\n     * @returns true if the document exists.\r\n     */\r\n    exists() {\r\n        return this._document !== null;\r\n    }\r\n    /**\r\n     * Retrieves all fields in the document as an `Object`. Returns `undefined` if\r\n     * the document doesn't exist.\r\n     *\r\n     * @returns An `Object` containing all fields in the document or `undefined`\r\n     * if the document doesn't exist.\r\n     */\r\n    data() {\r\n        if (!this._document) {\r\n            return undefined;\r\n        }\r\n        else if (this._converter) {\r\n            // We only want to use the converter and create a new DocumentSnapshot\r\n            // if a converter has been provided.\r\n            const snapshot = new QueryDocumentSnapshot$1(this._firestore, this._userDataWriter, this._key, this._document, \r\n            /* converter= */ null);\r\n            return this._converter.fromFirestore(snapshot);\r\n        }\r\n        else {\r\n            return this._userDataWriter.convertValue(this._document.data.value);\r\n        }\r\n    }\r\n    /**\r\n     * Retrieves the field specified by `fieldPath`. Returns `undefined` if the\r\n     * document or field doesn't exist.\r\n     *\r\n     * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific\r\n     * field.\r\n     * @returns The data at the specified field location or undefined if no such\r\n     * field exists in the document.\r\n     */\r\n    // We are using `any` here to avoid an explicit cast by our users.\r\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n    get(fieldPath) {\r\n        if (this._document) {\r\n            const value = this._document.data.field(fieldPathFromArgument('DocumentSnapshot.get', fieldPath));\r\n            if (value !== null) {\r\n                return this._userDataWriter.convertValue(value);\r\n            }\r\n        }\r\n        return undefined;\r\n    }\r\n}\r\n/**\r\n * A `QueryDocumentSnapshot` contains data read from a document in your\r\n * Firestore database as part of a query. The document is guaranteed to exist\r\n * and its data can be extracted with `.data()` or `.get(<field>)` to get a\r\n * specific field.\r\n *\r\n * A `QueryDocumentSnapshot` offers the same API surface as a\r\n * `DocumentSnapshot`. Since query results contain only existing documents, the\r\n * `exists` property will always be true and `data()` will never return\r\n * 'undefined'.\r\n */\r\nclass QueryDocumentSnapshot$1 extends DocumentSnapshot$1 {\r\n    /**\r\n     * Retrieves all fields in the document as an `Object`.\r\n     *\r\n     * @override\r\n     * @returns An `Object` containing all fields in the document.\r\n     */\r\n    data() {\r\n        return super.data();\r\n    }\r\n}\r\n/**\r\n * Helper that calls `fromDotSeparatedString()` but wraps any error thrown.\r\n */\r\nfunction fieldPathFromArgument(methodName, arg) {\r\n    if (typeof arg === 'string') {\r\n        return fieldPathFromDotSeparatedString(methodName, arg);\r\n    }\r\n    else if (arg instanceof FieldPath) {\r\n        return arg._internalPath;\r\n    }\r\n    else {\r\n        return arg._delegate._internalPath;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Metadata about a snapshot, describing the state of the snapshot.\r\n */\r\nclass SnapshotMetadata {\r\n    /** @hideconstructor */\r\n    constructor(hasPendingWrites, fromCache) {\r\n        this.hasPendingWrites = hasPendingWrites;\r\n        this.fromCache = fromCache;\r\n    }\r\n    /**\r\n     * Returns true if this `SnapshotMetadata` is equal to the provided one.\r\n     *\r\n     * @param other - The `SnapshotMetadata` to compare against.\r\n     * @returns true if this `SnapshotMetadata` is equal to the provided one.\r\n     */\r\n    isEqual(other) {\r\n        return (this.hasPendingWrites === other.hasPendingWrites &&\r\n            this.fromCache === other.fromCache);\r\n    }\r\n}\r\n/**\r\n * A `DocumentSnapshot` contains data read from a document in your Firestore\r\n * database. The data can be extracted with `.data()` or `.get(<field>)` to\r\n * get a specific field.\r\n *\r\n * For a `DocumentSnapshot` that points to a non-existing document, any data\r\n * access will return 'undefined'. You can use the `exists()` method to\r\n * explicitly verify a document's existence.\r\n */\r\nclass DocumentSnapshot extends DocumentSnapshot$1 {\r\n    /** @hideconstructor protected */\r\n    constructor(_firestore, userDataWriter, key, document, metadata, converter) {\r\n        super(_firestore, userDataWriter, key, document, converter);\r\n        this._firestore = _firestore;\r\n        this._firestoreImpl = _firestore;\r\n        this.metadata = metadata;\r\n    }\r\n    /**\r\n     * Property of the `DocumentSnapshot` that signals whether or not the data\r\n     * exists. True if the document exists.\r\n     */\r\n    exists() {\r\n        return super.exists();\r\n    }\r\n    /**\r\n     * Retrieves all fields in the document as an `Object`. Returns `undefined` if\r\n     * the document doesn't exist.\r\n     *\r\n     * By default, `FieldValue.serverTimestamp()` values that have not yet been\r\n     * set to their final value will be returned as `null`. You can override\r\n     * this by passing an options object.\r\n     *\r\n     * @param options - An options object to configure how data is retrieved from\r\n     * the snapshot (for example the desired behavior for server timestamps that\r\n     * have not yet been set to their final value).\r\n     * @returns An `Object` containing all fields in the document or `undefined` if\r\n     * the document doesn't exist.\r\n     */\r\n    data(options = {}) {\r\n        if (!this._document) {\r\n            return undefined;\r\n        }\r\n        else if (this._converter) {\r\n            // We only want to use the converter and create a new DocumentSnapshot\r\n            // if a converter has been provided.\r\n            const snapshot = new QueryDocumentSnapshot(this._firestore, this._userDataWriter, this._key, this._document, this.metadata, \r\n            /* converter= */ null);\r\n            return this._converter.fromFirestore(snapshot, options);\r\n        }\r\n        else {\r\n            return this._userDataWriter.convertValue(this._document.data.value, options.serverTimestamps);\r\n        }\r\n    }\r\n    /**\r\n     * Retrieves the field specified by `fieldPath`. Returns `undefined` if the\r\n     * document or field doesn't exist.\r\n     *\r\n     * By default, a `FieldValue.serverTimestamp()` that has not yet been set to\r\n     * its final value will be returned as `null`. You can override this by\r\n     * passing an options object.\r\n     *\r\n     * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific\r\n     * field.\r\n     * @param options - An options object to configure how the field is retrieved\r\n     * from the snapshot (for example the desired behavior for server timestamps\r\n     * that have not yet been set to their final value).\r\n     * @returns The data at the specified field location or undefined if no such\r\n     * field exists in the document.\r\n     */\r\n    // We are using `any` here to avoid an explicit cast by our users.\r\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n    get(fieldPath, options = {}) {\r\n        if (this._document) {\r\n            const value = this._document.data.field(fieldPathFromArgument('DocumentSnapshot.get', fieldPath));\r\n            if (value !== null) {\r\n                return this._userDataWriter.convertValue(value, options.serverTimestamps);\r\n            }\r\n        }\r\n        return undefined;\r\n    }\r\n}\r\n/**\r\n * A `QueryDocumentSnapshot` contains data read from a document in your\r\n * Firestore database as part of a query. The document is guaranteed to exist\r\n * and its data can be extracted with `.data()` or `.get(<field>)` to get a\r\n * specific field.\r\n *\r\n * A `QueryDocumentSnapshot` offers the same API surface as a\r\n * `DocumentSnapshot`. Since query results contain only existing documents, the\r\n * `exists` property will always be true and `data()` will never return\r\n * 'undefined'.\r\n */\r\nclass QueryDocumentSnapshot extends DocumentSnapshot {\r\n    /**\r\n     * Retrieves all fields in the document as an `Object`.\r\n     *\r\n     * By default, `FieldValue.serverTimestamp()` values that have not yet been\r\n     * set to their final value will be returned as `null`. You can override\r\n     * this by passing an options object.\r\n     *\r\n     * @override\r\n     * @param options - An options object to configure how data is retrieved from\r\n     * the snapshot (for example the desired behavior for server timestamps that\r\n     * have not yet been set to their final value).\r\n     * @returns An `Object` containing all fields in the document.\r\n     */\r\n    data(options = {}) {\r\n        return super.data(options);\r\n    }\r\n}\r\n/**\r\n * A `QuerySnapshot` contains zero or more `DocumentSnapshot` objects\r\n * representing the results of a query. The documents can be accessed as an\r\n * array via the `docs` property or enumerated using the `forEach` method. The\r\n * number of documents can be determined via the `empty` and `size`\r\n * properties.\r\n */\r\nclass QuerySnapshot {\r\n    /** @hideconstructor */\r\n    constructor(_firestore, _userDataWriter, query, _snapshot) {\r\n        this._firestore = _firestore;\r\n        this._userDataWriter = _userDataWriter;\r\n        this._snapshot = _snapshot;\r\n        this.metadata = new SnapshotMetadata(_snapshot.hasPendingWrites, _snapshot.fromCache);\r\n        this.query = query;\r\n    }\r\n    /** An array of all the documents in the `QuerySnapshot`. */\r\n    get docs() {\r\n        const result = [];\r\n        this.forEach(doc => result.push(doc));\r\n        return result;\r\n    }\r\n    /** The number of documents in the `QuerySnapshot`. */\r\n    get size() {\r\n        return this._snapshot.docs.size;\r\n    }\r\n    /** True if there are no documents in the `QuerySnapshot`. */\r\n    get empty() {\r\n        return this.size === 0;\r\n    }\r\n    /**\r\n     * Enumerates all of the documents in the `QuerySnapshot`.\r\n     *\r\n     * @param callback - A callback to be called with a `QueryDocumentSnapshot` for\r\n     * each document in the snapshot.\r\n     * @param thisArg - The `this` binding for the callback.\r\n     */\r\n    forEach(callback, thisArg) {\r\n        this._snapshot.docs.forEach(doc => {\r\n            callback.call(thisArg, new QueryDocumentSnapshot(this._firestore, this._userDataWriter, doc.key, doc, new SnapshotMetadata(this._snapshot.mutatedKeys.has(doc.key), this._snapshot.fromCache), this.query.converter));\r\n        });\r\n    }\r\n    /**\r\n     * Returns an array of the documents changes since the last snapshot. If this\r\n     * is the first snapshot, all documents will be in the list as 'added'\r\n     * changes.\r\n     *\r\n     * @param options - `SnapshotListenOptions` that control whether metadata-only\r\n     * changes (i.e. only `DocumentSnapshot.metadata` changed) should trigger\r\n     * snapshot events.\r\n     */\r\n    docChanges(options = {}) {\r\n        const includeMetadataChanges = !!options.includeMetadataChanges;\r\n        if (includeMetadataChanges && this._snapshot.excludesMetadataChanges) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'To include metadata changes with your document changes, you must ' +\r\n                'also pass { includeMetadataChanges:true } to onSnapshot().');\r\n        }\r\n        if (!this._cachedChanges ||\r\n            this._cachedChangesIncludeMetadataChanges !== includeMetadataChanges) {\r\n            this._cachedChanges = changesFromSnapshot(this, includeMetadataChanges);\r\n            this._cachedChangesIncludeMetadataChanges = includeMetadataChanges;\r\n        }\r\n        return this._cachedChanges;\r\n    }\r\n}\r\n/** Calculates the array of `DocumentChange`s for a given `ViewSnapshot`. */\r\nfunction changesFromSnapshot(querySnapshot, includeMetadataChanges) {\r\n    if (querySnapshot._snapshot.oldDocs.isEmpty()) {\r\n        let index = 0;\r\n        return querySnapshot._snapshot.docChanges.map(change => {\r\n            const doc = new QueryDocumentSnapshot(querySnapshot._firestore, querySnapshot._userDataWriter, change.doc.key, change.doc, new SnapshotMetadata(querySnapshot._snapshot.mutatedKeys.has(change.doc.key), querySnapshot._snapshot.fromCache), querySnapshot.query.converter);\r\n            return {\r\n                type: 'added',\r\n                doc,\r\n                oldIndex: -1,\r\n                newIndex: index++\r\n            };\r\n        });\r\n    }\r\n    else {\r\n        // A `DocumentSet` that is updated incrementally as changes are applied to use\r\n        // to lookup the index of a document.\r\n        let indexTracker = querySnapshot._snapshot.oldDocs;\r\n        return querySnapshot._snapshot.docChanges\r\n            .filter(change => includeMetadataChanges || change.type !== 3 /* Metadata */)\r\n            .map(change => {\r\n            const doc = new QueryDocumentSnapshot(querySnapshot._firestore, querySnapshot._userDataWriter, change.doc.key, change.doc, new SnapshotMetadata(querySnapshot._snapshot.mutatedKeys.has(change.doc.key), querySnapshot._snapshot.fromCache), querySnapshot.query.converter);\r\n            let oldIndex = -1;\r\n            let newIndex = -1;\r\n            if (change.type !== 0 /* Added */) {\r\n                oldIndex = indexTracker.indexOf(change.doc.key);\r\n                indexTracker = indexTracker.delete(change.doc.key);\r\n            }\r\n            if (change.type !== 1 /* Removed */) {\r\n                indexTracker = indexTracker.add(change.doc);\r\n                newIndex = indexTracker.indexOf(change.doc.key);\r\n            }\r\n            return {\r\n                type: resultChangeType(change.type),\r\n                doc,\r\n                oldIndex,\r\n                newIndex\r\n            };\r\n        });\r\n    }\r\n}\r\nfunction resultChangeType(type) {\r\n    switch (type) {\r\n        case 0 /* Added */:\r\n            return 'added';\r\n        case 2 /* Modified */:\r\n        case 3 /* Metadata */:\r\n            return 'modified';\r\n        case 1 /* Removed */:\r\n            return 'removed';\r\n        default:\r\n            return fail();\r\n    }\r\n}\r\n// TODO(firestoreexp): Add tests for snapshotEqual with different snapshot\r\n// metadata\r\n/**\r\n * Returns true if the provided snapshots are equal.\r\n *\r\n * @param left - A snapshot to compare.\r\n * @param right - A snapshot to compare.\r\n * @returns true if the snapshots are equal.\r\n */\r\nfunction snapshotEqual(left, right) {\r\n    if (left instanceof DocumentSnapshot && right instanceof DocumentSnapshot) {\r\n        return (left._firestore === right._firestore &&\r\n            left._key.isEqual(right._key) &&\r\n            (left._document === null\r\n                ? right._document === null\r\n                : left._document.isEqual(right._document)) &&\r\n            left._converter === right._converter);\r\n    }\r\n    else if (left instanceof QuerySnapshot && right instanceof QuerySnapshot) {\r\n        return (left._firestore === right._firestore &&\r\n            queryEqual(left.query, right.query) &&\r\n            left.metadata.isEqual(right.metadata) &&\r\n            left._snapshot.isEqual(right._snapshot));\r\n    }\r\n    return false;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction validateHasExplicitOrderByForLimitToLast(query) {\r\n    if (hasLimitToLast(query) && query.explicitOrderBy.length === 0) {\r\n        throw new FirestoreError(Code.UNIMPLEMENTED, 'limitToLast() queries require specifying at least one orderBy() clause');\r\n    }\r\n}\r\n/**\r\n * A `QueryConstraint` is used to narrow the set of documents returned by a\r\n * Firestore query. `QueryConstraint`s are created by invoking {@link where},\r\n * {@link orderBy}, {@link (startAt:1)}, {@link (startAfter:1)}, {@link\r\n * endBefore:1}, {@link (endAt:1)}, {@link limit} or {@link limitToLast} and\r\n * can then be passed to {@link query} to create a new query instance that\r\n * also contains this `QueryConstraint`.\r\n */\r\nclass QueryConstraint {\r\n}\r\n/**\r\n * Creates a new immutable instance of {@link Query} that is extended to also include\r\n * additional query constraints.\r\n *\r\n * @param query - The {@link Query} instance to use as a base for the new constraints.\r\n * @param queryConstraints - The list of {@link QueryConstraint}s to apply.\r\n * @throws if any of the provided query constraints cannot be combined with the\r\n * existing or new constraints.\r\n */\r\nfunction query(query, ...queryConstraints) {\r\n    for (const constraint of queryConstraints) {\r\n        query = constraint._apply(query);\r\n    }\r\n    return query;\r\n}\r\nclass QueryFilterConstraint extends QueryConstraint {\r\n    constructor(_field, _op, _value) {\r\n        super();\r\n        this._field = _field;\r\n        this._op = _op;\r\n        this._value = _value;\r\n        this.type = 'where';\r\n    }\r\n    _apply(query) {\r\n        const reader = newUserDataReader(query.firestore);\r\n        const filter = newQueryFilter(query._query, 'where', reader, query.firestore._databaseId, this._field, this._op, this._value);\r\n        return new Query(query.firestore, query.converter, queryWithAddedFilter(query._query, filter));\r\n    }\r\n}\r\n/**\r\n * Creates a {@link QueryConstraint} that enforces that documents must contain the\r\n * specified field and that the value should satisfy the relation constraint\r\n * provided.\r\n *\r\n * @param fieldPath - The path to compare\r\n * @param opStr - The operation string (e.g \"&lt;\", \"&lt;=\", \"==\", \"&lt;\",\r\n *   \"&lt;=\", \"!=\").\r\n * @param value - The value for comparison\r\n * @returns The created {@link Query}.\r\n */\r\nfunction where(fieldPath, opStr, value) {\r\n    const op = opStr;\r\n    const field = fieldPathFromArgument('where', fieldPath);\r\n    return new QueryFilterConstraint(field, op, value);\r\n}\r\nclass QueryOrderByConstraint extends QueryConstraint {\r\n    constructor(_field, _direction) {\r\n        super();\r\n        this._field = _field;\r\n        this._direction = _direction;\r\n        this.type = 'orderBy';\r\n    }\r\n    _apply(query) {\r\n        const orderBy = newQueryOrderBy(query._query, this._field, this._direction);\r\n        return new Query(query.firestore, query.converter, queryWithAddedOrderBy(query._query, orderBy));\r\n    }\r\n}\r\n/**\r\n * Creates a {@link QueryConstraint} that sorts the query result by the\r\n * specified field, optionally in descending order instead of ascending.\r\n *\r\n * @param fieldPath - The field to sort by.\r\n * @param directionStr - Optional direction to sort by ('asc' or 'desc'). If\r\n * not specified, order will be ascending.\r\n * @returns The created {@link Query}.\r\n */\r\nfunction orderBy(fieldPath, directionStr = 'asc') {\r\n    const direction = directionStr;\r\n    const path = fieldPathFromArgument('orderBy', fieldPath);\r\n    return new QueryOrderByConstraint(path, direction);\r\n}\r\nclass QueryLimitConstraint extends QueryConstraint {\r\n    constructor(type, _limit, _limitType) {\r\n        super();\r\n        this.type = type;\r\n        this._limit = _limit;\r\n        this._limitType = _limitType;\r\n    }\r\n    _apply(query) {\r\n        return new Query(query.firestore, query.converter, queryWithLimit(query._query, this._limit, this._limitType));\r\n    }\r\n}\r\n/**\r\n * Creates a {@link QueryConstraint} that only returns the first matching documents.\r\n *\r\n * @param limit - The maximum number of items to return.\r\n * @returns The created {@link Query}.\r\n */\r\nfunction limit(limit) {\r\n    validatePositiveNumber('limit', limit);\r\n    return new QueryLimitConstraint('limit', limit, \"F\" /* First */);\r\n}\r\n/**\r\n * Creates a {@link QueryConstraint} that only returns the last matching documents.\r\n *\r\n * You must specify at least one `orderBy` clause for `limitToLast` queries,\r\n * otherwise an exception will be thrown during execution.\r\n *\r\n * @param limit - The maximum number of items to return.\r\n * @returns The created {@link Query}.\r\n */\r\nfunction limitToLast(limit) {\r\n    validatePositiveNumber('limitToLast', limit);\r\n    return new QueryLimitConstraint('limitToLast', limit, \"L\" /* Last */);\r\n}\r\nclass QueryStartAtConstraint extends QueryConstraint {\r\n    constructor(type, _docOrFields, _before) {\r\n        super();\r\n        this.type = type;\r\n        this._docOrFields = _docOrFields;\r\n        this._before = _before;\r\n    }\r\n    _apply(query) {\r\n        const bound = newQueryBoundFromDocOrFields(query, this.type, this._docOrFields, this._before);\r\n        return new Query(query.firestore, query.converter, queryWithStartAt(query._query, bound));\r\n    }\r\n}\r\nfunction startAt(...docOrFields) {\r\n    return new QueryStartAtConstraint('startAt', docOrFields, /*before=*/ true);\r\n}\r\nfunction startAfter(...docOrFields) {\r\n    return new QueryStartAtConstraint('startAfter', docOrFields, \r\n    /*before=*/ false);\r\n}\r\nclass QueryEndAtConstraint extends QueryConstraint {\r\n    constructor(type, _docOrFields, _before) {\r\n        super();\r\n        this.type = type;\r\n        this._docOrFields = _docOrFields;\r\n        this._before = _before;\r\n    }\r\n    _apply(query) {\r\n        const bound = newQueryBoundFromDocOrFields(query, this.type, this._docOrFields, this._before);\r\n        return new Query(query.firestore, query.converter, queryWithEndAt(query._query, bound));\r\n    }\r\n}\r\nfunction endBefore(...docOrFields) {\r\n    return new QueryEndAtConstraint('endBefore', docOrFields, /*before=*/ true);\r\n}\r\nfunction endAt(...docOrFields) {\r\n    return new QueryEndAtConstraint('endAt', docOrFields, /*before=*/ false);\r\n}\r\n/** Helper function to create a bound from a document or fields */\r\nfunction newQueryBoundFromDocOrFields(query, methodName, docOrFields, before) {\r\n    docOrFields[0] = getModularInstance(docOrFields[0]);\r\n    if (docOrFields[0] instanceof DocumentSnapshot$1) {\r\n        return newQueryBoundFromDocument(query._query, query.firestore._databaseId, methodName, docOrFields[0]._document, before);\r\n    }\r\n    else {\r\n        const reader = newUserDataReader(query.firestore);\r\n        return newQueryBoundFromFields(query._query, query.firestore._databaseId, reader, methodName, docOrFields, before);\r\n    }\r\n}\r\nfunction newQueryFilter(query, methodName, dataReader, databaseId, fieldPath, op, value) {\r\n    let fieldValue;\r\n    if (fieldPath.isKeyField()) {\r\n        if (op === \"array-contains\" /* ARRAY_CONTAINS */ || op === \"array-contains-any\" /* ARRAY_CONTAINS_ANY */) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid Query. You can't perform '${op}' ` +\r\n                'queries on FieldPath.documentId().');\r\n        }\r\n        else if (op === \"in\" /* IN */ || op === \"not-in\" /* NOT_IN */) {\r\n            validateDisjunctiveFilterElements(value, op);\r\n            const referenceList = [];\r\n            for (const arrayValue of value) {\r\n                referenceList.push(parseDocumentIdValue(databaseId, query, arrayValue));\r\n            }\r\n            fieldValue = { arrayValue: { values: referenceList } };\r\n        }\r\n        else {\r\n            fieldValue = parseDocumentIdValue(databaseId, query, value);\r\n        }\r\n    }\r\n    else {\r\n        if (op === \"in\" /* IN */ ||\r\n            op === \"not-in\" /* NOT_IN */ ||\r\n            op === \"array-contains-any\" /* ARRAY_CONTAINS_ANY */) {\r\n            validateDisjunctiveFilterElements(value, op);\r\n        }\r\n        fieldValue = parseQueryValue(dataReader, methodName, value, \r\n        /* allowArrays= */ op === \"in\" /* IN */ || op === \"not-in\" /* NOT_IN */);\r\n    }\r\n    const filter = FieldFilter.create(fieldPath, op, fieldValue);\r\n    validateNewFilter(query, filter);\r\n    return filter;\r\n}\r\nfunction newQueryOrderBy(query, fieldPath, direction) {\r\n    if (query.startAt !== null) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You must not call startAt() or startAfter() before ' +\r\n            'calling orderBy().');\r\n    }\r\n    if (query.endAt !== null) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You must not call endAt() or endBefore() before ' +\r\n            'calling orderBy().');\r\n    }\r\n    const orderBy = new OrderBy(fieldPath, direction);\r\n    validateNewOrderBy(query, orderBy);\r\n    return orderBy;\r\n}\r\n/**\r\n * Create a `Bound` from a query and a document.\r\n *\r\n * Note that the `Bound` will always include the key of the document\r\n * and so only the provided document will compare equal to the returned\r\n * position.\r\n *\r\n * Will throw if the document does not contain all fields of the order by\r\n * of the query or if any of the fields in the order by are an uncommitted\r\n * server timestamp.\r\n */\r\nfunction newQueryBoundFromDocument(query, databaseId, methodName, doc, before) {\r\n    if (!doc) {\r\n        throw new FirestoreError(Code.NOT_FOUND, `Can't use a DocumentSnapshot that doesn't exist for ` +\r\n            `${methodName}().`);\r\n    }\r\n    const components = [];\r\n    // Because people expect to continue/end a query at the exact document\r\n    // provided, we need to use the implicit sort order rather than the explicit\r\n    // sort order, because it's guaranteed to contain the document key. That way\r\n    // the position becomes unambiguous and the query continues/ends exactly at\r\n    // the provided document. Without the key (by using the explicit sort\r\n    // orders), multiple documents could match the position, yielding duplicate\r\n    // results.\r\n    for (const orderBy of queryOrderBy(query)) {\r\n        if (orderBy.field.isKeyField()) {\r\n            components.push(refValue(databaseId, doc.key));\r\n        }\r\n        else {\r\n            const value = doc.data.field(orderBy.field);\r\n            if (isServerTimestamp(value)) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You are trying to start or end a query using a ' +\r\n                    'document for which the field \"' +\r\n                    orderBy.field +\r\n                    '\" is an uncommitted server timestamp. (Since the value of ' +\r\n                    'this field is unknown, you cannot start/end a query with it.)');\r\n            }\r\n            else if (value !== null) {\r\n                components.push(value);\r\n            }\r\n            else {\r\n                const field = orderBy.field.canonicalString();\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. You are trying to start or end a query using a ` +\r\n                    `document for which the field '${field}' (used as the ` +\r\n                    `orderBy) does not exist.`);\r\n            }\r\n        }\r\n    }\r\n    return new Bound(components, before);\r\n}\r\n/**\r\n * Converts a list of field values to a `Bound` for the given query.\r\n */\r\nfunction newQueryBoundFromFields(query, databaseId, dataReader, methodName, values, before) {\r\n    // Use explicit order by's because it has to match the query the user made\r\n    const orderBy = query.explicitOrderBy;\r\n    if (values.length > orderBy.length) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Too many arguments provided to ${methodName}(). ` +\r\n            `The number of arguments must be less than or equal to the ` +\r\n            `number of orderBy() clauses`);\r\n    }\r\n    const components = [];\r\n    for (let i = 0; i < values.length; i++) {\r\n        const rawValue = values[i];\r\n        const orderByComponent = orderBy[i];\r\n        if (orderByComponent.field.isKeyField()) {\r\n            if (typeof rawValue !== 'string') {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. Expected a string for document ID in ` +\r\n                    `${methodName}(), but got a ${typeof rawValue}`);\r\n            }\r\n            if (!isCollectionGroupQuery(query) && rawValue.indexOf('/') !== -1) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. When querying a collection and ordering by FieldPath.documentId(), ` +\r\n                    `the value passed to ${methodName}() must be a plain document ID, but ` +\r\n                    `'${rawValue}' contains a slash.`);\r\n            }\r\n            const path = query.path.child(ResourcePath.fromString(rawValue));\r\n            if (!DocumentKey.isDocumentKey(path)) {\r\n                throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. When querying a collection group and ordering by ` +\r\n                    `FieldPath.documentId(), the value passed to ${methodName}() must result in a ` +\r\n                    `valid document path, but '${path}' is not because it contains an odd number ` +\r\n                    `of segments.`);\r\n            }\r\n            const key = new DocumentKey(path);\r\n            components.push(refValue(databaseId, key));\r\n        }\r\n        else {\r\n            const wrapped = parseQueryValue(dataReader, methodName, rawValue);\r\n            components.push(wrapped);\r\n        }\r\n    }\r\n    return new Bound(components, before);\r\n}\r\n/**\r\n * Parses the given `documentIdValue` into a `ReferenceValue`, throwing\r\n * appropriate errors if the value is anything other than a `DocumentReference`\r\n * or `string`, or if the string is malformed.\r\n */\r\nfunction parseDocumentIdValue(databaseId, query, documentIdValue) {\r\n    documentIdValue = getModularInstance(documentIdValue);\r\n    if (typeof documentIdValue === 'string') {\r\n        if (documentIdValue === '') {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. When querying with FieldPath.documentId(), you ' +\r\n                'must provide a valid document ID, but it was an empty string.');\r\n        }\r\n        if (!isCollectionGroupQuery(query) && documentIdValue.indexOf('/') !== -1) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. When querying a collection by ` +\r\n                `FieldPath.documentId(), you must provide a plain document ID, but ` +\r\n                `'${documentIdValue}' contains a '/' character.`);\r\n        }\r\n        const path = query.path.child(ResourcePath.fromString(documentIdValue));\r\n        if (!DocumentKey.isDocumentKey(path)) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. When querying a collection group by ` +\r\n                `FieldPath.documentId(), the value provided must result in a valid document path, ` +\r\n                `but '${path}' is not because it has an odd number of segments (${path.length}).`);\r\n        }\r\n        return refValue(databaseId, new DocumentKey(path));\r\n    }\r\n    else if (documentIdValue instanceof DocumentReference) {\r\n        return refValue(databaseId, documentIdValue._key);\r\n    }\r\n    else {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. When querying with FieldPath.documentId(), you must provide a valid ` +\r\n            `string or a DocumentReference, but it was: ` +\r\n            `${valueDescription(documentIdValue)}.`);\r\n    }\r\n}\r\n/**\r\n * Validates that the value passed into a disjunctive filter satisfies all\r\n * array requirements.\r\n */\r\nfunction validateDisjunctiveFilterElements(value, operator) {\r\n    if (!Array.isArray(value) || value.length === 0) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid Query. A non-empty array is required for ' +\r\n            `'${operator.toString()}' filters.`);\r\n    }\r\n    if (value.length > 10) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid Query. '${operator.toString()}' filters support a ` +\r\n            'maximum of 10 elements in the value array.');\r\n    }\r\n}\r\n/**\r\n * Given an operator, returns the set of operators that cannot be used with it.\r\n *\r\n * Operators in a query must adhere to the following set of rules:\r\n * 1. Only one array operator is allowed.\r\n * 2. Only one disjunctive operator is allowed.\r\n * 3. `NOT_EQUAL` cannot be used with another `NOT_EQUAL` operator.\r\n * 4. `NOT_IN` cannot be used with array, disjunctive, or `NOT_EQUAL` operators.\r\n *\r\n * Array operators: `ARRAY_CONTAINS`, `ARRAY_CONTAINS_ANY`\r\n * Disjunctive operators: `IN`, `ARRAY_CONTAINS_ANY`, `NOT_IN`\r\n */\r\nfunction conflictingOps(op) {\r\n    switch (op) {\r\n        case \"!=\" /* NOT_EQUAL */:\r\n            return [\"!=\" /* NOT_EQUAL */, \"not-in\" /* NOT_IN */];\r\n        case \"array-contains\" /* ARRAY_CONTAINS */:\r\n            return [\r\n                \"array-contains\" /* ARRAY_CONTAINS */,\r\n                \"array-contains-any\" /* ARRAY_CONTAINS_ANY */,\r\n                \"not-in\" /* NOT_IN */\r\n            ];\r\n        case \"in\" /* IN */:\r\n            return [\"array-contains-any\" /* ARRAY_CONTAINS_ANY */, \"in\" /* IN */, \"not-in\" /* NOT_IN */];\r\n        case \"array-contains-any\" /* ARRAY_CONTAINS_ANY */:\r\n            return [\r\n                \"array-contains\" /* ARRAY_CONTAINS */,\r\n                \"array-contains-any\" /* ARRAY_CONTAINS_ANY */,\r\n                \"in\" /* IN */,\r\n                \"not-in\" /* NOT_IN */\r\n            ];\r\n        case \"not-in\" /* NOT_IN */:\r\n            return [\r\n                \"array-contains\" /* ARRAY_CONTAINS */,\r\n                \"array-contains-any\" /* ARRAY_CONTAINS_ANY */,\r\n                \"in\" /* IN */,\r\n                \"not-in\" /* NOT_IN */,\r\n                \"!=\" /* NOT_EQUAL */\r\n            ];\r\n        default:\r\n            return [];\r\n    }\r\n}\r\nfunction validateNewFilter(query, filter) {\r\n    if (filter.isInequality()) {\r\n        const existingField = getInequalityFilterField(query);\r\n        if (existingField !== null && !existingField.isEqual(filter.field)) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. All where filters with an inequality' +\r\n                ' (<, <=, !=, not-in, >, or >=) must be on the same field. But you have' +\r\n                ` inequality filters on '${existingField.toString()}'` +\r\n                ` and '${filter.field.toString()}'`);\r\n        }\r\n        const firstOrderByField = getFirstOrderByField(query);\r\n        if (firstOrderByField !== null) {\r\n            validateOrderByAndInequalityMatch(query, filter.field, firstOrderByField);\r\n        }\r\n    }\r\n    const conflictingOp = findFilterOperator(query, conflictingOps(filter.op));\r\n    if (conflictingOp !== null) {\r\n        // Special case when it's a duplicate op to give a slightly clearer error message.\r\n        if (conflictingOp === filter.op) {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You cannot use more than one ' +\r\n                `'${filter.op.toString()}' filter.`);\r\n        }\r\n        else {\r\n            throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. You cannot use '${filter.op.toString()}' filters ` +\r\n                `with '${conflictingOp.toString()}' filters.`);\r\n        }\r\n    }\r\n}\r\nfunction validateNewOrderBy(query, orderBy) {\r\n    if (getFirstOrderByField(query) === null) {\r\n        // This is the first order by. It must match any inequality.\r\n        const inequalityField = getInequalityFilterField(query);\r\n        if (inequalityField !== null) {\r\n            validateOrderByAndInequalityMatch(query, inequalityField, orderBy.field);\r\n        }\r\n    }\r\n}\r\nfunction validateOrderByAndInequalityMatch(baseQuery, inequality, orderBy) {\r\n    if (!orderBy.isEqual(inequality)) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, `Invalid query. You have a where filter with an inequality ` +\r\n            `(<, <=, !=, not-in, >, or >=) on field '${inequality.toString()}' ` +\r\n            `and so you must also use '${inequality.toString()}' ` +\r\n            `as your first argument to orderBy(), but your first orderBy() ` +\r\n            `is on field '${orderBy.toString()}' instead.`);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Converts Firestore's internal types to the JavaScript types that we expose\r\n * to the user.\r\n *\r\n * @internal\r\n */\r\nclass AbstractUserDataWriter {\r\n    convertValue(value, serverTimestampBehavior = 'none') {\r\n        switch (typeOrder(value)) {\r\n            case 0 /* NullValue */:\r\n                return null;\r\n            case 1 /* BooleanValue */:\r\n                return value.booleanValue;\r\n            case 2 /* NumberValue */:\r\n                return normalizeNumber(value.integerValue || value.doubleValue);\r\n            case 3 /* TimestampValue */:\r\n                return this.convertTimestamp(value.timestampValue);\r\n            case 4 /* ServerTimestampValue */:\r\n                return this.convertServerTimestamp(value, serverTimestampBehavior);\r\n            case 5 /* StringValue */:\r\n                return value.stringValue;\r\n            case 6 /* BlobValue */:\r\n                return this.convertBytes(normalizeByteString(value.bytesValue));\r\n            case 7 /* RefValue */:\r\n                return this.convertReference(value.referenceValue);\r\n            case 8 /* GeoPointValue */:\r\n                return this.convertGeoPoint(value.geoPointValue);\r\n            case 9 /* ArrayValue */:\r\n                return this.convertArray(value.arrayValue, serverTimestampBehavior);\r\n            case 10 /* ObjectValue */:\r\n                return this.convertObject(value.mapValue, serverTimestampBehavior);\r\n            default:\r\n                throw fail();\r\n        }\r\n    }\r\n    convertObject(mapValue, serverTimestampBehavior) {\r\n        const result = {};\r\n        forEach(mapValue.fields, (key, value) => {\r\n            result[key] = this.convertValue(value, serverTimestampBehavior);\r\n        });\r\n        return result;\r\n    }\r\n    convertGeoPoint(value) {\r\n        return new GeoPoint(normalizeNumber(value.latitude), normalizeNumber(value.longitude));\r\n    }\r\n    convertArray(arrayValue, serverTimestampBehavior) {\r\n        return (arrayValue.values || []).map(value => this.convertValue(value, serverTimestampBehavior));\r\n    }\r\n    convertServerTimestamp(value, serverTimestampBehavior) {\r\n        switch (serverTimestampBehavior) {\r\n            case 'previous':\r\n                const previousValue = getPreviousValue(value);\r\n                if (previousValue == null) {\r\n                    return null;\r\n                }\r\n                return this.convertValue(previousValue, serverTimestampBehavior);\r\n            case 'estimate':\r\n                return this.convertTimestamp(getLocalWriteTime(value));\r\n            default:\r\n                return null;\r\n        }\r\n    }\r\n    convertTimestamp(value) {\r\n        const normalizedValue = normalizeTimestamp(value);\r\n        return new Timestamp(normalizedValue.seconds, normalizedValue.nanos);\r\n    }\r\n    convertDocumentKey(name, expectedDatabaseId) {\r\n        const resourcePath = ResourcePath.fromString(name);\r\n        hardAssert(isValidResourceName(resourcePath));\r\n        const databaseId = new DatabaseId(resourcePath.get(1), resourcePath.get(3));\r\n        const key = new DocumentKey(resourcePath.popFirst(5));\r\n        if (!databaseId.isEqual(expectedDatabaseId)) {\r\n            // TODO(b/64130202): Somehow support foreign references.\r\n            logError(`Document ${key} contains a document ` +\r\n                `reference within a different database (` +\r\n                `${databaseId.projectId}/${databaseId.database}) which is not ` +\r\n                `supported. It will be treated as a reference in the current ` +\r\n                `database (${expectedDatabaseId.projectId}/${expectedDatabaseId.database}) ` +\r\n                `instead.`);\r\n        }\r\n        return key;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Converts custom model object of type T into `DocumentData` by applying the\r\n * converter if it exists.\r\n *\r\n * This function is used when converting user objects to `DocumentData`\r\n * because we want to provide the user with a more specific error message if\r\n * their `set()` or fails due to invalid data originating from a `toFirestore()`\r\n * call.\r\n */\r\nfunction applyFirestoreDataConverter(converter, value, options) {\r\n    let convertedValue;\r\n    if (converter) {\r\n        if (options && (options.merge || options.mergeFields)) {\r\n            // Cast to `any` in order to satisfy the union type constraint on\r\n            // toFirestore().\r\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n            convertedValue = converter.toFirestore(value, options);\r\n        }\r\n        else {\r\n            convertedValue = converter.toFirestore(value);\r\n        }\r\n    }\r\n    else {\r\n        convertedValue = value;\r\n    }\r\n    return convertedValue;\r\n}\r\nclass LiteUserDataWriter extends AbstractUserDataWriter {\r\n    constructor(firestore) {\r\n        super();\r\n        this.firestore = firestore;\r\n    }\r\n    convertBytes(bytes) {\r\n        return new Bytes(bytes);\r\n    }\r\n    convertReference(name) {\r\n        const key = this.convertDocumentKey(name, this.firestore._databaseId);\r\n        return new DocumentReference(this.firestore, /* converter= */ null, key);\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A write batch, used to perform multiple writes as a single atomic unit.\r\n *\r\n * A `WriteBatch` object can be acquired by calling {@link writeBatch}. It\r\n * provides methods for adding writes to the write batch. None of the writes\r\n * will be committed (or visible locally) until {@link WriteBatch.commit} is\r\n * called.\r\n */\r\nclass WriteBatch {\r\n    /** @hideconstructor */\r\n    constructor(_firestore, _commitHandler) {\r\n        this._firestore = _firestore;\r\n        this._commitHandler = _commitHandler;\r\n        this._mutations = [];\r\n        this._committed = false;\r\n        this._dataReader = newUserDataReader(_firestore);\r\n    }\r\n    set(documentRef, data, options) {\r\n        this._verifyNotCommitted();\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        const convertedValue = applyFirestoreDataConverter(ref.converter, data, options);\r\n        const parsed = parseSetData(this._dataReader, 'WriteBatch.set', ref._key, convertedValue, ref.converter !== null, options);\r\n        this._mutations.push(parsed.toMutation(ref._key, Precondition.none()));\r\n        return this;\r\n    }\r\n    update(documentRef, fieldOrUpdateData, value, ...moreFieldsAndValues) {\r\n        this._verifyNotCommitted();\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        // For Compat types, we have to \"extract\" the underlying types before\r\n        // performing validation.\r\n        fieldOrUpdateData = getModularInstance(fieldOrUpdateData);\r\n        let parsed;\r\n        if (typeof fieldOrUpdateData === 'string' ||\r\n            fieldOrUpdateData instanceof FieldPath) {\r\n            parsed = parseUpdateVarargs(this._dataReader, 'WriteBatch.update', ref._key, fieldOrUpdateData, value, moreFieldsAndValues);\r\n        }\r\n        else {\r\n            parsed = parseUpdateData(this._dataReader, 'WriteBatch.update', ref._key, fieldOrUpdateData);\r\n        }\r\n        this._mutations.push(parsed.toMutation(ref._key, Precondition.exists(true)));\r\n        return this;\r\n    }\r\n    /**\r\n     * Deletes the document referred to by the provided {@link DocumentReference}.\r\n     *\r\n     * @param documentRef - A reference to the document to be deleted.\r\n     * @returns This `WriteBatch` instance. Used for chaining method calls.\r\n     */\r\n    delete(documentRef) {\r\n        this._verifyNotCommitted();\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        this._mutations = this._mutations.concat(new DeleteMutation(ref._key, Precondition.none()));\r\n        return this;\r\n    }\r\n    /**\r\n     * Commits all of the writes in this write batch as a single atomic unit.\r\n     *\r\n     * The result of these writes will only be reflected in document reads that\r\n     * occur after the returned promise resolves. If the client is offline, the\r\n     * write fails. If you would like to see local modifications or buffer writes\r\n     * until the client is online, use the full Firestore SDK.\r\n     *\r\n     * @returns A `Promise` resolved once all of the writes in the batch have been\r\n     * successfully written to the backend as an atomic unit (note that it won't\r\n     * resolve while you're offline).\r\n     */\r\n    commit() {\r\n        this._verifyNotCommitted();\r\n        this._committed = true;\r\n        if (this._mutations.length > 0) {\r\n            return this._commitHandler(this._mutations);\r\n        }\r\n        return Promise.resolve();\r\n    }\r\n    _verifyNotCommitted() {\r\n        if (this._committed) {\r\n            throw new FirestoreError(Code.FAILED_PRECONDITION, 'A write batch can no longer be used after commit() ' +\r\n                'has been called.');\r\n        }\r\n    }\r\n}\r\nfunction validateReference(documentRef, firestore) {\r\n    documentRef = getModularInstance(documentRef);\r\n    if (documentRef.firestore !== firestore) {\r\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Provided document reference is from a different Firestore instance.');\r\n    }\r\n    else {\r\n        return documentRef;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n// TODO(mrschmidt) Consider using `BaseTransaction` as the base class in the\r\n// legacy SDK.\r\n/**\r\n * A reference to a transaction.\r\n *\r\n * The `Transaction` object passed to a transaction's `updateFunction` provides\r\n * the methods to read and write data within the transaction context. See\r\n * {@link runTransaction}.\r\n */\r\nclass Transaction$1 {\r\n    /** @hideconstructor */\r\n    constructor(_firestore, _transaction) {\r\n        this._firestore = _firestore;\r\n        this._transaction = _transaction;\r\n        this._dataReader = newUserDataReader(_firestore);\r\n    }\r\n    /**\r\n     * Reads the document referenced by the provided {@link DocumentReference}.\r\n     *\r\n     * @param documentRef - A reference to the document to be read.\r\n     * @returns A `DocumentSnapshot` with the read data.\r\n     */\r\n    get(documentRef) {\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        const userDataWriter = new LiteUserDataWriter(this._firestore);\r\n        return this._transaction.lookup([ref._key]).then(docs => {\r\n            if (!docs || docs.length !== 1) {\r\n                return fail();\r\n            }\r\n            const doc = docs[0];\r\n            if (doc.isFoundDocument()) {\r\n                return new DocumentSnapshot$1(this._firestore, userDataWriter, doc.key, doc, ref.converter);\r\n            }\r\n            else if (doc.isNoDocument()) {\r\n                return new DocumentSnapshot$1(this._firestore, userDataWriter, ref._key, null, ref.converter);\r\n            }\r\n            else {\r\n                throw fail();\r\n            }\r\n        });\r\n    }\r\n    set(documentRef, value, options) {\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        const convertedValue = applyFirestoreDataConverter(ref.converter, value, options);\r\n        const parsed = parseSetData(this._dataReader, 'Transaction.set', ref._key, convertedValue, ref.converter !== null, options);\r\n        this._transaction.set(ref._key, parsed);\r\n        return this;\r\n    }\r\n    update(documentRef, fieldOrUpdateData, value, ...moreFieldsAndValues) {\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        // For Compat types, we have to \"extract\" the underlying types before\r\n        // performing validation.\r\n        fieldOrUpdateData = getModularInstance(fieldOrUpdateData);\r\n        let parsed;\r\n        if (typeof fieldOrUpdateData === 'string' ||\r\n            fieldOrUpdateData instanceof FieldPath) {\r\n            parsed = parseUpdateVarargs(this._dataReader, 'Transaction.update', ref._key, fieldOrUpdateData, value, moreFieldsAndValues);\r\n        }\r\n        else {\r\n            parsed = parseUpdateData(this._dataReader, 'Transaction.update', ref._key, fieldOrUpdateData);\r\n        }\r\n        this._transaction.update(ref._key, parsed);\r\n        return this;\r\n    }\r\n    /**\r\n     * Deletes the document referred to by the provided {@link DocumentReference}.\r\n     *\r\n     * @param documentRef - A reference to the document to be deleted.\r\n     * @returns This `Transaction` instance. Used for chaining method calls.\r\n     */\r\n    delete(documentRef) {\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        this._transaction.delete(ref._key);\r\n        return this;\r\n    }\r\n}\n\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nfunction isPartialObserver(obj) {\r\n    return implementsAnyMethods(obj, ['next', 'error', 'complete']);\r\n}\r\n/**\r\n * Returns true if obj is an object and contains at least one of the specified\r\n * methods.\r\n */\r\nfunction implementsAnyMethods(obj, methods) {\r\n    if (typeof obj !== 'object' || obj === null) {\r\n        return false;\r\n    }\r\n    const object = obj;\r\n    for (const method of methods) {\r\n        if (method in object && typeof object[method] === 'function') {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Reads the document referred to by this `DocumentReference`.\r\n *\r\n * Note: `getDoc()` attempts to provide up-to-date data when possible by waiting\r\n * for data from the server, but it may return cached data or fail if you are\r\n * offline and the server cannot be reached. To specify this behavior, invoke\r\n * {@link getDocFromCache} or {@link getDocFromServer}.\r\n *\r\n * @param reference - The reference of the document to fetch.\r\n * @returns A Promise resolved with a `DocumentSnapshot` containing the\r\n * current document contents.\r\n */\r\nfunction getDoc(reference) {\r\n    reference = cast(reference, DocumentReference);\r\n    const firestore = cast(reference.firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientGetDocumentViaSnapshotListener(client, reference._key).then(snapshot => convertToDocSnapshot(firestore, reference, snapshot));\r\n}\r\nclass ExpUserDataWriter extends AbstractUserDataWriter {\r\n    constructor(firestore) {\r\n        super();\r\n        this.firestore = firestore;\r\n    }\r\n    convertBytes(bytes) {\r\n        return new Bytes(bytes);\r\n    }\r\n    convertReference(name) {\r\n        const key = this.convertDocumentKey(name, this.firestore._databaseId);\r\n        return new DocumentReference(this.firestore, /* converter= */ null, key);\r\n    }\r\n}\r\n/**\r\n * Reads the document referred to by this `DocumentReference` from cache.\r\n * Returns an error if the document is not currently cached.\r\n *\r\n * @returns A `Promise` resolved with a `DocumentSnapshot` containing the\r\n * current document contents.\r\n */\r\nfunction getDocFromCache(reference) {\r\n    reference = cast(reference, DocumentReference);\r\n    const firestore = cast(reference.firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const userDataWriter = new ExpUserDataWriter(firestore);\r\n    return firestoreClientGetDocumentFromLocalCache(client, reference._key).then(doc => new DocumentSnapshot(firestore, userDataWriter, reference._key, doc, new SnapshotMetadata(doc !== null && doc.hasLocalMutations, \r\n    /* fromCache= */ true), reference.converter));\r\n}\r\n/**\r\n * Reads the document referred to by this `DocumentReference` from the server.\r\n * Returns an error if the network is not available.\r\n *\r\n * @returns A `Promise` resolved with a `DocumentSnapshot` containing the\r\n * current document contents.\r\n */\r\nfunction getDocFromServer(reference) {\r\n    reference = cast(reference, DocumentReference);\r\n    const firestore = cast(reference.firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientGetDocumentViaSnapshotListener(client, reference._key, {\r\n        source: 'server'\r\n    }).then(snapshot => convertToDocSnapshot(firestore, reference, snapshot));\r\n}\r\n/**\r\n * Executes the query and returns the results as a `QuerySnapshot`.\r\n *\r\n * Note: `getDocs()` attempts to provide up-to-date data when possible by\r\n * waiting for data from the server, but it may return cached data or fail if\r\n * you are offline and the server cannot be reached. To specify this behavior,\r\n * invoke {@link getDocsFromCache} or {@link getDocsFromServer}.\r\n *\r\n * @returns A `Promise` that will be resolved with the results of the query.\r\n */\r\nfunction getDocs(query) {\r\n    query = cast(query, Query);\r\n    const firestore = cast(query.firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const userDataWriter = new ExpUserDataWriter(firestore);\r\n    validateHasExplicitOrderByForLimitToLast(query._query);\r\n    return firestoreClientGetDocumentsViaSnapshotListener(client, query._query).then(snapshot => new QuerySnapshot(firestore, userDataWriter, query, snapshot));\r\n}\r\n/**\r\n * Executes the query and returns the results as a `QuerySnapshot` from cache.\r\n * Returns an error if the document is not currently cached.\r\n *\r\n * @returns A `Promise` that will be resolved with the results of the query.\r\n */\r\nfunction getDocsFromCache(query) {\r\n    query = cast(query, Query);\r\n    const firestore = cast(query.firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const userDataWriter = new ExpUserDataWriter(firestore);\r\n    return firestoreClientGetDocumentsFromLocalCache(client, query._query).then(snapshot => new QuerySnapshot(firestore, userDataWriter, query, snapshot));\r\n}\r\n/**\r\n * Executes the query and returns the results as a `QuerySnapshot` from the\r\n * server. Returns an error if the network is not available.\r\n *\r\n * @returns A `Promise` that will be resolved with the results of the query.\r\n */\r\nfunction getDocsFromServer(query) {\r\n    query = cast(query, Query);\r\n    const firestore = cast(query.firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const userDataWriter = new ExpUserDataWriter(firestore);\r\n    return firestoreClientGetDocumentsViaSnapshotListener(client, query._query, {\r\n        source: 'server'\r\n    }).then(snapshot => new QuerySnapshot(firestore, userDataWriter, query, snapshot));\r\n}\r\nfunction setDoc(reference, data, options) {\r\n    reference = cast(reference, DocumentReference);\r\n    const firestore = cast(reference.firestore, Firestore);\r\n    const convertedValue = applyFirestoreDataConverter(reference.converter, data, options);\r\n    const dataReader = newUserDataReader(firestore);\r\n    const parsed = parseSetData(dataReader, 'setDoc', reference._key, convertedValue, reference.converter !== null, options);\r\n    const mutation = parsed.toMutation(reference._key, Precondition.none());\r\n    return executeWrite(firestore, [mutation]);\r\n}\r\nfunction updateDoc(reference, fieldOrUpdateData, value, ...moreFieldsAndValues) {\r\n    reference = cast(reference, DocumentReference);\r\n    const firestore = cast(reference.firestore, Firestore);\r\n    const dataReader = newUserDataReader(firestore);\r\n    // For Compat types, we have to \"extract\" the underlying types before\r\n    // performing validation.\r\n    fieldOrUpdateData = getModularInstance(fieldOrUpdateData);\r\n    let parsed;\r\n    if (typeof fieldOrUpdateData === 'string' ||\r\n        fieldOrUpdateData instanceof FieldPath) {\r\n        parsed = parseUpdateVarargs(dataReader, 'updateDoc', reference._key, fieldOrUpdateData, value, moreFieldsAndValues);\r\n    }\r\n    else {\r\n        parsed = parseUpdateData(dataReader, 'updateDoc', reference._key, fieldOrUpdateData);\r\n    }\r\n    const mutation = parsed.toMutation(reference._key, Precondition.exists(true));\r\n    return executeWrite(firestore, [mutation]);\r\n}\r\n/**\r\n * Deletes the document referred to by the specified `DocumentReference`.\r\n *\r\n * @param reference - A reference to the document to delete.\r\n * @returns A Promise resolved once the document has been successfully\r\n * deleted from the backend (note that it won't resolve while you're offline).\r\n */\r\nfunction deleteDoc(reference) {\r\n    const firestore = cast(reference.firestore, Firestore);\r\n    const mutations = [new DeleteMutation(reference._key, Precondition.none())];\r\n    return executeWrite(firestore, mutations);\r\n}\r\n/**\r\n * Add a new document to specified `CollectionReference` with the given data,\r\n * assigning it a document ID automatically.\r\n *\r\n * @param reference - A reference to the collection to add this document to.\r\n * @param data - An Object containing the data for the new document.\r\n * @returns A `Promise` resolved with a `DocumentReference` pointing to the\r\n * newly created document after it has been written to the backend (Note that it\r\n * won't resolve while you're offline).\r\n */\r\nfunction addDoc(reference, data) {\r\n    const firestore = cast(reference.firestore, Firestore);\r\n    const docRef = doc(reference);\r\n    const convertedValue = applyFirestoreDataConverter(reference.converter, data);\r\n    const dataReader = newUserDataReader(reference.firestore);\r\n    const parsed = parseSetData(dataReader, 'addDoc', docRef._key, convertedValue, reference.converter !== null, {});\r\n    const mutation = parsed.toMutation(docRef._key, Precondition.exists(false));\r\n    return executeWrite(firestore, [mutation]).then(() => docRef);\r\n}\r\nfunction onSnapshot(reference, ...args) {\r\n    var _a, _b, _c;\r\n    reference = getModularInstance(reference);\r\n    let options = {\r\n        includeMetadataChanges: false\r\n    };\r\n    let currArg = 0;\r\n    if (typeof args[currArg] === 'object' && !isPartialObserver(args[currArg])) {\r\n        options = args[currArg];\r\n        currArg++;\r\n    }\r\n    const internalOptions = {\r\n        includeMetadataChanges: options.includeMetadataChanges\r\n    };\r\n    if (isPartialObserver(args[currArg])) {\r\n        const userObserver = args[currArg];\r\n        args[currArg] = (_a = userObserver.next) === null || _a === void 0 ? void 0 : _a.bind(userObserver);\r\n        args[currArg + 1] = (_b = userObserver.error) === null || _b === void 0 ? void 0 : _b.bind(userObserver);\r\n        args[currArg + 2] = (_c = userObserver.complete) === null || _c === void 0 ? void 0 : _c.bind(userObserver);\r\n    }\r\n    let observer;\r\n    let firestore;\r\n    let internalQuery;\r\n    if (reference instanceof DocumentReference) {\r\n        firestore = cast(reference.firestore, Firestore);\r\n        internalQuery = newQueryForPath(reference._key.path);\r\n        observer = {\r\n            next: snapshot => {\r\n                if (args[currArg]) {\r\n                    args[currArg](convertToDocSnapshot(firestore, reference, snapshot));\r\n                }\r\n            },\r\n            error: args[currArg + 1],\r\n            complete: args[currArg + 2]\r\n        };\r\n    }\r\n    else {\r\n        const query = cast(reference, Query);\r\n        firestore = cast(query.firestore, Firestore);\r\n        internalQuery = query._query;\r\n        const userDataWriter = new ExpUserDataWriter(firestore);\r\n        observer = {\r\n            next: snapshot => {\r\n                if (args[currArg]) {\r\n                    args[currArg](new QuerySnapshot(firestore, userDataWriter, query, snapshot));\r\n                }\r\n            },\r\n            error: args[currArg + 1],\r\n            complete: args[currArg + 2]\r\n        };\r\n        validateHasExplicitOrderByForLimitToLast(reference._query);\r\n    }\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientListen(client, internalQuery, internalOptions, observer);\r\n}\r\nfunction onSnapshotsInSync(firestore, arg) {\r\n    firestore = cast(firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    const observer = isPartialObserver(arg)\r\n        ? arg\r\n        : {\r\n            next: arg\r\n        };\r\n    return firestoreClientAddSnapshotsInSyncListener(client, observer);\r\n}\r\n/**\r\n * Locally writes `mutations` on the async queue.\r\n * @internal\r\n */\r\nfunction executeWrite(firestore, mutations) {\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientWrite(client, mutations);\r\n}\r\n/**\r\n * Converts a {@link ViewSnapshot} that contains the single document specified by `ref`\r\n * to a {@link DocumentSnapshot}.\r\n */\r\nfunction convertToDocSnapshot(firestore, ref, snapshot) {\r\n    const doc = snapshot.docs.get(ref._key);\r\n    const userDataWriter = new ExpUserDataWriter(firestore);\r\n    return new DocumentSnapshot(firestore, userDataWriter, ref._key, doc, new SnapshotMetadata(snapshot.hasPendingWrites, snapshot.fromCache), ref.converter);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * A reference to a transaction.\r\n *\r\n * The `Transaction` object passed to a transaction's `updateFunction` provides\r\n * the methods to read and write data within the transaction context. See\r\n * {@link runTransaction}.\r\n */\r\nclass Transaction extends Transaction$1 {\r\n    // This class implements the same logic as the Transaction API in the Lite SDK\r\n    // but is subclassed in order to return its own DocumentSnapshot types.\r\n    /** @hideconstructor */\r\n    constructor(_firestore, _transaction) {\r\n        super(_firestore, _transaction);\r\n        this._firestore = _firestore;\r\n    }\r\n    /**\r\n     * Reads the document referenced by the provided {@link DocumentReference}.\r\n     *\r\n     * @param documentRef - A reference to the document to be read.\r\n     * @returns A `DocumentSnapshot` with the read data.\r\n     */\r\n    get(documentRef) {\r\n        const ref = validateReference(documentRef, this._firestore);\r\n        const userDataWriter = new ExpUserDataWriter(this._firestore);\r\n        return super\r\n            .get(documentRef)\r\n            .then(liteDocumentSnapshot => new DocumentSnapshot(this._firestore, userDataWriter, ref._key, liteDocumentSnapshot._document, new SnapshotMetadata(\r\n        /* hasPendingWrites= */ false, \r\n        /* fromCache= */ false), ref.converter));\r\n    }\r\n}\r\n/**\r\n * Executes the given `updateFunction` and then attempts to commit the changes\r\n * applied within the transaction. If any document read within the transaction\r\n * has changed, Cloud Firestore retries the `updateFunction`. If it fails to\r\n * commit after 5 attempts, the transaction fails.\r\n *\r\n * The maximum number of writes allowed in a single transaction is 500.\r\n *\r\n * @param firestore - A reference to the Firestore database to run this\r\n * transaction against.\r\n * @param updateFunction - The function to execute within the transaction\r\n * context.\r\n * @returns If the transaction completed successfully or was explicitly aborted\r\n * (the `updateFunction` returned a failed promise), the promise returned by the\r\n * `updateFunction `is returned here. Otherwise, if the transaction failed, a\r\n * rejected promise with the corresponding failure error is returned.\r\n */\r\nfunction runTransaction(firestore, updateFunction) {\r\n    firestore = cast(firestore, Firestore);\r\n    const client = ensureFirestoreConfigured(firestore);\r\n    return firestoreClientTransaction(client, internalTransaction => updateFunction(new Transaction(firestore, internalTransaction)));\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Returns a sentinel for use with {@link @firebase/firestore/lite#(updateDoc:1)} or\r\n * {@link @firebase/firestore/lite#(setDoc:1)} with `{merge: true}` to mark a field for deletion.\r\n */\r\nfunction deleteField() {\r\n    return new DeleteFieldValueImpl('deleteField');\r\n}\r\n/**\r\n * Returns a sentinel used with {@link @firebase/firestore/lite#(setDoc:1)} or {@link @firebase/firestore/lite#(updateDoc:1)} to\r\n * include a server-generated timestamp in the written data.\r\n */\r\nfunction serverTimestamp() {\r\n    return new ServerTimestampFieldValueImpl('serverTimestamp');\r\n}\r\n/**\r\n * Returns a special value that can be used with {@link @firebase/firestore/lite#(setDoc:1)} or {@link\r\n * @firebase/firestore/lite#(updateDoc:1)} that tells the server to union the given elements with any array\r\n * value that already exists on the server. Each specified element that doesn't\r\n * already exist in the array will be added to the end. If the field being\r\n * modified is not already an array it will be overwritten with an array\r\n * containing exactly the specified elements.\r\n *\r\n * @param elements - The elements to union into the array.\r\n * @returns The `FieldValue` sentinel for use in a call to `setDoc()` or\r\n * `updateDoc()`.\r\n */\r\nfunction arrayUnion(...elements) {\r\n    // NOTE: We don't actually parse the data until it's used in set() or\r\n    // update() since we'd need the Firestore instance to do this.\r\n    return new ArrayUnionFieldValueImpl('arrayUnion', elements);\r\n}\r\n/**\r\n * Returns a special value that can be used with {@link (setDoc:1)} or {@link\r\n * updateDoc:1} that tells the server to remove the given elements from any\r\n * array value that already exists on the server. All instances of each element\r\n * specified will be removed from the array. If the field being modified is not\r\n * already an array it will be overwritten with an empty array.\r\n *\r\n * @param elements - The elements to remove from the array.\r\n * @returns The `FieldValue` sentinel for use in a call to `setDoc()` or\r\n * `updateDoc()`\r\n */\r\nfunction arrayRemove(...elements) {\r\n    // NOTE: We don't actually parse the data until it's used in set() or\r\n    // update() since we'd need the Firestore instance to do this.\r\n    return new ArrayRemoveFieldValueImpl('arrayRemove', elements);\r\n}\r\n/**\r\n * Returns a special value that can be used with {@link @firebase/firestore/lite#(setDoc:1)} or {@link\r\n * @firebase/firestore/lite#(updateDoc:1)} that tells the server to increment the field's current value by\r\n * the given value.\r\n *\r\n * If either the operand or the current field value uses floating point\r\n * precision, all arithmetic follows IEEE 754 semantics. If both values are\r\n * integers, values outside of JavaScript's safe number range\r\n * (`Number.MIN_SAFE_INTEGER` to `Number.MAX_SAFE_INTEGER`) are also subject to\r\n * precision loss. Furthermore, once processed by the Firestore backend, all\r\n * integer operations are capped between -2^63 and 2^63-1.\r\n *\r\n * If the current field value is not of type `number`, or if the field does not\r\n * yet exist, the transformation sets the field to the given value.\r\n *\r\n * @param n - The value to increment by.\r\n * @returns The `FieldValue` sentinel for use in a call to `setDoc()` or\r\n * `updateDoc()`\r\n */\r\nfunction increment(n) {\r\n    return new NumericIncrementFieldValueImpl('increment', n);\r\n}\n\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n/**\r\n * Creates a write batch, used for performing multiple writes as a single\r\n * atomic operation. The maximum number of writes allowed in a single {@link WriteBatch}\r\n * is 500.\r\n *\r\n * Unlike transactions, write batches are persisted offline and therefore are\r\n * preferable when you don't need to condition your writes on read data.\r\n *\r\n * @returns A {@link WriteBatch} that can be used to atomically execute multiple\r\n * writes.\r\n */\r\nfunction writeBatch(firestore) {\r\n    firestore = cast(firestore, Firestore);\r\n    ensureFirestoreConfigured(firestore);\r\n    return new WriteBatch(firestore, mutations => executeWrite(firestore, mutations));\r\n}\n\n/**\r\n * @license\r\n * Copyright 2021 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\nregisterFirestore('node');\n\nexport { AbstractUserDataWriter, Bytes, CACHE_SIZE_UNLIMITED, CollectionReference, DocumentReference, DocumentSnapshot, FieldPath, FieldValue, Firestore, FirestoreError, GeoPoint, LoadBundleTask, Query, QueryConstraint, QueryDocumentSnapshot, QuerySnapshot, SnapshotMetadata, Timestamp, Transaction, WriteBatch, DatabaseId as _DatabaseId, DocumentKey as _DocumentKey, EmptyCredentialsProvider as _EmptyCredentialsProvider, FieldPath$1 as _FieldPath, cast as _cast, debugAssert as _debugAssert, isBase64Available as _isBase64Available, logWarn as _logWarn, validateIsNotUsedTogether as _validateIsNotUsedTogether, addDoc, arrayRemove, arrayUnion, clearIndexedDbPersistence, collection, collectionGroup, connectFirestoreEmulator, deleteDoc, deleteField, disableNetwork, doc, documentId, enableIndexedDbPersistence, enableMultiTabIndexedDbPersistence, enableNetwork, endAt, endBefore, ensureFirestoreConfigured, executeWrite, getDoc, getDocFromCache, getDocFromServer, getDocs, getDocsFromCache, getDocsFromServer, getFirestore, increment, initializeFirestore, limit, limitToLast, loadBundle, namedQuery, onSnapshot, onSnapshotsInSync, orderBy, query, queryEqual, refEqual, runTransaction, serverTimestamp, setDoc, setLogLevel, snapshotEqual, startAfter, startAt, terminate, updateDoc, waitForPendingWrites, where, writeBatch };\n//# sourceMappingURL=index.node.mjs.map\n", "// Import the functions you need from the SDKs you need\nimport { initializeApp } from 'firebase/app';\nimport { getFirestore } from 'firebase/firestore';\n\n// TODO: Add SDKs for Firebase products that you want to use\n// https://firebase.google.com/docs/web/setup#available-libraries\n\n// Your web app's Firebase configuration\nconst firebaseConfig = {\n  apiKey: 'AIzaSyAn9Q4vpZpQj3OWra7UP-9J77KbGA0CdHw',\n  authDomain: 'logif-sixers-61229.firebaseapp.com',\n  projectId: 'logif-sixers-61229',\n  storageBucket: 'logif-sixers-61229.appspot.com',\n  messagingSenderId: '897742317031',\n  appId: '1:897742317031:web:67237182be7fc8c2e68942',\n};\n\n// Initialize Firebase\nconst app = initializeApp(firebaseConfig);\nconst db = getFirestore();\n\nconst testEnv = () => process.env;\n\nexport { app, db, testEnv };\n", "import { testEnv } from './firebase.config';\n\nexports.handler = async () => {\n  const bla = 'adsf';\n  return {\n    statusCode: 200,\n    body: JSON.stringify(testEnv()),\n    test: bla,\n  };\n};\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,QAAY;AAAZ,IAAA,UAAY,SAAM;AAChB,cAAA,QAAA,QAAA,KAAA;AACA,cAAA,QAAA,eAAA,KAAA;AACA,cAAA,QAAA,aAAA,KAAA;AACA,cAAA,QAAA,sBAAA,KAAA;AACA,cAAA,QAAA,uBAAA,KAAA;AACA,cAAA,QAAA,eAAA,KAAA;AACA,cAAA,QAAA,oBAAA,KAAA;AACA,cAAA,QAAA,uBAAA,KAAA;AACA,cAAA,QAAA,wBAAA,KAAA;AACA,cAAA,QAAA,yBAAA,KAAA;AACA,cAAA,QAAA,aAAA,MAAA;AACA,cAAA,QAAA,kBAAA,MAAA;AACA,cAAA,QAAA,mBAAA,MAAA;AACA,cAAA,QAAA,cAAA,MAAA;AACA,cAAA,QAAA,iBAAA,MAAA;AACA,cAAA,QAAA,eAAA,MAAA;AACA,cAAA,QAAA,qBAAA,MAAA;OAjBU,SAAA,SAAA,UAAA,UAAA,SAAM;AAoBlB,QAAY;AAAZ,IAAA,UAAY,eAAY;AACtB,oBAAA,cAAA,WAAA,KAAA;AACA,oBAAA,cAAA,UAAA,KAAA;AACA,oBAAA,cAAA,WAAA,KAAA;AACA,oBAAA,cAAA,UAAA,KAAA;OAJU,eAAA,SAAA,gBAAA,UAAA,eAAY;AAWxB,QAAY;AAAZ,IAAA,UAAY,YAAS;AACnB,iBAAA,WAAA,cAAA,KAAA;AACA,iBAAA,WAAA,0BAAA,KAAA;AACA,iBAAA,WAAA,4BAAA,KAAA;AACA,iBAAA,WAAA,kBAAA,KAAA;AAEA,iBAAA,WAAA,cAAA,SAAA;OANU,YAAA,SAAA,aAAA,UAAA,YAAS;AAcR,aAAA,kCAAkC;AAGlC,aAAA,qCAAqC,IAAI,OAAO;;;;;;;;;;;;;;AChD7D,QAAA,cAAA;AAEA,QAAM,iBAAmC;MACvC,OAAO,CAAC,YAAkB,mBAAyB;AACjD,gBAAQ,MAAM,OAAO,SAAS,GAAG;;MAEnC,MAAM,CAAC,YAAkB,mBAAyB;AAChD,gBAAQ,MAAM,OAAO,SAAS,GAAG;;MAEnC,OAAO,CAAC,YAAkB,mBAAyB;AACjD,gBAAQ,MAAM,OAAO,SAAS,GAAG;;;AAIrC,QAAI,UAA4B;AAChC,QAAI,gBAA8B,YAAA,aAAa;AAE/C,QAAM,kBAAe,MAAA,MACnB,QAAQ,IAAI,yBAAmB,QAAA,OAAA,SAAA,KAAI,QAAQ,IAAI,oBAAc,QAAA,OAAA,SAAA,KAAI;AAEnE,YAAQ,gBAAgB;WACjB;AACH,wBAAgB,YAAA,aAAa;AAC7B;WACG;AACH,wBAAgB,YAAA,aAAa;AAC7B;WACG;AACH,wBAAgB,YAAA,aAAa;AAC7B;WACG;AACH,wBAAgB,YAAA,aAAa;AAC7B;;;AAKS,aAAA,YAAY,MAAuB;AAC9C,aAAO;;AAGI,aAAA,YAAY,CAAC,YAAkC;AAC1D,gBAAU;;AAGC,aAAA,qBAAqB,CAAC,cAAiC;AAClE,sBAAgB;;AAIL,aAAA,MAAM,CAAC,aAA2B,SAAqB;AAClE,UAAI;AACJ,UAAI,YAAY,eAAe;AAC7B,gBAAQ;eACD,YAAA,aAAa;AAChB,0BAAc,QAAQ;AACtB;eACG,YAAA,aAAa;AAChB,0BAAc,QAAQ;AACtB;eACG,YAAA,aAAa;AAChB,0BAAc,QAAQ;AACtB;;AAIJ,YAAI,CAAC,aAAa;AAChB,wBAAc,QAAQ;;AAExB,YAAI,aAAa;AACf,sBAAY,KAAK,SAAS,GAAG;;;;AAKnC,QAAM,gBAAa,MAAA,MACjB,QAAQ,IAAI,qBAAe,QAAA,OAAA,SAAA,KAAI,QAAQ,IAAI,gBAAU,QAAA,OAAA,SAAA,KAAI;AAC3D,QAAM,iBAAiB,IAAI;AAC3B,QAAM,kBAAkB,IAAI;AAC5B,eAAW,cAAc,cAAc,MAAM,MAAM;AACjD,UAAI,WAAW,WAAW,MAAM;AAC9B,wBAAgB,IAAI,WAAW,UAAU;aACpC;AACL,uBAAe,IAAI;;;AAGvB,QAAM,aAAa,eAAe,IAAI;AAEtC,mBACE,UACA,QACA,MAAY;AAEZ,UACE,CAAC,gBAAgB,IAAI,WACpB,eAAc,eAAe,IAAI,UAClC;AACA,iBAAA,IAAI,UAAU,IAAI,OAAO,gBAAgB,QAAQ,SAAS,QAAQ;;;AATtE,aAAA,QAAA;;;;;;;;;;ACvFA,QAAA,YAAA;AACA,QAAA,cAAA;AACA,QAAM,kBAAkB;AACxB,QAAM,+BAA+B;AAKrC,wBAAoB,KAAW;AAC7B,aAAO,gBAAgB,KAAK;;AAG9B,mCAA+B,OAAa;AAC1C,aAAO,6BAA6B,KAAK;;AAG3C,yBAAqB,KAAW;AAC9B,aAAO,IAAI,SAAS;;AAGtB,8BAA0B,KAAW;AACnC,aAAO,CAAC,IAAI,WAAW;;AAGzB,0BAAsB,KAAW;AAC/B,aAAO,IAAI;;AAGb,sBAAkB,KAAa,OAAqB;AAClD,UAAI,CAAC,WAAW,MAAM;AACpB,cAAM,IAAI,MAAM,mBAAmB,MAAM;;AAE3C,UAAI,UAAU,QAAQ,UAAU,QAAW;AACzC,YAAI,YAAY,MAAM;AACpB,cAAI,CAAE,kBAAiB,SAAS;AAC9B,kBAAM,IAAI,MAAM;;eAEb;AACL,cAAI,iBAAiB,QAAQ;AAC3B,kBAAM,IAAI,MACR;;AAGJ,cAAI,CAAC,sBAAsB,QAAQ;AACjC,kBAAM,IAAI,MACR,4BAA4B,QAAQ;;;;;AAuB9C,0BAAqB;MAInB,YAAY,SAAyB;AAH3B,aAAA,eAA+B,IAAI;AAI3C,YAAI,YAAY,QAAW;AACzB,eAAK,UAAU;eACV;AACL,eAAK,UAAU;;;MAWnB,IAAI,KAAa,OAAoB;AACnC,cAAM,aAAa;AACnB,iBAAS,KAAK;AACd,aAAK,aAAa,IAAI,KAAK,CAAC;;MAU9B,IAAI,KAAa,OAAoB;AACnC,cAAM,aAAa;AACnB,iBAAS,KAAK;AAEd,cAAM,gBAA6C,KAAK,aAAa,IACnE;AAGF,YAAI,kBAAkB,QAAW;AAC/B,eAAK,aAAa,IAAI,KAAK,CAAC;eACvB;AACL,wBAAc,KAAK;;;MAQvB,OAAO,KAAW;AAChB,cAAM,aAAa;AACnB,iBAAS;AACT,aAAK,aAAa,OAAO;;MAQ3B,IAAI,KAAW;AACb,cAAM,aAAa;AACnB,iBAAS;AACT,eAAO,KAAK,aAAa,IAAI,QAAQ;;MAQvC,SAAM;AACJ,cAAM,SAA2C;AAEjD,aAAK,aAAa,QAAQ,CAAC,QAAQ,QAAO;AACxC,cAAI,OAAO,SAAS,GAAG;AACrB,kBAAM,IAAI,OAAO;AACjB,mBAAO,OAAO,aAAa,SAAS,EAAE,UAAU;;;AAGpD,eAAO;;MAOT,QAAK;AACH,cAAM,cAAc,IAAI,UAAS,KAAK;AACtC,cAAM,kBAAkB,YAAY;AAEpC,aAAK,aAAa,QAAQ,CAAC,OAAO,QAAO;AACvC,gBAAM,cAA+B,MAAM,IAAI,CAAC,MAAK;AACnD,gBAAI,aAAa,QAAQ;AACvB,qBAAO,OAAO,KAAK;mBACd;AACL,qBAAO;;;AAIX,0BAAgB,IAAI,KAAK;;AAG3B,eAAO;;MAUT,MAAM,OAAe;AACnB,cAAM,aAAa,QAAQ,CAAC,QAAQ,QAAO;AACzC,gBAAM,cACJ,MAAK,aAAa,IAAI,QAAQ,IAC9B,OAAO;AAET,eAAK,aAAa,IAAI,KAAK;;;MAI/B,WAAW,SAAwB;AACjC,aAAK,UAAU;;MAGjB,aAAU;AACR,eAAO,KAAK;;MAMd,iBAAc;AAEZ,cAAM,SAAoC;AAC1C,aAAK,aAAa,QAAQ,CAAC,QAAQ,QAAO;AAGxC,iBAAO,OAAO,OAAO,IAAI,CAAC,UAAS;AACjC,gBAAI,iBAAiB,QAAQ;AAC3B,qBAAO,MAAM,SAAS;mBACjB;AACL,qBAAO;;;;AAIb,eAAO;;MAID,yBAAsB;AAC5B,eAAO,KAAK;;MAOd,SAAM;AACJ,cAAM,SAA6C;AACnD,mBAAW,CAAC,KAAK,WAAW,KAAK,aAAa,WAAW;AACvD,iBAAO,OAAO;;AAEhB,eAAO;;aAQF,iBAAiB,SAAkC;AACxD,cAAM,SAAS,IAAI;AACnB,eAAO,KAAK,SAAS,QAAQ,CAAC,QAAO;AAEnC,cAAI,IAAI,OAAO,OAAO,KAAK;AACzB;;AAGF,gBAAM,SAAS,QAAQ;AAEvB,cAAI;AACF,gBAAI,YAAY,MAAM;AACpB,kBAAI,MAAM,QAAQ,SAAS;AACzB,uBAAO,QAAQ,CAAC,UAAS;AACvB,yBAAO,IAAI,KAAK,OAAO,KAAK,OAAO;;yBAE5B,WAAW,QAAW;AAC/B,oBAAI,iBAAiB,MAAM;AACzB,yBAAO,MAAM,KAAK,QAAQ,CAAC,MAAK;AAC9B,2BAAO,IAAI,KAAK,OAAO,KAAK,EAAE,QAAQ;;uBAEnC;AACL,yBAAO,IAAI,KAAK,OAAO,KAAK,QAAQ;;;mBAGnC;AACL,kBAAI,MAAM,QAAQ,SAAS;AACzB,uBAAO,QAAQ,CAAC,UAAS;AACvB,yBAAO,IAAI,KAAK;;yBAET,WAAW,QAAW;AAC/B,uBAAO,IAAI,KAAK;;;mBAGb,OAAP;AACA,kBAAM,UAAU,gCAAgC,QAAQ,WAAW,MAAM;AACzE,sBAAA,IAAI,YAAA,aAAa,OAAO;;;AAG5B,eAAO;;;AAtNX,aAAA,WAAA;;;;;;;;;;ACrEA,QAAA,aAAA;AA+BA,mCACE,QAAoB;AAEpB,aACE,uBAAuB,UACvB,OAAO,OAAO,sBAAsB;;AAQxC,gCAAqC;aA6B5B,4BACL,mBAAwC;AAExC,eAAO,IAAI,sBAAsB;;aAQ5B,2BACL,mBAA+B;AAE/B,eAAO,gBAAgB,4BAA4B,CAAC,SAAS,aAAY;AACvE,cAAI;AACJ,cAAI,sBAAsB,oBAAoB;AAC5C,yBAAa,kBAAkB,kBAAkB,QAAQ;iBACpD;AACL,yBAAa,IAAI,QAAQ,CAAC,UAAS,WAAU;AAC3C,gCAAkB,mBAChB,QAAQ,aACR,CAAC,KAAK,YAAW;AACf,oBAAI,KAAK;AACP,yBAAO;AACP;;AAEF,yBAAQ;;;;AAKhB,qBAAW,KACT,CAAC,YAAW;AACV,kBAAM,WAAW,IAAI,WAAA;AACrB,uBAAW,OAAO,OAAO,KAAK,UAAU;AACtC,uBAAS,IAAI,KAAK,QAAQ;;AAE5B,qBAAS,MAAM;aAEjB,CAAC,QAAO;AACN,qBAAS;;;;aAMV,cAAW;AAChB,eAAO,IAAI;;;AA7Ef,aAAA,kBAAA;AAiFA,gDAAsC,gBAAe;MACnD,YAAoB,OAAwB;AAC1C;AADkB,aAAA,QAAA;;YAId,iBAAiB,SAA4B;AACjD,cAAM,OAAiB,IAAI,WAAA;AAC3B,cAAM,YAAwB,MAAM,QAAQ,IAC1C,KAAK,MAAM,IAAI,CAAC,SAAS,KAAK,iBAAiB;AAEjD,mBAAW,OAAO,WAAW;AAC3B,eAAK,MAAM;;AAEb,eAAO;;MAGT,QAAQ,OAAsB;AAC5B,eAAO,IAAI,wBAAwB,KAAK,MAAM,OAAO,CAAC;;MAGxD,QAAQ,OAAsB;AAC5B,YAAI,SAAS,OAAO;AAClB,iBAAO;;AAET,YAAI,iBAAiB,yBAAyB;AAC5C,iBAAO,KAAK,MAAM,MAAM,CAAC,OAAO,UAC9B,MAAM,QAAQ,MAAM,MAAM;eAEvB;AACL,iBAAO;;;;AAKb,8CAAoC,gBAAe;MACjD,YAAoB,mBAAwC;AAC1D;AADkB,aAAA,oBAAA;;MAIpB,iBAAiB,SAA4B;AAC3C,eAAO,IAAI,QAAkB,CAAC,UAAS,WAAU;AAC/C,eAAK,kBAAkB,SAAS,CAAC,KAAK,aAAY;AAChD,gBAAI,aAAa,QAAW;AAC1B,uBAAQ;mBACH;AACL,qBAAO;;;;;MAMf,QAAQ,OAAsB;AAC5B,eAAO,IAAI,wBAAwB,CAAC,MAAM;;MAG5C,QAAQ,OAAsB;AAC5B,YAAI,SAAS,OAAO;AAClB,iBAAO;;AAET,YAAI,iBAAiB,uBAAuB;AAC1C,iBAAO,KAAK,sBAAsB,MAAM;eACnC;AACL,iBAAO;;;;AAKb,6CAAmC,gBAAe;MAChD,iBAAiB,SAA4B;AAC3C,eAAO,QAAQ,QAAQ,IAAI,WAAA;;MAG7B,QAAQ,OAAsB;AAC5B,eAAO;;MAGT,QAAQ,OAAsB;AAC5B,eAAO,iBAAiB;;;;;;;;;;;;AC1M5B,QAAK;AAAL,IAAA,UAAK,YAAS;AACZ,iBAAA,WAAA,aAAA,KAAA;AACA,iBAAA,WAAA,kBAAA,KAAA;AACA,iBAAA,WAAA,qBAAA,KAAA;OAHG,aAAA,aAAS;AAMd,8BAA0B;MAA1B,cAAA;AACU,aAAA,YAAuB,UAAU;AACjC,aAAA,mBAA2B,OAAO,MAAM;AACxC,aAAA,kBAA0B,OAAO,MAAM;AACvC,aAAA,oBAAoB;AACpB,aAAA,kBAAkB;AAClB,aAAA,qBAA+B;AAC/B,aAAA,uBAAuB;;MAE/B,MAAM,MAAY;AAChB,YAAI,WAAW;AACf,YAAI;AACJ,cAAM,SAAmB;AAEzB,eAAO,WAAW,KAAK,QAAQ;AAC7B,kBAAQ,KAAK;iBACN,UAAU;AACb,mBAAK,mBAAmB,KAAK,MAAM,UAAU,WAAW;AACxD,0BAAY;AACZ,mBAAK,YAAY,UAAU;AAC3B,mBAAK,gBAAgB,KAAK;AAC1B,mBAAK,oBAAoB;AACzB,mBAAK,kBAAkB;AACvB,mBAAK,uBAAuB;AAC5B,mBAAK,qBAAqB;AAC1B;iBACG,UAAU;AACb,uBAAS,KAAK,IAAI,KAAK,SAAS,UAAU,KAAK;AAC/C,mBAAK,KACH,KAAK,iBACL,IAAI,KAAK,mBACT,UACA,WAAW;AAEb,mBAAK,qBAAqB;AAC1B,0BAAY;AAEZ,kBAAI,KAAK,sBAAsB,GAAG;AAChC,qBAAK,kBAAkB,KAAK,gBAAgB,aAAa;AACzD,qBAAK,uBAAuB,KAAK;AACjC,oBAAI,KAAK,uBAAuB,GAAG;AACjC,uBAAK,YAAY,UAAU;uBACtB;AACL,wBAAM,UAAU,OAAO,OACrB,CAAC,KAAK,kBAAkB,KAAK,kBAC7B;AAGF,uBAAK,YAAY,UAAU;AAC3B,yBAAO,KAAK;;;AAGhB;iBACG,UAAU;AACb,uBAAS,KAAK,IAAI,KAAK,SAAS,UAAU,KAAK;AAC/C,mBAAK,mBAAmB,KAAK,KAAK,MAAM,UAAU,WAAW;AAC7D,mBAAK,wBAAwB;AAC7B,0BAAY;AAEZ,kBAAI,KAAK,yBAAyB,GAAG;AAEnC,sBAAM,uBAAuB;kBAC3B,KAAK;kBACL,KAAK;kBACL,OAAO,KAAK;AACd,sBAAM,gBAAgB,OAAO,OAC3B,sBACA,KAAK,kBAAkB;AAGzB,qBAAK,YAAY,UAAU;AAC3B,uBAAO,KAAK;;AAEd;;AAEA,oBAAM,IAAI,MAAM;;;AAItB,eAAO;;;AA/EX,aAAA,gBAAA;;;;;;;;;;ACNA,QAAA,QAAA,QAAA;AACA,QAAA,KAAA,QAAA;AAGA,QAAA,cAAA;AAGA,QAAA,aAAA;AACA,QAAA,mBAAA;AAGA,QAAA,UAAA;AACA,QAAA,cAAA;AAGA,QAAM,cAAc;AAEpB,QAAM,EACJ,qBACA,2BACA,mBACE,MAAM;AAuBV,gCAA4B,OAAa;AACvC,iBAAW,CAAC,OAAM,QAAQ,OAAO,QAAQ,GAAG,UAAU,QAAQ;AAC5D,YAAI,QAAQ,OAAO;AACjB,iBAAO;;;AAGX,aAAO,0BAA0B;;AAKnC,4BAAwB,cAAwB;AAC9C,UAAI,WAAW;AACf,iBAAW,YAAY,cAAc;AACnC,cAAM,gBACJ,oBAAoB,OAAO,SAAS,YAAY;AAClD,YAAI,gBAAgB,UAAU;AAC5B,qBAAW;;;AAGf,aAAO;;AA4DT,oCACE,UAAyC;AAEzC,aACE,SAAS,sBAAsB,UAC/B,SAAS,kBAAkB,WAAW;;AAL1C,aAAA,yBAAA;AASA,yCAAqC;MAGnC,YACU,UACA,cAAkC;AADlC,aAAA,WAAA;AACA,aAAA,eAAA;AAJF,aAAA,oBAAoB;AACpB,aAAA,gBAAqC;;MAM7C,kBAAkB,UAAkB;AAClC,aAAK,SAAS,kBAAkB,UAAU,CAAC,cAAY;AACrD,eAAK,aAAa,kBAAkB;;;MAIxC,iBAAiB,SAAY;AAG3B,aAAK,oBAAoB;AACzB,aAAK,SAAS,iBAAiB,SAAS,CAAC,QAAO;AAC9C,eAAK,oBAAoB;AACzB,eAAK,aAAa,iBAAiB;AACnC,cAAI,KAAK,eAAe;AACtB,iBAAK,aAAa,gBAAgB,KAAK;;;;MAI7C,gBAAgB,QAAoB;AAClC,aAAK,SAAS,gBAAgB,QAAQ,CAAC,oBAAmB;AACxD,cAAI,KAAK,mBAAmB;AAC1B,iBAAK,gBAAgB;iBAChB;AACL,iBAAK,aAAa,gBAAgB;;;;;AA/B1C,aAAA,2BAAA;AA6DA,gCAA4B;MA6C1B,YACmB,YACA,SACA,SACjB,oBACiB,wBACA,YAAkB;AALlB,aAAA,aAAA;AACA,aAAA,UAAA;AACA,aAAA,UAAA;AAEA,aAAA,yBAAA;AACA,aAAA,aAAA;AAhDX,aAAA,cAA8C;AAC9C,aAAA,cAAc;AACd,aAAA,uBAAuB;AACvB,aAAA,eAA8B;AAC9B,aAAA,uBAA6C;AAC7C,aAAA,eAAe;AAEf,aAAA,UAAU,IAAI,iBAAA;AAEd,aAAA,sBAAsB;AACtB,aAAA,UAAU;AAKV,aAAA,cAAc;AAEd,aAAA,eAAe;AAEf,aAAA,uBAAiC;AACjC,aAAA,yBAAmC;AAGnC,aAAA,mBAA2B,YAAA,OAAO;AAGlC,aAAA,cAAmC;AAEnC,aAAA,aAAgC;AAGhC,aAAA,WAAwC;AAExC,aAAA,gBAAoC;AAEpC,aAAA,iBAA2B;AAE3B,aAAA,iBAAqD;AACrD,aAAA,oBAAoD;AAEpD,aAAA,mBAAsD;AAU5D,aAAK,cAAc,mBAAmB,aAAa;AACnD,aAAK,cAAc;AACnB,aAAK,qBAAqB,MAAK;AAC7B,eAAK,QAAQ;YACX,MAAM,YAAA,OAAO;YACb,SAAS;YACT,UAAU,IAAI,WAAA;;;AAGlB,YACE,KAAK,QAAQ,cACb,KAAK,QAAQ,QAAQ,YAAA,UAAU,cAC/B;AACA,eAAK,QAAQ,WAAW,GAAG,aAAa,MAAK;AAC3C,iBAAK,iBAAiB,YAAA,OAAO,WAAW;;;;MAKtC,eAAY;AAElB,YAAI,CAAC,KAAK,cAAc;AACtB,eAAK,eAAe;AACpB,gBAAM,iBAAiB,KAAK,YAAY,gBACtC,KAAK;AAEP,eAAK,eAAe,QAAQ,aAAW,QAAQ;AAO/C,kBAAQ,SAAS,MAAK;;AACpB,YAAA,MAAA,KAAK,cAAQ,QAAA,OAAA,SAAA,SAAA,GAAE,gBAAgB;;AAEjC,cAAI,KAAK,YAAY;AACnB,iBAAK,WAAW;AAChB,iBAAK,WAAW,yBAAyB,KAAK;;;;MAK5C,MAAM,MAAY;AACxB,gBAAQ,MACN,YAAA,aAAa,OACb,aACA,MAAM,KAAK,aAAa,OAAO;;MAS3B,QAAQ,QAAoB;AAGlC,YAAI,KAAK,gBAAgB,QAAQ,KAAK,YAAY,SAAS,YAAA,OAAO,IAAI;AACpE,eAAK,MACH,6BACE,OAAO,OACP,eACA,OAAO,UACP;AAEJ,eAAK,cAAc;AACnB,eAAK;;AAEP,aAAK;;MAGC,oBAAiB;AACvB,YAAI,KAAK,gBAAgB,MAAM;AAI7B,cACE,KAAK,YAAY,SAAS,YAAA,OAAO,MAChC,KAAK,eACJ,KAAK,qBAAqB,WAAW,KACrC,KAAK,uBAAuB,WAAW,KACvC,CAAC,KAAK,qBACR;AACA,iBAAK;;;;MAKH,KAAK,SAAe;AAC1B,aAAK,MACH,yCACG,oBAAmB,SAAS,QAAQ,SAAS;AAElD,aAAK,UAAU;AACf,gBAAQ,SAAS,MAAK;;AAKpB,cAAI,KAAK,cAAc;AACrB;;AAEF,UAAA,MAAA,KAAK,cAAQ,QAAA,OAAA,SAAA,SAAA,GAAE,iBAAiB;AAChC,eAAK;;;MAID,kBAAkB,OAAY;AACpC,aAAK,iBAAiB,YAAA,OAAO,UAAU,MAAM;;MAGvC,mBAAmB,SAAe;AAIxC,YAAI,KAAK,gBAAgB,QAAQ,KAAK,YAAY,SAAS,YAAA,OAAO,IAAI;AACpE,eAAK;AACL;;AAEF,aAAK,sBAAsB;AAC3B,YAAI,KAAK,SAAS;AAChB,eAAK,YAAa;AAClB,eAAK,KAAK;eACL;AACL,eAAK,MACH,iDAAiD,QAAQ;AAE3D,eAAK,qBAAqB,KAAK;;AAEjC,YAAI,KAAK,uBAAuB,SAAS,GAAG;AAG1C,gBAAM,cAAc,KAAK,uBAAuB;AAChD,eAAK,sBAAsB;;;MAIvB,sBAAsB,eAAqB;AAIjD,YAAI,KAAK,gBAAgB,QAAQ,KAAK,YAAY,SAAS,YAAA,OAAO,IAAI;AACpE,eAAK;AACL;;AAEF,aAAK,MAAM,qCAAqC,cAAc;AAC9D,aAAK,sBAAsB;AAC3B,aAAK,YACF,eAAe,QAAQ,QAAQ,gBAC/B,KACC,KAAK,mBAAmB,KAAK,OAC7B,KAAK,kBAAkB,KAAK;;MAI1B,QAAQ,cAAoB;AAClC,YAAI,KAAK,qBAAqB;AAC5B,eAAK,MACH,mDACG,iBAAgB,aAAa;AAElC,eAAK,uBAAuB,KAAK;eAC5B;AACL,eAAK,sBAAsB;;;MAIvB,eAAe,SAAkC;AACvD,aAAK,kBAAkB,QAAQ,aAAW,QAAQ;AAClD,YAAI,gBAAgB;AACpB,mBAAW,UAAU,OAAO,KAAK,UAAU;AACzC,2BAAiB,OAAS,SAAS,OAAO,QAAQ,UAAU;;AAE9D,aAAK,MAAM,gCAAgC;AAC3C,YAAI;AACJ,YAAI;AACF,qBAAW,WAAA,SAAS,iBAAiB;iBAC9B,GAAP;AACA,qBAAW,IAAI,WAAA;;AAEjB,cAAM,cAAc,SAAS;AAC7B,YAAI,OAAe,KAAK;AACxB,YACE,SAAS,YAAA,OAAO,WAChB,OAAO,YAAY,mBAAmB,UACtC;AACA,gBAAM,iBAAiB,OAAO,YAAY;AAC1C,cAAI,kBAAkB,YAAA,QAAQ;AAC5B,mBAAO;AACP,iBAAK,MAAM,0BAA0B,iBAAiB;;AAExD,mBAAS,OAAO;;AAElB,YAAI,UAAU;AACd,YAAI,OAAO,YAAY,oBAAoB,UAAU;AACnD,oBAAU,UAAU,YAAY;AAChC,mBAAS,OAAO;AAChB,eAAK,MACH,qCAAqC,UAAU;;AAGnD,cAAM,SAAuB,EAAE,MAAM,SAAS;AAE9C,aAAK,QAAQ;;MAGP,qBAAqB,SAAiB,UAAuB;;AACnE,QAAA,MAAA,KAAK,sBAAgB,QAAA,OAAA,SAAA,SAAA,GAAE;AACvB,aAAK,YAAa,MAAM,SAAS;;MAGnC,kBACE,QACA,YACA,cACA,kBAA4C;AAE5C,aAAK,YAAY,KAAK;AACtB,YAAI,KAAK,gBAAgB,MAAM;AAC7B,iBAAO,MAAM;eACR;AACL,eAAK,MACH,uCAAuC,WAAW;AAEpD,eAAK,cAAc;AACnB,eAAK,aAAa;AAClB,eAAK,mBAAmB;AACxB,qBAAW,sBAAsB,KAAK;AACtC,qBAAW;AACX,iBAAO,GAAG,YAAY,CAAC,SAAS,UAAS;;AACvC,gBAAI,gBAAgB;AACpB,uBAAW,UAAU,OAAO,KAAK,UAAU;AACzC,+BAAiB,OAAS,SAAS,OAAO,QAAQ,UAAU;;AAE9D,iBAAK,MAAM,+BAA+B;AAC1C,oBAAQ,QAAQ;mBAET;AACH,qBAAK,mBAAmB,YAAA,OAAO;AAC/B;mBACG;AACH,qBAAK,mBAAmB,YAAA,OAAO;AAC/B;mBACG;AACH,qBAAK,mBAAmB,YAAA,OAAO;AAC/B;mBACG;AACH,qBAAK,mBAAmB,YAAA,OAAO;AAC/B;mBACG;mBACA;mBACA;mBACA;AACH,qBAAK,mBAAmB,YAAA,OAAO;AAC/B;;AAEA,qBAAK,mBAAmB,YAAA,OAAO;;AAGnC,gBAAI,QAAQ,MAAM,UAAU,yBAAyB;AACnD,mBAAK,eAAe;mBACf;AACL,kBAAI;AACJ,kBAAI;AACF,2BAAW,WAAA,SAAS,iBAAiB;uBAC9B,OAAP;AACA,qBAAK,QAAQ;kBACX,MAAM,YAAA,OAAO;kBACb,SAAS,MAAM;kBACf,UAAU,IAAI,WAAA;;AAEhB;;AAEF,kBAAI;AACF,sBAAM,gBAAgB,KAAK,YAAY,gBAAgB;AACvD,gBAAA,MAAA,KAAK,cAAQ,QAAA,OAAA,SAAA,SAAA,GAAE,kBAAkB;uBAC1B,OAAP;AACA,qBAAK,QAAQ;kBACX,MAAM,YAAA,OAAO;kBACb,SAAS,MAAM;kBACf,UAAU,IAAI,WAAA;;;;;AAKtB,iBAAO,GAAG,YAAY,KAAK,eAAe,KAAK;AAC/C,iBAAO,GAAG,QAAQ,CAAC,SAAgB;AACjC,iBAAK,MAAM,yCAAyC,KAAK;AACzD,kBAAM,WAAW,KAAK,QAAQ,MAAM;AAEpC,uBAAW,WAAW,UAAU;AAC9B,mBAAK,MAAM,8BAA8B,QAAQ;AACjD,mBAAK,iBAAkB;AACvB,mBAAK,QAAQ;;;AAGjB,iBAAO,GAAG,OAAO,MAAK;AACpB,iBAAK,cAAc;AACnB,iBAAK;;AAEP,iBAAO,GAAG,SAAS,MAAK;AAItB,oBAAQ,SAAS,MAAK;;AACpB,mBAAK,MAAM,oCAAoC,OAAO;AAKtD,kBAAI,OAAA,KAAK,iBAAW,QAAA,OAAA,SAAA,SAAA,GAAE,UAAS,YAAA,OAAO,IAAI;AACxC;;AAEF,kBAAI;AACJ,kBAAI,UAAU;AACd,sBAAQ,OAAO;qBACR,MAAM,UAAU;AAInB,sBAAI,KAAK,gBAAgB,MAAM;AAC7B;;AAEF,yBAAO,YAAA,OAAO;AACd,4BAAU,iCAAiC,OAAO;AAClD;qBACG,MAAM,UAAU;AACnB,yBAAO,YAAA,OAAO;AACd,4BAAU;AACV;qBACG,MAAM,UAAU;AACnB,yBAAO,YAAA,OAAO;AACd,4BAAU;AACV;qBACG,MAAM,UAAU;AACnB,yBAAO,YAAA,OAAO;AACd,4BAAU;AACV;qBACG,MAAM,UAAU;AACnB,yBAAO,YAAA,OAAO;AACd,4BAAU;AACV;qBACG,MAAM,UAAU;AACnB,yBAAO,YAAA,OAAO;AACd,sBAAI,KAAK,kBAAkB,MAAM;AAM/B,8BAAU,iCAAiC,OAAO;yBAC7C;AACL,wBAAI,KAAK,cAAc,SAAS,gBAAgB,KAAK,cAAc,SAAS,aAAa;AACvF,6BAAO,YAAA,OAAO;AACd,gCAAU,KAAK,cAAc;2BACxB;AAKL,gCAAU,iCAAiC,OAAO,+CAA+C,KAAK,cAAc;;;AAGxH;;AAEA,yBAAO,YAAA,OAAO;AACd,4BAAU,iCAAiC,OAAO;;AAMtD,mBAAK,QAAQ,EAAE,MAAM,SAAS,UAAU,IAAI,WAAA;;;AAGhD,iBAAO,GAAG,SAAS,CAAC,QAAoB;AAQtC,gBAAI,IAAI,SAAS,0BAA0B;AACzC,mBAAK,MACH,+BACE,IAAI,UACJ,WACA,IAAI,OACJ,YACA,mBAAmB,IAAI,SACvB,cACA,IAAI;AAER,mBAAK,gBAAgB;;AAEvB,iBAAK,kBAAkB,QAAQ,aAAW,QAAQ;;AAEpD,cAAI,CAAC,KAAK,aAAa;AACrB,mBAAO;;AAET,cAAI,KAAK,cAAc;AACrB,gBAAI,CAAC,KAAK,sBAAsB;AAC9B,oBAAM,IAAI,MAAM;;AAElB,iBAAK,MACH,kCACE,KAAK,aAAa,SAClB;AAEJ,gBAAI;AACF,mBAAK,qBAAqB,KAAK,cAAc,KAAK;qBAC3C,OAAP;AACA,mBAAK,QAAQ;gBACX,MAAM,YAAA,OAAO;gBACb,SAAS,2BAA2B,MAAM;gBAC1C,UAAU,IAAI,WAAA;;;;AAIpB,eAAK;;;MAIT,MAAM,UAAoB,UAA8B;AACtD,aAAK,MAAM;AACX,aAAK,WAAW;AAChB,aAAK,QAAQ,iBAAiB,MAAM;;MAG9B,qBAAkB;;AAGxB,YAAI,KAAK,gBAAgB,QAAQ,CAAC,KAAK,YAAY,WAAW;AAI5D,cAAI;AACJ,cAAI,OAAA,KAAK,iBAAW,QAAA,OAAA,SAAA,SAAA,GAAE,UAAS,YAAA,OAAO,IAAI;AACxC,mBAAO,MAAM,UAAU;iBAClB;AACL,mBAAO,MAAM,UAAU;;AAEzB,eAAK,MAAM,kCAAkC;AAC7C,eAAK,YAAY,MAAM;;;MAI3B,iBAAiB,QAAgB,SAAe;AAC9C,aAAK,MACH,4BAA4B,SAAS,gBAAgB,UAAU;AAEjE,aAAK,QAAQ,EAAE,MAAM,QAAQ,SAAS,UAAU,IAAI,WAAA;;MAGtD,cAAW;AACT,cAAM,eAAe,CAAC,KAAK,QAAQ;AACnC,YAAI,KAAK,QAAQ,cAAc,KAAK,QAAQ,QAAQ,YAAA,UAAU,UAAU;AACtE,uBAAa,KAAK,KAAK,QAAQ,WAAW;;AAE5C,YAAI,KAAK,gBAAgB;AACvB,uBAAa,KAAK,KAAK;;AAEzB,eAAO,eAAe;;MAGxB,iBAAc;AACZ,eAAO,KAAK;;MAGd,eAAe,cAA4B;AACzC,aAAK,cAAc,KAAK,uBAAuB,QAAQ;;MAGzD,YAAS;AACP,eAAO,KAAK;;MAGd,UAAO;;AACL,eAAA,MAAA,MAAO,KAAK,gBAAU,QAAA,OAAA,SAAA,SAAA,GAAE,kBAAU,QAAA,OAAA,SAAA,KAAM,KAAK,QAAQ;;MAGvD,YAAS;AACP,eAAO,KAAK;;MAGd,UAAO;AACL,eAAO,KAAK,QAAQ;;MAGtB,kBAAkB,gBAAwB;AACxC,aAAK,iBAAiB;;MAGxB,iBAAiB,SAAuC;AACtD,aAAK,eAAe,KAAK;;MAG3B,oBAAoB,SAAmC;AACrD,aAAK,kBAAkB,KAAK;;MAG9B,WAAW,cAAsB;AAC/B,aAAK,YAAY,KAAK;;MAGxB,YAAS;AAGP,YAAI,KAAK,gBAAgB,QAAQ,KAAK,YAAY,SAAS,YAAA,OAAO,IAAI;AACpE,eAAK,cAAc;AACnB,eAAK;AACL;;AAEF,aAAK,UAAU;AACf,YAAI,KAAK,gBAAgB,MAAM;AAC7B,eAAK,cAAc;eACd;AACL,cAAI,KAAK,qBAAqB,SAAS,GAAG;AACxC,kBAAM,cAAsB,KAAK,qBAAqB;AACtD,iBAAK,KAAK;AACV;;AAIF,eAAK,YAAY;;;MAIb,mBAAgB;AACtB,YACE,KAAK,gBACL,CAAC,KAAK,wBACN,KAAK,gBAAgB,MACrB;AACA,eAAK,MAAM;AACX,eAAK,YAAY;;;MAIrB,uBAAuB,SAAyB,SAAe;;AAC7D,aAAK,MAAM,2CAA2C,QAAQ;AAC9D,cAAM,WAAwB;UAC5B;UACA,OAAO,QAAQ;;AAEjB,cAAM,KAAE,MAAkB,QAAQ,cAAQ,QAAA,OAAA,SAAA,KAAK,MAAK;;AACpD,aAAK,uBAAuB;AAC5B,aAAK,YAAY,YAAY,QAAQ,QAAQ,WAAW,KAAK,CAAC,aAAW;AACvE,eAAK,uBAAuB;AAC5B,cAAI,KAAK,gBAAgB,MAAM;AAC7B,iBAAK,MACH,4CAA4C,SAAQ,QAAQ;AAE9D,iBAAK,eAAe,SAAQ;AAC5B,iBAAK,uBAAuB;iBACvB;AACL,iBAAK,MAAM,kCAAkC,SAAQ,QAAQ;AAC7D,gBAAI;AACJ,mBAAK,qBAAqB,SAAQ,SAAS;qBACjC,OAAP;AACD,mBAAK,QAAQ;gBACX,MAAM,YAAA,OAAO;gBACb,SAAS,2BAA2B,MAAM;gBAC1C,UAAU,IAAI,WAAA;;;AAGlB,iBAAK;;WAEN,KAAK,kBAAkB,KAAK;;MAGjC,YAAS;AACP,aAAK,MAAM;AACX,aAAK,eAAe;AACpB,aAAK;;;AAtnBT,aAAA,kBAAA;;;;;;;;;;AClMA,QAAA,KAAA,QAAA;AAEa,aAAA,gBACX,QAAQ,IAAI;AAEd,QAAM,0BAA0B,QAAQ,IAAI;AAE5C,QAAI,mBAAkC;AAEtC,mCAAmC;AACjC,UAAI,yBAAyB;AAC3B,YAAI,qBAAqB,MAAM;AAC7B,6BAAmB,GAAG,aAAa;;AAErC,eAAO;;AAET,aAAO;;AAPT,aAAA,sBAAA;;;;;;;;;;ACTA,QAAA,QAAA,QAAA;AAEA,QAAA,qBAAA;AACA,QAAA,gBAAA;AAGA,kCAA8B,KAAU,cAAoB;AAC1D,UAAI,OAAO,CAAE,gBAAe,SAAS;AACnC,cAAM,IAAI,UAAU,GAAG;;;AAyB3B,+BAA2B,MAAqB,MAAmB;AACjE,UAAI,SAAS,QAAQ,SAAS,MAAM;AAClC,eAAO;aACF;AACL,eAAO,SAAS,QAAQ,SAAS,QAAQ,KAAK,OAAO;;;AAqBzD,mCAAwC;MAGtC,YAAsB,iBAAiC;AACrD,aAAK,kBAAkB,mBAAmB,mBAAA,gBAAgB;;MAa5D,sBAAmB;AACjB,eAAO,KAAK;;aA8BP,UACL,WACA,YACA,WACA,eAA6B;AAE7B,6BAAqB,WAAW;AAChC,6BAAqB,YAAY;AACjC,6BAAqB,WAAW;AAChC,YAAI,cAAc,CAAC,WAAW;AAC5B,gBAAM,IAAI,MACR;;AAGJ,YAAI,CAAC,cAAc,WAAW;AAC5B,gBAAM,IAAI,MACR;;AAGJ,eAAO,IAAI,6BACT,aAAa,cAAA,uBACb,cAAc,MACd,aAAa,MACb,iBAAiB;;aAOd,iBAAc;AACnB,eAAO,IAAI;;;AA/Ef,aAAA,qBAAA;AAmFA,uDAA6C,mBAAkB;MAC7D,YAAY,iBAAiC;AAC3C,cAAM;;MAGR,QAAQ,iBAAgC;AACtC,cAAM,IAAI,MAAM;;MAGlB,wBAAqB;AACnB,eAAO;;MAET,YAAS;AACP,eAAO;;MAET,QAAQ,OAAyB;AAC/B,eAAO,iBAAiB;;;AAI5B,qDAA2C,mBAAkB;MAG3D,YACU,WACA,YACA,WACA,eAA4B;AAEpC;AALQ,aAAA,YAAA;AACA,aAAA,aAAA;AACA,aAAA,YAAA;AACA,aAAA,gBAAA;AAGR,cAAM,gBAAgB,MAAA,oBAAoB;UACxC,IAAI,aAAa;UACjB,KAAK,cAAc;UACnB,MAAM,aAAa;UACnB,SAAS,cAAA;;AAEX,aAAK,oBAAoB,EAAE;AAC3B,YAAI,iBAAiB,cAAc,qBAAqB;AACtD,eAAK,kBAAkB,sBAAsB,CAC3C,MACA,SACE;AACF,mBAAO,cAAc,oBAAqB,MAAM,EAAE,KAAK,KAAK;;;;MAKlE,QAAQ,iBAAgC;AACtC,cAAM,0BAA0B,KAAK,gBAAgB,QACnD;AAEF,eAAO,IAAI,+BAA+B,MAAM;;MAGlD,wBAAqB;AAEnB,eAAA,OAAA,OAAA,IAAY,KAAK;;MAEnB,YAAS;AACP,eAAO;;MAET,QAAQ,OAAyB;AAC/B,YAAI,SAAS,OAAO;AAClB,iBAAO;;AAET,YAAI,iBAAiB,8BAA8B;AACjD,cAAI,CAAC,kBAAkB,KAAK,WAAW,MAAM,YAAY;AACvD,mBAAO;;AAET,cAAI,CAAC,kBAAkB,KAAK,YAAY,MAAM,aAAa;AACzD,mBAAO;;AAET,cAAI,CAAC,kBAAkB,KAAK,WAAW,MAAM,YAAY;AACvD,mBAAO;;AAET,iBACE,KAAK,cAAc,wBACnB,MAAM,cAAc;eAEjB;AACL,iBAAO;;;;AAKb,uDAA6C,mBAAkB;MAC7D,YACU,oBACR,WAA0B;AAE1B,cAAM;AAHE,aAAA,qBAAA;;MAKV,QAAQ,iBAAgC;AACtC,cAAM,0BAA0B,KAAK,gBAAgB,QACnD;AAEF,eAAO,IAAI,+BACT,KAAK,oBACL;;MAIJ,wBAAqB;AACnB,eAAO,KAAK,mBAAmB;;MAEjC,YAAS;AACP,eAAO;;MAET,QAAQ,OAAyB;AAC/B,YAAI,SAAS,OAAO;AAClB,iBAAO;;AAET,YAAI,iBAAiB,gCAAgC;AACnD,iBACE,KAAK,mBAAmB,QAAQ,MAAM,uBACtC,KAAK,gBAAgB,QAAQ,MAAM;eAEhC;AACL,iBAAO;;;;;;;;;;;;;ACtNb,6CAAgD,QAA8B,WAAwC;;AACpH,aAAO;QACL,kBAAgB,MAAA,MAAE,UAAU,sBAAgB,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,gBAAS,QAAA,OAAA,SAAA,KAAK,OAAO,iBAAiB,KAAK;QAC9F,aAAW,MAAA,MAAE,UAAU,iBAAW,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,gBAAS,QAAA,OAAA,SAAA,KAAK,OAAO,YAAY,KAAK;QAC/E,qBAAmB,MAAA,MAAE,UAAU,yBAAmB,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,gBAAS,QAAA,OAAA,SAAA,KAAK,OAAO,oBAAoB,KAAK;QACvG,kBAAgB,MAAA,MAAE,UAAU,sBAAgB,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,gBAAS,QAAA,OAAA,SAAA,KAAK,OAAO,iBAAiB,KAAK;QAC9F,qBAAmB,MAAA,MAAE,UAAU,yBAAmB,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,gBAAS,QAAA,OAAA,SAAA,KAAK,OAAO,oBAAoB,KAAK;;;AAN3G,aAAA,kCAAA;AAoEA,QAAM,8BAKF;AAEJ,QAAI,0BAAyC;AAE7C,sCACE,UACA,kBACA,yBAAuD;AAEvD,kCAA4B,YAAY;QACtC,cAAc;QACd,qBAAqB;;;AAPzB,aAAA,2BAAA;AAWA,6CAAgD,UAAgB;AAC9D,gCAA0B;;AAD5B,aAAA,kCAAA;AAIA,gCACE,QACA,sBAA0C;AAE1C,YAAM,WAAW,OAAO;AACxB,UAAI,YAAY,6BAA6B;AAC3C,eAAO,IAAI,4BAA4B,UAAU,aAC/C;aAEG;AACL,eAAO;;;AAVX,aAAA,qBAAA;AAcA,0CAA6C,UAAgB;AAC3D,aAAO,YAAY;;AADrB,aAAA,+BAAA;AAQA,kCACE,SACA,oBAAoB,OAAK;AAEzB,iBAAW,UAAU,SAAS;AAC5B,YAAI,OAAO,yBAAyB,6BAA6B;AAC/D,iBAAO;;;AAGX,UAAI,mBAAmB;AACrB,YAAI,yBAAyB;AAC3B,iBAAO,IAAI,4BACT,yBACC;eACE;AACL,iBAAO;;aAEJ;AACL,eAAO;;;AAlBX,aAAA,uBAAA;AAuBA,yCAA4C,KAAQ;AAClD,UAAI,CAAE,SAAQ,QAAQ,OAAO,QAAQ,WAAW;AAC9C,cAAM,IAAI,MAAM;;AAElB,YAAM,OAAO,OAAO,KAAK;AACzB,UAAI,KAAK,WAAW,GAAG;AACrB,cAAM,IAAI,MACR;;AAGJ,YAAM,WAAW,KAAK;AACtB,UAAI,YAAY,6BAA6B;AAC3C,eAAO,4BACL,UACA,oBAAoB,eAAe,IAAI;aACpC;AACL,cAAM,IAAI,MAAM,2CAA2C;;;AAhB/D,aAAA,8BAAA;;;;;;;;;;AC3KA,QAAA,KAAA,QAAA;AACA,QAAA,kBAAA;AAwCA,QAAM,gBAAgB;AAMtB,QAAM,yBAAyB;AAE/B,0BAAsB,KAAQ;AAC5B,UAAI,CAAE,cAAa,QAAQ,OAAO,IAAI,YAAY,UAAU;AAC1D,cAAM,IAAI,MAAM;;AAElB,YAAM,SAA2B;QAC/B,SAAS,IAAI;;AAEf,UAAI,YAAY,KAAK;AACnB,YAAI,OAAO,IAAI,WAAW,UAAU;AAClC,iBAAO,SAAS,IAAI;eACf;AACL,gBAAM,IAAI,MAAM;;;AAGpB,aAAO;;AAGT,kCAA8B,KAAQ;;AACpC,YAAM,SAAuB;QAC3B,MAAM;;AAER,UAAI,CAAE,WAAU,QAAQ,CAAC,MAAM,QAAQ,IAAI,OAAO;AAChD,cAAM,IAAI,MAAM;;AAElB,iBAAW,SAAQ,IAAI,MAAM;AAC3B,eAAO,KAAK,KAAK,aAAa;;AAEhC,UAAI,kBAAkB,KAAK;AACzB,YAAI,OAAO,IAAI,iBAAiB,WAAW;AACzC,gBAAM,IAAI,MAAM;;AAElB,eAAO,eAAe,IAAI;;AAE5B,UAAI,aAAa,KAAK;AACpB,YAAI,OAAO,IAAI,YAAY,UAAU;AACnC,cACE,CAAE,cAAa,IAAI,YACnB,CAAE,QAAO,IAAI,QAAQ,YAAY,WACjC;AACA,kBAAM,IAAI,MAAM;;AAElB,cACE,CAAE,YAAW,IAAI,YACjB,CAAE,QAAO,IAAI,QAAQ,UAAU,WAC/B;AACA,kBAAM,IAAI,MAAM;;AAElB,iBAAO,UAAU,IAAI;mBAErB,OAAO,IAAI,YAAY,YACvB,cAAc,KAAK,IAAI,UACvB;AACA,gBAAM,eAAe,IAAI,QACtB,UAAU,GAAG,IAAI,QAAQ,SAAS,GAClC,MAAM;AACT,iBAAO,UAAU;YACf,SAAS,aAAa,KAAK;YAC3B,OAAO,OAAC,aAAa,QAAE,QAAA,OAAA,SAAA,KAAI,KAAK;;eAE7B;AACL,gBAAM,IAAI,MAAM;;;AAGpB,UAAI,qBAAqB,KAAK;AAC5B,YAAI,OAAO,IAAI,oBAAoB,UAAU;AAC3C,gBAAM,IAAI,MAAM;;AAElB,eAAO,kBAAkB,IAAI;;AAE/B,UAAI,sBAAsB,KAAK;AAC7B,YAAI,OAAO,IAAI,qBAAqB,UAAU;AAC5C,gBAAM,IAAI,MAAM;;AAElB,eAAO,mBAAmB,IAAI;;AAEhC,aAAO;;AAGT,mCAAsC,KAAQ;AAC5C,YAAM,SAAwB;QAC5B,qBAAqB;QACrB,cAAc;;AAEhB,UAAI,yBAAyB,KAAK;AAChC,YAAI,OAAO,IAAI,wBAAwB,UAAU;AAC/C,iBAAO,sBAAsB,IAAI;eAC5B;AACL,gBAAM,IAAI,MAAM;;;AAGpB,UAAI,yBAAyB,KAAK;AAChC,YAAI,MAAM,QAAQ,IAAI,sBAAsB;AAC1C,qBAAW,UAAU,IAAI,qBAAqB;AAC5C,mBAAO,oBAAoB,KAAK,gBAAA,4BAA4B;;eAEzD;AACL,gBAAM,IAAI,MAAM;;;AAGpB,UAAI,kBAAkB,KAAK;AACzB,YAAI,MAAM,QAAQ,IAAI,eAAe;AACnC,qBAAW,gBAAgB,IAAI,cAAc;AAC3C,mBAAO,aAAa,KAAK,qBAAqB;;;;AAKpD,YAAM,kBAAsC;AAC5C,iBAAW,gBAAgB,OAAO,cAAc;AAC9C,mBAAW,SAAQ,aAAa,MAAM;AACpC,qBAAW,YAAY,iBAAiB;AACtC,gBACE,MAAK,YAAY,SAAS,WAC1B,MAAK,WAAW,SAAS,QACzB;AACA,oBAAM,IAAI,MACR,0CAA0C,MAAK,WAAW,MAAK;;;AAIrE,0BAAgB,KAAK;;;AAGzB,aAAO;;AA7CT,aAAA,wBAAA;AAgDA,kCAA8B,KAAQ;AACpC,UAAI,CAAE,oBAAmB,MAAM;AAC7B,cAAM,IAAI,MAAM;;AAElB,YAAM,SAAoC;QACxC,eAAe,sBAAsB,IAAI;;AAE3C,UAAI,oBAAoB,KAAK;AAC3B,YAAI,MAAM,QAAQ,IAAI,iBAAiB;AACrC,iBAAO,iBAAiB;AACxB,qBAAW,QAAQ,IAAI,gBAAgB;AACrC,gBAAI,OAAO,SAAS,UAAU;AAC5B,qBAAO,eAAe,KAAK;mBACtB;AACL,oBAAM,IAAI,MACR;;;eAID;AACL,gBAAM,IAAI,MAAM;;;AAGpB,UAAI,oBAAoB,KAAK;AAC3B,YAAI,MAAM,QAAQ,IAAI,iBAAiB;AACrC,iBAAO,iBAAiB;AACxB,qBAAW,QAAQ,IAAI,gBAAgB;AACrC,gBAAI,OAAO,SAAS,UAAU;AAC5B,qBAAO,eAAe,KAAK;mBACtB;AACL,oBAAM,IAAI,MACR;;;eAID;AACL,gBAAM,IAAI,MAAM;;;AAGpB,UAAI,gBAAgB,KAAK;AACvB,YACE,OAAO,IAAI,eAAe,YAC1B,KAAK,IAAI,cACT,IAAI,cAAc,KAClB;AACA,iBAAO,aAAa,IAAI;eACnB;AACL,gBAAM,IAAI,MAAM;;;AAIpB,YAAM,gBAAgB;QACpB;QACA;QACA;QACA;;AAEF,iBAAW,SAAS,KAAK;AACvB,YAAI,CAAC,cAAc,SAAS,QAAQ;AAClC,gBAAM,IAAI,MACR,mDAAmD;;;AAIzD,aAAO;;AAGT,2CACE,KACA,YAAkB;AAElB,UAAI,CAAC,MAAM,QAAQ,MAAM;AACvB,cAAM,IAAI,MAAM;;AAElB,iBAAW,UAAU,KAAK;AACxB,cAAM,kBAAkB,qBAAqB;AAG7C,YACE,OAAO,gBAAgB,eAAe,YACtC,aAAa,gBAAgB,YAC7B;AACA;;AAEF,YAAI,MAAM,QAAQ,gBAAgB,iBAAiB;AACjD,cAAI,kBAAkB;AACtB,qBAAW,YAAY,gBAAgB,gBAAgB;AACrD,gBAAI,aAAa,GAAG,YAAY;AAC9B,gCAAkB;;;AAGtB,cAAI,CAAC,iBAAiB;AACpB;;;AAGJ,YAAI,MAAM,QAAQ,gBAAgB,iBAAiB;AACjD,cAAI,kBAAkB;AACtB,qBAAW,YAAY,gBAAgB,gBAAgB;AACrD,gBAAI,aAAa,wBAAwB;AACvC,gCAAkB;;;AAGtB,cAAI,CAAC,iBAAiB;AACpB;;;AAGJ,eAAO,gBAAgB;;AAEzB,YAAM,IAAI,MAAM;;AAYlB,2CACE,WACA,YAAkB;AAElB,iBAAW,UAAU,WAAW;AAC9B,YAAI,OAAO,SAAS,KAAK,OAAO,GAAG,WAAW,iBAAiB;AAG7D,gBAAM,eAAe,OAAO,KAAK,IAAI,UAAU,eAAe;AAC9D,gBAAM,aAAkB,KAAK,MAAM;AACnC,iBAAO,8BAA8B,YAAY;;;AAGrD,aAAO;;AAbT,aAAA,gCAAA;;;;;;;;;;AClTA,QAAY;AAAZ,IAAA,UAAY,oBAAiB;AAC3B,yBAAA,mBAAA,UAAA,KAAA;AACA,yBAAA,mBAAA,gBAAA,KAAA;AACA,yBAAA,mBAAA,WAAA,KAAA;AACA,yBAAA,mBAAA,uBAAA,KAAA;AACA,yBAAA,mBAAA,cAAA,KAAA;OALU,oBAAA,SAAA,qBAAA,UAAA,oBAAiB;;;;;;;;;;ACY7B,QAAM,YAAY;AAElB,sBAAyB,WAAiB;AACxC,YAAM,YAAY,UAAU,KAAK;AACjC,UAAI,cAAc,MAAM;AACtB,eAAO;;AAET,aAAO;QACL,QAAQ,UAAU;QAClB,WAAW,UAAU;QACrB,MAAM,UAAU;;;AARpB,aAAA,WAAA;AAiBA,QAAM,eAAe;AAErB,2BAA8B,MAAY;AACxC,UAAI,KAAK,WAAW,MAAM;AACxB,cAAM,UAAU,KAAK,QAAQ;AAC7B,YAAI,YAAY,IAAI;AAClB,iBAAO;;AAET,cAAM,OAAO,KAAK,UAAU,GAAG;AAG/B,YAAI,KAAK,QAAQ,SAAS,IAAI;AAC5B,iBAAO;;AAET,YAAI,KAAK,SAAS,UAAU,GAAG;AAC7B,cAAI,KAAK,UAAU,OAAO,KAAK;AAC7B,kBAAM,aAAa,KAAK,UAAU,UAAU;AAC5C,gBAAI,aAAa,KAAK,aAAa;AACjC,qBAAO;gBACL;gBACA,MAAM,CAAC;;mBAEJ;AACL,qBAAO;;iBAEJ;AACL,mBAAO;;eAEJ;AACL,iBAAO;YACL;;;aAGC;AACL,cAAM,YAAY,KAAK,MAAM;AAI7B,YAAI,UAAU,WAAW,GAAG;AAC1B,cAAI,aAAa,KAAK,UAAU,KAAK;AACnC,mBAAO;cACL,MAAM,UAAU;cAChB,MAAM,CAAC,UAAU;;iBAEd;AACL,mBAAO;;eAEJ;AACL,iBAAO;YACL,MAAM;;;;;AA/Cd,aAAA,gBAAA;AAqDA,yBAA4B,KAAY;AACtC,UAAI,SAAS;AACb,UAAI,IAAI,WAAW,QAAW;AAC5B,kBAAU,IAAI,SAAS;;AAEzB,UAAI,IAAI,cAAc,QAAW;AAC/B,kBAAU,OAAO,IAAI,YAAY;;AAEnC,gBAAU,IAAI;AACd,aAAO;;AATT,aAAA,cAAA;;;;;;;;;;ACnFA,QAAA,eAAA;AAoFA,QAAM,sBAAiE;AACvE,QAAI,gBAA+B;AASnC,8BACE,QACA,eAAkC;AAElC,0BAAoB,UAAU;;AAJhC,aAAA,mBAAA;AAYA,mCAAsC,QAAc;AAClD,sBAAgB;;AADlB,aAAA,wBAAA;AAUA,4BACE,QACA,UACA,SAAuB;AAEvB,UAAI,OAAO,WAAW,UAAa,OAAO,UAAU,qBAAqB;AACvE,eAAO,IAAI,oBAAoB,OAAO,QAAQ,QAAQ,UAAU;aAC3D;AACL,cAAM,IAAI,MACR,2CAA2C,aAAA,YAAY;;;AAT7D,aAAA,iBAAA;AAmBA,iCAAoC,QAAe;AACjD,UAAI,OAAO,WAAW,UAAa,OAAO,UAAU,qBAAqB;AACvE,eAAO,oBAAoB,OAAO,QAAQ,oBAAoB;aACzD;AACL,cAAM,IAAI,MAAM,kBAAkB,aAAA,YAAY;;;AAJlD,aAAA,sBAAA;AAQA,iCAAoC,QAAe;AACjD,UAAI,OAAO,WAAW,UAAa,CAAE,QAAO,UAAU,sBAAsB;AAC1E,YAAI,kBAAkB,MAAM;AAC1B,iBAAO;YACL,QAAQ;YACR,WAAW;YACX,MAAM,aAAA,YAAY;;eAEf;AACL,iBAAO;;;AAGX,aAAO;;AAZT,aAAA,sBAAA;;;;;;;;;;AChJA,QAAA,aAAA;AACA,QAAA,cAAA;AAIA,QAAY;AAAZ,IAAA,UAAY,iBAAc;AACxB,sBAAA,gBAAA,cAAA,KAAA;AACA,sBAAA,gBAAA,WAAA,KAAA;AACA,sBAAA,gBAAA,uBAAA,KAAA;AACA,sBAAA,gBAAA,UAAA,KAAA;OAJU,iBAAA,SAAA,kBAAA,UAAA,iBAAc;AA+E1B,kCAA8B;MAE5B,YAAY,QAAqB;AAC/B,YAAI,WAAW,QAAW;AACxB,eAAK,SAAS;eACT;AACL,eAAK,SAAS;YACZ,MAAM,YAAA,OAAO;YACb,SAAS;YACT,UAAU,IAAI,WAAA;;;;MAIpB,KAAK,UAAkB;AACrB,eAAO;UACL,gBAAgB,eAAe;UAC/B,YAAY;UACZ,QAAQ,KAAK;UACb,sBAAsB;UACtB,eAAe;;;;AAnBrB,aAAA,oBAAA;AA+BA,4BAAwB;MAGtB,YAAoB,cAA0B;AAA1B,aAAA,eAAA;AAFZ,aAAA,iBAAiB;;MAIzB,KAAK,UAAkB;AACrB,YAAI,CAAC,KAAK,gBAAgB;AACxB,kBAAQ,SAAS,MAAK;AACpB,iBAAK,aAAa;;AAEpB,eAAK,iBAAiB;;AAExB,eAAO;UACL,gBAAgB,eAAe;UAC/B,YAAY;UACZ,QAAQ;UACR,sBAAsB;UACtB,eAAe;;;;AAjBrB,aAAA,cAAA;;;;;;;;;;ACrHA,QAAM,qBAAqB;AAC3B,QAAM,qBAAqB;AAC3B,QAAM,iBAAiB;AACvB,QAAM,iBAAiB;AAOvB,2BAAuB,KAAa,KAAW;AAC7C,aAAO,KAAK,WAAY,OAAM,OAAO;;AAUvC,+BAA2B;MAUzB,YAAoB,UAAsB,SAAwB;AAA9C,aAAA,WAAA;AATZ,aAAA,eAAuB;AACvB,aAAA,aAAqB;AACrB,aAAA,WAAmB;AACnB,aAAA,SAAiB;AAGjB,aAAA,UAAU;AACV,aAAA,SAAS;AAGf,YAAI,SAAS;AACX,cAAI,QAAQ,cAAc;AACxB,iBAAK,eAAe,QAAQ;;AAE9B,cAAI,QAAQ,YAAY;AACtB,iBAAK,aAAa,QAAQ;;AAE5B,cAAI,QAAQ,QAAQ;AAClB,iBAAK,SAAS,QAAQ;;AAExB,cAAI,QAAQ,UAAU;AACpB,iBAAK,WAAW,QAAQ;;;AAG5B,aAAK,YAAY,KAAK;AACtB,aAAK,UAAU,WAAW,MAAK;WAAK;AACpC,qBAAa,KAAK;;MAMpB,UAAO;;AACL,aAAK,UAAU;AACf,aAAK,UAAU,WAAW,MAAK;AAC7B,eAAK;AACL,eAAK,UAAU;WACd,KAAK;AACR,YAAI,CAAC,KAAK,QAAQ;AAChB,UAAA,MAAA,MAAA,KAAK,SAAQ,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;AAEpB,cAAM,cAAc,KAAK,IACvB,KAAK,YAAY,KAAK,YACtB,KAAK;AAEP,cAAM,kBAAkB,cAAc,KAAK;AAC3C,aAAK,YACH,cAAc,cAAc,CAAC,iBAAiB;;MAOlD,OAAI;AACF,qBAAa,KAAK;AAClB,aAAK,UAAU;;MAMjB,QAAK;AACH,aAAK,YAAY,KAAK;;MAGxB,YAAS;AACP,eAAO,KAAK;;MAGd,MAAG;;AACD,aAAK,SAAS;AACd,QAAA,MAAA,MAAA,KAAK,SAAQ,SAAG,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;MAGlB,QAAK;;AACH,aAAK,SAAS;AACd,QAAA,MAAA,MAAA,KAAK,SAAQ,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;;AA9EtB,aAAA,iBAAA;;;;;;;;;;ACrBA,QAAA,kBAAA;AASA,QAAA,uBAAA;AAIA,QAAM,YAAY;AAElB,yCAAqC;MAqDnC,YAA6B,sBAA0C;AAA1C,aAAA,uBAAA;AApDrB,aAAA,eAAoC;AACpC,aAAA,eAAoC;AAEpC,aAAA,oBAAoB,MAAA;UAE1B,YAAoB,QAAgC;AAAhC,iBAAA,SAAA;AADZ,iBAAA,QAA6B;;UAErC,iBACE,mBACA,gBAA8B;AAE9B,mBAAO,KAAK,OAAO,qBAAqB,iBACtC,mBACA;;UAGJ,YAAY,mBAAsC,QAAc;;AAC9D,gBAAI,KAAK,wBAAwB;AAC/B,kBAAI,sBAAsB,qBAAA,kBAAkB,OAAO;AACjD;;AAEF,cAAA,MAAA,KAAK,OAAO,kBAAY,QAAA,OAAA,SAAA,SAAA,GAAE;AAC1B,mBAAK,OAAO,eAAe,KAAK,OAAO;AACvC,mBAAK,OAAO,eAAe;uBAClB,CAAC,KAAK,wBAAwB;AACvC;;AAEF,iBAAK,OAAO,qBAAqB,YAAY,mBAAmB;;UAElE,sBAAmB;;AACjB,kBAAM,cAAW,MAAG,KAAK,OAAO,kBAAY,QAAA,OAAA,SAAA,KAAI,KAAK,OAAO;AAC5D,gBAAI,KAAK,UAAU,aAAa;AAC9B,mBAAK,OAAO,qBAAqB;;;UAGrC,SAAS,UAAsB;AAC7B,iBAAK,QAAQ;;UAEf,iBAAiB,OAAiC;AAChD,iBAAK,OAAO,qBAAqB,iBAAiB;;UAEpD,oBAAoB,OAAiC;AACnD,iBAAK,OAAO,qBAAqB,oBAAoB;;UAG/C,uBAAoB;AAC1B,mBAAO,KAAK,UAAU,KAAK,OAAO;;UAE5B,uBAAoB;AAC1B,mBAAO,KAAK,UAAU,KAAK,OAAO;;;;MAYtC,kBACE,aACA,UACA,YAAsC;AAEtC,YAAI;AACJ,YACE,KAAK,iBAAiB,QACtB,KAAK,aAAa,kBAAkB,SAAS,uBAC7C;AACA,gBAAM,YAAY,IAAI,KAAK,kBAAkB;AAC7C,gBAAM,WAAW,gBAAA,mBAAmB,UAAU;AAC9C,oBAAU,SAAS;AACnB,cAAI,KAAK,iBAAiB,MAAM;AAC9B,iBAAK,eAAe;AACpB,4BAAgB,KAAK;iBAChB;AACL,gBAAI,KAAK,cAAc;AACrB,mBAAK,aAAa;;AAEpB,iBAAK,eAAe;AACpB,4BAAgB,KAAK;;eAElB;AACL,cAAI,KAAK,iBAAiB,MAAM;AAC9B,4BAAgB,KAAK;iBAChB;AACL,4BAAgB,KAAK;;;AAGzB,sBAAc,kBAAkB,aAAa,UAAU;;MAEzD,WAAQ;AACN,YAAI,KAAK,cAAc;AACrB,eAAK,aAAa;AAClB,cAAI,KAAK,cAAc;AACrB,iBAAK,aAAa;;;;MAIxB,eAAY;AACV,YAAI,KAAK,cAAc;AACrB,eAAK,aAAa;AAClB,cAAI,KAAK,cAAc;AACrB,iBAAK,aAAa;;;;MAIxB,UAAO;AACL,YAAI,KAAK,cAAc;AACrB,eAAK,aAAa;AAClB,eAAK,eAAe;;AAEtB,YAAI,KAAK,cAAc;AACrB,eAAK,aAAa;AAClB,eAAK,eAAe;;;MAGxB,cAAW;AACT,eAAO;;;AAxHX,aAAA,2BAAA;;;;;;;;;;ACfA,QAAA,kBAAA;AAMA,QAAA,mBAAA;AACA,QAAA,uBAAA;AACA,QAAA,aAAA;AAEA,QAAA,WAAA;AACA,QAAA,oBAAA;AACA,QAAA,cAAA;AAEA,QAAA,aAAA;AACA,QAAA,UAAA;AACA,QAAA,cAAA;AAEA,QAAA,eAAA;AACA,QAAA,gCAAA;AAIA,QAAM,cAAc;AAEpB,mBAAe,MAAY;AACzB,cAAQ,MAAM,YAAA,aAAa,OAAO,aAAa;;AAKjD,sCACE,eAAmC;AAEnC,aAAO,+BACL,YACA,UAAkB;;AAElB,cAAM,YAAY,WAAW,MAAM,KAAK,OAAO,CAAC,MAAM,EAAE,SAAS;AACjE,cAAM,UAAO,MAAG,UAAU,QAAE,QAAA,OAAA,SAAA,KAAI;AAChC,cAAM,SAAM,MAAG,UAAU,QAAE,QAAA,OAAA,SAAA,KAAI;AAC/B,YAAI,iBAAiB,cAAc,cAAc;AAC/C,qBAAW,gBAAgB,cAAc,cAAc;AACrD,uBAAW,SAAQ,aAAa,MAAM;AACpC,kBACE,MAAK,YAAY,WAChB,OAAK,WAAW,UAAa,MAAK,WAAW,SAC9C;AACA,uBAAO;kBACL;kBACA,iBAAiB;kBACjB,QAAQ,YAAA,OAAO;kBACf,wBAAwB;;;;;;AAMlC,eAAO;UACL,cAAc,EAAE,MAAM;UACtB,iBAAiB;UACjB,QAAQ,YAAA,OAAO;UACf,wBAAwB;;;;AAa9B,sCAAkC;MA4ChC,YACmB,QACA,sBACA,gBACA,wBACA,oBAA6C;AAJ7C,aAAA,SAAA;AACA,aAAA,uBAAA;AACA,aAAA,iBAAA;AACA,aAAA,yBAAA;AACA,aAAA,qBAAA;AA1CX,aAAA,mBAAsC,qBAAA,kBAAkB;AACxD,aAAA,oBAA4B,IAAI,SAAA,YAAY;AAI5C,aAAA,eAAkC,qBAAA,kBAAkB;AAOpD,aAAA,wBAA8C;AAW9C,aAAA,oBAAoB;AAqB1B,YAAI,eAAe,wBAAwB;AACzC,eAAK,uBAAuB,iBAAA,sBAC1B,KAAK,MAAM,eAAe;eAEvB;AACL,eAAK,uBAAuB;YAC1B,qBAAqB;YACrB,cAAc;;;AAGlB,aAAK,YAAY,qBAAA,kBAAkB,MAAM,IAAI,SAAA,YAAY;AACzD,aAAK,oBAAoB,IAAI,8BAAA,yBAAyB;UACpD,kBAAkB,qBAAqB,iBAAiB,KACtD;UAEF,qBAAqB,MAAK;AAKxB,gBAAI,KAAK,eAAe,aAAa;AACnC,mBAAK,oBAAoB;mBACpB;AACL,mBAAK;;;UAGT,aAAa,CAAC,UAA6B,WAAkB;AAC3D,iBAAK,mBAAmB;AACxB,iBAAK,oBAAoB;AACzB,iBAAK,YAAY,UAAU;;UAE7B,kBAAkB,qBAAqB,iBAAiB,KACtD;UAEF,qBAAqB,qBAAqB,oBAAoB,KAC5D;;AAGJ,aAAK,gBAAgB,WAAA,eACnB,QACA;UACE,wBAAwB,CACtB,aACA,eACA,oBACA,gBACA,eACE;;AACF,gBAAI,uBAA6C;AAKjD,gBAAI,kBAAkB,MAAM;AAE1B,kBAAI,uBAAuB,MAAM;AAE/B,qBAAK,wBAAwB;AAC7B,uCAAuB,KAAK;qBACvB;AAEL,oBAAI,KAAK,0BAA0B,MAAM;AAEvC,uBAAK,wBAAwB;uBACxB;AAEL,yCAAuB,KAAK;;;mBAG3B;AAEL,qCAAuB;AACvB,mBAAK,wBAAwB;;AAE/B,kBAAM,oBAAiB,MACrB,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,yBAAmB,QAAA,OAAA,SAAA,KAAI;AAC/C,kBAAM,sBAAsB,gBAAA,qBAC1B,mBACA;AAEF,gBAAI,wBAAwB,MAAM;AAEhC,mBAAK,wBAAwB;gBAC3B,MAAM,YAAA,OAAO;gBACb,SACE;gBACF,UAAU,IAAI,WAAA;;AAEhB;;AAEF,iBAAK,kBAAkB,kBACrB,aACA,qBACA;AAEF,kBAAM,qBACJ,yBAAoB,QAApB,yBAAoB,SAApB,uBAAwB,KAAK;AAC/B,iBAAK,uBACH,mBAAc,QAAd,mBAAc,SAAd,iBAAkB,yBAAyB;;UAG/C,SAAS,CAAC,UAAuB;AAC/B,iBAAK,wBAAwB;;WAGjC;AAGF,aAAK,iBAAiB,IAAI,kBAAA,eAAe,MAAK;AAC5C,cAAI,KAAK,mBAAmB;AAC1B,iBAAK;AACL,iBAAK,oBAAoB;iBACpB;AACL,iBAAK,YAAY,KAAK,kBAAkB,KAAK;;;AAGjD,aAAK,eAAe;;MAGd,mBAAgB;AACtB,aAAK,cAAc;AACnB,YAAI,KAAK,iBAAiB,qBAAA,kBAAkB,MAAM;AAChD,eAAK,YAAY,qBAAA,kBAAkB,YAAY,IAAI,SAAA,YAAY;;;MAI3D,YAAY,mBAAsC,QAAc;AACtE,cACE,aAAA,YAAY,KAAK,UACf,MACA,qBAAA,kBAAkB,KAAK,gBACvB,SACA,qBAAA,kBAAkB;AAGtB,YAAI,sBAAsB,qBAAA,kBAAkB,MAAM;AAChD,mBAAS,IAAI,SAAA,YAAY;;AAE3B,aAAK,eAAe;AACpB,aAAK,qBAAqB,YAAY,mBAAmB;;MAGnD,wBAAwB,OAAmB;AACjD,YAAI,KAAK,qBAAqB,qBAAA,kBAAkB,MAAM;AACpD,eAAK,YACH,qBAAA,kBAAkB,mBAClB,IAAI,SAAA,kBAAkB;AAExB,eAAK,mBAAmB;;AAE1B,aAAK,eAAe;;MAGtB,WAAQ;AACN,aAAK,kBAAkB;AACvB,YAAI,KAAK,iBAAiB,qBAAA,kBAAkB,MAAM;AAChD,cAAI,KAAK,eAAe,aAAa;AACnC,iBAAK,oBAAoB;iBACpB;AACL,iBAAK;;AAEP,eAAK,YAAY,qBAAA,kBAAkB,YAAY,IAAI,SAAA,YAAY;;;MAInE,kBACE,aACA,UAAoC;AAEpC,cAAM,IAAI,MAAM;;MAGlB,eAAY;AACV,aAAK,eAAe;AACpB,aAAK,kBAAkB;;MAGzB,UAAO;AACL,aAAK,kBAAkB;AACvB,aAAK,cAAc;AACnB,aAAK,YAAY,qBAAA,kBAAkB,UAAU,IAAI,SAAA;;MAGnD,cAAW;AACT,eAAO;;;AA3OX,aAAA,wBAAA;;;;;;;;;;AC5Ca,aAAA,oBAAoB;MAC/B,iCAAiC;MACjC,2BAA2B;MAC3B,6BAA6B;MAC7B,0BAA0B;MAC1B,0BAA0B;MAC1B,6BAA6B;MAC7B,uCAAuC;MACvC,uBAAuB;MACvB,+BAA+B;MAC/B,qCAAqC;MACrC,iCAAiC;MACjC,kCAAkC;MAClC,gCAAgC;MAChC,mCAAmC;MACnC,0BAA0B;MAC1B,wBAAwB;MACxB,gCAAgC;;AAGlC,iCACE,UACA,UAAwB;AAExB,YAAM,QAAQ,OAAO,KAAK,UAAU;AACpC,YAAM,QAAQ,OAAO,KAAK,UAAU;AACpC,UAAI,MAAM,WAAW,MAAM,QAAQ;AACjC,eAAO;;AAET,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,GAAG;AACxC,YAAI,MAAM,OAAO,MAAM,IAAI;AACzB,iBAAO;;AAET,YAAI,SAAS,MAAM,QAAQ,SAAS,MAAM,KAAK;AAC7C,iBAAO;;;AAGX,aAAO;;AAjBT,aAAA,sBAAA;;;;;;;;;;ACnDA,QAAA,QAAA,QAAA;AAmBA,oCACE,SAA0B;AAE1B,aAAO,UAAU;;AAHnB,aAAA,yBAAA;AAMA,oCACE,UACA,UAA2B;AAE3B,UAAI,uBAAuB,WAAW;AACpC,eACE,uBAAuB,aACvB,SAAS,SAAS,SAAS,QAC3B,SAAS,SAAS,SAAS;aAExB;AACL,eAAO,CAAC,uBAAuB,aAAa,SAAS,SAAS,SAAS;;;AAX3E,aAAA,yBAAA;AAeA,uCAA0C,SAA0B;AAClE,UAAI,uBAAuB,UAAU;AACnC,eAAO,QAAQ,OAAO,MAAM,QAAQ;aAC/B;AACL,eAAO,QAAQ;;;AAJnB,aAAA,4BAAA;AAQA,QAAM,eAAe;AAErB,uCAA0C,eAAuB,MAAa;AAC5E,UAAI,MAAA,KAAK,gBAAgB;AACvB,eAAO;UACL,MAAM;UACN,MAAM,SAAI,QAAJ,SAAI,SAAJ,OAAQ;;aAEX;AACL,eAAO;UACL,MAAM;;;;AARZ,aAAA,4BAAA;;;;;;;;;;AClDA,QAAA,YAAA;AACA,QAAA,cAAA;AACA,QAAA,aAAA;AAEA,QAAA,OAAA,QAAA;AACA,QAAA,MAAA,QAAA;AACA,QAAA,UAAA;AACA,QAAA,uBAAA;AAMA,QAAA,eAAA;AACA,QAAA,QAAA,QAAA;AAEA,QAAM,cAAc;AAEpB,mBAAe,MAAY;AACzB,cAAQ,MAAM,YAAA,aAAa,OAAO,aAAa;;AAQjD,4BAAqB;AACnB,UAAI,WAAW;AACf,UAAI,SAAS;AAKb,UAAI,QAAQ,IAAI,YAAY;AAC1B,iBAAS;AACT,mBAAW,QAAQ,IAAI;iBACd,QAAQ,IAAI,aAAa;AAClC,iBAAS;AACT,mBAAW,QAAQ,IAAI;iBACd,QAAQ,IAAI,YAAY;AACjC,iBAAS;AACT,mBAAW,QAAQ,IAAI;aAClB;AACL,eAAO;;AAET,UAAI;AACJ,UAAI;AACF,mBAAW,IAAI,MAAA,IAAI;eACZ,GAAP;AACA,kBAAA,IAAI,YAAA,aAAa,OAAO,0BAA0B;AAClD,eAAO;;AAET,UAAI,SAAS,aAAa,SAAS;AACjC,kBAAA,IACE,YAAA,aAAa,OACb,IAAI,SAAS;AAEf,eAAO;;AAET,UAAI,WAA0B;AAC9B,UAAI,SAAS,UAAU;AACrB,YAAI,SAAS,UAAU;AACrB,oBAAA,IAAI,YAAA,aAAa,MAAM;AACvB,qBAAW,GAAG,SAAS,YAAY,SAAS;eACvC;AACL,qBAAW,SAAS;;;AAGxB,YAAM,WAAW,SAAS;AAC1B,UAAI,OAAO,SAAS;AAIpB,UAAI,SAAS,IAAI;AACf,eAAO;;AAET,YAAM,SAAoB;QACxB,SAAS,GAAG,YAAY;;AAE1B,UAAI,UAAU;AACZ,eAAO,QAAQ;;AAEjB,YACE,kBAAkB,OAAO,UAAU,kCAAkC;AAEvE,aAAO;;AAGT,kCAA2B;AAEzB,UAAI,aAAiC,QAAQ,IAAI;AACjD,UAAI,SAAS;AACb,UAAI,CAAC,YAAY;AACf,qBAAa,QAAQ,IAAI;AACzB,iBAAS;;AAEX,UAAI,YAAY;AACd,cAAM,sDAAsD;AAC5D,eAAO,WAAW,MAAM;aACnB;AACL,eAAO;;;AASX,0BACE,QACA,SAAuB;;AAEvB,YAAM,gBAAgC;QACpC;QACA,cAAc;;AAEhB,UAAI,OAAC,QAAQ,+BAAyB,QAAA,OAAA,SAAA,KAAI,OAAO,GAAG;AAClD,eAAO;;AAET,YAAM,YAAY;AAClB,UAAI,CAAC,UAAU,SAAS;AACtB,eAAO;;AAET,YAAM,WAAW,aAAA,cAAc,OAAO;AACtC,UAAI,CAAC,UAAU;AACb,eAAO;;AAET,YAAM,aAAa,SAAS;AAC5B,iBAAW,QAAQ,sBAAsB;AACvC,YAAI,SAAS,YAAY;AACvB,gBACE,kDAAkD,aAAA,YAAY;AAEhE,iBAAO;;;AAGX,YAAM,eAA+B;QACnC,4BAA4B,aAAA,YAAY;;AAE1C,UAAI,UAAU,OAAO;AACnB,qBAAa,6BAA6B,UAAU;;AAEtD,aAAO;QACL,QAAQ;UACN,QAAQ;UACR,MAAM,UAAU;;QAElB;;;AAvCJ,aAAA,eAAA;AAgDA,kCACE,SACA,gBACA,mBAAwC;AAExC,UAAI,CAAE,+BAA8B,iBAAiB;AACnD,eAAO,QAAQ,QAA+B;;AAEhD,YAAM,aAAa,eAAe;AAClC,YAAM,eAAe,aAAA,SAAS;AAC9B,UAAI,iBAAiB,MAAM;AACzB,eAAO,QAAQ,QAA+B;;AAEhD,YAAM,UAA+B;QACnC,QAAQ;QACR,MAAM,aAAa;;AAErB,YAAM,UAAoC;QACxC,MAAM,aAAa;;AAGrB,UAAI,qBAAA,uBAAuB,UAAU;AACnC,gBAAQ,OAAO,QAAQ;AACvB,gBAAQ,OAAO,QAAQ;aAClB;AACL,gBAAQ,aAAa,QAAQ;;AAE/B,UAAI,6BAA6B,gBAAgB;AAC/C,gBAAQ,yBACN,WACA,OAAO,KACL,eAAe,4BACf,SAAS;;AAEf,cAAQ,UAAU;AAClB,YAAM,qBAAqB,qBAAA,0BAA0B;AACrD,YAAM,iBAAiB,qBAAqB,oBAAoB,QAAQ;AACxE,aAAO,IAAI,QAA+B,CAAC,UAAS,WAAU;AAC5D,cAAM,UAAU,KAAK,QAAQ;AAC7B,gBAAQ,KAAK,WAAW,CAAC,KAAK,QAAQ,SAAQ;;AAC5C,kBAAQ;AACR,iBAAO;AACP,cAAI,IAAI,eAAe,KAAK;AAC1B,kBACE,+BACE,QAAQ,OACR,oBACA;AAEJ,gBAAI,mBAAmB,mBAAmB;AAKxC,oBAAM,aAAa,WAAA,oBAAoB;AACvC,oBAAM,WAAW,aAAA,cAAc;AAC/B,oBAAM,aAAU,MAAG,aAAQ,QAAR,aAAQ,SAAA,SAAR,SAAU,UAAI,QAAA,OAAA,SAAA,KAAI;AAErC,oBAAM,MAAM,IAAI,QAAO,OAAA,OAAA,EAEnB,MAAM,YACN,YAAY,YACZ,UACG,oBAEL,MAAK;AACH,sBACE,kDACE,QAAQ,OACR,oBACA;AAEJ,yBAAQ,EAAE,QAAQ,KAAK,YAAY;;AAGvC,kBAAI,GAAG,SAAS,CAAC,UAAgB;AAC/B,sBAAM,6CACE,QAAQ,OACR,oBACA,qBACA,iBACA,MAAM;AACd;;mBAEG;AACL,oBACE,wDACE,QAAQ,OACR,oBACA;AAEJ,uBAAQ;gBACN;gBACA,YAAY;;;iBAGX;AACL,sBAAA,IACE,YAAA,aAAa,OACb,0BACE,QAAQ,OACR,oBACA,qBACA,kBACA,IAAI;AAER;;;AAGJ,gBAAQ,KAAK,SAAS,CAAC,QAAO;AAC5B,kBAAQ;AACR,oBAAA,IACE,YAAA,aAAa,OACb,gCACE,qBACA,iBACA,IAAI;AAER;;AAEF,gBAAQ;;;AAxHZ,aAAA,uBAAA;;;;;;;;;;ACnJA,QAAM,0BAAoG;AAE1G,kCAAqC,sBAA4C,aAAwB;AACvG,8BAAwB,KAAK,EAAC,sBAAsB;;AADtD,aAAA,uBAAA;AAIA,sCAAyC,QAAc;AACrD,iBAAW,EAAC,sBAAsB,iBAAgB,yBAAyB;AACzE,eAAO,WAAW,wBAAwB;;;AAF9C,aAAA,2BAAA;;;;;;;;;;ACjBA,QAAA,WAAA,QAAA;AACA,QAAA,WAAA,QAAA;AAGA,QAAA,cAAA;AAyDA,iCAAoC,QAAoB;AACtD,YAAM,UAAU,GAAG,OAAO,QAAQ,YAAA,OAAO,OAAO,UAAU,OAAO;AACjE,aAAO,OAAO,OAAO,IAAI,MAAM,UAAU;;AAF3C,aAAA,sBAAA;AAKA,4CACU,SAAA,aAAY;MAGpB,cAAA;AACE;;MAGF,SAAM;;AACJ,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,iBAAiB,YAAA,OAAO,WAAW;;MAGhD,UAAO;;AACL,eAAA,MAAA,MAAO,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,eAAO,QAAA,OAAA,SAAA,KAAM;;;AAbnC,aAAA,sBAAA;AAiBA,iDACU,SAAA,SAAQ;MAGhB,YAAqB,aAA4C;AAC/D,cAAM,EAAE,YAAY;AADD,aAAA,cAAA;;MAIrB,SAAM;;AACJ,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,iBAAiB,YAAA,OAAO,WAAW;;MAGhD,UAAO;;AACL,eAAA,MAAA,MAAO,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,eAAO,QAAA,OAAA,SAAA,KAAM;;MAGjC,MAAM,OAAa;;AACjB,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE;;;AAjBf,aAAA,2BAAA;AAqBA,iDACU,SAAA,SAAQ;MAGhB,YAAqB,WAAyC;AAC5D,cAAM,EAAE,YAAY;AADD,aAAA,YAAA;;MAIrB,SAAM;;AACJ,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,iBAAiB,YAAA,OAAO,WAAW;;MAGhD,UAAO;;AACL,eAAA,MAAA,MAAO,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,eAAO,QAAA,OAAA,SAAA,KAAM;;MAGjC,OAAO,OAAoB,UAAkB,IAAiB;;AAC5D,cAAM,UAA0B;UAC9B,UAAU;;AAEZ,cAAM,QAAQ,OAAO;AACrB,YAAI,CAAC,OAAO,MAAM,QAAQ;AACxB,kBAAQ,QAAQ;;AAElB,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,uBAAuB,SAAS;;MAG7C,OAAO,IAAY;;AACjB,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE;AACX;;;AA7BJ,aAAA,2BAAA;AAiCA,+CACU,SAAA,OAAM;MAGd,YACW,WACA,aAA4C;AAErD,cAAM,EAAE,YAAY;AAHX,aAAA,YAAA;AACA,aAAA,cAAA;;MAKX,SAAM;;AACJ,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,iBAAiB,YAAA,OAAO,WAAW;;MAGhD,UAAO;;AACL,eAAA,MAAA,MAAO,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,eAAO,QAAA,OAAA,SAAA,KAAM;;MAGjC,MAAM,OAAa;;AACjB,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE;;MAGb,OAAO,OAAoB,UAAkB,IAAiB;;AAC5D,cAAM,UAA0B;UAC9B,UAAU;;AAEZ,cAAM,QAAQ,OAAO;AACrB,YAAI,CAAC,OAAO,MAAM,QAAQ;AACxB,kBAAQ,QAAQ;;AAElB,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE,uBAAuB,SAAS;;MAG7C,OAAO,IAAY;;AACjB,QAAA,MAAA,KAAK,UAAI,QAAA,OAAA,SAAA,SAAA,GAAE;AACX;;;AApCJ,aAAA,yBAAA;;;;;;;;;;ACzIA,QAAA,aAAA;AACA,QAAA,gBAAA;AAaA,QAAA,cAAA;AAUA,sDAAmD,MAAK;MACtD,YAAY,SAAe;AACzB,cAAM;AACN,aAAK,OAAO;AACZ,cAAM,kBAAkB,MAAM;;;AAJlC,aAAA,gCAAA;AA4CA,gCAA4B;MAA5B,cAAA;AACU,aAAA,WAAyC;AACzC,aAAA,UAAuC;AACvC,aAAA,SAAqC;;MAE7C,sBAAsB,mBAAmC;AACvD,aAAK,WAAW;AAChB,eAAO;;MAGT,qBAAqB,kBAAiC;AACpD,aAAK,UAAU;AACf,eAAO;;MAGT,oBAAoB,iBAA+B;AACjD,aAAK,SAAS;AACd,eAAO;;MAGT,QAAK;AACH,eAAO;UACL,mBAAmB,KAAK;UACxB,kBAAkB,KAAK;UACvB,iBAAiB,KAAK;;;;AAxB5B,aAAA,kBAAA;AA6BA,iCAA6B;MAA7B,cAAA;AACU,aAAA,QAAuC;AACvC,aAAA,UAAwC;AACxC,aAAA,YAAwC;AACxC,aAAA,SAAsC;;MAE9C,UAAU,OAAwB;AAChC,aAAK,QAAQ;AACb,eAAO;;MAGT,gBAAgB,aAA6B;AAC3C,aAAK,UAAU;AACf,eAAO;;MAGT,cAAc,WAAyB;AACrC,aAAK,YAAY;AACjB,eAAO;;MAGT,WAAW,QAAuB;AAChC,aAAK,SAAS;AACd,eAAO;;MAGT,QAAK;AACH,eAAO;UACL,OAAO,KAAK;UACZ,aAAa,KAAK;UAClB,WAAW,KAAK;UAChB,QAAQ,KAAK;;;;AA/BnB,aAAA,mBAAA;AAwCA,QAAM,kBAAgC;MACpC,mBAAmB,CAAC,UAAU,SAAQ;AACpC,aAAK;;MAEP,kBAAkB,CAAC,SAAS,SAAQ;AAClC,aAAK;;MAEP,iBAAiB,CAAC,QAAQ,SAAQ;AAChC,aAAK;;;AAQT,QAAM,mBAAkC;MACtC,OAAO,CAAC,UAAU,UAAU,SAAQ;AAClC,aAAK,UAAU;;MAEjB,aAAa,CAAC,SAAS,SAAQ;AAC7B,aAAK;;MAEP,WAAW,CAAC,SAAQ;AAClB;;MAEF,QAAQ,CAAC,SAAQ;AACf;;;AAuBJ,iCAA6B;MAe3B,YACU,UACR,WAAqB;;AADb,aAAA,WAAA;AAPF,aAAA,oBAAoB;AAKpB,aAAA,mBAAmB;AAKzB,YAAI,WAAW;AACb,eAAK,YAAY;YACf,OAAK,MAAE,UAAU,WAAK,QAAA,OAAA,SAAA,KAAI,iBAAiB;YAC3C,aAAW,MAAE,UAAU,iBAAW,QAAA,OAAA,SAAA,KAAI,iBAAiB;YACvD,WAAS,MAAE,UAAU,eAAS,QAAA,OAAA,SAAA,KAAI,iBAAiB;YACnD,QAAM,MAAE,UAAU,YAAM,QAAA,OAAA,SAAA,KAAI,iBAAiB;;eAE1C;AACL,eAAK,YAAY;;;MAIrB,iBAAiB,QAAgB,SAAe;AAC9C,aAAK,UAAU,OAAO,MAAK;AACzB,eAAK,SAAS,iBAAiB,QAAQ;;;MAI3C,UAAO;AACL,eAAO,KAAK,SAAS;;MAEvB,MACE,UACA,sBAAoD;;AAEpD,cAAM,2BAAiD;UACrD,mBAAiB,MAAA,MACf,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,uBAAiB,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,2BAAoB,QAAA,OAAA,SAAA,KACjE,CAAC,cAAY;;UAChB,kBAAgB,MAAA,MACd,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,sBAAgB,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,2BAAoB,QAAA,OAAA,SAAA,KAChE,CAAC,YAAW;;UACf,iBAAe,MAAA,MACb,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,qBAAe,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,2BAAoB,QAAA,OAAA,SAAA,KAC/D,CAAC,WAAU;;;AAEhB,aAAK,UAAU,MAAM,UAAU,0BAA0B,CAAC,IAAI,aAAY;;AACxE,cAAI;AACJ,cAAI,cAAA,uBAAuB,WAAW;AACpC,wCAA4B;iBACvB;AACL,kBAAM,eAA6B;cACjC,mBAAiB,OACf,SAAS,uBAAiB,QAAA,QAAA,SAAA,MAAI,gBAAgB;cAChD,kBAAgB,OACd,SAAS,sBAAgB,QAAA,QAAA,SAAA,MAAI,gBAAgB;cAC/C,iBAAe,OACb,SAAS,qBAAe,QAAA,QAAA,SAAA,MAAI,gBAAgB;;AAEhD,wCAA4B,IAAI,cAAA,yBAC9B,cACA;;AAGJ,eAAK,SAAS,MAAM,IAAI;;;MAI5B,uBAAuB,SAAyB,SAAY;AAC1D,aAAK,oBAAoB;AACzB,aAAK,UAAU,YAAY,SAAS,CAAC,iBAAgB;AACnD,eAAK,oBAAoB;AACzB,eAAK,SAAS,uBAAuB,SAAS;AAC9C,cAAI,KAAK,kBAAkB;AACzB,iBAAK,SAAS;;;;MAKpB,YAAY,SAAY;AACtB,aAAK,uBAAuB,IAAI;;MAElC,YAAS;AACP,aAAK,SAAS;;MAEhB,YAAS;AACP,aAAK,UAAU,UAAU,MAAK;AAC5B,cAAI,KAAK,mBAAmB;AAC1B,iBAAK,mBAAmB;iBACnB;AACL,iBAAK,SAAS;;;;MAIpB,eAAe,cAA4B;AACzC,aAAK,SAAS,eAAe;;;AAxGjC,aAAA,mBAAA;AA4GA,qBAAiB,SAAkB,MAAc,SAAoB;;AACnE,YAAM,WAAQ,MAAG,QAAQ,cAAQ,QAAA,OAAA,SAAA,KAAI;AACrC,YAAM,OAAO,QAAQ;AACrB,YAAM,SAAM,MAAG,QAAQ,YAAM,QAAA,OAAA,SAAA,KAAI;AACjC,YAAM,iBAAiB,QAAQ;AAC/B,YAAM,eAAc,QAAQ;AAC5B,YAAM,OAAO,QAAQ,WAAW,MAAM,UAAU,MAAM,QAAQ;AAC9D,UAAI,cAAa;AACf,aAAK,eAAe;;AAEtB,aAAO;;AAOT,qCAA0B;MACxB,YACY,MAEA,kBAAkD;AAFlD,aAAA,OAAA;AAEA,aAAA,mBAAA;;MAEZ,iBAAiB,QAAgB,SAAe;AAC9C,aAAK,KAAK,iBAAiB,QAAQ;;MAErC,UAAO;AACL,eAAO,KAAK,KAAK;;MAEnB,eAAe,cAA4B;AACzC,aAAK,KAAK,eAAe;;MAG3B,uBAAuB,SAAyB,SAAY;AAC1D,YAAI;AACJ,YAAI;AACF,uBAAa,KAAK,iBAAiB,iBAAiB;iBAC7C,GAAP;AACA,eAAK,KAAK,iBACR,YAAA,OAAO,UACP,0CAA0C,EAAE;AAE9C;;AAEF,aAAK,KAAK,uBAAuB,SAAS;;MAG5C,YAAY,SAAY;AACtB,aAAK,uBAAuB,IAAI;;MAElC,MACE,UACA,sBAAoD;AAEpD,YAAI,YAAiC;AACrC,aAAK,KAAK,MAAM,UAAU;UACxB,mBAAmB,CAAC,cAAY;;AAC9B,YAAA,MAAA,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,uBAAiB,QAAA,OAAA,SAAA,SAAA,GAAA,KAAvC,sBAA0C;;UAE5C,kBAAkB,CAAC,YAAW;;AAE5B,gBAAI;AACJ,gBAAI;AACF,6BAAe,KAAK,iBAAiB,oBAAoB;qBAClD,GAAP;AACA,0BAAY;gBACV,MAAM,YAAA,OAAO;gBACb,SAAS,mCAAmC,EAAE;gBAC9C,UAAU,IAAI,WAAA;;AAEhB,mBAAK,KAAK,iBAAiB,UAAU,MAAM,UAAU;AACrD;;AAEF,YAAA,MAAA,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,sBAAgB,QAAA,OAAA,SAAA,SAAA,GAAA,KAAtC,sBAAyC;;UAE3C,iBAAiB,CAAC,WAAU;;AAC1B,gBAAI,WAAW;AACb,cAAA,MAAA,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,qBAAe,QAAA,OAAA,SAAA,SAAA,GAAA,KAArC,sBAAwC;mBACnC;AACL,cAAA,MAAA,yBAAoB,QAApB,yBAAoB,SAAA,SAApB,qBAAsB,qBAAe,QAAA,OAAA,SAAA,SAAA,GAAA,KAArC,sBAAwC;;;;;MAKhD,YAAS;AACP,aAAK,KAAK;;MAEZ,YAAS;AACP,aAAK,KAAK;;;AAQd,kDACU,qBAAoB;MAG5B,YAAY,MAAY,kBAAkD;AACxE,cAAM,MAAM;;MAEd,MAAM,UAAoB,UAAwC;;AAChE,YAAI,kBAAkB;AACtB,cAAM,kBAAwC;UAC5C,mBAAiB,MAAA,MACf,aAAQ,QAAR,aAAQ,SAAA,SAAR,SAAU,uBAAiB,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK,eAAQ,QAAA,OAAA,SAAA,KAAM,CAAC,cAAY;;UAE/D,kBAAkB,CAAC,YAAgB;;AACjC,8BAAkB;AAClB,YAAA,OAAA,aAAQ,QAAR,aAAQ,SAAA,SAAR,SAAU,sBAAgB,QAAA,QAAA,SAAA,SAAA,IAAA,KAA1B,UAA6B;;UAE/B,iBAAiB,CAAC,WAAwB;;AACxC,gBAAI,CAAC,iBAAiB;AACpB,cAAA,OAAA,aAAQ,QAAR,aAAQ,SAAA,SAAR,SAAU,sBAAgB,QAAA,QAAA,SAAA,SAAA,IAAA,KAA1B,UAA6B;;AAE/B,YAAA,OAAA,aAAQ,QAAR,aAAQ,SAAA,SAAR,SAAU,qBAAe,QAAA,QAAA,SAAA,SAAA,IAAA,KAAzB,UAA4B;;;AAGhC,cAAM,MAAM,UAAU;AACtB,aAAK,KAAK;;;AAQd,sDACU,qBAAoB;;AAG9B,uCACE,SACA,SAEA,kBAAkD;AAElD,YAAM,OAAO,QAAQ,SAAS,iBAAiB,MAAM;AACrD,UAAI,iBAAiB,gBAAgB;AACnC,eAAO,IAAI,8BAA8B,MAAM;aAC1C;AACL,eAAO,IAAI,0BAA0B,MAAM;;;AAwB/C,iCACE,iBAEA,kBACA,SACA,SAAgB;AAEhB,UACE,gBAAgB,mBAAmB,SAAS,KAC5C,gBAAgB,2BAA2B,SAAS,GACpD;AACA,cAAM,IAAI,8BACR;;AAIJ,UACE,gBAAgB,iBAAiB,SAAS,KAC1C,gBAAgB,yBAAyB,SAAS,GAClD;AACA,cAAM,IAAI,8BACR;;AAIJ,UAAI,eAA8B;AAElC,UACE,gBAAgB,iBAAiB,SAAS,KAC1C,gBAAgB,yBAAyB,SAAS,GAClD;AACA,uBAAgB,GACb,OACC,gBAAgB,kBAChB,gBAAgB,yBAAyB,IAAI,CAAC,aAC5C,SAAS,oBAGZ,OAAO,CAAC,gBAAgB;aAEtB;AACL,uBAAgB,GACb,OACC,gBAAgB,oBAChB,gBAAgB,2BAA2B,IAAI,CAAC,aAC9C,SAAS,oBAGZ,OAAO,CAAC,gBAAgB;;AAG7B,YAAM,qBAAqB,OAAO,OAAO,IAAI,SAAS;QACpD,mBAAmB;;AASrB,YAAM,WAAoB,aAAa,YACrC,CAAC,UAAoB,oBAAgC;AACnD,eAAO,CAAC,mBAAmB,gBAAgB,gBAAgB;SAE7D,CAAC,iBACC,0BAA0B,SAAS,cAAc;AAErD,aAAO,SAAQ;;AApEjB,aAAA,sBAAA;;;;;;;;;;AC9cA,QAAA,SAAA;AAeA,QAAA,YAAA;AACA,QAAA,uBAAA;AAGA,QAAA,cAAA;AACA,QAAA,aAAA;AAEA,QAAA,wBAAA;AAcA,QAAM,iBAAiB;AACvB,QAAM,qBAAqB;AAC3B,QAAM,8BAA8B;AACpC,QAAM,qCAAqC;AAE3C,wBACE,KAAqE;AAErE,aAAO,OAAO,QAAQ;;AAqDxB,uBAAmB;MAKjB,YACE,SACA,cACA,UAAyB,IAAE;;AAE3B,kBAAU,OAAO,OAAO,IAAI;AAC5B,aAAK,sBAAmB,MAAG,QAAQ,kBAAY,QAAA,OAAA,SAAA,KAAI;AACnD,eAAO,QAAQ;AACf,aAAK,+BAA4B,MAAG,QAAQ,2BAAqB,QAAA,OAAA,SAAA,KAAI;AACrE,eAAO,QAAQ;AACf,YACE,KAAK,oBAAoB,SAAS,KAClC,KAAK,6BAA6B,SAAS,GAC3C;AACA,gBAAM,IAAI,MACR;;AAIJ,aAAK,sCACH,QAAQ;AACV,eAAO,QAAQ;AACf,YAAI,QAAQ,iBAAiB;AAC3B,eAAK,kBAAkB,QAAQ;mBACtB,QAAQ,wBAAwB;AACzC,gBAAM,yBAAyB,QAAQ;AACvC,iBAAO,QAAQ;AACf,eAAK,kBAAkB,uBACrB,SACA,cACA;eAEG;AACL,eAAK,kBAAkB,IAAI,UAAA,sBACzB,SACA,cACA;;;MAKN,QAAK;AACH,aAAK,gBAAgB;;MAGvB,aAAU;AACR,eAAO,KAAK;;MAGd,aAAa,UAAoB,UAAiC;AAChE,cAAM,aAAa,CAAC,QAAe;AACjC,cAAI,KAAK;AACP,qBAAS,IAAI,MAAM;AACnB;;AAEF,cAAI;AACJ,cAAI;AACF,uBAAW,KAAK,gBAAgB,qBAAqB;mBAC9C,GAAP;AACA,qBAAS,IAAI,MAAM;AACnB;;AAEF,cAAI,aAAa,qBAAA,kBAAkB,OAAO;AACxC;iBACK;AACL,gBAAI;AACF,mBAAK,gBAAgB,uBACnB,UACA,UACA;qBAEK,GAAP;AACA,uBAAS,IAAI,MAAM;;;;AAIzB,qBAAa;;MAGP,oCACN,MACA,MACA,MAAkC;AAMlC,YAAI,WAAW,OAAO;AACpB,iBAAO,EAAE,UAAU,IAAI,WAAA,YAAY,SAAS,IAAI,UAAU;mBACjD,WAAW,OAAO;AAC3B,cAAI,gBAAgB,WAAA,UAAU;AAC5B,mBAAO,EAAE,UAAU,MAAM,SAAS,IAAI,UAAU;iBAC3C;AACL,mBAAO,EAAE,UAAU,IAAI,WAAA,YAAY,SAAS,MAAM,UAAU;;eAEzD;AACL,cACE,CACE,iBAAgB,WAAA,YAChB,gBAAgB,UAChB,WAAW,QAEb;AACA,kBAAM,IAAI,MAAM;;AAElB,iBAAO,EAAE,UAAU,MAAM,SAAS,MAAM,UAAU;;;MAoCtD,iBACE,QACA,WACA,aACA,UACA,UACA,SACA,UAAsC;;AAEtC,cAAM,mBAAmB,KAAK,oCAC5B,UACA,SACA;AAEF,cAAM,mBAGF;UACF,MAAM;UACN,eAAe;UACf,gBAAgB;UAChB,kBAAkB;UAClB,qBAAqB;;AAEvB,YAAI,iBAA4D;UAC9D;UACA,UAAU,iBAAiB;UAC3B,MAAM,IAAI,OAAA;UACV,SAAS,KAAK;UACd;UACA,aAAa,iBAAiB;UAC9B,UAAU,iBAAiB;;AAE7B,YAAI,KAAK,qCAAqC;AAC5C,2BAAiB,KAAK,oCACpB;;AAGJ,cAAM,UAA2B,eAAe;AAChD,cAAM,kBAAwC;UAC5C,oBAAoB,KAAK;UACzB,4BAA4B,KAAK;UACjC,kBAAgB,MAAE,eAAe,YAAY,kBAAY,QAAA,OAAA,SAAA,KAAI;UAC7D,0BAAwB,MACtB,eAAe,YAAY,2BAAqB,QAAA,OAAA,SAAA,KAAI;;AAExD,cAAM,OAAkC,sBAAA,oBACtC,iBACA,eAAe,kBACf,eAAe,aACf,eAAe;AAMjB,gBAAQ,OAAO;AACf,YAAI,eAAe,YAAY,aAAa;AAC1C,eAAK,eAAe,eAAe,YAAY;;AAEjD,YAAI,kBAAuC;AAC3C,YAAI,iBAAiB;AACrB,aAAK,MAAM,eAAe,UAAU;UAClC,mBAAmB,CAAC,cAAY;AAC9B,oBAAQ,KAAK,YAAY;;UAG3B,iBAAiB,SAAY;AAC3B,gBAAI,oBAAoB,MAAM;AAC5B,mBAAK,iBAAiB,YAAA,OAAO,UAAU;;AAEzC,8BAAkB;;UAEpB,gBAAgB,QAAoB;AAClC,gBAAI,gBAAgB;AAClB;;AAEF,6BAAiB;AACjB,gBAAI,OAAO,SAAS,YAAA,OAAO,IAAI;AAC7B,6BAAe,SAAU,MAAM;mBAC1B;AACL,6BAAe,SAAU,OAAA,oBAAoB;;AAE/C,oBAAQ,KAAK,UAAU;;;AAG3B,aAAK,YAAY;AACjB,aAAK;AACL,eAAO;;MA+BT,wBACE,QACA,WACA,aACA,UACA,SACA,UAAsC;;AAEtC,cAAM,mBAAmB,KAAK,oCAC5B,UACA,SACA;AAEF,cAAM,mBAGF;UACF,MAAM;UACN,eAAe;UACf,gBAAgB;UAChB,kBAAkB;UAClB,qBAAqB;;AAEvB,YAAI,iBAA4D;UAC9D,UAAU,iBAAiB;UAC3B,MAAM,IAAI,OAAA,yBAAsC;UAChD,SAAS,KAAK;UACd;UACA,aAAa,iBAAiB;UAC9B,UAAU,iBAAiB;;AAE7B,YAAI,KAAK,qCAAqC;AAC5C,2BAAiB,KAAK,oCACpB;;AAGJ,cAAM,UAA6C,eAAe;AAClE,cAAM,kBAAwC;UAC5C,oBAAoB,KAAK;UACzB,4BAA4B,KAAK;UACjC,kBAAgB,MAAE,eAAe,YAAY,kBAAY,QAAA,OAAA,SAAA,KAAI;UAC7D,0BAAwB,MACtB,eAAe,YAAY,2BAAqB,QAAA,OAAA,SAAA,KAAI;;AAExD,cAAM,OAAkC,sBAAA,oBACtC,iBACA,eAAe,kBACf,eAAe,aACf,eAAe;AAMjB,gBAAQ,OAAO;AACf,YAAI,eAAe,YAAY,aAAa;AAC1C,eAAK,eAAe,eAAe,YAAY;;AAEjD,YAAI,kBAAuC;AAC3C,YAAI,iBAAiB;AACrB,aAAK,MAAM,eAAe,UAAU;UAClC,mBAAmB,CAAC,cAAY;AAC9B,oBAAQ,KAAK,YAAY;;UAG3B,iBAAiB,SAAY;AAC3B,gBAAI,oBAAoB,MAAM;AAC5B,mBAAK,iBAAiB,YAAA,OAAO,UAAU;;AAEzC,8BAAkB;;UAEpB,gBAAgB,QAAoB;AAClC,gBAAI,gBAAgB;AAClB;;AAEF,6BAAiB;AACjB,gBAAI,OAAO,SAAS,YAAA,OAAO,IAAI;AAC7B,6BAAe,SAAU,MAAM;mBAC1B;AACL,6BAAe,SAAU,OAAA,oBAAoB;;AAE/C,oBAAQ,KAAK,UAAU;;;AAG3B,eAAO;;MAGD,wBACN,MACA,MAAkB;AAElB,YAAI;AACJ,YAAI;AACJ,YAAI,gBAAgB,WAAA,UAAU;AAC5B,qBAAW;AACX,cAAI,MAAM;AACR,sBAAU;iBACL;AACL,sBAAU;;eAEP;AACL,cAAI,MAAM;AACR,sBAAU;iBACL;AACL,sBAAU;;AAEZ,qBAAW,IAAI,WAAA;;AAEjB,eAAO,EAAE,UAAU;;MAkBrB,wBACE,QACA,WACA,aACA,UACA,UACA,SAAqB;;AAErB,cAAM,mBAAmB,KAAK,wBAAwB,UAAU;AAChE,cAAM,mBAGF;UACF,MAAM;UACN,eAAe;UACf,gBAAgB;UAChB,kBAAkB;UAClB,qBAAqB;;AAEvB,YAAI,iBAA4D;UAC9D;UACA,UAAU,iBAAiB;UAC3B,MAAM,IAAI,OAAA,yBAAuC;UACjD,SAAS,KAAK;UACd;UACA,aAAa,iBAAiB;;AAEhC,YAAI,KAAK,qCAAqC;AAC5C,2BAAiB,KAAK,oCACpB;;AAGJ,cAAM,SAA6C,eAAe;AAClE,cAAM,kBAAwC;UAC5C,oBAAoB,KAAK;UACzB,4BAA4B,KAAK;UACjC,kBAAgB,MAAE,eAAe,YAAY,kBAAY,QAAA,OAAA,SAAA,KAAI;UAC7D,0BAAwB,MACtB,eAAe,YAAY,2BAAqB,QAAA,OAAA,SAAA,KAAI;;AAExD,cAAM,OAAkC,sBAAA,oBACtC,iBACA,eAAe,kBACf,eAAe,aACf,eAAe;AAMjB,eAAO,OAAO;AACd,YAAI,eAAe,YAAY,aAAa;AAC1C,eAAK,eAAe,eAAe,YAAY;;AAEjD,YAAI,iBAAiB;AACrB,aAAK,MAAM,eAAe,UAAU;UAClC,kBAAkB,WAAkB;AAClC,mBAAO,KAAK,YAAY;;UAG1B,iBAAiB,SAAY;AAC3B,mBAAO,KAAK;;UAEd,gBAAgB,QAAoB;AAClC,gBAAI,gBAAgB;AAClB;;AAEF,6BAAiB;AACjB,mBAAO,KAAK;AACZ,gBAAI,OAAO,SAAS,YAAA,OAAO,IAAI;AAC7B,qBAAO,KAAK,SAAS,OAAA,oBAAoB;;AAE3C,mBAAO,KAAK,UAAU;;;AAG1B,aAAK,YAAY;AACjB,aAAK;AACL,eAAO;;MAgBT,sBACE,QACA,WACA,aACA,UACA,SAAqB;;AAErB,cAAM,mBAAmB,KAAK,wBAAwB,UAAU;AAChE,cAAM,mBAGF;UACF,MAAM;UACN,eAAe;UACf,gBAAgB;UAChB,kBAAkB;UAClB,qBAAqB;;AAEvB,YAAI,iBAA4D;UAC9D,UAAU,iBAAiB;UAC3B,MAAM,IAAI,OAAA,uBACR,WACA;UAEF,SAAS,KAAK;UACd;UACA,aAAa,iBAAiB;;AAEhC,YAAI,KAAK,qCAAqC;AAC5C,2BAAiB,KAAK,oCACpB;;AAGJ,cAAM,SAGF,eAAe;AACnB,cAAM,kBAAwC;UAC5C,oBAAoB,KAAK;UACzB,4BAA4B,KAAK;UACjC,kBAAgB,MAAE,eAAe,YAAY,kBAAY,QAAA,OAAA,SAAA,KAAI;UAC7D,0BAAwB,MACtB,eAAe,YAAY,2BAAqB,QAAA,OAAA,SAAA,KAAI;;AAExD,cAAM,OAAkC,sBAAA,oBACtC,iBACA,eAAe,kBACf,eAAe,aACf,eAAe;AAMjB,eAAO,OAAO;AACd,YAAI,eAAe,YAAY,aAAa;AAC1C,eAAK,eAAe,eAAe,YAAY;;AAEjD,YAAI,iBAAiB;AACrB,aAAK,MAAM,eAAe,UAAU;UAClC,kBAAkB,WAAkB;AAClC,mBAAO,KAAK,YAAY;;UAE1B,iBAAiB,SAAe;AAC9B,mBAAO,KAAK;;UAEd,gBAAgB,QAAoB;AAClC,gBAAI,gBAAgB;AAClB;;AAEF,6BAAiB;AACjB,mBAAO,KAAK;AACZ,gBAAI,OAAO,SAAS,YAAA,OAAO,IAAI;AAC7B,qBAAO,KAAK,SAAS,OAAA,oBAAoB;;AAE3C,mBAAO,KAAK,UAAU;;;AAG1B,eAAO;;;AAnjBX,aAAA,SAAA;;;;;;;;;;AC/FA,QAAA,WAAA;AAwDA,QAAM,iBAAiB;MACrB,OAAO,SAAA,OAAO,UAAU;MACxB,eAAe,SAAA,OAAO,UAAU;MAChC,eAAe,SAAA,OAAO,UAAU;MAChC,MAAM,SAAA,OAAO,UAAU;;AAqBzB,iCAA6B,KAAW;AACtC,aAAO,CAAC,aAAa,aAAa,eAAe,SAAS;;AAiB5D,mCACE,SACA,aACA,cAAiB;AAEjB,UAAI,CAAC,cAAc;AACjB,uBAAe;;AAGjB,sCAAgC,SAAA,OAAM;;AAKtC,aAAO,KAAK,SAAS,QAAQ,CAAC,UAAQ;AACpC,YAAI,oBAAoB,QAAO;AAC7B;;AAEF,cAAM,QAAQ,QAAQ;AACtB,YAAI;AAEJ,YAAI,OAAO,UAAS,YAAY,MAAK,OAAO,OAAO,KAAK;AACtD,gBAAM,IAAI,MAAM;;AAElB,YAAI,MAAM,eAAe;AACvB,cAAI,MAAM,gBAAgB;AACxB,yBAAa;iBACR;AACL,yBAAa;;eAEV;AACL,cAAI,MAAM,gBAAgB;AACxB,yBAAa;iBACR;AACL,yBAAa;;;AAGjB,cAAM,YAAY,MAAM;AACxB,cAAM,cAAc,MAAM;AAC1B,cAAM,aAAa,QACjB,eAAe,aACf,MAAM,MACN,WACA;AAEF,0BAAkB,UAAU,SAAQ;AAEpC,eAAO,OAAO,kBAAkB,UAAU,QAAO;AACjD,YAAI,MAAM,gBAAgB,CAAC,oBAAoB,MAAM,eAAe;AAClE,4BAAkB,UAAU,MAAM,gBAChC,kBAAkB,UAAU;;;AAIlC,wBAAkB,UAAU;AAE5B,aAAO;;AAxDT,aAAA,wBAAA;AA2DA,qBACE,IACA,MACA,WACA,aAAqB;AAGrB,aAAO,YAAwB,MAAW;AACxC,eAAO,GAAG,KAAK,MAAM,MAAM,WAAW,aAAa,GAAG;;;AAW1D,sCACE,KAA+C;AAE/C,aAAO,YAAY;;AAQrB,oCACE,YAA6B;AAE7B,YAAM,SAAqB;AAC3B,iBAAW,cAAc,YAAY;AACnC,YAAI,OAAO,UAAU,eAAe,KAAK,YAAY,aAAa;AAChE,gBAAM,UAAU,WAAW;AAC3B,gBAAM,iBAAiB,WAAW,MAAM;AACxC,cAAI,eAAe,KAAK,CAAC,SAAiB,oBAAoB,QAAQ;AACpE;;AAEF,gBAAM,cAAc,eAAe,eAAe,SAAS;AAC3D,cAAI,UAAU;AACd,qBAAW,eAAe,eAAe,MAAM,GAAG,KAAK;AACrD,gBAAI,CAAC,QAAQ,cAAc;AACzB,sBAAQ,eAAe;;AAEzB,sBAAU,QAAQ;;AAEpB,cAAI,yBAAyB,UAAU;AACrC,oBAAQ,eAAe;iBAClB;AACL,oBAAQ,eAAe,sBAAsB,SAAS,aAAa;;;;AAIzE,aAAO;;AA1BT,aAAA,wBAAA;;;;;AC/MA;AAAA;AAUA,QAAI,WAAW,IAAI;AAGnB,QAAI,YAAY;AAGhB,QAAI,cAAc;AAGlB,QAAI,UAAU;AAGd,QAAI,gBAAgB;AAApB,QACI,oBAAoB;AADxB,QAEI,sBAAsB;AAF1B,QAGI,iBAAiB;AAHrB,QAII,eAAe;AAJnB,QAKI,gBAAgB;AALpB,QAMI,iBAAiB;AANrB,QAOI,qBAAqB;AAPzB,QAQI,eAAe;AARnB,QASI,eAAe;AATnB,QAUI,aAAa;AAVjB,QAWI,eAAe,gBAAgB,iBAAiB,qBAAqB;AAGzE,QAAI,SAAS;AAAb,QACI,WAAW,MAAM,gBAAgB;AADrC,QAEI,UAAU,MAAM,eAAe;AAFnC,QAGI,UAAU,MAAM,oBAAoB,sBAAsB;AAH9D,QAII,WAAW;AAJf,QAKI,YAAY,MAAM,iBAAiB;AALvC,QAMI,UAAU,MAAM,eAAe;AANnC,QAOI,SAAS,OAAO,gBAAgB,eAAe,WAAW,iBAAiB,eAAe,eAAe;AAP7G,QAQI,SAAS;AARb,QASI,aAAa,QAAQ,UAAU,MAAM,SAAS;AATlD,QAUI,cAAc,OAAO,gBAAgB;AAVzC,QAWI,aAAa;AAXjB,QAYI,aAAa;AAZjB,QAaI,UAAU,MAAM,eAAe;AAbnC,QAcI,QAAQ;AAGZ,QAAI,cAAc,QAAQ,UAAU,MAAM,SAAS;AAAnD,QACI,cAAc,QAAQ,UAAU,MAAM,SAAS;AADnD,QAEI,kBAAkB,QAAQ,SAAS;AAFvC,QAGI,kBAAkB,QAAQ,SAAS;AAHvC,QAII,WAAW,aAAa;AAJ5B,QAKI,WAAW,MAAM,aAAa;AALlC,QAMI,YAAY,QAAQ,QAAQ,QAAQ,CAAC,aAAa,YAAY,YAAY,KAAK,OAAO,MAAM,WAAW,WAAW;AANtH,QAOI,QAAQ,WAAW,WAAW;AAPlC,QAQI,UAAU,QAAQ,CAAC,WAAW,YAAY,YAAY,KAAK,OAAO,MAAM;AAR5E,QASI,WAAW,QAAQ,CAAC,cAAc,UAAU,KAAK,SAAS,YAAY,YAAY,UAAU,KAAK,OAAO;AAG5G,QAAI,SAAS,OAAO,QAAQ;AAM5B,QAAI,cAAc,OAAO,SAAS;AAGlC,QAAI,YAAY,OAAO,SAAS,QAAQ,SAAS,OAAO,WAAW,OAAO;AAG1E,QAAI,gBAAgB,OAAO;AAAA,MACzB,UAAU,MAAM,UAAU,MAAM,kBAAkB,QAAQ,CAAC,SAAS,SAAS,KAAK,KAAK,OAAO;AAAA,MAC9F,cAAc,MAAM,kBAAkB,QAAQ,CAAC,SAAS,UAAU,aAAa,KAAK,KAAK,OAAO;AAAA,MAChG,UAAU,MAAM,cAAc,MAAM;AAAA,MACpC,UAAU,MAAM;AAAA,MAChB;AAAA,MACA;AAAA,MACA,KAAK,MAAM;AAGb,QAAI,eAAe,OAAO,MAAM,QAAQ,gBAAiB,oBAAoB,sBAAsB,aAAa;AAGhH,QAAI,mBAAmB;AAGvB,QAAI,kBAAkB;AAAA,MAEpB,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAC1E,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAC1E,QAAQ;AAAA,MAAM,QAAQ;AAAA,MACtB,QAAQ;AAAA,MAAM,QAAQ;AAAA,MACtB,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAChD,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAChD,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAChD,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAChD,QAAQ;AAAA,MAAM,QAAQ;AAAA,MACtB,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAC1E,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAC1E,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAChD,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAAK,QAAQ;AAAA,MAChD,QAAQ;AAAA,MAAM,QAAQ;AAAA,MAAK,QAAQ;AAAA,MACnC,QAAQ;AAAA,MAAM,QAAQ;AAAA,MACtB,QAAQ;AAAA,MAAM,QAAQ;AAAA,MACtB,QAAQ;AAAA,MAER,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACvE,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACvE,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACvE,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACvE,UAAU;AAAA,MAAM,UAAU;AAAA,MAC1B,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACvE,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACvE,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACxD,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACtF,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MAAK,UAAU;AAAA,MACtF,UAAU;AAAA,MAAM,UAAU;AAAA,MAC1B,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAAK,UAAU;AAAA,MACzC,UAAU;AAAA,MAAM,UAAU;AAAA,MAC1B,UAAU;AAAA,MAAM,UAAU;AAAA,MAC1B,UAAU;AAAA,MAAM,UAAU;AAAA;AAI5B,QAAI,aAAa,OAAO,UAAU,YAAY,UAAU,OAAO,WAAW,UAAU;AAGpF,QAAI,WAAW,OAAO,QAAQ,YAAY,QAAQ,KAAK,WAAW,UAAU;AAG5E,QAAI,OAAO,cAAc,YAAY,SAAS;AAc9C,yBAAqB,OAAO,UAAU,aAAa,WAAW;AAC5D,UAAI,QAAQ,IACR,SAAS,QAAQ,MAAM,SAAS;AAEpC,UAAI,aAAa,QAAQ;AACvB,sBAAc,MAAM,EAAE;AAAA;AAExB,aAAO,EAAE,QAAQ,QAAQ;AACvB,sBAAc,SAAS,aAAa,MAAM,QAAQ,OAAO;AAAA;AAE3D,aAAO;AAAA;AAUT,0BAAsB,QAAQ;AAC5B,aAAO,OAAO,MAAM;AAAA;AAUtB,wBAAoB,QAAQ;AAC1B,aAAO,OAAO,MAAM,gBAAgB;AAAA;AAUtC,4BAAwB,QAAQ;AAC9B,aAAO,SAAS,KAAK;AACnB,eAAO,UAAU,OAAO,SAAY,OAAO;AAAA;AAAA;AAY/C,QAAI,eAAe,eAAe;AASlC,wBAAoB,QAAQ;AAC1B,aAAO,aAAa,KAAK;AAAA;AAU3B,4BAAwB,QAAQ;AAC9B,aAAO,iBAAiB,KAAK;AAAA;AAU/B,2BAAuB,QAAQ;AAC7B,aAAO,WAAW,UACd,eAAe,UACf,aAAa;AAAA;AAUnB,4BAAwB,QAAQ;AAC9B,aAAO,OAAO,MAAM,cAAc;AAAA;AAUpC,0BAAsB,QAAQ;AAC5B,aAAO,OAAO,MAAM,kBAAkB;AAAA;AAIxC,QAAI,cAAc,OAAO;AAOzB,QAAI,iBAAiB,YAAY;AAGjC,QAAI,UAAS,KAAK;AAGlB,QAAI,cAAc,UAAS,QAAO,YAAY;AAA9C,QACI,iBAAiB,cAAc,YAAY,WAAW;AAW1D,uBAAmB,OAAO,OAAO,KAAK;AACpC,UAAI,QAAQ,IACR,SAAS,MAAM;AAEnB,UAAI,QAAQ,GAAG;AACb,gBAAQ,CAAC,QAAQ,SAAS,IAAK,SAAS;AAAA;AAE1C,YAAM,MAAM,SAAS,SAAS;AAC9B,UAAI,MAAM,GAAG;AACX,eAAO;AAAA;AAET,eAAS,QAAQ,MAAM,IAAM,MAAM,UAAW;AAC9C,iBAAW;AAEX,UAAI,SAAS,MAAM;AACnB,aAAO,EAAE,QAAQ,QAAQ;AACvB,eAAO,SAAS,MAAM,QAAQ;AAAA;AAEhC,aAAO;AAAA;AAWT,0BAAsB,OAAO;AAE3B,UAAI,OAAO,SAAS,UAAU;AAC5B,eAAO;AAAA;AAET,UAAI,SAAS,QAAQ;AACnB,eAAO,iBAAiB,eAAe,KAAK,SAAS;AAAA;AAEvD,UAAI,SAAU,QAAQ;AACtB,aAAQ,UAAU,OAAQ,IAAI,SAAU,CAAC,WAAY,OAAO;AAAA;AAY9D,uBAAmB,OAAO,OAAO,KAAK;AACpC,UAAI,SAAS,MAAM;AACnB,YAAM,QAAQ,SAAY,SAAS;AACnC,aAAQ,CAAC,SAAS,OAAO,SAAU,QAAQ,UAAU,OAAO,OAAO;AAAA;AAUrE,6BAAyB,YAAY;AACnC,aAAO,SAAS,QAAQ;AACtB,iBAAS,SAAS;AAElB,YAAI,aAAa,WAAW,UACxB,cAAc,UACd;AAEJ,YAAI,MAAM,aACN,WAAW,KACX,OAAO,OAAO;AAElB,YAAI,WAAW,aACX,UAAU,YAAY,GAAG,KAAK,MAC9B,OAAO,MAAM;AAEjB,eAAO,IAAI,gBAAgB;AAAA;AAAA;AAW/B,8BAA0B,UAAU;AAClC,aAAO,SAAS,QAAQ;AACtB,eAAO,YAAY,MAAM,OAAO,QAAQ,QAAQ,QAAQ,MAAM,UAAU;AAAA;AAAA;AA4B5E,0BAAsB,OAAO;AAC3B,aAAO,CAAC,CAAC,SAAS,OAAO,SAAS;AAAA;AAoBpC,sBAAkB,OAAO;AACvB,aAAO,OAAO,SAAS,YACpB,aAAa,UAAU,eAAe,KAAK,UAAU;AAAA;AAwB1D,sBAAkB,OAAO;AACvB,aAAO,SAAS,OAAO,KAAK,aAAa;AAAA;AAuB3C,QAAI,YAAY,iBAAiB,SAAS,QAAQ,MAAM,OAAO;AAC7D,aAAO,KAAK;AACZ,aAAO,SAAU,SAAQ,WAAW,QAAQ;AAAA;AAkB9C,wBAAoB,QAAQ;AAC1B,aAAO,WAAW,SAAS,QAAQ;AAAA;AAqBrC,oBAAgB,QAAQ;AACtB,eAAS,SAAS;AAClB,aAAO,UAAU,OAAO,QAAQ,SAAS,cAAc,QAAQ,aAAa;AAAA;AAoB9E,QAAI,aAAa,gBAAgB;AAqBjC,mBAAe,QAAQ,SAAS,OAAO;AACrC,eAAS,SAAS;AAClB,gBAAU,QAAQ,SAAY;AAE9B,UAAI,YAAY,QAAW;AACzB,eAAO,eAAe,UAAU,aAAa,UAAU,WAAW;AAAA;AAEpE,aAAO,OAAO,MAAM,YAAY;AAAA;AAGlC,YAAO,UAAU;AAAA;AAAA;;;ACtlBjB;AAAA;AAAA;AACA,YAAO,UAAU;AAmBjB,uBAAmB,IAAI,KAAmB;AACtC,UAAI,SAAU,IAAI,MAAM,UAAU,SAAS,IACvC,SAAU,GACV,QAAU,GACV,UAAU;AACd,aAAO,QAAQ,UAAU;AACrB,eAAO,YAAY,UAAU;AACjC,aAAO,IAAI,QAAQ,kBAAkB,UAAS,QAAQ;AAClD,eAAO,UAAU,kBAAkB,KAAmB;AAClD,cAAI,SAAS;AACT,sBAAU;AACV,gBAAI;AACA,qBAAO;AAAA,iBACN;AACD,kBAAI,UAAS,IAAI,MAAM,UAAU,SAAS,IACtC,UAAS;AACb,qBAAO,UAAS,QAAO;AACnB,wBAAO,aAAY,UAAU;AACjC,uBAAQ,MAAM,MAAM;AAAA;AAAA;AAAA;AAIhC,YAAI;AACA,aAAG,MAAM,OAAO,MAAM;AAAA,iBACjB,KAAP;AACE,cAAI,SAAS;AACT,sBAAU;AACV,mBAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AC/CvB;AAAA;AAAA;AAOA,QAAI,SAAS;AAOb,WAAO,SAAS,gBAAgB,QAAQ;AACpC,UAAI,IAAI,OAAO;AACf,UAAI,CAAC;AACD,eAAO;AACX,UAAI,IAAI;AACR,aAAO,EAAE,IAAI,IAAI,KAAK,OAAO,OAAO,OAAO;AACvC,UAAE;AACN,aAAO,KAAK,KAAK,OAAO,SAAS,KAAK,IAAI;AAAA;AAI9C,QAAI,MAAM,IAAI,MAAM;AAGpB,QAAI,MAAM,IAAI,MAAM;AAGpB,aAAS,IAAI,GAAG,IAAI;AAChB,UAAI,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,IAAI,IAAI,KAAK,MAAM;AASrF,WAAO,SAAS,gBAAgB,QAAQ,OAAO,KAAK;AAChD,UAAI,QAAQ,MACR,QAAQ;AACZ,UAAI,KAAI,GACJ,IAAI,GACJ;AACJ,aAAO,QAAQ,KAAK;AAChB,YAAI,IAAI,OAAO;AACf,gBAAQ;AAAA,eACC;AACD,kBAAM,QAAO,IAAI,KAAK;AACtB,gBAAK,KAAI,MAAM;AACf,gBAAI;AACJ;AAAA,eACC;AACD,kBAAM,QAAO,IAAI,IAAI,KAAK;AAC1B,gBAAK,KAAI,OAAO;AAChB,gBAAI;AACJ;AAAA,eACC;AACD,kBAAM,QAAO,IAAI,IAAI,KAAK;AAC1B,kBAAM,QAAO,IAAI,IAAI;AACrB,gBAAI;AACJ;AAAA;AAER,YAAI,KAAI,MAAM;AACV,UAAC,UAAU,SAAQ,KAAK,KAAK,OAAO,aAAa,MAAM,QAAQ;AAC/D,eAAI;AAAA;AAAA;AAGZ,UAAI,GAAG;AACH,cAAM,QAAO,IAAI;AACjB,cAAM,QAAO;AACb,YAAI,MAAM;AACN,gBAAM,QAAO;AAAA;AAErB,UAAI,OAAO;AACP,YAAI;AACA,gBAAM,KAAK,OAAO,aAAa,MAAM,QAAQ,MAAM,MAAM,GAAG;AAChE,eAAO,MAAM,KAAK;AAAA;AAEtB,aAAO,OAAO,aAAa,MAAM,QAAQ,MAAM,MAAM,GAAG;AAAA;AAG5D,QAAI,kBAAkB;AAUtB,WAAO,SAAS,gBAAgB,QAAQ,QAAQ,QAAQ;AACpD,UAAI,QAAQ;AACZ,UAAI,IAAI,GACJ;AACJ,eAAS,KAAI,GAAG,KAAI,OAAO,UAAS;AAChC,YAAI,IAAI,OAAO,WAAW;AAC1B,YAAI,MAAM,MAAM,IAAI;AAChB;AACJ,YAAK,KAAI,IAAI,QAAQ;AACjB,gBAAM,MAAM;AAChB,gBAAQ;AAAA,eACC;AACD,gBAAI;AACJ,gBAAI;AACJ;AAAA,eACC;AACD,mBAAO,YAAY,KAAK,IAAK,KAAI,OAAO;AACxC,gBAAI;AACJ,gBAAI;AACJ;AAAA,eACC;AACD,mBAAO,YAAa,KAAI,OAAO,IAAK,KAAI,OAAO;AAC/C,gBAAI;AACJ,gBAAI;AACJ;AAAA,eACC;AACD,mBAAO,YAAa,KAAI,MAAM,IAAI;AAClC,gBAAI;AACJ;AAAA;AAAA;AAGZ,UAAI,MAAM;AACN,cAAM,MAAM;AAChB,aAAO,SAAS;AAAA;AAQpB,WAAO,OAAO,cAAc,QAAQ;AAChC,aAAO,mEAAmE,KAAK;AAAA;AAAA;AAAA;;;ACzInF;AAAA;AAAA;AACA,YAAO,UAAU;AAQjB,4BAAwB;AAOpB,WAAK,aAAa;AAAA;AAUtB,iBAAa,UAAU,KAAK,YAAY,KAAK,IAAI,KAAK;AAClD,MAAC,MAAK,WAAW,QAAS,MAAK,WAAW,OAAO,KAAK,KAAK;AAAA,QACvD;AAAA,QACA,KAAM,OAAO;AAAA;AAEjB,aAAO;AAAA;AASX,iBAAa,UAAU,MAAM,aAAa,KAAK,IAAI;AAC/C,UAAI,QAAQ;AACR,aAAK,aAAa;AAAA,WACjB;AACD,YAAI,OAAO;AACP,eAAK,WAAW,OAAO;AAAA,aACtB;AACD,cAAI,YAAY,KAAK,WAAW;AAChC,mBAAS,IAAI,GAAG,IAAI,UAAU;AAC1B,gBAAI,UAAU,GAAG,OAAO;AACpB,wBAAU,OAAO,GAAG;AAAA;AAEpB,gBAAE;AAAA;AAAA;AAGlB,aAAO;AAAA;AASX,iBAAa,UAAU,OAAO,cAAc,KAAK;AAC7C,UAAI,YAAY,KAAK,WAAW;AAChC,UAAI,WAAW;AACX,YAAI,OAAO,IACP,IAAI;AACR,eAAO,IAAI,UAAU;AACjB,eAAK,KAAK,UAAU;AACxB,aAAK,IAAI,GAAG,IAAI,UAAU;AACtB,oBAAU,GAAG,GAAG,MAAM,UAAU,KAAK,KAAK;AAAA;AAElD,aAAO;AAAA;AAAA;AAAA;;;AC1EX;AAAA;AAAA;AAEA,YAAO,UAAU,QAAQ;AAqFzB,qBAAiB,UAAS;AAGtB,UAAI,OAAO,iBAAiB;AAAa,QAAC,YAAW;AAEjD,cAAI,MAAM,IAAI,aAAa,CAAE,MACzB,MAAM,IAAI,WAAW,IAAI,SACzB,KAAM,IAAI,OAAO;AAErB,sCAA4B,KAAK,KAAK,KAAK;AACvC,gBAAI,KAAK;AACT,gBAAI,OAAW,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AAAA;AAGvB,sCAA4B,KAAK,KAAK,KAAK;AACvC,gBAAI,KAAK;AACT,gBAAI,OAAW,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AAAA;AAIvB,mBAAQ,eAAe,KAAK,qBAAqB;AAEjD,mBAAQ,eAAe,KAAK,qBAAqB;AAEjD,qCAA2B,KAAK,KAAK;AACjC,gBAAI,KAAK,IAAI;AACb,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,mBAAO,IAAI;AAAA;AAGf,qCAA2B,KAAK,KAAK;AACjC,gBAAI,KAAK,IAAI;AACb,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,mBAAO,IAAI;AAAA;AAIf,mBAAQ,cAAc,KAAK,oBAAoB;AAE/C,mBAAQ,cAAc,KAAK,oBAAoB;AAAA;AAAA;AAGxC,QAAC,YAAW;AAEnB,sCAA4B,WAAW,KAAK,KAAK,KAAK;AAClD,gBAAI,OAAO,MAAM,IAAI,IAAI;AACzB,gBAAI;AACA,oBAAM,CAAC;AACX,gBAAI,QAAQ;AACR,wBAAU,IAAI,MAAM,IAAmB,IAAqB,YAAY,KAAK;AAAA,qBACxE,MAAM;AACX,wBAAU,YAAY,KAAK;AAAA,qBACtB,MAAM;AACX,wBAAW,SAAQ,KAAK,gBAAgB,GAAG,KAAK;AAAA,qBAC3C,MAAM;AACX,wBAAW,SAAQ,KAAK,KAAK,MAAM,MAAM,2BAA4B,GAAG,KAAK;AAAA,iBAC5E;AACD,kBAAI,WAAW,KAAK,MAAM,KAAK,IAAI,OAAO,KAAK,MAC3C,WAAW,KAAK,MAAM,MAAM,KAAK,IAAI,GAAG,CAAC,YAAY,WAAW;AACpE,wBAAW,SAAQ,KAAK,WAAW,OAAO,KAAK,cAAc,GAAG,KAAK;AAAA;AAAA;AAI7E,mBAAQ,eAAe,mBAAmB,KAAK,MAAM;AACrD,mBAAQ,eAAe,mBAAmB,KAAK,MAAM;AAErD,qCAA2B,UAAU,KAAK,KAAK;AAC3C,gBAAI,OAAO,SAAS,KAAK,MACrB,OAAQ,SAAQ,MAAM,IAAI,GAC1B,WAAW,SAAS,KAAK,KACzB,WAAW,OAAO;AACtB,mBAAO,aAAa,MACd,WACA,MACA,OAAO,WACP,aAAa,IACb,OAAO,uBAAwB,WAC/B,OAAO,KAAK,IAAI,GAAG,WAAW,OAAQ,YAAW;AAAA;AAG3D,mBAAQ,cAAc,kBAAkB,KAAK,MAAM;AACnD,mBAAQ,cAAc,kBAAkB,KAAK,MAAM;AAAA;AAKvD,UAAI,OAAO,iBAAiB;AAAa,QAAC,YAAW;AAEjD,cAAI,MAAM,IAAI,aAAa,CAAC,MACxB,MAAM,IAAI,WAAW,IAAI,SACzB,KAAM,IAAI,OAAO;AAErB,uCAA6B,KAAK,KAAK,KAAK;AACxC,gBAAI,KAAK;AACT,gBAAI,OAAW,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AAAA;AAGvB,uCAA6B,KAAK,KAAK,KAAK;AACxC,gBAAI,KAAK;AACT,gBAAI,OAAW,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AACnB,gBAAI,MAAM,KAAK,IAAI;AAAA;AAIvB,mBAAQ,gBAAgB,KAAK,sBAAsB;AAEnD,mBAAQ,gBAAgB,KAAK,sBAAsB;AAEnD,sCAA4B,KAAK,KAAK;AAClC,gBAAI,KAAK,IAAI;AACb,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,mBAAO,IAAI;AAAA;AAGf,sCAA4B,KAAK,KAAK;AAClC,gBAAI,KAAK,IAAI;AACb,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,gBAAI,KAAK,IAAI,MAAM;AACnB,mBAAO,IAAI;AAAA;AAIf,mBAAQ,eAAe,KAAK,qBAAqB;AAEjD,mBAAQ,eAAe,KAAK,qBAAqB;AAAA;AAAA;AAG1C,QAAC,YAAW;AAEnB,uCAA6B,WAAW,MAAM,MAAM,KAAK,KAAK,KAAK;AAC/D,gBAAI,OAAO,MAAM,IAAI,IAAI;AACzB,gBAAI;AACA,oBAAM,CAAC;AACX,gBAAI,QAAQ,GAAG;AACX,wBAAU,GAAG,KAAK,MAAM;AACxB,wBAAU,IAAI,MAAM,IAAmB,IAAqB,YAAY,KAAK,MAAM;AAAA,uBAC5E,MAAM,MAAM;AACnB,wBAAU,GAAG,KAAK,MAAM;AACxB,wBAAU,YAAY,KAAK,MAAM;AAAA,uBAC1B,MAAM,uBAAyB;AACtC,wBAAU,GAAG,KAAK,MAAM;AACxB,wBAAW,SAAQ,KAAK,gBAAgB,GAAG,KAAK,MAAM;AAAA,mBACnD;AACH,kBAAI;AACJ,kBAAI,MAAM,wBAAyB;AAC/B,2BAAW,MAAM;AACjB,0BAAU,aAAa,GAAG,KAAK,MAAM;AACrC,0BAAW,SAAQ,KAAK,WAAW,gBAAgB,GAAG,KAAK,MAAM;AAAA,qBAC9D;AACH,oBAAI,WAAW,KAAK,MAAM,KAAK,IAAI,OAAO,KAAK;AAC/C,oBAAI,aAAa;AACb,6BAAW;AACf,2BAAW,MAAM,KAAK,IAAI,GAAG,CAAC;AAC9B,0BAAU,WAAW,qBAAqB,GAAG,KAAK,MAAM;AACxD,0BAAW,SAAQ,KAAK,WAAW,QAAQ,KAAK,WAAW,UAAU,aAAa,GAAG,KAAK,MAAM;AAAA;AAAA;AAAA;AAK5G,mBAAQ,gBAAgB,oBAAoB,KAAK,MAAM,aAAa,GAAG;AACvE,mBAAQ,gBAAgB,oBAAoB,KAAK,MAAM,aAAa,GAAG;AAEvE,sCAA4B,UAAU,MAAM,MAAM,KAAK,KAAK;AACxD,gBAAI,KAAK,SAAS,KAAK,MAAM,OACzB,KAAK,SAAS,KAAK,MAAM;AAC7B,gBAAI,OAAQ,OAAM,MAAM,IAAI,GACxB,WAAW,OAAO,KAAK,MACvB,WAAW,aAAc,MAAK,WAAW;AAC7C,mBAAO,aAAa,OACd,WACA,MACA,OAAO,WACP,aAAa,IACb,OAAO,SAAS,WAChB,OAAO,KAAK,IAAI,GAAG,WAAW,QAAS,YAAW;AAAA;AAG5D,mBAAQ,eAAe,mBAAmB,KAAK,MAAM,YAAY,GAAG;AACpE,mBAAQ,eAAe,mBAAmB,KAAK,MAAM,YAAY,GAAG;AAAA;AAIxE,aAAO;AAAA;AAKX,yBAAqB,KAAK,KAAK,KAAK;AAChC,UAAI,OAAY,MAAa;AAC7B,UAAI,MAAM,KAAM,QAAQ,IAAK;AAC7B,UAAI,MAAM,KAAM,QAAQ,KAAK;AAC7B,UAAI,MAAM,KAAM,QAAQ;AAAA;AAG5B,yBAAqB,KAAK,KAAK,KAAK;AAChC,UAAI,OAAY,QAAQ;AACxB,UAAI,MAAM,KAAM,QAAQ,KAAK;AAC7B,UAAI,MAAM,KAAM,QAAQ,IAAK;AAC7B,UAAI,MAAM,KAAM,MAAa;AAAA;AAGjC,wBAAoB,KAAK,KAAK;AAC1B,aAAQ,KAAI,OACJ,IAAI,MAAM,MAAM,IAChB,IAAI,MAAM,MAAM,KAChB,IAAI,MAAM,MAAM,QAAQ;AAAA;AAGpC,wBAAoB,KAAK,KAAK;AAC1B,aAAQ,KAAI,QAAY,KAChB,IAAI,MAAM,MAAM,KAChB,IAAI,MAAM,MAAM,IAChB,IAAI,MAAM,QAAQ;AAAA;AAAA;AAAA;;;AC7U9B;AAAA;AAAA;AACA,WAAO,UAAU;AAQjB,qBAAiB,YAAY;AACzB,UAAI;AACA,YAAI,MAAM,KAAK,QAAQ,QAAQ,KAAI,OAAO;AAC1C,YAAI,OAAQ,KAAI,UAAU,OAAO,KAAK,KAAK;AACvC,iBAAO;AAAA,eACN,GAAP;AAAA;AACF,aAAO;AAAA;AAAA;AAAA;;;ACfX;AAAA;AAAA;AAOA,QAAI,OAAO;AAOX,SAAK,SAAS,qBAAqB,QAAQ;AACvC,UAAI,MAAM,GACN,IAAI;AACR,eAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AACpC,YAAI,OAAO,WAAW;AACtB,YAAI,IAAI;AACJ,iBAAO;AAAA,iBACF,IAAI;AACT,iBAAO;AAAA,iBACD,KAAI,WAAY,SAAW,QAAO,WAAW,IAAI,KAAK,WAAY,OAAQ;AAChF,YAAE;AACF,iBAAO;AAAA;AAEP,iBAAO;AAAA;AAEf,aAAO;AAAA;AAUX,SAAK,OAAO,mBAAmB,QAAQ,OAAO,KAAK;AAC/C,UAAI,MAAM,MAAM;AAChB,UAAI,MAAM;AACN,eAAO;AACX,UAAI,QAAQ,MACR,QAAQ,IACR,IAAI,GACJ;AACJ,aAAO,QAAQ,KAAK;AAChB,YAAI,OAAO;AACX,YAAI,IAAI;AACJ,gBAAM,OAAO;AAAA,iBACR,IAAI,OAAO,IAAI;AACpB,gBAAM,OAAQ,KAAI,OAAO,IAAI,OAAO,WAAW;AAAA,iBAC1C,IAAI,OAAO,IAAI,KAAK;AACzB,cAAM,MAAI,MAAM,KAAM,QAAO,WAAW,OAAO,KAAM,QAAO,WAAW,OAAO,IAAI,OAAO,WAAW,MAAM;AAC1G,gBAAM,OAAO,QAAU,MAAK;AAC5B,gBAAM,OAAO,QAAU,KAAI;AAAA;AAE3B,gBAAM,OAAQ,KAAI,OAAO,KAAM,QAAO,WAAW,OAAO,IAAI,OAAO,WAAW;AAClF,YAAI,IAAI,MAAM;AACV,UAAC,UAAU,SAAQ,KAAK,KAAK,OAAO,aAAa,MAAM,QAAQ;AAC/D,cAAI;AAAA;AAAA;AAGZ,UAAI,OAAO;AACP,YAAI;AACA,gBAAM,KAAK,OAAO,aAAa,MAAM,QAAQ,MAAM,MAAM,GAAG;AAChE,eAAO,MAAM,KAAK;AAAA;AAEtB,aAAO,OAAO,aAAa,MAAM,QAAQ,MAAM,MAAM,GAAG;AAAA;AAU5D,SAAK,QAAQ,oBAAoB,QAAQ,QAAQ,QAAQ;AACrD,UAAI,QAAQ,QACR,IACA;AACJ,eAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AACpC,aAAK,OAAO,WAAW;AACvB,YAAI,KAAK,KAAK;AACV,iBAAO,YAAY;AAAA,mBACZ,KAAK,MAAM;AAClB,iBAAO,YAAY,MAAM,IAAU;AACnC,iBAAO,YAAY,KAAW,KAAK;AAAA,mBAC3B,MAAK,WAAY,SAAY,OAAK,OAAO,WAAW,IAAI,MAAM,WAAY,OAAQ;AAC1F,eAAK,QAAY,OAAK,SAAW,MAAO,MAAK;AAC7C,YAAE;AACF,iBAAO,YAAY,MAAM,KAAU;AACnC,iBAAO,YAAY,MAAM,KAAK,KAAK;AACnC,iBAAO,YAAY,MAAM,IAAK,KAAK;AACnC,iBAAO,YAAY,KAAW,KAAK;AAAA,eAChC;AACH,iBAAO,YAAY,MAAM,KAAU;AACnC,iBAAO,YAAY,MAAM,IAAK,KAAK;AACnC,iBAAO,YAAY,KAAW,KAAK;AAAA;AAAA;AAG3C,aAAO,SAAS;AAAA;AAAA;AAAA;;;ACvGpB;AAAA;AAAA;AACA,YAAO,UAAU;AA6BjB,kBAAc,OAAO,OAAO,MAAM;AAC9B,UAAI,OAAS,QAAQ;AACrB,UAAI,MAAS,SAAS;AACtB,UAAI,OAAS;AACb,UAAI,SAAS;AACb,aAAO,oBAAoB,OAAM;AAC7B,YAAI,QAAO,KAAK,QAAO;AACnB,iBAAO,MAAM;AACjB,YAAI,SAAS,QAAO,MAAM;AACtB,iBAAO,MAAM;AACb,mBAAS;AAAA;AAEb,YAAI,MAAM,MAAM,KAAK,MAAM,QAAQ,UAAU;AAC7C,YAAI,SAAS;AACT,mBAAU,UAAS,KAAK;AAC5B,eAAO;AAAA;AAAA;AAAA;AAAA;;;AC7Cf;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAO;AAUX,sBAAkB,IAAI,IAAI;AAStB,WAAK,KAAK,OAAO;AAMjB,WAAK,KAAK,OAAO;AAAA;AAQrB,QAAI,OAAO,SAAS,OAAO,IAAI,SAAS,GAAG;AAE3C,SAAK,WAAW,WAAW;AAAE,aAAO;AAAA;AACpC,SAAK,WAAW,KAAK,WAAW,WAAW;AAAE,aAAO;AAAA;AACpD,SAAK,SAAS,WAAW;AAAE,aAAO;AAAA;AAOlC,QAAI,WAAW,SAAS,WAAW;AAOnC,aAAS,aAAa,oBAAoB,OAAO;AAC7C,UAAI,UAAU;AACV,eAAO;AACX,UAAI,OAAO,QAAQ;AACnB,UAAI;AACA,gBAAQ,CAAC;AACb,UAAI,KAAK,UAAU,GACf,KAAM,SAAQ,MAAM,eAAe;AACvC,UAAI,MAAM;AACN,aAAK,CAAC,OAAO;AACb,aAAK,CAAC,OAAO;AACb,YAAI,EAAE,KAAK,YAAY;AACnB,eAAK;AACL,cAAI,EAAE,KAAK;AACP,iBAAK;AAAA;AAAA;AAGjB,aAAO,IAAI,SAAS,IAAI;AAAA;AAQ5B,aAAS,OAAO,cAAc,OAAO;AACjC,UAAI,OAAO,UAAU;AACjB,eAAO,SAAS,WAAW;AAC/B,UAAI,KAAK,SAAS,QAAQ;AAEtB,YAAI,KAAK;AACL,kBAAQ,KAAK,KAAK,WAAW;AAAA;AAE7B,iBAAO,SAAS,WAAW,SAAS,OAAO;AAAA;AAEnD,aAAO,MAAM,OAAO,MAAM,OAAO,IAAI,SAAS,MAAM,QAAQ,GAAG,MAAM,SAAS,KAAK;AAAA;AAQvF,aAAS,UAAU,WAAW,kBAAkB,UAAU;AACtD,UAAI,CAAC,YAAY,KAAK,OAAO,IAAI;AAC7B,YAAI,KAAK,CAAC,KAAK,KAAK,MAAM,GACtB,KAAK,CAAC,KAAK,OAAW;AAC1B,YAAI,CAAC;AACD,eAAK,KAAK,MAAM;AACpB,eAAO,CAAE,MAAK,KAAK;AAAA;AAEvB,aAAO,KAAK,KAAK,KAAK,KAAK;AAAA;AAQ/B,aAAS,UAAU,SAAS,gBAAgB,UAAU;AAClD,aAAO,KAAK,OACN,IAAI,KAAK,KAAK,KAAK,KAAK,GAAG,KAAK,KAAK,GAAG,QAAQ,aAEhD,EAAE,KAAK,KAAK,KAAK,GAAG,MAAM,KAAK,KAAK,GAAG,UAAU,QAAQ;AAAA;AAGnE,QAAI,aAAa,OAAO,UAAU;AAOlC,aAAS,WAAW,kBAAkB,MAAM;AACxC,UAAI,SAAS;AACT,eAAO;AACX,aAAO,IAAI,SACL,YAAW,KAAK,MAAM,KACtB,WAAW,KAAK,MAAM,MAAM,IAC5B,WAAW,KAAK,MAAM,MAAM,KAC5B,WAAW,KAAK,MAAM,MAAM,QAAQ,GAEpC,YAAW,KAAK,MAAM,KACtB,WAAW,KAAK,MAAM,MAAM,IAC5B,WAAW,KAAK,MAAM,MAAM,KAC5B,WAAW,KAAK,MAAM,MAAM,QAAQ;AAAA;AAQ9C,aAAS,UAAU,SAAS,kBAAkB;AAC1C,aAAO,OAAO,aACV,KAAK,KAAY,KACjB,KAAK,OAAO,IAAK,KACjB,KAAK,OAAO,KAAK,KACjB,KAAK,OAAO,IACZ,KAAK,KAAY,KACjB,KAAK,OAAO,IAAK,KACjB,KAAK,OAAO,KAAK,KACjB,KAAK,OAAO;AAAA;AAQpB,aAAS,UAAU,WAAW,oBAAoB;AAC9C,UAAI,OAAS,KAAK,MAAM;AACxB,WAAK,KAAQ,OAAK,MAAM,IAAI,KAAK,OAAO,MAAM,UAAU;AACxD,WAAK,KAAQ,MAAK,MAAM,IAAsB,UAAU;AACxD,aAAO;AAAA;AAOX,aAAS,UAAU,WAAW,oBAAoB;AAC9C,UAAI,OAAO,CAAE,MAAK,KAAK;AACvB,WAAK,KAAQ,OAAK,OAAO,IAAI,KAAK,MAAM,MAAM,UAAU;AACxD,WAAK,KAAQ,MAAK,OAAO,IAAqB,UAAU;AACxD,aAAO;AAAA;AAOX,aAAS,UAAU,SAAS,kBAAkB;AAC1C,UAAI,QAAS,KAAK,IACd,QAAS,MAAK,OAAO,KAAK,KAAK,MAAM,OAAO,GAC5C,QAAS,KAAK,OAAO;AACzB,aAAO,UAAU,IACV,UAAU,IACR,QAAQ,QACN,QAAQ,MAAM,IAAI,IAClB,QAAQ,UAAU,IAAI,IACxB,QAAQ,QACN,QAAQ,MAAM,IAAI,IAClB,QAAQ,UAAU,IAAI,IAC1B,QAAQ,MAAM,IAAI;AAAA;AAAA;AAAA;;;ACtM7B;AAAA;AAAA;AACA,QAAI,OAAO;AAGX,SAAK,YAAY;AAGjB,SAAK,SAAS;AAGd,SAAK,eAAe;AAGpB,SAAK,QAAQ;AAGb,SAAK,UAAU;AAGf,SAAK,OAAO;AAGZ,SAAK,OAAO;AAGZ,SAAK,WAAW;AAOhB,SAAK,SAAS,QAAQ,OAAO,WAAW,eAClB,UACA,OAAO,WACP,OAAO,QAAQ,YACf,OAAO,QAAQ,SAAS;AAO9C,SAAK,SAAS,KAAK,UAAU,UACf,OAAO,WAAW,eAAe,UACjC,OAAO,SAAW,eAAe,QACjC;AAQd,SAAK,aAAa,OAAO,SAAS,OAAO,OAAO,MAAiC;AAOjF,SAAK,cAAc,OAAO,SAAS,OAAO,OAAO,MAAiC;AAQlF,SAAK,YAAY,OAAO,aAAwC,mBAAmB,OAAO;AACtF,aAAO,OAAO,UAAU,YAAY,SAAS,UAAU,KAAK,MAAM,WAAW;AAAA;AAQjF,SAAK,WAAW,kBAAkB,OAAO;AACrC,aAAO,OAAO,UAAU,YAAY,iBAAiB;AAAA;AAQzD,SAAK,WAAW,mBAAkB,OAAO;AACrC,aAAO,SAAS,OAAO,UAAU;AAAA;AAWrC,SAAK,QAQL,KAAK,QAAQ,eAAe,KAAK,MAAM;AACnC,UAAI,QAAQ,IAAI;AAChB,UAAI,SAAS,QAAQ,IAAI,eAAe;AACpC,eAAO,OAAO,UAAU,YAAa,OAAM,QAAQ,SAAS,MAAM,SAAS,OAAO,KAAK,OAAO,UAAU;AAC5G,aAAO;AAAA;AAcX,SAAK,SAAU,WAAW;AACtB,UAAI;AACA,YAAI,UAAS,KAAK,QAAQ,UAAU;AAEpC,eAAO,QAAO,UAAU,YAAY,UAAoC;AAAA,eACnE,GAAP;AAEE,eAAO;AAAA;AAAA;AAKf,SAAK,eAAe;AAGpB,SAAK,sBAAsB;AAO3B,SAAK,YAAY,mBAAmB,aAAa;AAE7C,aAAO,OAAO,gBAAgB,WACxB,KAAK,SACD,KAAK,oBAAoB,eACzB,IAAI,KAAK,MAAM,eACnB,KAAK,SACD,KAAK,aAAa,eAClB,OAAO,eAAe,cAClB,cACA,IAAI,WAAW;AAAA;AAOjC,SAAK,QAAQ,OAAO,eAAe,cAAc,aAAwC;AAezF,SAAK,OAAkC,KAAK,OAAO,WAAsC,KAAK,OAAO,QAAQ,QACtE,KAAK,OAAO,QACvC,KAAK,QAAQ;AAOzB,SAAK,SAAS;AAOd,SAAK,UAAU;AAOf,SAAK,UAAU;AAOf,SAAK,aAAa,oBAAoB,OAAO;AACzC,aAAO,QACD,KAAK,SAAS,KAAK,OAAO,WAC1B,KAAK,SAAS;AAAA;AASxB,SAAK,eAAe,sBAAsB,MAAM,UAAU;AACtD,UAAI,OAAO,KAAK,SAAS,SAAS;AAClC,UAAI,KAAK;AACL,eAAO,KAAK,KAAK,SAAS,KAAK,IAAI,KAAK,IAAI;AAChD,aAAO,KAAK,SAAS,QAAQ;AAAA;AAWjC,mBAAe,KAAK,KAAK,UAAU;AAC/B,eAAS,OAAO,OAAO,KAAK,MAAM,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE;AACxD,YAAI,IAAI,KAAK,QAAQ,UAAa,CAAC;AAC/B,cAAI,KAAK,MAAM,IAAI,KAAK;AAChC,aAAO;AAAA;AAGX,SAAK,QAAQ;AAOb,SAAK,UAAU,iBAAiB,KAAK;AACjC,aAAO,IAAI,OAAO,GAAG,gBAAgB,IAAI,UAAU;AAAA;AASvD,sBAAkB,OAAM;AAEpB,2BAAqB,SAAS,YAAY;AAEtC,YAAI,CAAE,iBAAgB;AAClB,iBAAO,IAAI,YAAY,SAAS;AAKpC,eAAO,eAAe,MAAM,WAAW,EAAE,KAAK,WAAW;AAAE,iBAAO;AAAA;AAGlE,YAAI,MAAM;AACN,gBAAM,kBAAkB,MAAM;AAAA;AAE9B,iBAAO,eAAe,MAAM,SAAS,EAAE,OAAO,IAAI,QAAQ,SAAS;AAEvE,YAAI;AACA,gBAAM,MAAM;AAAA;AAGpB,MAAC,aAAY,YAAY,OAAO,OAAO,MAAM,YAAY,cAAc;AAEvE,aAAO,eAAe,YAAY,WAAW,QAAQ,EAAE,KAAK,WAAW;AAAE,eAAO;AAAA;AAEhF,kBAAY,UAAU,WAAW,oBAAoB;AACjD,eAAO,KAAK,OAAO,OAAO,KAAK;AAAA;AAGnC,aAAO;AAAA;AAGX,SAAK,WAAW;AAmBhB,SAAK,gBAAgB,SAAS;AAoB9B,SAAK,cAAc,kBAAkB,YAAY;AAC7C,UAAI,WAAW;AACf,eAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,EAAE;AACrC,iBAAS,WAAW,MAAM;AAO9B,aAAO,WAAW;AACd,iBAAS,OAAO,OAAO,KAAK,OAAO,KAAI,KAAK,SAAS,GAAG,KAAI,IAAI,EAAE;AAC9D,cAAI,SAAS,KAAK,SAAQ,KAAK,KAAK,KAAK,SAAQ,UAAa,KAAK,KAAK,SAAQ;AAC5E,mBAAO,KAAK;AAAA;AAAA;AAiB5B,SAAK,cAAc,kBAAkB,YAAY;AAQ7C,aAAO,SAAS,OAAM;AAClB,iBAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,EAAE;AACrC,cAAI,WAAW,OAAO;AAClB,mBAAO,KAAK,WAAW;AAAA;AAAA;AAoBvC,SAAK,gBAAgB;AAAA,MACjB,OAAO;AAAA,MACP,OAAO;AAAA,MACP,OAAO;AAAA,MACP,MAAM;AAAA;AAIV,SAAK,aAAa,WAAW;AACzB,UAAI,UAAS,KAAK;AAElB,UAAI,CAAC,SAAQ;AACT,aAAK,eAAe,KAAK,sBAAsB;AAC/C;AAAA;AAIJ,WAAK,eAAe,QAAO,SAAS,WAAW,QAAQ,QAAO,QAE1D,qBAAqB,OAAO,UAAU;AAClC,eAAO,IAAI,QAAO,OAAO;AAAA;AAEjC,WAAK,sBAAsB,QAAO,eAE9B,4BAA4B,MAAM;AAC9B,eAAO,IAAI,QAAO;AAAA;AAAA;AAAA;AAAA;;;ACla9B;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAY;AAEhB,QAAI;AAEJ,QAAI,WAAY,KAAK;AAArB,QACI,SAAY,KAAK;AADrB,QAEI,OAAY,KAAK;AAWrB,gBAAY,IAAI,KAAK,KAAK;AAMtB,WAAK,KAAK;AAMV,WAAK,MAAM;AAMX,WAAK,OAAO;AAMZ,WAAK,MAAM;AAAA;AAIf,oBAAgB;AAAA;AAUhB,mBAAe,QAAQ;AAMnB,WAAK,OAAO,OAAO;AAMnB,WAAK,OAAO,OAAO;AAMnB,WAAK,MAAM,OAAO;AAMlB,WAAK,OAAO,OAAO;AAAA;AAQvB,sBAAkB;AAMd,WAAK,MAAM;AAMX,WAAK,OAAO,IAAI,GAAG,MAAM,GAAG;AAM5B,WAAK,OAAO,KAAK;AAMjB,WAAK,SAAS;AAAA;AASlB,QAAI,SAAS,mBAAkB;AAC3B,aAAO,KAAK,SACN,+BAA+B;AAC7B,eAAQ,QAAO,SAAS,yBAAyB;AAC7C,iBAAO,IAAI;AAAA;AAAA,UAIjB,wBAAwB;AACtB,eAAO,IAAI;AAAA;AAAA;AASvB,WAAO,SAAS;AAOhB,WAAO,QAAQ,eAAe,MAAM;AAChC,aAAO,IAAI,KAAK,MAAM;AAAA;AAK1B,QAAI,KAAK,UAAU;AACf,aAAO,QAAQ,KAAK,KAAK,OAAO,OAAO,KAAK,MAAM,UAAU;AAUhE,WAAO,UAAU,QAAQ,cAAc,IAAI,KAAK,KAAK;AACjD,WAAK,OAAO,KAAK,KAAK,OAAO,IAAI,GAAG,IAAI,KAAK;AAC7C,WAAK,OAAO;AACZ,aAAO;AAAA;AAGX,uBAAmB,KAAK,KAAK,KAAK;AAC9B,UAAI,OAAO,MAAM;AAAA;AAGrB,2BAAuB,KAAK,KAAK,KAAK;AAClC,aAAO,MAAM,KAAK;AACd,YAAI,SAAS,MAAM,MAAM;AACzB,iBAAS;AAAA;AAEb,UAAI,OAAO;AAAA;AAYf,sBAAkB,KAAK,KAAK;AACxB,WAAK,MAAM;AACX,WAAK,OAAO;AACZ,WAAK,MAAM;AAAA;AAGf,aAAS,YAAY,OAAO,OAAO,GAAG;AACtC,aAAS,UAAU,KAAK;AAOxB,WAAO,UAAU,SAAS,sBAAsB,OAAO;AAGnD,WAAK,OAAQ,MAAK,OAAO,KAAK,KAAK,OAAO,IAAI,SACzC,SAAQ,UAAU,KACT,MAAY,IACpB,QAAQ,QAAY,IACpB,QAAQ,UAAY,IACpB,QAAQ,YAAY,IACA,GAC1B,QAAQ;AACR,aAAO;AAAA;AASX,WAAO,UAAU,QAAQ,qBAAqB,OAAO;AACjD,aAAO,QAAQ,IACT,KAAK,MAAM,eAAe,IAAI,SAAS,WAAW,UAClD,KAAK,OAAO;AAAA;AAQtB,WAAO,UAAU,SAAS,sBAAsB,OAAO;AACnD,aAAO,KAAK,OAAQ,UAAS,IAAI,SAAS,QAAQ;AAAA;AAGtD,2BAAuB,KAAK,KAAK,KAAK;AAClC,aAAO,IAAI,IAAI;AACX,YAAI,SAAS,IAAI,KAAK,MAAM;AAC5B,YAAI,KAAM,KAAI,OAAO,IAAI,IAAI,MAAM,QAAQ;AAC3C,YAAI,QAAQ;AAAA;AAEhB,aAAO,IAAI,KAAK,KAAK;AACjB,YAAI,SAAS,IAAI,KAAK,MAAM;AAC5B,YAAI,KAAK,IAAI,OAAO;AAAA;AAExB,UAAI,SAAS,IAAI;AAAA;AASrB,WAAO,UAAU,SAAS,sBAAsB,OAAO;AACnD,UAAI,OAAO,SAAS,KAAK;AACzB,aAAO,KAAK,MAAM,eAAe,KAAK,UAAU;AAAA;AAUpD,WAAO,UAAU,QAAQ,OAAO,UAAU;AAQ1C,WAAO,UAAU,SAAS,sBAAsB,OAAO;AACnD,UAAI,OAAO,SAAS,KAAK,OAAO;AAChC,aAAO,KAAK,MAAM,eAAe,KAAK,UAAU;AAAA;AAQpD,WAAO,UAAU,OAAO,oBAAoB,OAAO;AAC/C,aAAO,KAAK,MAAM,WAAW,GAAG,QAAQ,IAAI;AAAA;AAGhD,0BAAsB,KAAK,KAAK,KAAK;AACjC,UAAI,OAAY,MAAc;AAC9B,UAAI,MAAM,KAAM,QAAQ,IAAM;AAC9B,UAAI,MAAM,KAAM,QAAQ,KAAM;AAC9B,UAAI,MAAM,KAAM,QAAQ;AAAA;AAQ5B,WAAO,UAAU,UAAU,uBAAuB,OAAO;AACrD,aAAO,KAAK,MAAM,cAAc,GAAG,UAAU;AAAA;AASjD,WAAO,UAAU,WAAW,OAAO,UAAU;AAQ7C,WAAO,UAAU,UAAU,uBAAuB,OAAO;AACrD,UAAI,OAAO,SAAS,KAAK;AACzB,aAAO,KAAK,MAAM,cAAc,GAAG,KAAK,IAAI,MAAM,cAAc,GAAG,KAAK;AAAA;AAU5E,WAAO,UAAU,WAAW,OAAO,UAAU;AAQ7C,WAAO,UAAU,QAAQ,qBAAqB,OAAO;AACjD,aAAO,KAAK,MAAM,KAAK,MAAM,cAAc,GAAG;AAAA;AASlD,WAAO,UAAU,SAAS,sBAAsB,OAAO;AACnD,aAAO,KAAK,MAAM,KAAK,MAAM,eAAe,GAAG;AAAA;AAGnD,QAAI,aAAa,KAAK,MAAM,UAAU,MAChC,wBAAwB,KAAK,KAAK,KAAK;AACrC,UAAI,IAAI,KAAK;AAAA,QAGf,wBAAwB,KAAK,KAAK,KAAK;AACrC,eAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,EAAE;AAC9B,YAAI,MAAM,KAAK,IAAI;AAAA;AAQ/B,WAAO,UAAU,QAAQ,qBAAqB,OAAO;AACjD,UAAI,MAAM,MAAM,WAAW;AAC3B,UAAI,CAAC;AACD,eAAO,KAAK,MAAM,WAAW,GAAG;AACpC,UAAI,KAAK,SAAS,QAAQ;AACtB,YAAI,MAAM,OAAO,MAAM,MAAM,OAAO,OAAO;AAC3C,eAAO,OAAO,OAAO,KAAK;AAC1B,gBAAQ;AAAA;AAEZ,aAAO,KAAK,OAAO,KAAK,MAAM,YAAY,KAAK;AAAA;AAQnD,WAAO,UAAU,SAAS,sBAAsB,OAAO;AACnD,UAAI,MAAM,KAAK,OAAO;AACtB,aAAO,MACD,KAAK,OAAO,KAAK,MAAM,KAAK,OAAO,KAAK,SACxC,KAAK,MAAM,WAAW,GAAG;AAAA;AAQnC,WAAO,UAAU,OAAO,gBAAgB;AACpC,WAAK,SAAS,IAAI,MAAM;AACxB,WAAK,OAAO,KAAK,OAAO,IAAI,GAAG,MAAM,GAAG;AACxC,WAAK,MAAM;AACX,aAAO;AAAA;AAOX,WAAO,UAAU,QAAQ,iBAAiB;AACtC,UAAI,KAAK,QAAQ;AACb,aAAK,OAAS,KAAK,OAAO;AAC1B,aAAK,OAAS,KAAK,OAAO;AAC1B,aAAK,MAAS,KAAK,OAAO;AAC1B,aAAK,SAAS,KAAK,OAAO;AAAA,aACvB;AACH,aAAK,OAAO,KAAK,OAAO,IAAI,GAAG,MAAM,GAAG;AACxC,aAAK,MAAO;AAAA;AAEhB,aAAO;AAAA;AAOX,WAAO,UAAU,SAAS,kBAAkB;AACxC,UAAI,OAAO,KAAK,MACZ,OAAO,KAAK,MACZ,MAAO,KAAK;AAChB,WAAK,QAAQ,OAAO;AACpB,UAAI,KAAK;AACL,aAAK,KAAK,OAAO,KAAK;AACtB,aAAK,OAAO;AACZ,aAAK,OAAO;AAAA;AAEhB,aAAO;AAAA;AAOX,WAAO,UAAU,SAAS,kBAAkB;AACxC,UAAI,OAAO,KAAK,KAAK,MACjB,MAAO,KAAK,YAAY,MAAM,KAAK,MACnC,MAAO;AACX,aAAO,MAAM;AACT,aAAK,GAAG,KAAK,KAAK,KAAK;AACvB,eAAO,KAAK;AACZ,eAAO,KAAK;AAAA;AAGhB,aAAO;AAAA;AAGX,WAAO,aAAa,SAAS,eAAe;AACxC,qBAAe;AACf,aAAO,SAAS;AAChB,mBAAa;AAAA;AAAA;AAAA;;;AC/cjB;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,SAAS;AACb,IAAC,cAAa,YAAY,OAAO,OAAO,OAAO,YAAY,cAAc;AAEzE,QAAI,OAAO;AAQX,4BAAwB;AACpB,aAAO,KAAK;AAAA;AAGhB,iBAAa,aAAa,WAAY;AAOlC,mBAAa,QAAQ,KAAK;AAE1B,mBAAa,mBAAmB,KAAK,UAAU,KAAK,OAAO,qBAAqB,cAAc,KAAK,OAAO,UAAU,IAAI,SAAS,QAC3H,8BAA8B,KAAK,KAAK,KAAK;AAC7C,YAAI,IAAI,KAAK;AAAA,UAIb,+BAA+B,KAAK,KAAK,KAAK;AAC9C,YAAI,IAAI;AACN,cAAI,KAAK,KAAK,KAAK,GAAG,IAAI;AAAA;AACvB,mBAAS,IAAI,GAAG,IAAI,IAAI;AAC3B,gBAAI,SAAS,IAAI;AAAA;AAAA;AAQ7B,iBAAa,UAAU,QAAQ,4BAA4B,OAAO;AAC9D,UAAI,KAAK,SAAS;AACd,gBAAQ,KAAK,aAAa,OAAO;AACrC,UAAI,MAAM,MAAM,WAAW;AAC3B,WAAK,OAAO;AACZ,UAAI;AACA,aAAK,MAAM,aAAa,kBAAkB,KAAK;AACnD,aAAO;AAAA;AAGX,+BAA2B,KAAK,KAAK,KAAK;AACtC,UAAI,IAAI,SAAS;AACb,aAAK,KAAK,MAAM,KAAK,KAAK;AAAA,eACrB,IAAI;AACT,YAAI,UAAU,KAAK;AAAA;AAEnB,YAAI,MAAM,KAAK;AAAA;AAMvB,iBAAa,UAAU,SAAS,6BAA6B,OAAO;AAChE,UAAI,MAAM,KAAK,OAAO,WAAW;AACjC,WAAK,OAAO;AACZ,UAAI;AACA,aAAK,MAAM,mBAAmB,KAAK;AACvC,aAAO;AAAA;AAWX,iBAAa;AAAA;AAAA;;;ACpFb;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAY;AAEhB,QAAI;AAEJ,QAAI,WAAY,KAAK;AAArB,QACI,OAAY,KAAK;AAGrB,6BAAyB,QAAQ,aAAa;AAC1C,aAAO,WAAW,yBAAyB,OAAO,MAAM,QAAS,gBAAe,KAAK,QAAQ,OAAO;AAAA;AASxG,oBAAgB,QAAQ;AAMpB,WAAK,MAAM;AAMX,WAAK,MAAM;AAMX,WAAK,MAAM,OAAO;AAAA;AAGtB,QAAI,eAAe,OAAO,eAAe,cACnC,4BAA4B,QAAQ;AAClC,UAAI,kBAAkB,cAAc,MAAM,QAAQ;AAC9C,eAAO,IAAI,OAAO;AACtB,YAAM,MAAM;AAAA,QAGd,uBAAsB,QAAQ;AAC5B,UAAI,MAAM,QAAQ;AACd,eAAO,IAAI,OAAO;AACtB,YAAM,MAAM;AAAA;AAGpB,QAAI,SAAS,mBAAkB;AAC3B,aAAO,KAAK,SACN,6BAA6B,QAAQ;AACnC,eAAQ,QAAO,SAAS,uBAAuB,SAAQ;AACnD,iBAAO,KAAK,OAAO,SAAS,WACtB,IAAI,aAAa,WAEjB,aAAa;AAAA,WACpB;AAAA,UAGL;AAAA;AAUV,WAAO,SAAS;AAEhB,WAAO,UAAU,SAAS,KAAK,MAAM,UAAU,YAAuC,KAAK,MAAM,UAAU;AAO3G,WAAO,UAAU,SAAU,6BAA6B;AACpD,UAAI,QAAQ;AACZ,aAAO,uBAAuB;AAC1B,gBAAkB,MAAK,IAAI,KAAK,OAAO,SAAgB;AAAG,YAAI,KAAK,IAAI,KAAK,SAAS;AAAK,iBAAO;AACjG,gBAAS,SAAS,MAAK,IAAI,KAAK,OAAO,QAAS,OAAO;AAAG,YAAI,KAAK,IAAI,KAAK,SAAS;AAAK,iBAAO;AACjG,gBAAS,SAAS,MAAK,IAAI,KAAK,OAAO,QAAQ,QAAQ;AAAG,YAAI,KAAK,IAAI,KAAK,SAAS;AAAK,iBAAO;AACjG,gBAAS,SAAS,MAAK,IAAI,KAAK,OAAO,QAAQ,QAAQ;AAAG,YAAI,KAAK,IAAI,KAAK,SAAS;AAAK,iBAAO;AACjG,gBAAS,SAAS,MAAK,IAAI,KAAK,OAAQ,OAAO,QAAQ;AAAG,YAAI,KAAK,IAAI,KAAK,SAAS;AAAK,iBAAO;AAGjG,YAAK,MAAK,OAAO,KAAK,KAAK,KAAK;AAC5B,eAAK,MAAM,KAAK;AAChB,gBAAM,gBAAgB,MAAM;AAAA;AAEhC,eAAO;AAAA;AAAA;AAQf,WAAO,UAAU,QAAQ,sBAAsB;AAC3C,aAAO,KAAK,WAAW;AAAA;AAO3B,WAAO,UAAU,SAAS,uBAAuB;AAC7C,UAAI,QAAQ,KAAK;AACjB,aAAO,UAAU,IAAI,CAAE,SAAQ,KAAK;AAAA;AAKxC,8BAA0B;AAEtB,UAAI,OAAO,IAAI,SAAS,GAAG;AAC3B,UAAI,IAAI;AACR,UAAI,KAAK,MAAM,KAAK,MAAM,GAAG;AACzB,eAAO,IAAI,GAAG,EAAE,GAAG;AAEf,eAAK,KAAM,MAAK,KAAM,MAAK,IAAI,KAAK,OAAO,QAAQ,IAAI,OAAO;AAC9D,cAAI,KAAK,IAAI,KAAK,SAAS;AACvB,mBAAO;AAAA;AAGf,aAAK,KAAM,MAAK,KAAM,MAAK,IAAI,KAAK,OAAO,QAAQ,QAAQ;AAC3D,aAAK,KAAM,MAAK,KAAM,MAAK,IAAI,KAAK,OAAO,QAAS,OAAO;AAC3D,YAAI,KAAK,IAAI,KAAK,SAAS;AACvB,iBAAO;AACX,YAAI;AAAA,aACD;AACH,eAAO,IAAI,GAAG,EAAE,GAAG;AAEf,cAAI,KAAK,OAAO,KAAK;AACjB,kBAAM,gBAAgB;AAE1B,eAAK,KAAM,MAAK,KAAM,MAAK,IAAI,KAAK,OAAO,QAAQ,IAAI,OAAO;AAC9D,cAAI,KAAK,IAAI,KAAK,SAAS;AACvB,mBAAO;AAAA;AAGf,aAAK,KAAM,MAAK,KAAM,MAAK,IAAI,KAAK,SAAS,QAAQ,IAAI,OAAO;AAChE,eAAO;AAAA;AAEX,UAAI,KAAK,MAAM,KAAK,MAAM,GAAG;AACzB,eAAO,IAAI,GAAG,EAAE,GAAG;AAEf,eAAK,KAAM,MAAK,KAAM,MAAK,IAAI,KAAK,OAAO,QAAQ,IAAI,IAAI,OAAO;AAClE,cAAI,KAAK,IAAI,KAAK,SAAS;AACvB,mBAAO;AAAA;AAAA,aAEZ;AACH,eAAO,IAAI,GAAG,EAAE,GAAG;AAEf,cAAI,KAAK,OAAO,KAAK;AACjB,kBAAM,gBAAgB;AAE1B,eAAK,KAAM,MAAK,KAAM,MAAK,IAAI,KAAK,OAAO,QAAQ,IAAI,IAAI,OAAO;AAClE,cAAI,KAAK,IAAI,KAAK,SAAS;AACvB,mBAAO;AAAA;AAAA;AAInB,YAAM,MAAM;AAAA;AA8BhB,WAAO,UAAU,OAAO,qBAAqB;AACzC,aAAO,KAAK,aAAa;AAAA;AAG7B,6BAAyB,KAAK,KAAK;AAC/B,aAAQ,KAAI,MAAM,KACV,IAAI,MAAM,MAAM,IAChB,IAAI,MAAM,MAAM,KAChB,IAAI,MAAM,MAAM,QAAQ;AAAA;AAOpC,WAAO,UAAU,UAAU,wBAAwB;AAG/C,UAAI,KAAK,MAAM,IAAI,KAAK;AACpB,cAAM,gBAAgB,MAAM;AAEhC,aAAO,gBAAgB,KAAK,KAAK,KAAK,OAAO;AAAA;AAOjD,WAAO,UAAU,WAAW,yBAAyB;AAGjD,UAAI,KAAK,MAAM,IAAI,KAAK;AACpB,cAAM,gBAAgB,MAAM;AAEhC,aAAO,gBAAgB,KAAK,KAAK,KAAK,OAAO,KAAK;AAAA;AAKtD,2BAAyC;AAGrC,UAAI,KAAK,MAAM,IAAI,KAAK;AACpB,cAAM,gBAAgB,MAAM;AAEhC,aAAO,IAAI,SAAS,gBAAgB,KAAK,KAAK,KAAK,OAAO,IAAI,gBAAgB,KAAK,KAAK,KAAK,OAAO;AAAA;AAwBxG,WAAO,UAAU,QAAQ,sBAAsB;AAG3C,UAAI,KAAK,MAAM,IAAI,KAAK;AACpB,cAAM,gBAAgB,MAAM;AAEhC,UAAI,QAAQ,KAAK,MAAM,YAAY,KAAK,KAAK,KAAK;AAClD,WAAK,OAAO;AACZ,aAAO;AAAA;AAQX,WAAO,UAAU,SAAS,uBAAuB;AAG7C,UAAI,KAAK,MAAM,IAAI,KAAK;AACpB,cAAM,gBAAgB,MAAM;AAEhC,UAAI,QAAQ,KAAK,MAAM,aAAa,KAAK,KAAK,KAAK;AACnD,WAAK,OAAO;AACZ,aAAO;AAAA;AAOX,WAAO,UAAU,QAAQ,sBAAsB;AAC3C,UAAI,SAAS,KAAK,UACd,QAAS,KAAK,KACd,MAAS,KAAK,MAAM;AAGxB,UAAI,MAAM,KAAK;AACX,cAAM,gBAAgB,MAAM;AAEhC,WAAK,OAAO;AACZ,UAAI,MAAM,QAAQ,KAAK;AACnB,eAAO,KAAK,IAAI,MAAM,OAAO;AACjC,aAAO,UAAU,MACX,IAAI,KAAK,IAAI,YAAY,KACzB,KAAK,OAAO,KAAK,KAAK,KAAK,OAAO;AAAA;AAO5C,WAAO,UAAU,SAAS,uBAAuB;AAC7C,UAAI,QAAQ,KAAK;AACjB,aAAO,KAAK,KAAK,OAAO,GAAG,MAAM;AAAA;AAQrC,WAAO,UAAU,OAAO,cAAc,QAAQ;AAC1C,UAAI,OAAO,WAAW,UAAU;AAE5B,YAAI,KAAK,MAAM,SAAS,KAAK;AACzB,gBAAM,gBAAgB,MAAM;AAChC,aAAK,OAAO;AAAA,aACT;AACH,WAAG;AAEC,cAAI,KAAK,OAAO,KAAK;AACjB,kBAAM,gBAAgB;AAAA,iBACrB,KAAK,IAAI,KAAK,SAAS;AAAA;AAEpC,aAAO;AAAA;AAQX,WAAO,UAAU,WAAW,SAAS,UAAU;AAC3C,cAAQ;AAAA,aACC;AACD,eAAK;AACL;AAAA,aACC;AACD,eAAK,KAAK;AACV;AAAA,aACC;AACD,eAAK,KAAK,KAAK;AACf;AAAA,aACC;AACD,iBAAQ,YAAW,KAAK,WAAW,OAAO,GAAG;AACzC,iBAAK,SAAS;AAAA;AAElB;AAAA,aACC;AACD,eAAK,KAAK;AACV;AAAA;AAIA,gBAAM,MAAM,uBAAuB,WAAW,gBAAgB,KAAK;AAAA;AAE3E,aAAO;AAAA;AAGX,WAAO,aAAa,SAAS,eAAe;AACxC,qBAAe;AACf,aAAO,SAAS;AAChB,mBAAa;AAEb,UAAI,KAAK,KAAK,OAAO,WAAsC;AAC3D,WAAK,MAAM,OAAO,WAAW;AAAA,QAEzB,OAAO,sBAAsB;AACzB,iBAAO,eAAe,KAAK,MAAM,IAAI;AAAA;AAAA,QAGzC,QAAQ,uBAAuB;AAC3B,iBAAO,eAAe,KAAK,MAAM,IAAI;AAAA;AAAA,QAGzC,QAAQ,uBAAuB;AAC3B,iBAAO,eAAe,KAAK,MAAM,WAAW,IAAI;AAAA;AAAA,QAGpD,SAAS,wBAAwB;AAC7B,iBAAO,YAAY,KAAK,MAAM,IAAI;AAAA;AAAA,QAGtC,UAAU,yBAAyB;AAC/B,iBAAO,YAAY,KAAK,MAAM,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACtZ9C;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,SAAS;AACb,IAAC,cAAa,YAAY,OAAO,OAAO,OAAO,YAAY,cAAc;AAEzE,QAAI,OAAO;AASX,0BAAsB,QAAQ;AAC1B,aAAO,KAAK,MAAM;AAAA;AAStB,iBAAa,aAAa,WAAY;AAElC,UAAI,KAAK;AACL,qBAAa,UAAU,SAAS,KAAK,OAAO,UAAU;AAAA;AAO9D,iBAAa,UAAU,SAAS,8BAA8B;AAC1D,UAAI,MAAM,KAAK;AACf,aAAO,KAAK,IAAI,YACV,KAAK,IAAI,UAAU,KAAK,KAAK,KAAK,MAAM,KAAK,IAAI,KAAK,MAAM,KAAK,KAAK,QACtE,KAAK,IAAI,SAAS,SAAS,KAAK,KAAK,KAAK,MAAM,KAAK,IAAI,KAAK,MAAM,KAAK,KAAK;AAAA;AAUxF,iBAAa;AAAA;AAAA;;;AClDb;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAO;AAGX,IAAC,SAAQ,YAAY,OAAO,OAAO,KAAK,aAAa,YAAY,cAAc;AAmC/E,qBAAiB,SAAS,kBAAkB,mBAAmB;AAE3D,UAAI,OAAO,YAAY;AACnB,cAAM,UAAU;AAEpB,WAAK,aAAa,KAAK;AAMvB,WAAK,UAAU;AAMf,WAAK,mBAAmB,QAAQ;AAMhC,WAAK,oBAAoB,QAAQ;AAAA;AAcrC,YAAQ,UAAU,UAAU,iBAAiB,QAAQ,aAAa,cAAc,SAAS,UAAU;AAE/F,UAAI,CAAC;AACD,cAAM,UAAU;AAEpB,UAAI,QAAO;AACX,UAAI,CAAC;AACD,eAAO,KAAK,UAAU,SAAS,OAAM,QAAQ,aAAa,cAAc;AAE5E,UAAI,CAAC,MAAK,SAAS;AACf,mBAAW,WAAW;AAAE,mBAAS,MAAM;AAAA,WAAsB;AAC7D,eAAO;AAAA;AAGX,UAAI;AACA,eAAO,MAAK,QACR,QACA,YAAY,MAAK,mBAAmB,oBAAoB,UAAU,SAAS,UAC3E,qBAAqB,KAAK,UAAU;AAEhC,cAAI,KAAK;AACL,kBAAK,KAAK,SAAS,KAAK;AACxB,mBAAO,SAAS;AAAA;AAGpB,cAAI,aAAa,MAAM;AACnB,kBAAK,IAAqB;AAC1B,mBAAO;AAAA;AAGX,cAAI,CAAE,qBAAoB,eAAe;AACrC,gBAAI;AACA,yBAAW,aAAa,MAAK,oBAAoB,oBAAoB,UAAU;AAAA,qBAC1E,MAAP;AACE,oBAAK,KAAK,SAAS,MAAK;AACxB,qBAAO,SAAS;AAAA;AAAA;AAIxB,gBAAK,KAAK,QAAQ,UAAU;AAC5B,iBAAO,SAAS,MAAM;AAAA;AAAA,eAGzB,KAAP;AACE,cAAK,KAAK,SAAS,KAAK;AACxB,mBAAW,WAAW;AAAE,mBAAS;AAAA,WAAS;AAC1C,eAAO;AAAA;AAAA;AASf,YAAQ,UAAU,MAAM,aAAa,YAAY;AAC7C,UAAI,KAAK,SAAS;AACd,YAAI,CAAC;AACD,eAAK,QAAQ,MAAM,MAAM;AAC7B,aAAK,UAAU;AACf,aAAK,KAAK,OAAO;AAAA;AAErB,aAAO;AAAA;AAAA;AAAA;;;AC5IX;AAAA;AAAA;AAMA,QAAI,MAAM;AA6BV,QAAI,UAAU;AAAA;AAAA;;;ACnCd;AAAA;AAAA;AACA,YAAO,UAAU;AAAA;AAAA;;;ACDjB;AAAA;AAAA;AACA,QAAI,WAAW;AAQf,aAAS,QAAQ;AAGjB,aAAS,SAAe;AACxB,aAAS,eAAe;AACxB,aAAS,SAAe;AACxB,aAAS,eAAe;AAGxB,aAAS,OAAe;AACxB,aAAS,MAAe;AACxB,aAAS,QAAe;AACxB,aAAS,YAAe;AAOxB,yBAAqB;AACjB,eAAS,KAAK;AACd,eAAS,OAAO,WAAW,SAAS;AACpC,eAAS,OAAO,WAAW,SAAS;AAAA;AAIxC;AAAA;AAAA;;;ACnCA;AAAA;AAAA;AACA,YAAO,UAAU;AASjB,qBAAiB,gBAAgB,cAAc;AAG3C,UAAI,OAAO,mBAAmB,UAAU;AACpC,uBAAe;AACf,yBAAiB;AAAA;AAGrB,UAAI,OAAO;AAYX,uBAAiB,qBAAqB;AAIlC,YAAI,OAAO,wBAAwB,UAAU;AACzC,cAAI,SAAS;AACb,cAAI,QAAQ;AACR,oBAAQ,IAAI,cAAc;AAC9B,mBAAS,YAAY;AACrB,cAAI,qBAAqB;AACrB,gBAAI,YAAc,OAAO,KAAK,sBAC1B,cAAc,IAAI,MAAM,UAAU,SAAS,IAC3C,cAAc,IAAI,MAAM,UAAU,SAClC,cAAc;AAClB,mBAAO,cAAc,UAAU,QAAQ;AACnC,0BAAY,eAAe,UAAU;AACrC,0BAAY,eAAe,oBAAoB,UAAU;AAAA;AAE7D,wBAAY,eAAe;AAC3B,mBAAO,SAAS,MAAM,MAAM,aAAa,MAAM,MAAM;AAAA;AAEzD,iBAAO,SAAS;AAAA;AAIpB,YAAI,eAAe,IAAI,MAAM,UAAU,SAAS,IAC5C,eAAe;AACnB,eAAO,eAAe,aAAa;AAC/B,uBAAa,gBAAgB,UAAU,EAAE;AAC7C,uBAAe;AACf,8BAAsB,oBAAoB,QAAQ,gBAAgB,iBAAiB,IAAI,IAAI;AACvF,cAAI,QAAQ,aAAa;AACzB,kBAAQ;AAAA,iBACC;AAAA,iBAAU;AAAK,qBAAO,OAAO,OAAO;AAAA,iBACpC;AAAK,qBAAO,OAAO,KAAK,MAAM;AAAA,iBAC9B;AAAK,qBAAO,KAAK,UAAU;AAAA,iBAC3B;AAAK,qBAAO,OAAO;AAAA;AAE5B,iBAAO;AAAA;AAEX,YAAI,iBAAiB,aAAa;AAC9B,gBAAM,MAAM;AAChB,aAAK,KAAK;AACV,eAAO;AAAA;AAGX,wBAAkB,sBAAsB;AACpC,eAAO,cAAe,yBAAwB,gBAAgB,MAAM,MAAO,mBAAkB,eAAe,KAAK,QAAQ,MAAM,WAAW,KAAK,KAAK,UAAU;AAAA;AAGlK,cAAQ,WAAW;AACnB,aAAO;AAAA;AAiBX,YAAQ,UAAU;AAAA;AAAA;;;AClGlB;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,YAAY;AAAhB,QACI,WAAY;AAEhB,QAAI,KAAK,SAAQ;AA2BjB,mBAAe,UAAU,SAAS,UAAU;AACxC,UAAI,OAAO,YAAY,YAAY;AAC/B,mBAAW;AACX,kBAAU;AAAA,iBACH,CAAC;AACR,kBAAU;AAEd,UAAI,CAAC;AACD,eAAO,UAAU,OAAO,MAAM,UAAU;AAG5C,UAAI,CAAC,QAAQ,OAAO,MAAM,GAAG;AACzB,eAAO,GAAG,SAAS,UAAU,+BAA+B,KAAK,UAAU;AACvE,iBAAO,OAAO,OAAO,mBAAmB,cAClC,MAAM,IAAI,UAAU,SAAS,YAC7B,MACA,SAAS,OACT,SAAS,MAAM,QAAQ,SAAS,WAAW,SAAS,SAAS;AAAA;AAI3E,aAAO,MAAM,IAAI,UAAU,SAAS;AAAA;AAwBxC,UAAM,MAAM,mBAAmB,UAAU,SAAS,UAAU;AACxD,UAAI,MAAM,IAAI;AACd,UAAI,qBAA4C,mCAAmC;AAE/E,YAAI,IAAI,eAAe;AACnB,iBAAO;AAKX,YAAI,IAAI,WAAW,KAAK,IAAI,WAAW;AACnC,iBAAO,SAAS,MAAM,YAAY,IAAI;AAI1C,YAAI,QAAQ,QAAQ;AAChB,cAAI,SAAS,IAAI;AACjB,cAAI,CAAC,QAAQ;AACT,qBAAS;AACT,qBAAS,IAAI,GAAG,IAAI,IAAI,aAAa,QAAQ,EAAE;AAC3C,qBAAO,KAAK,IAAI,aAAa,WAAW,KAAK;AAAA;AAErD,iBAAO,SAAS,MAAM,OAAO,eAAe,cAAc,IAAI,WAAW,UAAU;AAAA;AAEvF,eAAO,SAAS,MAAM,IAAI;AAAA;AAG9B,UAAI,QAAQ,QAAQ;AAEhB,YAAI,sBAAsB;AACtB,cAAI,iBAAiB;AACzB,YAAI,eAAe;AAAA;AAGvB,UAAI,KAAK,OAAO;AAChB,UAAI;AAAA;AAAA;AAAA;;;ACjHR;AAAA;AAAA;AAOA,QAAI,OAAO;AAEX,QAAI,aAMJ,KAAK,aAAa,qBAAoB,OAAM;AACxC,aAAO,eAAe,KAAK;AAAA;AAG/B,QAAI,YAMJ,KAAK,YAAY,oBAAmB,OAAM;AACtC,cAAO,MAAK,QAAQ,OAAO,KACf,QAAQ,WAAW;AAC/B,UAAI,QAAW,MAAK,MAAM,MACtB,WAAW,WAAW,QACtB,SAAW;AACf,UAAI;AACA,iBAAS,MAAM,UAAU;AAC7B,eAAS,IAAI,GAAG,IAAI,MAAM,UAAS;AAC/B,YAAI,MAAM,OAAO,MAAM;AACnB,cAAI,IAAI,KAAK,MAAM,IAAI,OAAO;AAC1B,kBAAM,OAAO,EAAE,GAAG;AAAA,mBACb;AACL,kBAAM,OAAO,GAAG;AAAA;AAEhB,cAAE;AAAA,mBACC,MAAM,OAAO;AACpB,gBAAM,OAAO,GAAG;AAAA;AAEhB,YAAE;AAAA;AAEV,aAAO,SAAS,MAAM,KAAK;AAAA;AAU/B,SAAK,UAAU,kBAAiB,YAAY,aAAa,mBAAmB;AACxE,UAAI,CAAC;AACD,sBAAc,UAAU;AAC5B,UAAI,WAAW;AACX,eAAO;AACX,UAAI,CAAC;AACD,qBAAa,UAAU;AAC3B,aAAQ,cAAa,WAAW,QAAQ,kBAAkB,KAAK,SAAS,UAAU,aAAa,MAAM,eAAe;AAAA;AAAA;AAAA;;;AC/DxH;AAAA;AAAA;AAMA,QAAI,QAAQ;AAEZ,QAAI,OAAO;AAEX,QAAI,IAAI;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAGJ,kBAAc,QAAQ,QAAQ;AAC1B,UAAI,IAAI,GAAG,IAAI;AACf,gBAAU;AACV,aAAO,IAAI,OAAO;AAAQ,UAAE,EAAE,IAAI,WAAW,OAAO;AACpD,aAAO;AAAA;AAuBX,UAAM,QAAQ,KAAK;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAwBnB,UAAM,WAAW,KAAK;AAAA,MACH;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,KAAK;AAAA,MACL;AAAA;AAanB,UAAM,OAAO,KAAK;AAAA,MACC;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,OAChB;AAmBH,UAAM,SAAS,KAAK;AAAA,MACD;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,OAChB;AAoBH,UAAM,SAAS,KAAK;AAAA,MACD;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAAA;;;AClMnB;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,mBAAmB;AACvB,IAAE,QAAM,YAAY,OAAO,OAAO,iBAAiB,YAAY,cAAc,OAAO,YAAY;AAEhG,QAAI,OAAQ;AAAZ,QACI,QAAQ;AADZ,QAEI,OAAQ;AAEZ,QAAI;AAEJ,QAAI,SAAS;AAuBb,UAAM,WAAW,kBAAkB,OAAM,MAAM;AAC3C,aAAO,IAAI,MAAM,OAAM,KAAK,IAAI,KAAK,MAAM,KAAK,MAAM,KAAK,QAAQ,KAAK,SAAS,KAAK;AAAA;AAiB1F,mBAAe,OAAM,IAAI,MAAM,MAAM,QAAQ,SAAS,SAAS;AAE3D,UAAI,KAAK,SAAS,OAAO;AACrB,kBAAU;AACV,kBAAU;AACV,eAAO,SAAS;AAAA,iBACT,KAAK,SAAS,SAAS;AAC9B,kBAAU;AACV,kBAAU;AACV,iBAAS;AAAA;AAGb,uBAAiB,KAAK,MAAM,OAAM;AAElC,UAAI,CAAC,KAAK,UAAU,OAAO,KAAK;AAC5B,cAAM,UAAU;AAEpB,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,UAAU;AAEpB,UAAI,SAAS,UAAa,CAAC,OAAO,KAAK,OAAO,KAAK,WAAW;AAC1D,cAAM,UAAU;AAEpB,UAAI,WAAW,UAAa,CAAC,KAAK,SAAS;AACvC,cAAM,UAAU;AAEpB,UAAI,SAAS,mBAAmB;AAC5B,eAAO;AAAA;AAMX,WAAK,OAAO,QAAQ,SAAS,aAAa,OAAO;AAMjD,WAAK,OAAO;AAMZ,WAAK,KAAK;AAMV,WAAK,SAAS,UAAU;AAMxB,WAAK,WAAW,SAAS;AAMzB,WAAK,WAAW,CAAC,KAAK;AAMtB,WAAK,WAAW,SAAS;AAMzB,WAAK,MAAM;AAMX,WAAK,UAAU;AAMf,WAAK,SAAS;AAMd,WAAK,cAAc;AAMnB,WAAK,eAAe;AAMpB,WAAK,OAAO,KAAK,OAAO,MAAM,KAAK,UAAU,SAAuC;AAMpF,WAAK,QAAQ,SAAS;AAMtB,WAAK,eAAe;AAMpB,WAAK,iBAAiB;AAMtB,WAAK,iBAAiB;AAOtB,WAAK,UAAU;AAMf,WAAK,UAAU;AAAA;AASnB,WAAO,eAAe,MAAM,WAAW,UAAU;AAAA,MAC7C,KAAK,WAAW;AAEZ,YAAI,KAAK,YAAY;AACjB,eAAK,UAAU,KAAK,UAAU,cAAc;AAChD,eAAO,KAAK;AAAA;AAAA;AAOpB,UAAM,UAAU,YAAY,mBAAmB,OAAM,OAAO,UAAU;AAClE,UAAI,UAAS;AACT,aAAK,UAAU;AACnB,aAAO,iBAAiB,UAAU,UAAU,KAAK,MAAM,OAAM,OAAO;AAAA;AAwBxE,UAAM,UAAU,SAAS,gBAAgB,eAAe;AACpD,UAAI,eAAe,gBAAgB,QAAQ,cAAc,gBAAgB;AACzE,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAY,KAAK,SAAS,cAAc,KAAK,QAAQ;AAAA,QACrD;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,eAAe,KAAK,UAAU;AAAA;AAAA;AASlD,UAAM,UAAU,UAAU,oBAAmB;AAEzC,UAAI,KAAK;AACL,eAAO;AAEX,UAAK,MAAK,cAAc,MAAM,SAAS,KAAK,WAAW,QAAW;AAC9D,aAAK,eAAgB,MAAK,iBAAiB,KAAK,eAAe,SAAS,KAAK,QAAQ,iBAAiB,KAAK;AAC3G,YAAI,KAAK,wBAAwB;AAC7B,eAAK,cAAc;AAAA;AAEnB,eAAK,cAAc,KAAK,aAAa,OAAO,OAAO,KAAK,KAAK,aAAa,QAAQ;AAAA;AAI1F,UAAI,KAAK,WAAW,KAAK,QAAQ,cAAc,MAAM;AACjD,aAAK,cAAc,KAAK,QAAQ;AAChC,YAAI,KAAK,wBAAwB,QAAQ,OAAO,KAAK,gBAAgB;AACjE,eAAK,cAAc,KAAK,aAAa,OAAO,KAAK;AAAA;AAIzD,UAAI,KAAK,SAAS;AACd,YAAI,KAAK,QAAQ,WAAW,QAAQ,KAAK,QAAQ,WAAW,UAAa,KAAK,gBAAgB,CAAE,MAAK,wBAAwB;AACzH,iBAAO,KAAK,QAAQ;AACxB,YAAI,CAAC,OAAO,KAAK,KAAK,SAAS;AAC3B,eAAK,UAAU;AAAA;AAIvB,UAAI,KAAK,MAAM;AACX,aAAK,cAAc,KAAK,KAAK,WAAW,KAAK,aAAa,KAAK,KAAK,OAAO,OAAO;AAGlF,YAAI,OAAO;AACP,iBAAO,OAAO,KAAK;AAAA,iBAEhB,KAAK,SAAS,OAAO,KAAK,gBAAgB,UAAU;AAC3D,YAAI;AACJ,YAAI,KAAK,OAAO,KAAK,KAAK;AACtB,eAAK,OAAO,OAAO,KAAK,aAAa,MAAM,KAAK,UAAU,KAAK,OAAO,OAAO,KAAK,eAAe;AAAA;AAEjG,eAAK,KAAK,MAAM,KAAK,aAAa,MAAM,KAAK,UAAU,KAAK,KAAK,OAAO,KAAK,eAAe;AAChG,aAAK,cAAc;AAAA;AAIvB,UAAI,KAAK;AACL,aAAK,eAAe,KAAK;AAAA,eACpB,KAAK;AACV,aAAK,eAAe,KAAK;AAAA;AAEzB,aAAK,eAAe,KAAK;AAG7B,UAAI,KAAK,kBAAkB;AACvB,aAAK,OAAO,KAAK,UAAU,KAAK,QAAQ,KAAK;AAEjD,aAAO,iBAAiB,UAAU,QAAQ,KAAK;AAAA;AAuBnD,UAAM,IAAI,uBAAuB,SAAS,WAAW,WAAW,cAAc;AAG1E,UAAI,OAAO,cAAc;AACrB,oBAAY,KAAK,aAAa,WAAW;AAAA,eAGpC,aAAa,OAAO,cAAc;AACvC,oBAAY,KAAK,aAAa,WAAW;AAE7C,aAAO,wBAAwB,WAAW,WAAW;AACjD,aAAK,aAAa,UAAU,aACvB,IAAI,IAAI,MAAM,WAAW,SAAS,WAAW,WAAW,EAAE,WAAW;AAAA;AAAA;AAkBlF,UAAM,aAAa,mBAAmB,OAAO;AACzC,aAAO;AAAA;AAAA;AAAA;;;ACpXX;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,mBAAmB;AACvB,IAAE,QAAM,YAAY,OAAO,OAAO,iBAAiB,YAAY,cAAc,OAAO,YAAY;AAEhG,QAAI,QAAQ;AAAZ,QACI,OAAQ;AAYZ,mBAAe,OAAM,YAAY,SAAS,SAAS;AAC/C,UAAI,CAAC,MAAM,QAAQ,aAAa;AAC5B,kBAAU;AACV,qBAAa;AAAA;AAEjB,uBAAiB,KAAK,MAAM,OAAM;AAGlC,UAAI,CAAE,gBAAe,UAAa,MAAM,QAAQ;AAC5C,cAAM,UAAU;AAMpB,WAAK,QAAQ,cAAc;AAO3B,WAAK,cAAc;AAMnB,WAAK,UAAU;AAAA;AAiBnB,UAAM,WAAW,kBAAkB,OAAM,MAAM;AAC3C,aAAO,IAAI,MAAM,OAAM,KAAK,OAAO,KAAK,SAAS,KAAK;AAAA;AAQ1D,UAAM,UAAU,SAAS,gBAAgB,eAAe;AACpD,UAAI,eAAe,gBAAgB,QAAQ,cAAc,gBAAgB;AACzE,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,eAAe,KAAK,UAAU;AAAA;AAAA;AAWlD,+BAA2B,OAAO;AAC9B,UAAI,MAAM;AACN,iBAAS,IAAI,GAAG,IAAI,MAAM,YAAY,QAAQ,EAAE;AAC5C,cAAI,CAAC,MAAM,YAAY,GAAG;AACtB,kBAAM,OAAO,IAAI,MAAM,YAAY;AAAA;AAAA;AAQnD,UAAM,UAAU,MAAM,aAAa,OAAO;AAGtC,UAAI,CAAE,kBAAiB;AACnB,cAAM,UAAU;AAEpB,UAAI,MAAM,UAAU,MAAM,WAAW,KAAK;AACtC,cAAM,OAAO,OAAO;AACxB,WAAK,MAAM,KAAK,MAAM;AACtB,WAAK,YAAY,KAAK;AACtB,YAAM,SAAS;AACf,wBAAkB;AAClB,aAAO;AAAA;AAQX,UAAM,UAAU,SAAS,gBAAgB,OAAO;AAG5C,UAAI,CAAE,kBAAiB;AACnB,cAAM,UAAU;AAEpB,UAAI,QAAQ,KAAK,YAAY,QAAQ;AAGrC,UAAI,QAAQ;AACR,cAAM,MAAM,QAAQ,yBAAyB;AAEjD,WAAK,YAAY,OAAO,OAAO;AAC/B,cAAQ,KAAK,MAAM,QAAQ,MAAM;AAGjC,UAAI,QAAQ;AACR,aAAK,MAAM,OAAO,OAAO;AAE7B,YAAM,SAAS;AACf,aAAO;AAAA;AAMX,UAAM,UAAU,QAAQ,eAAe,QAAQ;AAC3C,uBAAiB,UAAU,MAAM,KAAK,MAAM;AAC5C,UAAI,QAAO;AAEX,eAAS,IAAI,GAAG,IAAI,KAAK,MAAM,QAAQ,EAAE,GAAG;AACxC,YAAI,QAAQ,OAAO,IAAI,KAAK,MAAM;AAClC,YAAI,SAAS,CAAC,MAAM,QAAQ;AACxB,gBAAM,SAAS;AACf,gBAAK,YAAY,KAAK;AAAA;AAAA;AAI9B,wBAAkB;AAAA;AAMtB,UAAM,UAAU,WAAW,kBAAkB,QAAQ;AACjD,eAAS,IAAI,GAAG,OAAO,IAAI,KAAK,YAAY,QAAQ,EAAE;AAClD,YAAK,SAAQ,KAAK,YAAY,IAAI;AAC9B,gBAAM,OAAO,OAAO;AAC5B,uBAAiB,UAAU,SAAS,KAAK,MAAM;AAAA;AAmBnD,UAAM,IAAI,yBAAyB;AAC/B,UAAI,aAAa,IAAI,MAAM,UAAU,SACjC,QAAQ;AACZ,aAAO,QAAQ,UAAU;AACrB,mBAAW,SAAS,UAAU;AAClC,aAAO,wBAAwB,WAAW,WAAW;AACjD,aAAK,aAAa,UAAU,aACvB,IAAI,IAAI,MAAM,WAAW;AAC9B,eAAO,eAAe,WAAW,WAAW;AAAA,UACxC,KAAK,KAAK,YAAY;AAAA,UACtB,KAAK,KAAK,YAAY;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACvMlC;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,mBAAmB;AACvB,IAAE,YAAU,YAAY,OAAO,OAAO,iBAAiB,YAAY,cAAc,WAAW,YAAY;AAExG,QAAI,QAAW;AAAf,QACI,QAAW;AADf,QAEI,OAAW;AAEf,QAAI;AAAJ,QACI;AADJ,QAEI;AAqBJ,cAAU,WAAW,kBAAkB,OAAM,MAAM;AAC/C,aAAO,IAAI,UAAU,OAAM,KAAK,SAAS,QAAQ,KAAK;AAAA;AAU1D,yBAAqB,OAAO,eAAe;AACvC,UAAI,CAAE,UAAS,MAAM;AACjB,eAAO;AACX,UAAI,MAAM;AACV,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE;AAChC,YAAI,MAAM,GAAG,QAAQ,MAAM,GAAG,OAAO;AACzC,aAAO;AAAA;AAGX,cAAU,cAAc;AAQxB,cAAU,eAAe,sBAAsB,UAAU,IAAI;AACzD,UAAI;AACA,iBAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,EAAE;AACnC,cAAI,OAAO,SAAS,OAAO,YAAY,SAAS,GAAG,MAAM,MAAM,SAAS,GAAG,KAAK;AAC5E,mBAAO;AAAA;AACnB,aAAO;AAAA;AASX,cAAU,iBAAiB,wBAAwB,UAAU,OAAM;AAC/D,UAAI;AACA,iBAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,EAAE;AACnC,cAAI,SAAS,OAAO;AAChB,mBAAO;AAAA;AACnB,aAAO;AAAA;AAcX,uBAAmB,OAAM,SAAS;AAC9B,uBAAiB,KAAK,MAAM,OAAM;AAMlC,WAAK,SAAS;AAOd,WAAK,eAAe;AAAA;AAGxB,wBAAoB,WAAW;AAC3B,gBAAU,eAAe;AACzB,aAAO;AAAA;AASX,WAAO,eAAe,UAAU,WAAW,eAAe;AAAA,MACtD,KAAK,WAAW;AACZ,eAAO,KAAK,gBAAiB,MAAK,eAAe,KAAK,QAAQ,KAAK;AAAA;AAAA;AA6B3E,cAAU,UAAU,SAAS,gBAAgB,eAAe;AACxD,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,YAAY,KAAK,aAAa;AAAA;AAAA;AASlD,cAAU,UAAU,UAAU,iBAAiB,YAAY;AACvD,UAAI,KAAK;AAET,UAAI,YAAY;AACZ,iBAAS,QAAQ,OAAO,KAAK,aAAa,IAAI,GAAG,QAAQ,IAAI,MAAM,QAAQ,EAAE,GAAG;AAC5E,mBAAS,WAAW,MAAM;AAC1B,aAAG,IACG,QAAO,WAAW,SAClB,KAAK,WACL,OAAO,WAAW,SAClB,KAAK,WACL,OAAO,YAAY,SACnB,QAAQ,WACR,OAAO,OAAO,SACd,MAAM,WACN,UAAU,UAAW,MAAM,IAAI;AAAA;AAAA;AAI7C,aAAO;AAAA;AAQX,cAAU,UAAU,MAAM,aAAa,OAAM;AACzC,aAAO,KAAK,UAAU,KAAK,OAAO,UAC3B;AAAA;AAUX,cAAU,UAAU,UAAU,iBAAiB,OAAM;AACjD,UAAI,KAAK,UAAU,KAAK,OAAO,kBAAiB;AAC5C,eAAO,KAAK,OAAO,OAAM;AAC7B,YAAM,MAAM,mBAAmB;AAAA;AAUnC,cAAU,UAAU,MAAM,aAAa,QAAQ;AAE3C,UAAI,CAAE,mBAAkB,SAAS,OAAO,WAAW,UAAa,kBAAkB,QAAQ,kBAAkB,QAAQ,kBAAkB,WAAW,kBAAkB,aAAa,kBAAkB;AAC9L,cAAM,UAAU;AAEpB,UAAI,CAAC,KAAK;AACN,aAAK,SAAS;AAAA,WACb;AACD,YAAI,OAAO,KAAK,IAAI,OAAO;AAC3B,YAAI,MAAM;AACN,cAAI,gBAAgB,aAAa,kBAAkB,aAAa,CAAE,iBAAgB,QAAQ,gBAAgB,UAAU;AAEhH,gBAAI,SAAS,KAAK;AAClB,qBAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE;AACjC,qBAAO,IAAI,OAAO;AACtB,iBAAK,OAAO;AACZ,gBAAI,CAAC,KAAK;AACN,mBAAK,SAAS;AAClB,mBAAO,WAAW,KAAK,SAAS;AAAA;AAGhC,kBAAM,MAAM,qBAAqB,OAAO,OAAO,UAAU;AAAA;AAAA;AAGrE,WAAK,OAAO,OAAO,QAAQ;AAC3B,aAAO,MAAM;AACb,aAAO,WAAW;AAAA;AAUtB,cAAU,UAAU,SAAS,gBAAgB,QAAQ;AAEjD,UAAI,CAAE,mBAAkB;AACpB,cAAM,UAAU;AACpB,UAAI,OAAO,WAAW;AAClB,cAAM,MAAM,SAAS,yBAAyB;AAElD,aAAO,KAAK,OAAO,OAAO;AAC1B,UAAI,CAAC,OAAO,KAAK,KAAK,QAAQ;AAC1B,aAAK,SAAS;AAElB,aAAO,SAAS;AAChB,aAAO,WAAW;AAAA;AAStB,cAAU,UAAU,SAAS,gBAAgB,MAAM,MAAM;AAErD,UAAI,KAAK,SAAS;AACd,eAAO,KAAK,MAAM;AAAA,eACb,CAAC,MAAM,QAAQ;AACpB,cAAM,UAAU;AACpB,UAAI,QAAQ,KAAK,UAAU,KAAK,OAAO;AACnC,cAAM,MAAM;AAEhB,UAAI,MAAM;AACV,aAAO,KAAK,SAAS,GAAG;AACpB,YAAI,OAAO,KAAK;AAChB,YAAI,IAAI,UAAU,IAAI,OAAO,OAAO;AAChC,gBAAM,IAAI,OAAO;AACjB,cAAI,CAAE,gBAAe;AACjB,kBAAM,MAAM;AAAA;AAEhB,cAAI,IAAI,MAAM,IAAI,UAAU;AAAA;AAEpC,UAAI;AACA,YAAI,QAAQ;AAChB,aAAO;AAAA;AAOX,cAAU,UAAU,aAAa,sBAAsB;AACnD,UAAI,SAAS,KAAK,aAAa,IAAI;AACnC,aAAO,IAAI,OAAO;AACd,YAAI,OAAO,cAAc;AACrB,iBAAO,KAAK;AAAA;AAEZ,iBAAO,KAAK;AACpB,aAAO,KAAK;AAAA;AAUhB,cAAU,UAAU,SAAS,gBAAgB,MAAM,aAAa,sBAAsB;AAGlF,UAAI,OAAO,gBAAgB,WAAW;AAClC,+BAAuB;AACvB,sBAAc;AAAA,iBACP,eAAe,CAAC,MAAM,QAAQ;AACrC,sBAAc,CAAE;AAEpB,UAAI,KAAK,SAAS,SAAS,KAAK,QAAQ;AACpC,YAAI,SAAS;AACT,iBAAO,KAAK;AAChB,eAAO,KAAK,MAAM;AAAA,iBACX,CAAC,KAAK;AACb,eAAO;AAGX,UAAI,KAAK,OAAO;AACZ,eAAO,KAAK,KAAK,OAAO,KAAK,MAAM,IAAI;AAG3C,UAAI,QAAQ,KAAK,IAAI,KAAK;AAC1B,UAAI,OAAO;AACP,YAAI,KAAK,WAAW,GAAG;AACnB,cAAI,CAAC,eAAe,YAAY,QAAQ,MAAM,eAAe;AACzD,mBAAO;AAAA,mBACJ,iBAAiB,aAAc,SAAQ,MAAM,OAAO,KAAK,MAAM,IAAI,aAAa;AACvF,iBAAO;AAAA;AAIX,iBAAS,IAAI,GAAG,IAAI,KAAK,YAAY,QAAQ,EAAE;AAC3C,cAAI,KAAK,aAAa,cAAc,aAAc,SAAQ,KAAK,aAAa,GAAG,OAAO,MAAM,aAAa;AACrG,mBAAO;AAGnB,UAAI,KAAK,WAAW,QAAQ;AACxB,eAAO;AACX,aAAO,KAAK,OAAO,OAAO,MAAM;AAAA;AAqBpC,cAAU,UAAU,aAAa,oBAAoB,MAAM;AACvD,UAAI,QAAQ,KAAK,OAAO,MAAM,CAAE;AAChC,UAAI,CAAC;AACD,cAAM,MAAM,mBAAmB;AACnC,aAAO;AAAA;AAUX,cAAU,UAAU,aAAa,oBAAoB,MAAM;AACvD,UAAI,QAAQ,KAAK,OAAO,MAAM,CAAE;AAChC,UAAI,CAAC;AACD,cAAM,MAAM,mBAAmB,OAAO,UAAU;AACpD,aAAO;AAAA;AAUX,cAAU,UAAU,mBAAmB,0BAA0B,MAAM;AACnE,UAAI,QAAQ,KAAK,OAAO,MAAM,CAAE,MAAM;AACtC,UAAI,CAAC;AACD,cAAM,MAAM,2BAA2B,OAAO,UAAU;AAC5D,aAAO;AAAA;AAUX,cAAU,UAAU,gBAAgB,uBAAuB,MAAM;AAC7D,UAAI,QAAQ,KAAK,OAAO,MAAM,CAAE;AAChC,UAAI,CAAC;AACD,cAAM,MAAM,sBAAsB,OAAO,UAAU;AACvD,aAAO;AAAA;AAIX,cAAU,aAAa,SAAS,OAAO,UAAU,OAAO;AACpD,aAAU;AACV,gBAAU;AACV,aAAU;AAAA;AAAA;AAAA;;;AChbd;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,QAAQ;AACZ,IAAE,WAAS,YAAY,OAAO,OAAO,MAAM,YAAY,cAAc,UAAU,YAAY;AAE3F,QAAI,QAAU;AAAd,QACI,OAAU;AAcd,sBAAkB,OAAM,IAAI,SAAS,MAAM,SAAS,SAAS;AACzD,YAAM,KAAK,MAAM,OAAM,IAAI,MAAM,QAAW,QAAW,SAAS;AAGhE,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,UAAU;AAMpB,WAAK,UAAU;AAMf,WAAK,kBAAkB;AAGvB,WAAK,MAAM;AAAA;AAwBf,aAAS,WAAW,kBAAkB,OAAM,MAAM;AAC9C,aAAO,IAAI,SAAS,OAAM,KAAK,IAAI,KAAK,SAAS,KAAK,MAAM,KAAK,SAAS,KAAK;AAAA;AAQnF,aAAS,UAAU,SAAS,gBAAgB,eAAe;AACvD,UAAI,eAAe,gBAAgB,QAAQ,cAAc,gBAAgB;AACzE,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,KAAK;AAAA,QACjB;AAAA,QAAY,eAAe,KAAK,UAAU;AAAA;AAAA;AAOlD,aAAS,UAAU,UAAU,oBAAmB;AAC5C,UAAI,KAAK;AACL,eAAO;AAGX,UAAI,MAAM,OAAO,KAAK,aAAa;AAC/B,cAAM,MAAM,uBAAuB,KAAK;AAE5C,aAAO,MAAM,UAAU,QAAQ,KAAK;AAAA;AAaxC,aAAS,IAAI,0BAA0B,SAAS,cAAc,gBAAgB;AAG1E,UAAI,OAAO,mBAAmB;AAC1B,yBAAiB,KAAK,aAAa,gBAAgB;AAAA,eAG9C,kBAAkB,OAAO,mBAAmB;AACjD,yBAAiB,KAAK,aAAa,gBAAgB;AAEvD,aAAO,2BAA2B,WAAW,WAAW;AACpD,aAAK,aAAa,UAAU,aACvB,IAAI,IAAI,SAAS,WAAW,SAAS,cAAc;AAAA;AAAA;AAAA;AAAA;;;AC3HhE;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,mBAAmB;AACvB,IAAE,SAAO,YAAY,OAAO,OAAO,iBAAiB,YAAY,cAAc,QAAQ,YAAY;AAElG,QAAI,OAAO;AAiBX,oBAAgB,OAAM,MAAM,aAAa,cAAc,eAAe,gBAAgB,SAAS,SAAS,eAAe;AAGnH,UAAI,KAAK,SAAS,gBAAgB;AAC9B,kBAAU;AACV,wBAAgB,iBAAiB;AAAA,iBAC1B,KAAK,SAAS,iBAAiB;AACtC,kBAAU;AACV,yBAAiB;AAAA;AAIrB,UAAI,CAAE,UAAS,UAAa,KAAK,SAAS;AACtC,cAAM,UAAU;AAGpB,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,UAAU;AAGpB,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,UAAU;AAEpB,uBAAiB,KAAK,MAAM,OAAM;AAMlC,WAAK,OAAO,QAAQ;AAMpB,WAAK,cAAc;AAMnB,WAAK,gBAAgB,gBAAgB,OAAO;AAM5C,WAAK,eAAe;AAMpB,WAAK,iBAAiB,iBAAiB,OAAO;AAM9C,WAAK,sBAAsB;AAM3B,WAAK,uBAAuB;AAM5B,WAAK,UAAU;AAKf,WAAK,gBAAgB;AAAA;AAuBzB,WAAO,WAAW,kBAAkB,OAAM,MAAM;AAC5C,aAAO,IAAI,OAAO,OAAM,KAAK,MAAM,KAAK,aAAa,KAAK,cAAc,KAAK,eAAe,KAAK,gBAAgB,KAAK,SAAS,KAAK,SAAS,KAAK;AAAA;AAQtJ,WAAO,UAAU,SAAS,gBAAgB,eAAe;AACrD,UAAI,eAAe,gBAAgB,QAAQ,cAAc,gBAAgB;AACzE,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAmB,KAAK,SAAS,SAAoC,KAAK,QAAQ;AAAA,QAClF;AAAA,QAAmB,KAAK;AAAA,QACxB;AAAA,QAAmB,KAAK;AAAA,QACxB;AAAA,QAAmB,KAAK;AAAA,QACxB;AAAA,QAAmB,KAAK;AAAA,QACxB;AAAA,QAAmB,KAAK;AAAA,QACxB;AAAA,QAAmB,eAAe,KAAK,UAAU;AAAA,QACjD;AAAA,QAAmB,KAAK;AAAA;AAAA;AAOhC,WAAO,UAAU,UAAU,oBAAmB;AAG1C,UAAI,KAAK;AACL,eAAO;AAEX,WAAK,sBAAsB,KAAK,OAAO,WAAW,KAAK;AACvD,WAAK,uBAAuB,KAAK,OAAO,WAAW,KAAK;AAExD,aAAO,iBAAiB,UAAU,QAAQ,KAAK;AAAA;AAAA;AAAA;;;AC9JnD;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,YAAY;AAChB,IAAE,UAAQ,YAAY,OAAO,OAAO,UAAU,YAAY,cAAc,SAAS,YAAY;AAE7F,QAAI,SAAS;AAAb,QACI,OAAS;AADb,QAEI,MAAS;AAWb,qBAAiB,OAAM,SAAS;AAC5B,gBAAU,KAAK,MAAM,OAAM;AAM3B,WAAK,UAAU;AAOf,WAAK,gBAAgB;AAAA;AAiBzB,YAAQ,WAAW,kBAAkB,OAAM,MAAM;AAC7C,UAAI,UAAU,IAAI,QAAQ,OAAM,KAAK;AAErC,UAAI,KAAK;AACL,iBAAS,QAAQ,OAAO,KAAK,KAAK,UAAU,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE;AACnE,kBAAQ,IAAI,OAAO,SAAS,MAAM,IAAI,KAAK,QAAQ,MAAM;AACjE,UAAI,KAAK;AACL,gBAAQ,QAAQ,KAAK;AACzB,cAAQ,UAAU,KAAK;AACvB,aAAO;AAAA;AAQX,YAAQ,UAAU,SAAS,gBAAgB,eAAe;AACtD,UAAI,YAAY,UAAU,UAAU,OAAO,KAAK,MAAM;AACtD,UAAI,eAAe,gBAAgB,QAAQ,cAAc,gBAAgB;AACzE,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAY,aAAa,UAAU,WAAW;AAAA,QAC9C;AAAA,QAAY,UAAU,YAAY,KAAK,cAAc,kBAA6C;AAAA,QAClG;AAAA,QAAY,aAAa,UAAU,UAAU;AAAA,QAC7C;AAAA,QAAY,eAAe,KAAK,UAAU;AAAA;AAAA;AAUlD,WAAO,eAAe,QAAQ,WAAW,gBAAgB;AAAA,MACrD,KAAK,WAAW;AACZ,eAAO,KAAK,iBAAkB,MAAK,gBAAgB,KAAK,QAAQ,KAAK;AAAA;AAAA;AAI7E,wBAAoB,SAAS;AACzB,cAAQ,gBAAgB;AACxB,aAAO;AAAA;AAMX,YAAQ,UAAU,MAAM,aAAa,OAAM;AACvC,aAAO,KAAK,QAAQ,UACb,UAAU,UAAU,IAAI,KAAK,MAAM;AAAA;AAM9C,YAAQ,UAAU,aAAa,sBAAsB;AACjD,UAAI,UAAU,KAAK;AACnB,eAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,EAAE;AAClC,gBAAQ,GAAG;AACf,aAAO,UAAU,UAAU,QAAQ,KAAK;AAAA;AAM5C,YAAQ,UAAU,MAAM,aAAa,QAAQ;AAGzC,UAAI,KAAK,IAAI,OAAO;AAChB,cAAM,MAAM,qBAAqB,OAAO,OAAO,UAAU;AAE7D,UAAI,kBAAkB,QAAQ;AAC1B,aAAK,QAAQ,OAAO,QAAQ;AAC5B,eAAO,SAAS;AAChB,eAAO,WAAW;AAAA;AAEtB,aAAO,UAAU,UAAU,IAAI,KAAK,MAAM;AAAA;AAM9C,YAAQ,UAAU,SAAS,gBAAgB,QAAQ;AAC/C,UAAI,kBAAkB,QAAQ;AAG1B,YAAI,KAAK,QAAQ,OAAO,UAAU;AAC9B,gBAAM,MAAM,SAAS,yBAAyB;AAElD,eAAO,KAAK,QAAQ,OAAO;AAC3B,eAAO,SAAS;AAChB,eAAO,WAAW;AAAA;AAEtB,aAAO,UAAU,UAAU,OAAO,KAAK,MAAM;AAAA;AAUjD,YAAQ,UAAU,SAAS,gBAAgB,SAAS,kBAAkB,mBAAmB;AACrF,UAAI,aAAa,IAAI,IAAI,QAAQ,SAAS,kBAAkB;AAC5D,eAAS,IAAI,GAAG,QAAQ,IAAsB,KAAK,aAAa,QAAQ,EAAE,GAAG;AACzE,YAAI,aAAa,KAAK,QAAS,UAAS,KAAK,cAAc,IAAI,UAAU,MAAM,QAAQ,YAAY;AACnG,mBAAW,cAAc,KAAK,QAAQ,CAAC,KAAI,MAAM,KAAK,WAAW,cAAc,aAAa,MAAM,YAAY,kCAAkC;AAAA,UAC5I,GAAG;AAAA,UACH,GAAG,OAAO,oBAAoB;AAAA,UAC9B,GAAG,OAAO,qBAAqB;AAAA;AAAA;AAGvC,aAAO;AAAA;AAAA;AAAA;;;ACrKX;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAO;AASX,qBAAiB,YAAY;AAEzB,UAAI;AACA,iBAAS,OAAO,OAAO,KAAK,aAAa,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE;AAC/D,eAAK,KAAK,MAAM,WAAW,KAAK;AAAA;AA0B5C,YAAQ,SAAS,gBAAgB,YAAY;AACzC,aAAO,KAAK,MAAM,OAAO;AAAA;AAW7B,YAAQ,SAAS,gBAAgB,SAAS,QAAQ;AAC9C,aAAO,KAAK,MAAM,OAAO,SAAS;AAAA;AAWtC,YAAQ,kBAAkB,yBAAyB,SAAS,QAAQ;AAChE,aAAO,KAAK,MAAM,gBAAgB,SAAS;AAAA;AAY/C,YAAQ,SAAS,gBAAgB,QAAQ;AACrC,aAAO,KAAK,MAAM,OAAO;AAAA;AAY7B,YAAQ,kBAAkB,yBAAyB,QAAQ;AACvD,aAAO,KAAK,MAAM,gBAAgB;AAAA;AAUtC,YAAQ,SAAS,gBAAgB,SAAS;AACtC,aAAO,KAAK,MAAM,OAAO;AAAA;AAU7B,YAAQ,aAAa,oBAAoB,QAAQ;AAC7C,aAAO,KAAK,MAAM,WAAW;AAAA;AAWjC,YAAQ,WAAW,kBAAkB,SAAS,SAAS;AACnD,aAAO,KAAK,MAAM,SAAS,SAAS;AAAA;AAOxC,YAAQ,UAAU,SAAS,kBAAkB;AACzC,aAAO,KAAK,MAAM,SAAS,MAAM,KAAK;AAAA;AAAA;AAAA;;;ACvI1C;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAU;AAAd,QACI,QAAU;AADd,QAEI,OAAU;AAEd,qBAAiB,OAAO;AACpB,aAAO,uBAAuB,MAAM,OAAO;AAAA;AAQ/C,qBAAiB,OAAO;AAEpB,UAAI,MAAM,KAAK,QAAQ,CAAC,KAAK,MAAM,MAAM,OAAO,WAC/C,8BACI,sBACJ,sDAAuD,OAAM,YAAY,OAAO,SAAS,QAAO;AAAE,eAAO,OAAM;AAAA,SAAQ,SAAS,aAAa,KAC7I,mBACI;AACL,UAAI,MAAM;AAAO,YACZ,iBACI;AACT,UACK;AAEL,UAAI,IAAI;AACR,aAAO,IAAsB,MAAM,YAAY,QAAQ,EAAE,GAAG;AACxD,YAAI,QAAQ,MAAM,aAAa,GAAG,WAC9B,OAAQ,MAAM,wBAAwB,OAAO,UAAU,MAAM,MAC7D,MAAQ,MAAM,KAAK,SAAS,MAAM;AAAO,YACxC,YAAY,MAAM;AAGvB,YAAI,MAAM,KAAK;AAAE,cACR,6BAA6B,KACzB,SAAS,KACb;AAEL,cAAI,MAAM,SAAS,MAAM,aAAa;AAAW,gBAC5C,QAAQ,MAAM,SAAS,MAAM;AAAA;AAC7B,gBACA;AAEL,cAAI,MAAM,SAAS,UAAU;AAAW,gBACnC,YAAY,MAAM,SAAS;AAAA;AAC3B,gBACA;AAEL,cACK,oBACI,uBACA,qBACI,2BAA2B,MAAM,SACjC;AAEb,cAAI,MAAM,MAAM,UAAU;AAAW,gBACpB,wCAAwC;AAAA;AACpD,gBACY,gBAAgB;AAEjC,cACiB,SACJ,YACI,sBACA,SACR,KACJ;AAEL,cAAI,MAAM,KAAK,MAAM,aAAa;AAAW,gBACxC,sDAAwD;AAAA;AACxD,gBACA,eAAe;AAAA,mBAGb,MAAM,UAAU;AAAE,cAEpB,wBAAwB,KAAK,KACzB,SAAS;AAGlB,cAAI,MAAM,OAAO,UAAU;AAAW,gBACjC,kBACI,2BACA,mBACI,mBAAmB,KAAK,MAChC;AAGL,cAAI,MAAM,MAAM,UAAU;AAAW,gBAAI,MAAM,aAAa,QAClD,iCACA,2CAA2C,KAAK;AAAA;AACrD,gBACI,mBAAmB,KAAK;AAAA,mBAG1B,MAAM,MAAM,UAAU;AAAW,cAAI,MAAM,aAAa,QACzD,2BACA,qCAAqC,KAAK;AAAA;AAC/C,cACI,aAAa,KAAK;AAC3B,YACS;AAAA;AAEX,UACO,YACI,mBACA,SAER,KACJ;AAGD,WAAK,IAAI,GAAG,IAAI,MAAM,aAAa,QAAQ,EAAE,GAAG;AAC5C,YAAI,SAAS,MAAM,aAAa;AAChC,YAAI,OAAO;AAAU,cACxB,6BAA6B,OAAO,MAChC,6CAA6C,QAAQ;AAAA;AAG1D,aAAO,IACN;AAAA;AAAA;AAAA;;;AC7HL;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAY;AAAhB,QACI,OAAY;AAEhB,qBAAiB,OAAO,UAAU;AAC9B,aAAO,MAAM,OAAO,OAAO,WAAY,OAAM,YAAY,aAAa,UAAU,OAAO,MAAM,OAAO,aAAa,WAAW,QAAM,MAAM,UAAQ,MAAM,MAAM;AAAA;AAYhK,4BAAwB,KAAK,OAAO,YAAY,KAAK;AAEjD,UAAI,MAAM,cAAc;AACpB,YAAI,MAAM,wBAAwB,MAAM;AAAE,cACrC,eAAe,KACX,YACI,YAAY,QAAQ,OAAO;AACpC,mBAAS,OAAO,OAAO,KAAK,MAAM,aAAa,SAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE;AAAG,gBAChF,YAAY,MAAM,aAAa,OAAO,KAAK;AAChD,cACS,SACR;AAAA,eACE;AACH,cACC,KACI,+BAA+B,YAAY,KAC3C,SACI,cAAc,MAAM,OAAO,KACnC;AAAA;AAAA,aAEF;AACH,gBAAQ,MAAM;AAAA,eACL;AAAA,eACA;AAAA,eACA;AAAA,eACA;AAAA,eACA;AAAY,gBACZ,2BAA2B,KACvB,YAAY,QAAQ,OAAO;AAChC;AAAA,eACC;AAAA,eACA;AAAA,eACA;AAAA,eACA;AAAA,eACA;AAAY,gBACZ,mFAAmF,KAAK,KAAK,KAAK,KAC9F,YAAY,QAAQ,OAAO;AAChC;AAAA,eACC;AAAA,eACA;AAAU,gBACV,4BAA8B,KAC1B,YAAY,QAAQ,OAAO;AAChC;AAAA,eACC;AAAQ,gBACR,6BAA+B,KAC3B,YAAY,QAAQ,OAAO;AAChC;AAAA,eACC;AAAU,gBACV,0BAA0B,KACtB,YAAY,QAAQ,OAAO;AAChC;AAAA,eACC;AAAS,gBACT,6DAA+D,KAAK,KAAK,KACrE,YAAY,QAAQ,OAAO;AAChC;AAAA;AAAA;AAGZ,aAAO;AAAA;AAYX,0BAAsB,KAAK,OAAO,KAAK;AAEnC,cAAQ,MAAM;AAAA,aACL;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAY,cACZ,8BAA8B,KAC1B,YAAY,QAAQ,OAAO;AAChC;AAAA,aACC;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAY,cACZ,8BAA8B,KAC1B,YAAY,QAAQ,OAAO;AAChC;AAAA,aACC;AAAQ,cACR,6BAA6B,KACzB,YAAY,QAAQ,OAAO;AAChC;AAAA;AAER,aAAO;AAAA;AASX,sBAAkB,OAAO;AAGrB,UAAI,MAAM,KAAK,QAAQ,CAAC,MAAM,MAAM,OAAO,WAC1C,qCACI,YAAY;AACjB,UAAI,SAAS,MAAM,aACf,iBAAiB;AACrB,UAAI,OAAO;AAAQ,YAClB;AAED,eAAS,IAAI,GAAG,IAAsB,MAAM,YAAY,QAAQ,EAAE,GAAG;AACjE,YAAI,QAAQ,MAAM,aAAa,GAAG,WAC9B,MAAQ,MAAM,KAAK,SAAS,MAAM;AAEtC,YAAI,MAAM;AAAU,cACnB,uCAAuC,KAAK,MAAM;AAGnD,YAAI,MAAM,KAAK;AAAE,cACZ,0BAA0B,KACtB,YAAY,QAAQ,OAAO,WAC/B,yBAAyB,KACzB;AACG,uBAAa,KAAK,OAAO;AACzB,yBAAe,KAAK,OAAO,GAAG,MAAM,UACvC;AAAA,mBAGM,MAAM,UAAU;AAAE,cACxB,0BAA0B,KACtB,YAAY,QAAQ,OAAO,UAC/B,iCAAiC;AAC9B,yBAAe,KAAK,OAAO,GAAG,MAAM,OACvC;AAAA,eAGE;AACH,cAAI,MAAM,QAAQ;AACd,gBAAI,YAAY,KAAK,SAAS,MAAM,OAAO;AAC3C,gBAAI,eAAe,MAAM,OAAO,UAAU;AAAG,kBAChD,eAAe,WACX,YAAY,MAAM,OAAO,OAAO;AACjC,2BAAe,MAAM,OAAO,QAAQ;AACpC,gBACH,SAAS;AAAA;AAEV,yBAAe,KAAK,OAAO,GAAG;AAAA;AAElC,YAAI,MAAM;AAAU,cACnB;AAAA;AAEL,aAAO,IACN;AAAA;AAAA;AAAA;;;AC9KL;AAAA;AAAA;AAKA,QAAI,YAAY;AAEhB,QAAI,OAAO;AAAX,QACI,OAAO;AAWX,wCAAoC,KAAK,OAAO,YAAY,MAAM;AAE9D,UAAI,MAAM,cAAc;AACpB,YAAI,MAAM,wBAAwB,MAAM;AAAE,cACrC,gBAAgB;AACjB,mBAAS,SAAS,MAAM,aAAa,QAAQ,OAAO,OAAO,KAAK,SAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE,GAAG;AAClG,gBAAI,MAAM,YAAY,OAAO,KAAK,QAAQ,MAAM;AAAa,kBAC5D;AACD,gBACC,WAAW,KAAK,IAChB,YAAY,OAAO,KAAK,KACpB,UAAU,MAAM,OAAO,KAAK,KAC5B;AAAA;AACP,cACD;AAAA;AACE,cACF,6BAA+B,MAC3B,uBAAuB,MAAM,WAAW,qBAC5C,iCAAiC,MAAM,YAAY;AAAA,aACrD;AACH,YAAI,aAAa;AACjB,gBAAQ,MAAM;AAAA,eACL;AAAA,eACA;AAAS,gBACT,mBAAmB,MAAM;AAC1B;AAAA,eACC;AAAA,eACA;AAAW,gBACX,eAAe,MAAM;AACtB;AAAA,eACC;AAAA,eACA;AAAA,eACA;AAAY,gBACZ,aAAa,MAAM;AACpB;AAAA,eACC;AACD,yBAAa;AAAA,eAEZ;AAAA,eACA;AAAA,eACA;AAAA,eACA;AAAY,gBACZ,iBACI,8CAA8C,MAAM,MAAM,YAC9D,kCAAoC,MAChC,wBAAwB,MAAM,MAClC,kCAAoC,MAChC,WAAW,MAAM,MACrB,kCAAoC,MAChC,gEAAgE,MAAM,MAAM,MAAM,aAAa,SAAS;AAC7G;AAAA,eACC;AAAS,gBACT,6BAA+B,MAC3B,yEAAyE,MAAM,MAAM,MACzF,uBAAuB,MACnB,WAAW,MAAM;AACtB;AAAA,eACC;AAAU,gBACV,mBAAmB,MAAM;AAC1B;AAAA,eACC;AAAQ,gBACR,oBAAoB,MAAM;AAC3B;AAAA;AAAA;AAMZ,aAAO;AAAA;AASX,cAAU,aAAa,oBAAoB,OAAO;AAE9C,UAAI,SAAS,MAAM;AACnB,UAAI,MAAM,KAAK,QAAQ,CAAC,MAAM,MAAM,OAAO,eAC1C,8BACI;AACL,UAAI,CAAC,OAAO;AAAQ,eAAO,IAC1B;AACD,UACC;AACD,eAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AACpC,YAAI,QAAS,OAAO,GAAG,WACnB,OAAS,KAAK,SAAS,MAAM;AAGjC,YAAI,MAAM,KAAK;AAAE,cACpB,YAAY,MACR,6BAA+B,MAC3B,uBAAuB,MAAM,WAAW,qBAC5C,UAAU,MACV,qDAAqD;AAClD,qCAA2B,KAAK,OAAwB,GAAG,OAAO,WACrE,KACJ;AAAA,mBAGc,MAAM,UAAU;AAAE,cAChC,YAAY,MACR,2BAA2B,MACvB,uBAAuB,MAAM,WAAW,oBAC5C,UAAU,MACV,kCAAkC;AAC/B,qCAA2B,KAAK,OAAwB,GAAG,OAAO,OACrE,KACJ;AAAA,eAGU;AACH,cAAI,CAAE,OAAM,wBAAwB;AAAO,gBAClD,kBAAkB;AACf,qCAA2B,KAAK,OAAwB,GAAG;AACvD,cAAI,CAAE,OAAM,wBAAwB;AAAO,gBAClD;AAAA;AAAA;AAEC,aAAO,IACR;AAAA;AAaL,sCAAkC,KAAK,OAAO,YAAY,MAAM;AAE5D,UAAI,MAAM,cAAc;AACpB,YAAI,MAAM,wBAAwB;AAAM,cACnC,kDAAkD,MAAM,YAAY,MAAM;AAAA;AAC1E,cACA,iCAAiC,MAAM,YAAY;AAAA,aACrD;AACH,YAAI,aAAa;AACjB,gBAAQ,MAAM;AAAA,eACL;AAAA,eACA;AAAS,gBACb,8CAA8C,MAAM,MAAM,MAAM;AAC7D;AAAA,eACC;AACD,yBAAa;AAAA,eAEZ;AAAA,eACA;AAAA,eACA;AAAA,eACA;AAAY,gBAChB,6BAA+B,MAC3B,wCAAwC,MAAM,MAAM,MACxD,QACI,6IAA6I,MAAM,MAAM,MAAM,MAAM,aAAa,SAAQ,IAAI;AAC/L;AAAA,eACC;AAAS,gBACb,iHAAiH,MAAM,MAAM,MAAM,MAAM;AACtI;AAAA;AACK,gBACR,WAAW,MAAM;AACd;AAAA;AAAA;AAGZ,aAAO;AAAA;AASX,cAAU,WAAW,kBAAkB,OAAO;AAE1C,UAAI,SAAS,MAAM,YAAY,QAAQ,KAAK,KAAK;AACjD,UAAI,CAAC,OAAO;AACR,eAAO,KAAK,UAAU;AAC1B,UAAI,MAAM,KAAK,QAAQ,CAAC,KAAK,MAAM,MAAM,OAAO,aAC/C,UACI,QACJ;AAED,UAAI,iBAAiB,IACjB,YAAY,IACZ,eAAe,IACf,IAAI;AACR,aAAO,IAAI,OAAO,QAAQ,EAAE;AACxB,YAAI,CAAC,OAAO,GAAG;AACX,UAAE,QAAO,GAAG,UAAU,WAAW,iBAC/B,OAAO,GAAG,MAAM,YAChB,cAAc,KAAK,OAAO;AAEpC,UAAI,eAAe,QAAQ;AAAE,YAC5B;AACG,aAAK,IAAI,GAAG,IAAI,eAAe,QAAQ,EAAE;AAAG,cAC3C,UAAU,KAAK,SAAS,eAAe,GAAG;AAC3C,YACH;AAAA;AAGD,UAAI,UAAU,QAAQ;AAAE,YACvB;AACG,aAAK,IAAI,GAAG,IAAI,UAAU,QAAQ,EAAE;AAAG,cACtC,UAAU,KAAK,SAAS,UAAU,GAAG;AACtC,YACH;AAAA;AAGD,UAAI,aAAa,QAAQ;AAAE,YAC1B;AACG,aAAK,IAAI,GAAG,IAAI,aAAa,QAAQ,EAAE,GAAG;AACtC,cAAI,QAAQ,aAAa,IACrB,OAAQ,KAAK,SAAS,MAAM;AAChC,cAAI,MAAM,wBAAwB;AAAM,gBAC3C,8BAA8B,MAAM,MAAM,aAAa,WAAW,MAAM,cAAc,MAAM;AAAA,mBAChF,MAAM;AAAM,gBACxB,kBACI,iCAAiC,MAAM,YAAY,KAAK,MAAM,YAAY,MAAM,MAAM,YAAY,UAClG,qEAAqE,MACzE,SACI,8BAA8B,MAAM,MAAM,YAAY,YAAY,MAAM,YAAY;AAAA,mBAC5E,MAAM,OAAO;AAClB,gBAAI,eAAe,MAAM,MAAM,UAAU,MAAM,KAAK,MAAM,aAAa,KAAK,OAAO;AACnF,gBACP,8BAA8B,MAAM,OAAO,aAAa,MAAM,QAAQ,MAAM,cAC5E,SACI,UAAU,MAAM,cAChB,8CAA8C,MAAM,MACxD;AAAA;AACU,gBACV,UAAU,MAAM,MAAM;AAAA;AACrB,YACL;AAAA;AAED,UAAI,SAAS;AACb,WAAK,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AAChC,YAAI,QAAQ,OAAO,IACf,QAAQ,MAAM,aAAa,QAAQ,QACnC,OAAQ,KAAK,SAAS,MAAM;AAChC,YAAI,MAAM,KAAK;AACX,cAAI,CAAC,QAAQ;AAAE,qBAAS;AAAM,gBACrC;AAAA;AACS,cACT,2CAA2C,MAAM,MAC7C,UAAU,MACV;AACG,mCAAyB,KAAK,OAAoB,OAAO,OAAO,YACnE;AAAA,mBACU,MAAM,UAAU;AAAE,cAChC,wBAAwB,MAAM,MAC1B,UAAU,MACV,kCAAkC;AAC/B,mCAAyB,KAAK,OAAoB,OAAO,OAAO,OACnE;AAAA,eACM;AAAE,cACZ,wCAAwC,MAAM,MAAM;AACjD,mCAAyB,KAAK,OAAoB,OAAO;AACzD,cAAI,MAAM;AAAQ,gBACjB,gBACI,UAAU,KAAK,SAAS,MAAM,OAAO,OAAO,MAAM;AAAA;AAEvD,YACH;AAAA;AAED,aAAO,IACN;AAAA;AAAA;AAAA;;;AClSL;AAAA;AAAA;AAOA,QAAI,WAAW;AAEf,QAAI,UAAU;AA6Bd,aAAS,0BAA0B;AAAA,MAE/B,YAAY,SAAS,QAAQ;AAGzB,YAAI,UAAU,OAAO,UAAU;AAE3B,cAAI,QAAO,OAAO,SAAS,UAAU,OAAO,SAAS,YAAY,OAAO;AACxE,cAAI,OAAO,KAAK,OAAO;AAEvB,cAAI,MAAM;AAEN,gBAAI,WAAW,OAAO,SAAS,OAAO,OAAO,MACzC,OAAO,SAAS,OAAO,KAAK,OAAO;AAEvC,gBAAI,SAAS,QAAQ,SAAS,IAAI;AAC9B,yBAAW,MAAM;AAAA;AAErB,mBAAO,KAAK,OAAO;AAAA,cACf;AAAA,cACA,OAAO,KAAK,OAAO,KAAK,WAAW,SAAS;AAAA;AAAA;AAAA;AAKxD,eAAO,KAAK,WAAW;AAAA;AAAA,MAG3B,UAAU,SAAS,SAAS,SAAS;AAGjC,YAAI,YAAY;AAChB,YAAI,SAAS;AACb,YAAI,QAAO;AAGX,YAAI,WAAW,QAAQ,QAAQ,QAAQ,YAAY,QAAQ,OAAO;AAE9D,kBAAO,QAAQ,SAAS,UAAU,QAAQ,SAAS,YAAY,OAAO;AAEtE,mBAAS,QAAQ,SAAS,UAAU,GAAG,QAAQ,SAAS,YAAY,OAAO;AAC3E,cAAI,OAAO,KAAK,OAAO;AAEvB,cAAI;AACA,sBAAU,KAAK,OAAO,QAAQ;AAAA;AAItC,YAAI,CAAE,oBAAmB,KAAK,SAAS,mBAAmB,SAAS;AAC/D,cAAI,SAAS,QAAQ,MAAM,SAAS,SAAS;AAC7C,cAAI,cAAc,QAAQ,MAAM,SAAS,OAAO,MAC5C,QAAQ,MAAM,SAAS,OAAO,KAAK,QAAQ,MAAM;AAErD,cAAI,WAAW,IAAI;AACf,qBAAS;AAAA;AAEb,kBAAO,SAAS;AAChB,iBAAO,WAAW;AAClB,iBAAO;AAAA;AAGX,eAAO,KAAK,SAAS,SAAS;AAAA;AAAA;AAAA;AAAA;;;ACnGtC;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,YAAY;AAChB,IAAE,OAAK,YAAY,OAAO,OAAO,UAAU,YAAY,cAAc,MAAM,YAAY;AAEvF,QAAI,OAAY;AAAhB,QACI,QAAY;AADhB,QAEI,QAAY;AAFhB,QAGI,WAAY;AAHhB,QAII,UAAY;AAJhB,QAKI,UAAY;AALhB,QAMI,SAAY;AANhB,QAOI,SAAY;AAPhB,QAQI,OAAY;AARhB,QASI,UAAY;AAThB,QAUI,UAAY;AAVhB,QAWI,WAAY;AAXhB,QAYI,YAAY;AAZhB,QAaI,WAAY;AAUhB,kBAAc,OAAM,SAAS;AACzB,gBAAU,KAAK,MAAM,OAAM;AAM3B,WAAK,SAAS;AAMd,WAAK,SAAS;AAMd,WAAK,aAAa;AAMlB,WAAK,WAAW;AAMhB,WAAK,QAAQ;AAOb,WAAK,cAAc;AAOnB,WAAK,eAAe;AAOpB,WAAK,eAAe;AAOpB,WAAK,QAAQ;AAAA;AAGjB,WAAO,iBAAiB,KAAK,WAAW;AAAA,MAQpC,YAAY;AAAA,QACR,KAAK,WAAW;AAGZ,cAAI,KAAK;AACL,mBAAO,KAAK;AAEhB,eAAK,cAAc;AACnB,mBAAS,QAAQ,OAAO,KAAK,KAAK,SAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE,GAAG;AACrE,gBAAI,QAAQ,KAAK,OAAO,MAAM,KAC1B,KAAK,MAAM;AAGf,gBAAI,KAAK,YAAY;AACjB,oBAAM,MAAM,kBAAkB,KAAK,SAAS;AAEhD,iBAAK,YAAY,MAAM;AAAA;AAE3B,iBAAO,KAAK;AAAA;AAAA;AAAA,MAUpB,aAAa;AAAA,QACT,KAAK,WAAW;AACZ,iBAAO,KAAK,gBAAiB,MAAK,eAAe,KAAK,QAAQ,KAAK;AAAA;AAAA;AAAA,MAU3E,aAAa;AAAA,QACT,KAAK,WAAW;AACZ,iBAAO,KAAK,gBAAiB,MAAK,eAAe,KAAK,QAAQ,KAAK;AAAA;AAAA;AAAA,MAU3E,MAAM;AAAA,QACF,KAAK,WAAW;AACZ,iBAAO,KAAK,SAAU,MAAK,OAAO,KAAK,oBAAoB;AAAA;AAAA,QAE/D,KAAK,SAAS,MAAM;AAGhB,cAAI,YAAY,KAAK;AACrB,cAAI,CAAE,sBAAqB,UAAU;AACjC,YAAC,MAAK,YAAY,IAAI,WAAW,cAAc;AAC/C,iBAAK,MAAM,KAAK,WAAW;AAAA;AAI/B,eAAK,QAAQ,KAAK,UAAU,QAAQ;AAGpC,eAAK,MAAM,MAAM,SAAS;AAE1B,eAAK,QAAQ;AAGb,cAAI,IAAI;AACR,iBAAO,IAAsB,KAAK,YAAY,QAAQ,EAAE;AACpD,iBAAK,aAAa,GAAG;AAGzB,cAAI,iBAAiB;AACrB,eAAK,IAAI,GAAG,IAAsB,KAAK,YAAY,QAAQ,EAAE;AACzD,2BAAe,KAAK,aAAa,GAAG,UAAU,QAAQ;AAAA,cAClD,KAAK,KAAK,YAAY,KAAK,aAAa,GAAG;AAAA,cAC3C,KAAK,KAAK,YAAY,KAAK,aAAa,GAAG;AAAA;AAEnD,cAAI;AACA,mBAAO,iBAAiB,KAAK,WAAW;AAAA;AAAA;AAAA;AAUxD,SAAK,sBAAsB,6BAA6B,OAAO;AAE3D,UAAI,MAAM,KAAK,QAAQ,CAAC,MAAM,MAAM;AAEpC,eAAS,IAAI,GAAG,OAAO,IAAI,MAAM,YAAY,QAAQ,EAAE;AACnD,YAAK,SAAQ,MAAM,aAAa,IAAI;AAAK,cACpC,aAAa,KAAK,SAAS,MAAM;AAAA,iBAC7B,MAAM;AAAU,cACpB,aAAa,KAAK,SAAS,MAAM;AAC1C,aAAO,IACN,yEACI;AAAA;AAIT,wBAAoB,MAAM;AACtB,WAAK,cAAc,KAAK,eAAe,KAAK,eAAe;AAC3D,aAAO,KAAK;AACZ,aAAO,KAAK;AACZ,aAAO,KAAK;AACZ,aAAO;AAAA;AAoBX,SAAK,WAAW,kBAAkB,OAAM,MAAM;AAC1C,UAAI,OAAO,IAAI,KAAK,OAAM,KAAK;AAC/B,WAAK,aAAa,KAAK;AACvB,WAAK,WAAW,KAAK;AACrB,UAAI,QAAQ,OAAO,KAAK,KAAK,SACzB,IAAI;AACR,aAAO,IAAI,MAAM,QAAQ,EAAE;AACvB,aAAK,IACC,QAAO,KAAK,OAAO,MAAM,IAAI,YAAY,cACzC,SAAS,WACT,MAAM,UAAW,MAAM,IAAI,KAAK,OAAO,MAAM;AAEvD,UAAI,KAAK;AACL,aAAK,QAAQ,OAAO,KAAK,KAAK,SAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE;AAC9D,eAAK,IAAI,MAAM,SAAS,MAAM,IAAI,KAAK,OAAO,MAAM;AAC5D,UAAI,KAAK;AACL,aAAK,QAAQ,OAAO,KAAK,KAAK,SAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE,GAAG;AACjE,cAAI,SAAS,KAAK,OAAO,MAAM;AAC/B,eAAK,IACC,QAAO,OAAO,SACd,MAAM,WACN,OAAO,WAAW,SAClB,KAAK,WACL,OAAO,WAAW,SAClB,KAAK,WACL,OAAO,YAAY,SACnB,QAAQ,WACR,UAAU,UAAW,MAAM,IAAI;AAAA;AAG7C,UAAI,KAAK,cAAc,KAAK,WAAW;AACnC,aAAK,aAAa,KAAK;AAC3B,UAAI,KAAK,YAAY,KAAK,SAAS;AAC/B,aAAK,WAAW,KAAK;AACzB,UAAI,KAAK;AACL,aAAK,QAAQ;AACjB,UAAI,KAAK;AACL,aAAK,UAAU,KAAK;AACxB,aAAO;AAAA;AAQX,SAAK,UAAU,SAAS,gBAAgB,eAAe;AACnD,UAAI,YAAY,UAAU,UAAU,OAAO,KAAK,MAAM;AACtD,UAAI,eAAe,gBAAgB,QAAQ,cAAc,gBAAgB;AACzE,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAe,aAAa,UAAU,WAAW;AAAA,QACjD;AAAA,QAAe,UAAU,YAAY,KAAK,aAAa;AAAA,QACvD;AAAA,QAAe,UAAU,YAAY,KAAK,YAAY,OAAO,SAAS,KAAK;AAAE,iBAAO,CAAC,IAAI;AAAA,YAAoB,kBAAkB;AAAA,QAC/H;AAAA,QAAe,KAAK,cAAc,KAAK,WAAW,SAAS,KAAK,aAAa;AAAA,QAC7E;AAAA,QAAe,KAAK,YAAY,KAAK,SAAS,SAAS,KAAK,WAAW;AAAA,QACvE;AAAA,QAAe,KAAK,SAAS;AAAA,QAC7B;AAAA,QAAe,aAAa,UAAU,UAAU;AAAA,QAChD;AAAA,QAAe,eAAe,KAAK,UAAU;AAAA;AAAA;AAOrD,SAAK,UAAU,aAAa,sBAAsB;AAC9C,UAAI,SAAS,KAAK,aAAa,IAAI;AACnC,aAAO,IAAI,OAAO;AACd,eAAO,KAAK;AAChB,UAAI,SAAS,KAAK;AAAa,UAAI;AACnC,aAAO,IAAI,OAAO;AACd,eAAO,KAAK;AAChB,aAAO,UAAU,UAAU,WAAW,KAAK;AAAA;AAM/C,SAAK,UAAU,MAAM,aAAa,OAAM;AACpC,aAAO,KAAK,OAAO,UACZ,KAAK,UAAU,KAAK,OAAO,UAC3B,KAAK,UAAU,KAAK,OAAO,UAC3B;AAAA;AAUX,SAAK,UAAU,MAAM,aAAa,QAAQ;AAEtC,UAAI,KAAK,IAAI,OAAO;AAChB,cAAM,MAAM,qBAAqB,OAAO,OAAO,UAAU;AAE7D,UAAI,kBAAkB,SAAS,OAAO,WAAW,QAAW;AAMxD,YAAI,KAAK,cAAyC,KAAK,YAAY,OAAO,MAAM,KAAK,WAAW,OAAO;AACnG,gBAAM,MAAM,kBAAkB,OAAO,KAAK,SAAS;AACvD,YAAI,KAAK,aAAa,OAAO;AACzB,gBAAM,MAAM,QAAQ,OAAO,KAAK,qBAAqB;AACzD,YAAI,KAAK,eAAe,OAAO;AAC3B,gBAAM,MAAM,WAAW,OAAO,OAAO,sBAAsB;AAE/D,YAAI,OAAO;AACP,iBAAO,OAAO,OAAO;AACzB,aAAK,OAAO,OAAO,QAAQ;AAC3B,eAAO,UAAU;AACjB,eAAO,MAAM;AACb,eAAO,WAAW;AAAA;AAEtB,UAAI,kBAAkB,OAAO;AACzB,YAAI,CAAC,KAAK;AACN,eAAK,SAAS;AAClB,aAAK,OAAO,OAAO,QAAQ;AAC3B,eAAO,MAAM;AACb,eAAO,WAAW;AAAA;AAEtB,aAAO,UAAU,UAAU,IAAI,KAAK,MAAM;AAAA;AAU9C,SAAK,UAAU,SAAS,gBAAgB,QAAQ;AAC5C,UAAI,kBAAkB,SAAS,OAAO,WAAW,QAAW;AAIxD,YAAI,CAAC,KAAK,UAAU,KAAK,OAAO,OAAO,UAAU;AAC7C,gBAAM,MAAM,SAAS,yBAAyB;AAElD,eAAO,KAAK,OAAO,OAAO;AAC1B,eAAO,SAAS;AAChB,eAAO,SAAS;AAChB,eAAO,WAAW;AAAA;AAEtB,UAAI,kBAAkB,OAAO;AAGzB,YAAI,CAAC,KAAK,UAAU,KAAK,OAAO,OAAO,UAAU;AAC7C,gBAAM,MAAM,SAAS,yBAAyB;AAElD,eAAO,KAAK,OAAO,OAAO;AAC1B,eAAO,SAAS;AAChB,eAAO,SAAS;AAChB,eAAO,WAAW;AAAA;AAEtB,aAAO,UAAU,UAAU,OAAO,KAAK,MAAM;AAAA;AAQjD,SAAK,UAAU,eAAe,sBAAsB,IAAI;AACpD,aAAO,UAAU,aAAa,KAAK,UAAU;AAAA;AAQjD,SAAK,UAAU,iBAAiB,wBAAwB,OAAM;AAC1D,aAAO,UAAU,eAAe,KAAK,UAAU;AAAA;AAQnD,SAAK,UAAU,SAAS,gBAAgB,YAAY;AAChD,aAAO,IAAI,KAAK,KAAK;AAAA;AAOzB,SAAK,UAAU,QAAQ,iBAAiB;AAIpC,UAAI,WAAW,KAAK,UAChB,QAAW;AACf,eAAS,IAAI,GAAG,IAAsB,KAAK,YAAY,QAAQ,EAAE;AAC7D,cAAM,KAAK,KAAK,aAAa,GAAG,UAAU;AAG9C,WAAK,SAAS,QAAQ,MAAM;AAAA,QACxB;AAAA,QACA;AAAA,QACA;AAAA;AAEJ,WAAK,SAAS,QAAQ,MAAM;AAAA,QACxB;AAAA,QACA;AAAA,QACA;AAAA;AAEJ,WAAK,SAAS,SAAS,MAAM;AAAA,QACzB;AAAA,QACA;AAAA;AAEJ,WAAK,aAAa,UAAU,WAAW,MAAM;AAAA,QACzC;AAAA,QACA;AAAA;AAEJ,WAAK,WAAW,UAAU,SAAS,MAAM;AAAA,QACrC;AAAA,QACA;AAAA;AAIJ,UAAI,UAAU,SAAS;AACvB,UAAI,SAAS;AACT,YAAI,eAAe,OAAO,OAAO;AAE7B,qBAAa,aAAa,KAAK;AAC/B,aAAK,aAAa,QAAQ,WAAW,KAAK;AAG1C,qBAAa,WAAW,KAAK;AAC7B,aAAK,WAAW,QAAQ,SAAS,KAAK;AAAA;AAI9C,aAAO;AAAA;AASX,SAAK,UAAU,SAAS,sBAAsB,SAAS,QAAQ;AAC3D,aAAO,KAAK,QAAQ,OAAO,SAAS;AAAA;AASxC,SAAK,UAAU,kBAAkB,yBAAyB,SAAS,QAAQ;AACvE,aAAO,KAAK,OAAO,SAAS,UAAU,OAAO,MAAM,OAAO,SAAS,QAAQ;AAAA;AAW/E,SAAK,UAAU,SAAS,sBAAsB,QAAQ,QAAQ;AAC1D,aAAO,KAAK,QAAQ,OAAO,QAAQ;AAAA;AAUvC,SAAK,UAAU,kBAAkB,yBAAyB,QAAQ;AAC9D,UAAI,CAAE,mBAAkB;AACpB,iBAAS,OAAO,OAAO;AAC3B,aAAO,KAAK,OAAO,QAAQ,OAAO;AAAA;AAQtC,SAAK,UAAU,SAAS,sBAAsB,SAAS;AACnD,aAAO,KAAK,QAAQ,OAAO;AAAA;AAQ/B,SAAK,UAAU,aAAa,oBAAoB,QAAQ;AACpD,aAAO,KAAK,QAAQ,WAAW;AAAA;AA4BnC,SAAK,UAAU,WAAW,kBAAkB,SAAS,SAAS;AAC1D,aAAO,KAAK,QAAQ,SAAS,SAAS;AAAA;AAkB1C,SAAK,IAAI,sBAAsB,UAAU;AACrC,aAAO,uBAAuB,QAAQ;AAClC,aAAK,aAAa,QAAQ;AAAA;AAAA;AAAA;AAAA;;;AC1kBlC;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,YAAY;AAChB,IAAE,OAAK,YAAY,OAAO,OAAO,UAAU,YAAY,cAAc,MAAM,YAAY;AAEvF,QAAI,QAAU;AAAd,QACI,OAAU;AADd,QAEI,QAAU;AAFd,QAGI,OAAU;AAEd,QAAI;AAAJ,QACI;AADJ,QAEI;AASJ,kBAAc,SAAS;AACnB,gBAAU,KAAK,MAAM,IAAI;AAMzB,WAAK,WAAW;AAMhB,WAAK,QAAQ;AAAA;AASjB,SAAK,WAAW,kBAAkB,MAAM,MAAM;AAC1C,UAAI,CAAC;AACD,eAAO,IAAI;AACf,UAAI,KAAK;AACL,aAAK,WAAW,KAAK;AACzB,aAAO,KAAK,QAAQ,KAAK;AAAA;AAW7B,SAAK,UAAU,cAAc,KAAK,KAAK;AAUvC,SAAK,UAAU,QAAQ,KAAK;AAI5B,oBAAgB;AAAA;AAShB,SAAK,UAAU,OAAO,cAAc,UAAU,SAAS,UAAU;AAC7D,UAAI,OAAO,YAAY,YAAY;AAC/B,mBAAW;AACX,kBAAU;AAAA;AAEd,UAAI,QAAO;AACX,UAAI,CAAC;AACD,eAAO,KAAK,UAAU,MAAM,OAAM,UAAU;AAEhD,UAAI,OAAO,aAAa;AAGxB,sBAAgB,KAAK,MAAM;AAEvB,YAAI,CAAC;AACD;AACJ,YAAI,KAAK;AACT,mBAAW;AACX,YAAI;AACA,gBAAM;AACV,WAAG,KAAK;AAAA;AAIZ,kCAA4B,WAAU;AAClC,YAAI,MAAM,UAAS,YAAY;AAC/B,YAAI,MAAM,IAAI;AACV,cAAI,UAAU,UAAS,UAAU;AACjC,cAAI,WAAW;AAAQ,mBAAO;AAAA;AAElC,eAAO;AAAA;AAIX,wBAAiB,WAAU,QAAQ;AAC/B,YAAI;AACA,cAAI,KAAK,SAAS,WAAW,OAAO,OAAO,OAAO;AAC9C,qBAAS,KAAK,MAAM;AACxB,cAAI,CAAC,KAAK,SAAS;AACf,kBAAK,WAAW,OAAO,SAAS,QAAQ,OAAO;AAAA,eAC9C;AACD,kBAAM,WAAW;AACjB,gBAAI,SAAS,MAAM,QAAQ,OAAM,UAC7B,WACA,KAAI;AACR,gBAAI,OAAO;AACP,qBAAO,KAAI,OAAO,QAAQ,QAAQ,EAAE;AAChC,oBAAI,YAAW,mBAAmB,OAAO,QAAQ,QAAO,MAAK,YAAY,WAAU,OAAO,QAAQ;AAC9F,wBAAM;AAAA;AAClB,gBAAI,OAAO;AACP,mBAAK,KAAI,GAAG,KAAI,OAAO,YAAY,QAAQ,EAAE;AACzC,oBAAI,YAAW,mBAAmB,OAAO,YAAY,QAAO,MAAK,YAAY,WAAU,OAAO,YAAY;AACtG,wBAAM,WAAU;AAAA;AAAA;AAAA,iBAE3B,KAAP;AACE,iBAAO;AAAA;AAEX,YAAI,CAAC,QAAQ,CAAC;AACV,iBAAO,MAAM;AAAA;AAIrB,qBAAe,WAAU,MAAM;AAG3B,YAAI,MAAK,MAAM,QAAQ,aAAY;AAC/B;AACJ,cAAK,MAAM,KAAK;AAGhB,YAAI,aAAY,QAAQ;AACpB,cAAI;AACA,qBAAQ,WAAU,OAAO;AAAA,eACxB;AACD,cAAE;AACF,uBAAW,WAAW;AAClB,gBAAE;AACF,uBAAQ,WAAU,OAAO;AAAA;AAAA;AAGjC;AAAA;AAIJ,YAAI,MAAM;AACN,cAAI;AACJ,cAAI;AACA,qBAAS,KAAK,GAAG,aAAa,WAAU,SAAS;AAAA,mBAC5C,KAAP;AACE,gBAAI,CAAC;AACD,qBAAO;AACX;AAAA;AAEJ,mBAAQ,WAAU;AAAA,eACf;AACH,YAAE;AACF,gBAAK,MAAM,WAAU,SAAS,KAAK,SAAQ;AACvC,cAAE;AAEF,gBAAI,CAAC;AACD;AACJ,gBAAI,KAAK;AAEL,kBAAI,CAAC;AACD,uBAAO;AAAA,uBACF,CAAC;AACN,uBAAO,MAAM;AACjB;AAAA;AAEJ,qBAAQ,WAAU;AAAA;AAAA;AAAA;AAI9B,UAAI,SAAS;AAIb,UAAI,KAAK,SAAS;AACd,mBAAW,CAAE;AACjB,eAAS,IAAI,GAAG,UAAU,IAAI,SAAS,QAAQ,EAAE;AAC7C,YAAI,WAAW,MAAK,YAAY,IAAI,SAAS;AACzC,gBAAM;AAEd,UAAI;AACA,eAAO;AACX,UAAI,CAAC;AACD,eAAO,MAAM;AACjB,aAAO;AAAA;AAgCX,SAAK,UAAU,WAAW,mBAAkB,UAAU,SAAS;AAC3D,UAAI,CAAC,KAAK;AACN,cAAM,MAAM;AAChB,aAAO,KAAK,KAAK,UAAU,SAAS;AAAA;AAMxC,SAAK,UAAU,aAAa,sBAAsB;AAC9C,UAAI,KAAK,SAAS;AACd,cAAM,MAAM,8BAA8B,KAAK,SAAS,IAAI,SAAS,OAAO;AACxE,iBAAO,aAAa,MAAM,SAAS,UAAU,MAAM,OAAO;AAAA,WAC3D,KAAK;AACZ,aAAO,UAAU,UAAU,WAAW,KAAK;AAAA;AAI/C,QAAI,WAAW;AAUf,gCAA4B,MAAM,OAAO;AACrC,UAAI,eAAe,MAAM,OAAO,OAAO,MAAM;AAC7C,UAAI,cAAc;AACd,YAAI,cAAc,IAAI,MAAM,MAAM,UAAU,MAAM,IAAI,MAAM,MAAM,MAAM,MAAM,QAAW,MAAM;AAC/F,oBAAY,iBAAiB;AAC7B,cAAM,iBAAiB;AACvB,qBAAa,IAAI;AACjB,eAAO;AAAA;AAEX,aAAO;AAAA;AASX,SAAK,UAAU,aAAa,oBAAoB,QAAQ;AACpD,UAAI,kBAAkB,OAAO;AAEzB,YAA2D,OAAO,WAAW,UAAuC,CAAC,OAAO;AACxH,cAAI,CAAC,mBAAmB,MAAM;AAC1B,iBAAK,SAAS,KAAK;AAAA;AAAA,iBAEpB,kBAAkB,MAAM;AAE/B,YAAI,SAAS,KAAK,OAAO;AACrB,iBAAO,OAAO,OAAO,QAAQ,OAAO;AAAA,iBAEjC,CAAE,mBAAkB,QAA6C;AAExE,YAAI,kBAAkB;AAClB,mBAAS,IAAI,GAAG,IAAI,KAAK,SAAS;AAC9B,gBAAI,mBAAmB,MAAM,KAAK,SAAS;AACvC,mBAAK,SAAS,OAAO,GAAG;AAAA;AAExB,gBAAE;AACd,iBAAS,IAAI,GAAG,IAAsB,OAAO,YAAY,QAAQ,EAAE;AAC/D,eAAK,WAAW,OAAO,aAAa;AACxC,YAAI,SAAS,KAAK,OAAO;AACrB,iBAAO,OAAO,OAAO,QAAQ;AAAA;AAAA;AAczC,SAAK,UAAU,gBAAgB,uBAAuB,QAAQ;AAC1D,UAAI,kBAAkB,OAAO;AAEzB,YAA6B,OAAO,WAAW,QAAW;AACtD,cAA0B,OAAO,gBAAgB;AAC7C,mBAAO,eAAe,OAAO,OAAO,OAAO;AAC3C,mBAAO,iBAAiB;AAAA,iBACrB;AACH,gBAAI,QAAQ,KAAK,SAAS,QAAQ;AAElC,gBAAI,QAAQ;AACR,mBAAK,SAAS,OAAO,OAAO;AAAA;AAAA;AAAA,iBAIjC,kBAAkB,MAAM;AAE/B,YAAI,SAAS,KAAK,OAAO;AACrB,iBAAO,OAAO,OAAO,OAAO;AAAA,iBAEzB,kBAAkB,WAAW;AAEpC,iBAAS,IAAI,GAAG,IAAsB,OAAO,YAAY,QAAQ,EAAE;AAC/D,eAAK,cAAc,OAAO,aAAa;AAE3C,YAAI,SAAS,KAAK,OAAO;AACrB,iBAAO,OAAO,OAAO,OAAO;AAAA;AAAA;AAMxC,SAAK,aAAa,SAAS,OAAO,QAAQ,SAAS;AAC/C,aAAS;AACT,cAAS;AACT,eAAS;AAAA;AAAA;AAAA;;;ACzWb;AAAA;AAAA;AAMA,QAAI,OAAO,QAAO,UAAU;AAE5B,QAAI,QAAQ;AAEZ,QAAI;AAAJ,QACI;AAEJ,SAAK,UAAU;AACf,SAAK,QAAU;AACf,SAAK,OAAU;AAMf,SAAK,KAAK,KAAK,QAAQ;AAOvB,SAAK,UAAU,iBAAiB,QAAQ;AACpC,UAAI,QAAQ;AACR,YAAI,OAAQ,OAAO,KAAK,SACpB,QAAQ,IAAI,MAAM,KAAK,SACvB,QAAQ;AACZ,eAAO,QAAQ,KAAK;AAChB,gBAAM,SAAS,OAAO,KAAK;AAC/B,eAAO;AAAA;AAEX,aAAO;AAAA;AAQX,SAAK,WAAW,kBAAkB,OAAO;AACrC,UAAI,SAAS,IACT,QAAS;AACb,aAAO,QAAQ,MAAM,QAAQ;AACzB,YAAI,MAAM,MAAM,UACZ,MAAM,MAAM;AAChB,YAAI,QAAQ;AACR,iBAAO,OAAO;AAAA;AAEtB,aAAO;AAAA;AAGX,QAAI,sBAAsB;AAA1B,QACI,kBAAsB;AAO1B,SAAK,aAAa,oBAAoB,OAAM;AACxC,aAAO,uTAAuT,KAAK;AAAA;AAQvU,SAAK,WAAW,kBAAkB,MAAM;AACpC,UAAI,CAAC,YAAY,KAAK,SAAS,KAAK,WAAW;AAC3C,eAAO,OAAQ,KAAK,QAAQ,qBAAqB,QAAQ,QAAQ,iBAAiB,SAAU;AAChG,aAAO,MAAM;AAAA;AAQjB,SAAK,UAAU,iBAAiB,KAAK;AACjC,aAAO,IAAI,OAAO,GAAG,gBAAgB,IAAI,UAAU;AAAA;AAGvD,QAAI,cAAc;AAOlB,SAAK,YAAY,mBAAmB,KAAK;AACrC,aAAO,IAAI,UAAU,GAAG,KACjB,IAAI,UAAU,GACT,QAAQ,aAAa,SAAS,IAAI,IAAI;AAAE,eAAO,GAAG;AAAA;AAAA;AASlE,SAAK,oBAAoB,2BAA2B,GAAG,GAAG;AACtD,aAAO,EAAE,KAAK,EAAE;AAAA;AAWpB,SAAK,eAAe,sBAAsB,MAAM,UAAU;AAGtD,UAAI,KAAK,OAAO;AACZ,YAAI,YAAY,KAAK,MAAM,SAAS,UAAU;AAC1C,eAAK,aAAa,OAAO,KAAK;AAC9B,eAAK,MAAM,OAAO;AAClB,eAAK,aAAa,IAAI,KAAK;AAAA;AAE/B,eAAO,KAAK;AAAA;AAIhB,UAAI,CAAC;AACD,eAAO;AAEX,UAAI,OAAO,IAAI,KAAK,YAAY,KAAK;AACrC,WAAK,aAAa,IAAI;AACtB,WAAK,OAAO;AACZ,aAAO,eAAe,MAAM,SAAS,EAAE,OAAO,MAAM,YAAY;AAChE,aAAO,eAAe,KAAK,WAAW,SAAS,EAAE,OAAO,MAAM,YAAY;AAC1E,aAAO;AAAA;AAGX,QAAI,oBAAoB;AAOxB,SAAK,eAAe,sBAAsB,QAAQ;AAG9C,UAAI,OAAO;AACP,eAAO,OAAO;AAGlB,UAAI,CAAC;AACD,eAAO;AAEX,UAAI,MAAM,IAAI,KAAK,SAAS,qBAAqB;AACjD,WAAK,aAAa,IAAI;AACtB,aAAO,eAAe,QAAQ,SAAS,EAAE,OAAO,KAAK,YAAY;AACjE,aAAO;AAAA;AAWX,SAAK,cAAc,qBAAqB,KAAK,MAAM,OAAO;AACtD,uBAAiB,MAAK,OAAM,QAAO;AAC/B,YAAI,OAAO,MAAK;AAChB,YAAI,MAAK,SAAS,GAAG;AACjB,eAAI,QAAQ,QAAQ,KAAI,SAAS,IAAI,OAAM;AAAA,eACxC;AACH,cAAI,YAAY,KAAI;AACpB,cAAI;AACA,qBAAQ,GAAG,OAAO,WAAW,OAAO;AACxC,eAAI,QAAQ;AAAA;AAEhB,eAAO;AAAA;AAGX,UAAI,OAAO,QAAQ;AACf,cAAM,UAAU;AACpB,UAAI,CAAC;AACD,cAAM,UAAU;AAEpB,aAAO,KAAK,MAAM;AAClB,aAAO,QAAQ,KAAK,MAAM;AAAA;AAS9B,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,KAAK,WAAW;AACZ,eAAO,MAAM,gBAAiB,OAAM,eAAe,IAAK;AAAA;AAAA;AAAA;AAAA;;;AC9MhE;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,qBAAiB,YAAY;AAE7B,QAAI,OAAO;AAEX,QAAI;AAUJ,8BAA0B,OAAM,SAAS;AAErC,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,UAAU;AAEpB,UAAI,WAAW,CAAC,KAAK,SAAS;AAC1B,cAAM,UAAU;AAMpB,WAAK,UAAU;AAMf,WAAK,gBAAgB;AAMrB,WAAK,OAAO;AAMZ,WAAK,SAAS;AAMd,WAAK,WAAW;AAMhB,WAAK,UAAU;AAMf,WAAK,WAAW;AAAA;AAGpB,WAAO,iBAAiB,iBAAiB,WAAW;AAAA,MAQhD,MAAM;AAAA,QACF,KAAK,WAAW;AACZ,cAAI,MAAM;AACV,iBAAO,IAAI,WAAW;AAClB,kBAAM,IAAI;AACd,iBAAO;AAAA;AAAA;AAAA,MAUf,UAAU;AAAA,QACN,KAAK,WAAW;AACZ,cAAI,OAAO,CAAE,KAAK,OACd,MAAM,KAAK;AACf,iBAAO,KAAK;AACR,iBAAK,QAAQ,IAAI;AACjB,kBAAM,IAAI;AAAA;AAEd,iBAAO,KAAK,KAAK;AAAA;AAAA;AAAA;AAU7B,qBAAiB,UAAU,SAAoC,kBAAkB;AAC7E,YAAM;AAAA;AAQV,qBAAiB,UAAU,QAAQ,eAAe,QAAQ;AACtD,UAAI,KAAK,UAAU,KAAK,WAAW;AAC/B,aAAK,OAAO,OAAO;AACvB,WAAK,SAAS;AACd,WAAK,WAAW;AAChB,UAAI,OAAO,OAAO;AAClB,UAAI,gBAAgB;AAChB,aAAK,WAAW;AAAA;AAQxB,qBAAiB,UAAU,WAAW,kBAAkB,QAAQ;AAC5D,UAAI,OAAO,OAAO;AAClB,UAAI,gBAAgB;AAChB,aAAK,cAAc;AACvB,WAAK,SAAS;AACd,WAAK,WAAW;AAAA;AAOpB,qBAAiB,UAAU,UAAU,oBAAmB;AACpD,UAAI,KAAK;AACL,eAAO;AACX,UAAI,KAAK,gBAAgB;AACrB,aAAK,WAAW;AACpB,aAAO;AAAA;AAQX,qBAAiB,UAAU,YAAY,mBAAmB,OAAM;AAC5D,UAAI,KAAK;AACL,eAAO,KAAK,QAAQ;AACxB,aAAO;AAAA;AAUX,qBAAiB,UAAU,YAAY,mBAAmB,OAAM,OAAO,UAAU;AAC7E,UAAI,CAAC,YAAY,CAAC,KAAK,WAAW,KAAK,QAAQ,WAAU;AACrD,QAAC,MAAK,WAAY,MAAK,UAAU,KAAK,SAAQ;AAClD,aAAO;AAAA;AAUX,qBAAiB,UAAU,kBAAkB,yBAAyB,OAAM,OAAO,UAAU;AACzF,UAAI,CAAC,KAAK,eAAe;AACrB,aAAK,gBAAgB;AAAA;AAEzB,UAAI,gBAAgB,KAAK;AACzB,UAAI,UAAU;AAGV,YAAI,MAAM,cAAc,KAAK,SAAU,MAAK;AACxC,iBAAO,OAAO,UAAU,eAAe,KAAK,MAAK;AAAA;AAErD,YAAI,KAAK;AAEL,cAAI,WAAW,IAAI;AACnB,eAAK,YAAY,UAAU,UAAU;AAAA,eAClC;AAEH,gBAAM;AACN,cAAI,SAAQ,KAAK,YAAY,IAAI,UAAU;AAC3C,wBAAc,KAAK;AAAA;AAAA,aAEpB;AAEH,YAAI,SAAS;AACb,eAAO,SAAQ;AACf,sBAAc,KAAK;AAAA;AAEvB,aAAO;AAAA;AASX,qBAAiB,UAAU,aAAa,oBAAoB,SAAS,UAAU;AAC3E,UAAI;AACA,iBAAS,OAAO,OAAO,KAAK,UAAU,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE;AAC5D,eAAK,UAAU,KAAK,IAAI,QAAQ,KAAK,KAAK;AAClD,aAAO;AAAA;AAOX,qBAAiB,UAAU,WAAW,oBAAoB;AACtD,UAAI,YAAY,KAAK,YAAY,WAC7B,WAAY,KAAK;AACrB,UAAI,SAAS;AACT,eAAO,YAAY,MAAM;AAC7B,aAAO;AAAA;AAIX,qBAAiB,aAAa,SAAS,OAAO;AAC1C,aAAO;AAAA;AAAA;AAAA;;;ACjPX;AAAA;AAAA;AACA,YAAO,UAAU;AAGjB,QAAI,mBAAmB;AACvB,IAAE,OAAK,YAAY,OAAO,OAAO,iBAAiB,YAAY,cAAc,MAAM,YAAY;AAE9F,QAAI,YAAY;AAAhB,QACI,OAAO;AAaX,kBAAc,OAAM,QAAQ,SAAS,SAAS,UAAU;AACpD,uBAAiB,KAAK,MAAM,OAAM;AAElC,UAAI,UAAU,OAAO,WAAW;AAC5B,cAAM,UAAU;AAMpB,WAAK,aAAa;AAMlB,WAAK,SAAS,OAAO,OAAO,KAAK;AAMjC,WAAK,UAAU;AAMf,WAAK,WAAW,YAAY;AAM5B,WAAK,WAAW;AAMhB,UAAI;AACA,iBAAS,OAAO,OAAO,KAAK,SAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE;AAC3D,cAAI,OAAO,OAAO,KAAK,QAAQ;AAC3B,iBAAK,WAAY,KAAK,OAAO,KAAK,MAAM,OAAO,KAAK,OAAQ,KAAK;AAAA;AAAA;AAiBjF,SAAK,WAAW,kBAAkB,OAAM,MAAM;AAC1C,UAAI,MAAM,IAAI,KAAK,OAAM,KAAK,QAAQ,KAAK,SAAS,KAAK,SAAS,KAAK;AACvE,UAAI,WAAW,KAAK;AACpB,aAAO;AAAA;AAQX,SAAK,UAAU,SAAS,gBAAgB,eAAe;AACnD,UAAI,eAAe,gBAAgB,QAAQ,cAAc,gBAAgB;AACzE,aAAO,KAAK,SAAS;AAAA,QACjB;AAAA,QAAa,KAAK;AAAA,QAClB;AAAA,QAAa,KAAK;AAAA,QAClB;AAAA,QAAa,KAAK,YAAY,KAAK,SAAS,SAAS,KAAK,WAAW;AAAA,QACrE;AAAA,QAAa,eAAe,KAAK,UAAU;AAAA,QAC3C;AAAA,QAAa,eAAe,KAAK,WAAW;AAAA;AAAA;AAapD,SAAK,UAAU,MAAM,aAAa,OAAM,IAAI,SAAS;AAGjD,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,UAAU;AAEpB,UAAI,CAAC,KAAK,UAAU;AAChB,cAAM,UAAU;AAEpB,UAAI,KAAK,OAAO,WAAU;AACtB,cAAM,MAAM,qBAAqB,QAAO,UAAU;AAEtD,UAAI,KAAK,aAAa;AAClB,cAAM,MAAM,QAAQ,KAAK,qBAAqB;AAElD,UAAI,KAAK,eAAe;AACpB,cAAM,MAAM,WAAW,QAAO,sBAAsB;AAExD,UAAI,KAAK,WAAW,QAAQ,QAAW;AACnC,YAAI,CAAE,MAAK,WAAW,KAAK,QAAQ;AAC/B,gBAAM,MAAM,kBAAkB,KAAK,SAAS;AAChD,aAAK,OAAO,SAAQ;AAAA;AAEpB,aAAK,WAAW,KAAK,OAAO,SAAQ,MAAM;AAE9C,WAAK,SAAS,SAAQ,WAAW;AACjC,aAAO;AAAA;AAUX,SAAK,UAAU,SAAS,gBAAgB,OAAM;AAE1C,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,UAAU;AAEpB,UAAI,MAAM,KAAK,OAAO;AACtB,UAAI,OAAO;AACP,cAAM,MAAM,WAAW,QAAO,yBAAyB;AAE3D,aAAO,KAAK,WAAW;AACvB,aAAO,KAAK,OAAO;AACnB,aAAO,KAAK,SAAS;AAErB,aAAO;AAAA;AAQX,SAAK,UAAU,eAAe,sBAAsB,IAAI;AACpD,aAAO,UAAU,aAAa,KAAK,UAAU;AAAA;AAQjD,SAAK,UAAU,iBAAiB,wBAAwB,OAAM;AAC1D,aAAO,UAAU,eAAe,KAAK,UAAU;AAAA;AAAA;AAAA;;;ACnLnD;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,OAAW;AAAf,QACI,QAAW;AADf,QAEI,OAAW;AAWf,4BAAwB,KAAK,OAAO,YAAY,KAAK;AACjD,aAAO,MAAM,aAAa,QACpB,IAAI,gDAAgD,YAAY,KAAM,OAAM,MAAM,IAAI,OAAO,GAAI,OAAM,MAAM,IAAI,OAAO,KACxH,IAAI,qDAAqD,YAAY,KAAM,OAAM,MAAM,IAAI,OAAO;AAAA;AAQ5G,qBAAiB,OAAO;AAEpB,UAAI,MAAM,KAAK,QAAQ,CAAC,KAAK,MAAM,MAAM,OAAO,WAC/C,UACI;AAEL,UAAI,GAAG;AAGP,UAAI,SAA2B,MAAM,YAAY,QAAQ,KAAK,KAAK;AAEnE,eAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AACpC,YAAI,QAAW,OAAO,GAAG,WACrB,QAAW,MAAM,aAAa,QAAQ,QACtC,OAAW,MAAM,wBAAwB,OAAO,UAAU,MAAM,MAChE,WAAW,MAAM,MAAM;AACvB,cAAW,MAAM,KAAK,SAAS,MAAM;AAGzC,YAAI,MAAM,KAAK;AACX,cACP,mDAAmD,KAAK,MAAM,MAC1D,oDAAoD,KAChD,4CAA6C,OAAM,MAAM,IAAI,OAAO,GAAG,IAAI,MAAM,OAAO,MAAM,UAAU,MAAM;AAC/G,cAAI,aAAa;AAAW,gBAC3B,qEAAqE,OAAO;AAAA;AACxE,gBACJ,sCAAsC,KAAK,UAAU,MAAM;AAC5D,cACH,KACJ;AAAA,mBAGc,MAAM,UAAU;AAAE,cAChC,4BAA4B,KAAK;AAG1B,cAAI,MAAM,UAAU,MAAM,OAAO,UAAU,QAAW;AAAE,gBAE3D,uBAAwB,OAAM,MAAM,IAAI,OAAO,GAC/C,gCAAgC,KAC5B,eAAe,MAAM,KACzB;AAAA,iBAGU;AAAE,gBAEZ,gCAAgC;AACzB,gBAAI,aAAa;AACrB,6BAAe,KAAK,OAAO,OAAO,MAAM;AAAA;AAC/B,kBACR,0BAA2B,OAAM,MAAM,IAAI,cAAc,GAAG,MAAM;AAAA;AAEjE,cACT;AAAA,eAGU;AACH,cAAI,MAAM;AAAU,gBAC3B,kDAAkD,KAAK,MAAM;AAEtD,cAAI,aAAa;AACrB,2BAAe,KAAK,OAAO,OAAO;AAAA;AACzB,gBACR,uBAAwB,OAAM,MAAM,IAAI,cAAc,GAAG,MAAM;AAAA;AAAA;AAKpE,aAAO,IACN;AAAA;AAAA;AAAA;;;ACjGL;AAAA;AAAA;AACA,QAAI,WAAW,QAAO,UAAU;AAEhC,aAAS,QAAQ;AAmBjB,kBAAc,UAAU,MAAM,UAAU;AACpC,UAAI,OAAO,SAAS,YAAY;AAC5B,mBAAW;AACX,eAAO,IAAI,SAAS;AAAA,iBACb,CAAC;AACR,eAAO,IAAI,SAAS;AACxB,aAAO,KAAK,KAAK,UAAU;AAAA;AA2B/B,aAAS,OAAO;AAUhB,uBAAkB,UAAU,MAAM;AAC9B,UAAI,CAAC;AACD,eAAO,IAAI,SAAS;AACxB,aAAO,KAAK,SAAS;AAAA;AAGzB,aAAS,WAAW;AAGpB,aAAS,UAAmB;AAC5B,aAAS,UAAmB;AAC5B,aAAS,WAAmB;AAC5B,aAAS,YAAmB;AAG5B,aAAS,mBAAmB;AAC5B,aAAS,YAAmB;AAC5B,aAAS,OAAmB;AAC5B,aAAS,OAAmB;AAC5B,aAAS,OAAmB;AAC5B,aAAS,QAAmB;AAC5B,aAAS,QAAmB;AAC5B,aAAS,WAAmB;AAC5B,aAAS,UAAmB;AAC5B,aAAS,SAAmB;AAG5B,aAAS,UAAmB;AAC5B,aAAS,WAAmB;AAG5B,aAAS,QAAmB;AAC5B,aAAS,OAAmB;AAG5B,aAAS,iBAAiB,WAAW,SAAS;AAC9C,aAAS,UAAU,WAAW,SAAS,MAAM,SAAS,SAAS,SAAS;AACxE,aAAS,KAAK,WAAW,SAAS;AAClC,aAAS,MAAM,WAAW,SAAS;AAAA;AAAA;;;ACvGnC;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,UAAiB;AAArB,QACI,iBAAiB;AADrB,QAEI,iBAAiB;AAErB,QAAI,eAAe;AAAnB,QACI,kBAAkB;AADtB,QAEI,oBAAoB;AAFxB,QAGI,eAAe;AAHnB,QAII,aAAa;AAEjB,QAAI,cAAc;AAAA,MACd,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA;AAUT,sBAAkB,KAAK;AACnB,aAAO,IAAI,QAAQ,YAAY,SAAS,IAAI,IAAI;AAC5C,gBAAQ;AAAA,eACC;AAAA,eACA;AACD,mBAAO;AAAA;AAEP,mBAAO,YAAY,OAAO;AAAA;AAAA;AAAA;AAK1C,aAAS,WAAW;AA2DpB,sBAAkB,QAAQ,sBAAsB;AAE5C,eAAS,OAAO;AAEhB,UAAI,SAAS,GACT,SAAS,OAAO,QAChB,OAAO,GACP,cAAc,MACd,cAAc,MACd,cAAc,GACd,mBAAmB,OACnB,mBAAmB;AAEvB,UAAI,QAAQ;AAEZ,UAAI,cAAc;AASlB,uBAAiB,SAAS;AACtB,eAAO,MAAM,aAAa,UAAU,YAAY,OAAO;AAAA;AAQ3D,4BAAsB;AAClB,YAAI,KAAK,gBAAgB,MAAM,iBAAiB;AAChD,WAAG,YAAY,SAAS;AACxB,YAAI,QAAQ,GAAG,KAAK;AACpB,YAAI,CAAC;AACD,gBAAM,QAAQ;AAClB,iBAAS,GAAG;AACZ,aAAK;AACL,sBAAc;AACd,eAAO,SAAS,MAAM;AAAA;AAS1B,sBAAgB,KAAK;AACjB,eAAO,OAAO,OAAO;AAAA;AAWzB,0BAAoB,OAAO,KAAK,WAAW;AACvC,sBAAc,OAAO,OAAO;AAC5B,sBAAc;AACd,2BAAmB;AACnB,2BAAmB;AACnB,YAAI;AACJ,YAAI,sBAAsB;AACtB,qBAAW;AAAA,eACR;AACH,qBAAW;AAAA;AAEf,YAAI,gBAAgB,QAAQ,UACxB;AACJ,WAAG;AACC,cAAI,EAAE,gBAAgB,KACb,KAAI,OAAO,OAAO,oBAAoB,MAAM;AACjD,+BAAmB;AACnB;AAAA;AAAA,iBAEC,MAAM,OAAO,MAAM;AAC5B,YAAI,QAAQ,OACP,UAAU,OAAO,KACjB,MAAM;AACX,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE;AAChC,gBAAM,KAAK,MAAM,GACZ,QAAQ,uBAAuB,kBAAkB,cAAc,IAC/D;AACT,sBAAc,MACT,KAAK,MACL;AAAA;AAGT,wCAAkC,aAAa;AAC3C,YAAI,YAAY,cAAc;AAG9B,YAAI,WAAW,OAAO,UAAU,aAAa;AAG7C,YAAI,YAAY,cAAc,KAAK;AACnC,eAAO;AAAA;AAGX,6BAAuB,QAAQ;AAE3B,YAAI,YAAY;AAChB,eAAO,YAAY,UAAU,OAAO,eAAe,MAAM;AACrD;AAAA;AAEJ,eAAO;AAAA;AAQX,sBAAgB;AACZ,YAAI,MAAM,SAAS;AACf,iBAAO,MAAM;AACjB,YAAI;AACA,iBAAO;AACX,YAAI,QACA,MACA,MACA,OACA,OACA,mBAAmB,WAAW;AAClC,WAAG;AACC,cAAI,WAAW;AACX,mBAAO;AACX,mBAAS;AACT,iBAAO,aAAa,KAAK,OAAO,OAAO,UAAU;AAC7C,gBAAI,SAAS,MAAM;AACf,iCAAmB;AACnB,gBAAE;AAAA;AAEN,gBAAI,EAAE,WAAW;AACb,qBAAO;AAAA;AAGf,cAAI,OAAO,YAAY,KAAK;AACxB,gBAAI,EAAE,WAAW,QAAQ;AACrB,oBAAM,QAAQ;AAAA;AAElB,gBAAI,OAAO,YAAY,KAAK;AACxB,kBAAI,CAAC,sBAAsB;AAEvB,wBAAQ,OAAO,QAAQ,SAAS,OAAO;AAEvC,uBAAO,OAAO,EAAE,YAAY,MAAM;AAC9B,sBAAI,WAAW,QAAQ;AACnB,2BAAO;AAAA;AAAA;AAGf,kBAAE;AACF,oBAAI,OAAO;AACP,6BAAW,OAAO,SAAS,GAAG;AAAA;AAElC,kBAAE;AACF,yBAAS;AAAA,qBACN;AAEH,wBAAQ;AACR,wBAAQ;AACR,oBAAI,yBAAyB,SAAS;AAClC,0BAAQ;AACR,qBAAG;AACC,6BAAS,cAAc;AACvB,wBAAI,WAAW,QAAQ;AACnB;AAAA;AAEJ;AAAA,2BACK,yBAAyB;AAAA,uBAC/B;AACH,2BAAS,KAAK,IAAI,QAAQ,cAAc,UAAU;AAAA;AAEtD,oBAAI,OAAO;AACP,6BAAW,OAAO,QAAQ;AAAA;AAE9B;AACA,yBAAS;AAAA;AAAA,uBAEL,QAAO,OAAO,aAAa,KAAK;AAExC,sBAAQ,SAAS;AACjB,sBAAQ,wBAAwB,OAAO,WAAW;AAClD,iBAAG;AACC,oBAAI,SAAS,MAAM;AACf,oBAAE;AAAA;AAEN,oBAAI,EAAE,WAAW,QAAQ;AACrB,wBAAM,QAAQ;AAAA;AAElB,uBAAO;AACP,uBAAO,OAAO;AAAA,uBACT,SAAS,OAAO,SAAS;AAClC,gBAAE;AACF,kBAAI,OAAO;AACP,2BAAW,OAAO,SAAS,GAAG;AAAA;AAElC,uBAAS;AAAA,mBACN;AACH,qBAAO;AAAA;AAAA;AAAA,iBAGV;AAIT,YAAI,MAAM;AACV,gBAAQ,YAAY;AACpB,YAAI,QAAQ,QAAQ,KAAK,OAAO;AAChC,YAAI,CAAC;AACD,iBAAO,MAAM,UAAU,CAAC,QAAQ,KAAK,OAAO;AACxC,cAAE;AACV,YAAI,QAAQ,OAAO,UAAU,QAAQ,SAAS;AAC9C,YAAI,UAAU,OAAQ,UAAU;AAC5B,wBAAc;AAClB,eAAO;AAAA;AASX,oBAAc,OAAO;AACjB,cAAM,KAAK;AAAA;AAQf,sBAAgB;AACZ,YAAI,CAAC,MAAM,QAAQ;AACf,cAAI,QAAQ;AACZ,cAAI,UAAU;AACV,mBAAO;AACX,eAAK;AAAA;AAET,eAAO,MAAM;AAAA;AAWjB,oBAAc,UAAU,UAAU;AAC9B,YAAI,SAAS,QACT,SAAS,WAAW;AACxB,YAAI,QAAQ;AACR;AACA,iBAAO;AAAA;AAEX,YAAI,CAAC;AACD,gBAAM,QAAQ,YAAY,SAAS,SAAS,WAAW;AAC3D,eAAO;AAAA;AASX,oBAAc,cAAc;AACxB,YAAI,MAAM;AACV,YAAI,iBAAiB,QAAW;AAC5B,cAAI,gBAAgB,OAAO,KAAM,yBAAwB,gBAAgB,OAAO,mBAAmB;AAC/F,kBAAM,mBAAmB,cAAc;AAAA;AAAA,eAExC;AAEH,cAAI,cAAc,cAAc;AAC5B;AAAA;AAEJ,cAAI,gBAAgB,gBAAgB,CAAC,oBAAqB,yBAAwB,gBAAgB,MAAM;AACpG,kBAAM,mBAAmB,OAAO;AAAA;AAAA;AAGxC,eAAO;AAAA;AAGX,aAAO,OAAO,eAAe;AAAA,QACzB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,SACD,QAAQ;AAAA,QACP,KAAK,WAAW;AAAE,iBAAO;AAAA;AAAA;AAAA;AAAA;AAAA;;;AC/YjC;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,UAAM,WAAW;AACjB,UAAM,WAAW,EAAE,UAAU;AAE7B,QAAI,WAAY;AAAhB,QACI,OAAY;AADhB,QAEI,OAAY;AAFhB,QAGI,QAAY;AAHhB,QAII,WAAY;AAJhB,QAKI,QAAY;AALhB,QAMI,OAAY;AANhB,QAOI,UAAY;AAPhB,QAQI,SAAY;AARhB,QASI,QAAY;AAThB,QAUI,OAAY;AAEhB,QAAI,WAAc;AAAlB,QACI,cAAc;AADlB,QAEI,WAAc;AAFlB,QAGI,cAAc;AAHlB,QAII,UAAc;AAJlB,QAKI,aAAc;AALlB,QAMI,WAAc;AANlB,QAOI,SAAc;AAPlB,QAQI,YAAc;AARlB,QASI,cAAc;AAmClB,mBAAe,QAAQ,MAAM,SAAS;AAElC,UAAI,CAAE,iBAAgB,OAAO;AACzB,kBAAU;AACV,eAAO,IAAI;AAAA;AAEf,UAAI,CAAC;AACD,kBAAU,MAAM;AAEpB,UAAI,wBAAwB,QAAQ,yBAAyB;AAC7D,UAAI,KAAK,SAAS,QAAQ,QAAQ,wBAAwB,QACtD,OAAO,GAAG,MACV,OAAO,GAAG,MACV,OAAO,GAAG,MACV,OAAO,GAAG,MACV,OAAO,GAAG;AAEd,UAAI,OAAO,MACP,KACA,SACA,aACA,QACA,WAAW;AAEf,UAAI,MAAM;AAEV,UAAI,YAAY,QAAQ,WAAW,SAAS,OAAM;AAAE,eAAO;AAAA,UAAU,KAAK;AAG1E,uBAAiB,QAAO,OAAM,gBAAgB;AAC1C,YAAI,WAAW,MAAM;AACrB,YAAI,CAAC;AACD,gBAAM,WAAW;AACrB,eAAO,MAAM,aAAc,UAAQ,WAAW,OAAO,SAAQ,QAAS,YAAW,WAAW,OAAO,MAAM,UAAU,GAAG,OAAO;AAAA;AAGjI,4BAAsB;AAClB,YAAI,SAAS,IACT;AACJ,WAAG;AAEC,cAAK,UAAQ,YAAY,OAAQ,WAAU;AACvC,kBAAM,QAAQ;AAElB,iBAAO,KAAK;AACZ,eAAK;AACL,mBAAQ;AAAA,iBACH,WAAU,OAAQ,WAAU;AACrC,eAAO,OAAO,KAAK;AAAA;AAGvB,yBAAmB,eAAe;AAC9B,YAAI,SAAQ;AACZ,gBAAQ;AAAA,eACC;AAAA,eACA;AACD,iBAAK;AACL,mBAAO;AAAA,eACN;AAAA,eAAa;AACd,mBAAO;AAAA,eACN;AAAA,eAAc;AACf,mBAAO;AAAA;AAEf,YAAI;AACA,iBAAO,YAAY,QAA4B;AAAA,iBAC1C,GAAP;AAGE,cAAI,iBAAiB,UAAU,KAAK;AAChC,mBAAO;AAGX,gBAAM,QAAQ,QAAO;AAAA;AAAA;AAI7B,0BAAoB,QAAQ,eAAe;AACvC,YAAI,QAAO;AACX,WAAG;AACC,cAAI,iBAAmB,WAAQ,YAAY,OAAQ,WAAU;AACzD,mBAAO,KAAK;AAAA;AAEZ,mBAAO,KAAK,CAAE,QAAQ,QAAQ,SAAS,KAAK,MAAM,QAAQ,QAAQ,UAAU;AAAA,iBAC3E,KAAK,KAAK;AACnB,aAAK;AAAA;AAGT,2BAAqB,QAAO,gBAAgB;AACxC,YAAI,OAAO;AACX,YAAI,OAAM,OAAO,OAAO,KAAK;AACzB,iBAAO;AACP,mBAAQ,OAAM,UAAU;AAAA;AAE5B,gBAAQ;AAAA,eACC;AAAA,eAAY;AAAA,eAAY;AACzB,mBAAO,OAAO;AAAA,eACb;AAAA,eAAY;AAAA,eAAY;AAAA,eAAY;AACrC,mBAAO;AAAA,eACN;AACD,mBAAO;AAAA;AAEf,YAAI,SAAS,KAAK;AACd,iBAAO,OAAO,SAAS,QAAO;AAClC,YAAI,SAAS,KAAK;AACd,iBAAO,OAAO,SAAS,QAAO;AAClC,YAAI,QAAQ,KAAK;AACb,iBAAO,OAAO,SAAS,QAAO;AAGlC,YAAI,SAAS,KAAK;AACd,iBAAO,OAAO,WAAW;AAG7B,cAAM,QAAQ,QAAO,UAAU;AAAA;AAGnC,uBAAiB,QAAO,gBAAgB;AACpC,gBAAQ;AAAA,eACC;AAAA,eAAY;AAAA,eAAY;AACzB,mBAAO;AAAA,eACN;AACD,mBAAO;AAAA;AAIf,YAAI,CAAC,kBAAkB,OAAM,OAAO,OAAO;AACvC,gBAAM,QAAQ,QAAO;AAEzB,YAAI,YAAY,KAAK;AACjB,iBAAO,SAAS,QAAO;AAC3B,YAAI,YAAY,KAAK;AACjB,iBAAO,SAAS,QAAO;AAG3B,YAAI,WAAW,KAAK;AAChB,iBAAO,SAAS,QAAO;AAG3B,cAAM,QAAQ,QAAO;AAAA;AAGzB,8BAAwB;AAGpB,YAAI,QAAQ;AACR,gBAAM,QAAQ;AAElB,cAAM;AAGN,YAAI,CAAC,UAAU,KAAK;AAChB,gBAAM,QAAQ,KAAK;AAEvB,cAAM,IAAI,OAAO;AACjB,aAAK;AAAA;AAGT,6BAAuB;AACnB,YAAI,SAAQ;AACZ,YAAI;AACJ,gBAAQ;AAAA,eACC;AACD,2BAAe,eAAgB,eAAc;AAC7C;AACA;AAAA,eACC;AACD;AAAA;AAGA,2BAAe,WAAY,WAAU;AACrC;AAAA;AAER,iBAAQ;AACR,aAAK;AACL,qBAAa,KAAK;AAAA;AAGtB,6BAAuB;AACnB,aAAK;AACL,iBAAS;AACT,mBAAW,WAAW;AAGtB,YAAI,CAAC,YAAY,WAAW;AACxB,gBAAM,QAAQ,QAAQ;AAE1B,aAAK;AAAA;AAGT,2BAAqB,QAAQ,QAAO;AAChC,gBAAQ;AAAA,eAEC;AACD,wBAAY,QAAQ;AACpB,iBAAK;AACL,mBAAO;AAAA,eAEN;AACD,sBAAU,QAAQ;AAClB,mBAAO;AAAA,eAEN;AACD,sBAAU,QAAQ;AAClB,mBAAO;AAAA,eAEN;AACD,yBAAa,QAAQ;AACrB,mBAAO;AAAA,eAEN;AACD,2BAAe,QAAQ;AACvB,mBAAO;AAAA;AAEf,eAAO;AAAA;AAGX,uBAAiB,KAAK,MAAM,QAAQ;AAChC,YAAI,eAAe,GAAG;AACtB,YAAI,KAAK;AACL,cAAG,OAAO,IAAI,YAAY,UAAU;AAClC,gBAAI,UAAU;AAAA;AAEhB,cAAI,WAAW,MAAM;AAAA;AAEzB,YAAI,KAAK,KAAK,OAAO;AACjB,cAAI;AACJ,iBAAQ,UAAQ,YAAY;AACxB,iBAAK;AACT,eAAK,KAAK;AAAA,eACP;AACH,cAAI;AACA;AACJ,eAAK;AACL,cAAI,OAAQ,QAAO,IAAI,YAAY,YAAY;AAC3C,gBAAI,UAAU,KAAK,iBAAiB,IAAI;AAAA;AAAA;AAIpD,yBAAmB,QAAQ,QAAO;AAG9B,YAAI,CAAC,OAAO,KAAK,SAAQ;AACrB,gBAAM,QAAQ,QAAO;AAEzB,YAAI,OAAO,IAAI,KAAK;AACpB,gBAAQ,MAAM,yBAAyB,QAAO;AAC1C,cAAI,YAAY,MAAM;AAClB;AAEJ,kBAAQ;AAAA,iBAEC;AACD,4BAAc,MAAM;AACpB;AAAA,iBAEC;AAAA,iBACA;AACD,yBAAW,MAAM;AACjB;AAAA,iBAEC;AAED,kBAAI,UAAU;AACV,2BAAW,MAAM;AAAA,qBACd;AACH,2BAAW,MAAM;AAAA;AAErB;AAAA,iBAEC;AACD,yBAAW,MAAM;AACjB;AAAA,iBAEC;AACD,yBAAW,KAAK,cAAe,MAAK,aAAa;AACjD;AAAA,iBAEC;AACD,yBAAW,KAAK,YAAa,MAAK,WAAW,KAAK;AAClD;AAAA;AAIA,kBAAI,CAAC,YAAY,CAAC,UAAU,KAAK;AAC7B,sBAAM,QAAQ;AAElB,mBAAK;AACL,yBAAW,MAAM;AACjB;AAAA;AAAA;AAGZ,eAAO,IAAI;AAAA;AAGf,0BAAoB,QAAQ,MAAM,QAAQ;AACtC,YAAI,OAAO;AACX,YAAI,SAAS,SAAS;AAClB,qBAAW,QAAQ;AACnB;AAAA;AAIJ,YAAI,CAAC,UAAU,KAAK;AAChB,gBAAM,QAAQ,MAAM;AAExB,YAAI,QAAO;AAGX,YAAI,CAAC,OAAO,KAAK;AACb,gBAAM,QAAQ,OAAM;AAExB,gBAAO,UAAU;AACjB,aAAK;AAEL,YAAI,QAAQ,IAAI,MAAM,OAAM,QAAQ,SAAS,MAAM,MAAM;AACzD,gBAAQ,OAAO,0BAA0B,QAAO;AAG5C,cAAI,WAAU,UAAU;AACpB,wBAAY,OAAO;AACnB,iBAAK;AAAA;AAEL,kBAAM,QAAQ;AAAA,WAEnB,2BAA2B;AAC1B,6BAAmB;AAAA;AAGvB,YAAI,SAAS,mBAAmB;AAE5B,cAAI,QAAQ,IAAI,MAAM,MAAM;AAC5B,gBAAM,UAAU,mBAAmB;AACnC,gBAAM,IAAI;AACV,iBAAO,IAAI;AAAA,eACR;AACH,iBAAO,IAAI;AAAA;AAMf,YAAI,CAAC,YAAY,MAAM,YAAa,OAAM,OAAO,UAAU,UAAa,MAAM,MAAM,UAAU;AAC1F,gBAAM,UAAU,UAAU,OAAsB;AAAA;AAGxD,0BAAoB,QAAQ,MAAM;AAC9B,YAAI,QAAO;AAGX,YAAI,CAAC,OAAO,KAAK;AACb,gBAAM,QAAQ,OAAM;AAExB,YAAI,YAAY,KAAK,QAAQ;AAC7B,YAAI,UAAS;AACT,kBAAO,KAAK,QAAQ;AACxB,aAAK;AACL,YAAI,KAAK,QAAQ;AACjB,YAAI,OAAO,IAAI,KAAK;AACpB,aAAK,QAAQ;AACb,YAAI,QAAQ,IAAI,MAAM,WAAW,IAAI,OAAM;AAC3C,cAAM,WAAW,MAAM;AACvB,gBAAQ,MAAM,0BAA0B,QAAO;AAC3C,kBAAQ;AAAA,iBAEC;AACD,0BAAY,MAAM;AAClB,mBAAK;AACL;AAAA,iBAEC;AAAA,iBACA;AACD,yBAAW,MAAM;AACjB;AAAA,iBAEC;AAED,kBAAI,UAAU;AACV,2BAAW,MAAM;AAAA,qBACd;AACH,2BAAW,MAAM;AAAA;AAErB;AAAA;AAIA,oBAAM,QAAQ;AAAA;AAAA;AAG1B,eAAO,IAAI,MACJ,IAAI;AAAA;AAGf,6BAAuB,QAAQ;AAC3B,aAAK;AACL,YAAI,UAAU;AAGd,YAAI,MAAM,OAAO,aAAa;AAC1B,gBAAM,QAAQ,SAAS;AAE3B,aAAK;AACL,YAAI,YAAY;AAGhB,YAAI,CAAC,UAAU,KAAK;AAChB,gBAAM,QAAQ,WAAW;AAE7B,aAAK;AACL,YAAI,QAAO;AAGX,YAAI,CAAC,OAAO,KAAK;AACb,gBAAM,QAAQ,OAAM;AAExB,aAAK;AACL,YAAI,QAAQ,IAAI,SAAS,UAAU,QAAO,QAAQ,SAAS,SAAS;AACpE,gBAAQ,OAAO,6BAA6B,QAAO;AAG/C,cAAI,WAAU,UAAU;AACpB,wBAAY,OAAO;AACnB,iBAAK;AAAA;AAEL,kBAAM,QAAQ;AAAA,WAEnB,8BAA8B;AAC7B,6BAAmB;AAAA;AAEvB,eAAO,IAAI;AAAA;AAGf,0BAAoB,QAAQ,QAAO;AAG/B,YAAI,CAAC,OAAO,KAAK,SAAQ;AACrB,gBAAM,QAAQ,QAAO;AAEzB,YAAI,QAAQ,IAAI,MAAM,UAAU;AAChC,gBAAQ,OAAO,0BAA0B,QAAO;AAC5C,cAAI,WAAU,UAAU;AACpB,wBAAY,OAAO;AACnB,iBAAK;AAAA,iBACF;AACH,iBAAK;AACL,uBAAW,OAAO;AAAA;AAAA;AAG1B,eAAO,IAAI;AAAA;AAGf,yBAAmB,QAAQ,QAAO;AAG9B,YAAI,CAAC,OAAO,KAAK,SAAQ;AACrB,gBAAM,QAAQ,QAAO;AAEzB,YAAI,MAAM,IAAI,KAAK;AACnB,gBAAQ,KAAK,yBAAyB,QAAO;AAC3C,kBAAO;AAAA,iBACA;AACH,0BAAY,KAAK;AACjB,mBAAK;AACL;AAAA,iBAEG;AACH,yBAAW,IAAI,YAAa,KAAI,WAAW,KAAK;AAChD;AAAA;AAGA,6BAAe,KAAK;AAAA;AAAA;AAG1B,eAAO,IAAI;AAAA;AAGf,8BAAwB,QAAQ,QAAO;AAGnC,YAAI,CAAC,OAAO,KAAK;AACb,gBAAM,QAAQ,QAAO;AAEzB,aAAK;AACL,YAAI,QAAQ,QAAQ,QAAQ,OACxB,QAAQ;AACZ,gBAAQ,OAAO,8BAA8B,QAAO;AAGhD,cAAI,WAAU,UAAU;AACpB,wBAAY,OAAO;AACnB,iBAAK;AAAA;AAEL,kBAAM,QAAQ;AAAA,WAEnB,+BAA+B;AAC9B,6BAAmB;AAAA;AAEvB,eAAO,IAAI,QAAO,OAAO,MAAM;AAAA;AAGnC,2BAAqB,QAAQ,QAAO;AAChC,YAAI,WAAW,KAAK,KAAK;AAGzB,YAAI,CAAC,UAAU,KAAK,SAAQ;AACxB,gBAAM,QAAQ,QAAO;AAEzB,YAAI,QAAO;AACX,YAAI,SAAS;AACb,YAAI;AAEJ,YAAI,UAAU;AACV,eAAK;AACL,kBAAO,MAAM,QAAO;AACpB,mBAAS;AACT,mBAAQ;AACR,cAAI,YAAY,KAAK,SAAQ;AACzB,uBAAW,OAAM,OAAO;AACxB,qBAAQ;AACR;AAAA;AAAA;AAGR,aAAK;AACL,YAAI,cAAc,iBAAiB,QAAQ;AAC3C,wBAAgB,QAAQ,QAAQ,aAAa;AAAA;AAGjD,gCAA0B,QAAQ,OAAM;AACpC,YAAI,KAAK,KAAK,OAAO;AACjB,cAAI,SAAS;AACb,iBAAO,CAAC,KAAK,KAAK,OAAO;AAErB,gBAAI,CAAC,OAAO,KAAK,QAAQ;AACrB,oBAAM,QAAQ,OAAO;AAEzB,gBAAI;AACJ,gBAAI,WAAW;AACf,gBAAI,WAAW;AACX,sBAAQ,iBAAiB,QAAQ,QAAO,MAAM;AAAA,iBAC7C;AACD,mBAAK;AACL,kBAAI,WAAW;AACX,wBAAQ,iBAAiB,QAAQ,QAAO,MAAM;AAAA,mBAC7C;AACD,wBAAQ,UAAU;AAClB,0BAAU,QAAQ,QAAO,MAAM,OAAO;AAAA;AAAA;AAG9C,gBAAI,YAAY,OAAO;AACvB,gBAAI;AACA,sBAAQ,GAAG,OAAO,WAAW,OAAO;AACxC,mBAAO,YAAY;AACnB,iBAAK,KAAK;AAAA;AAEd,iBAAO;AAAA;AAGX,YAAI,cAAc,UAAU;AAC5B,kBAAU,QAAQ,OAAM;AACxB,eAAO;AAAA;AAIX,yBAAmB,QAAQ,OAAM,OAAO;AACpC,YAAI,OAAO;AACP,iBAAO,UAAU,OAAM;AAAA;AAG/B,+BAAyB,QAAQ,OAAM,OAAO,UAAU;AACpD,YAAI,OAAO;AACP,iBAAO,gBAAgB,OAAM,OAAO;AAAA;AAG5C,kCAA4B,QAAQ;AAChC,YAAI,KAAK,KAAK,OAAO;AACjB,aAAG;AACC,wBAAY,QAAQ;AAAA,mBACf,KAAK,KAAK;AACnB,eAAK;AAAA;AAET,eAAO;AAAA;AAGX,4BAAsB,QAAQ,QAAO;AAGjC,YAAI,CAAC,OAAO,KAAK,SAAQ;AACrB,gBAAM,QAAQ,QAAO;AAEzB,YAAI,UAAU,IAAI,QAAQ;AAC1B,gBAAQ,SAAS,4BAA4B,QAAO;AAChD,cAAI,YAAY,SAAS;AACrB;AAGJ,cAAI,WAAU;AACV,wBAAY,SAAS;AAAA;AAErB,kBAAM,QAAQ;AAAA;AAEtB,eAAO,IAAI;AAAA;AAGf,2BAAqB,QAAQ,QAAO;AAGhC,YAAI,cAAc;AAElB,YAAI,OAAO;AAGX,YAAI,CAAC,OAAO,KAAK,SAAQ;AACrB,gBAAM,QAAQ,QAAO;AAEzB,YAAI,QAAO,QACP,aAAa,eACb,cAAc;AAElB,aAAK;AACL,YAAI,KAAK,UAAU;AACf,0BAAgB;AAGpB,YAAI,CAAC,UAAU,KAAK,SAAQ;AACxB,gBAAM,QAAQ;AAElB,sBAAc;AACd,aAAK;AAAM,aAAK;AAAY,aAAK;AACjC,YAAI,KAAK,UAAU;AACf,2BAAiB;AAGrB,YAAI,CAAC,UAAU,KAAK,SAAQ;AACxB,gBAAM,QAAQ;AAElB,uBAAe;AACf,aAAK;AAEL,YAAI,SAAS,IAAI,OAAO,OAAM,MAAM,aAAa,cAAc,eAAe;AAC9E,eAAO,UAAU;AACjB,gBAAQ,QAAQ,2BAA2B,QAAO;AAG9C,cAAI,WAAU,UAAU;AACpB,wBAAY,QAAQ;AACpB,iBAAK;AAAA;AAEL,kBAAM,QAAQ;AAAA;AAGtB,eAAO,IAAI;AAAA;AAGf,8BAAwB,QAAQ,QAAO;AAGnC,YAAI,CAAC,UAAU,KAAK,SAAQ;AACxB,gBAAM,QAAQ,QAAO;AAEzB,YAAI,YAAY;AAChB,gBAAQ,MAAM,8BAA8B,QAAO;AAC/C,kBAAQ;AAAA,iBAEC;AAAA,iBACA;AACD,yBAAW,QAAQ,QAAO;AAC1B;AAAA,iBAEC;AAED,kBAAI,UAAU;AACV,2BAAW,QAAQ,mBAAmB;AAAA,qBACnC;AACH,2BAAW,QAAQ,YAAY;AAAA;AAEnC;AAAA;AAIA,kBAAI,CAAC,YAAY,CAAC,UAAU,KAAK;AAC7B,sBAAM,QAAQ;AAClB,mBAAK;AACL,yBAAW,QAAQ,YAAY;AAC/B;AAAA;AAAA;AAAA;AAKhB,UAAI;AACJ,aAAQ,SAAQ,YAAY,MAAM;AAC9B,gBAAQ;AAAA,eAEC;AAGD,gBAAI,CAAC;AACD,oBAAM,QAAQ;AAElB;AACA;AAAA,eAEC;AAGD,gBAAI,CAAC;AACD,oBAAM,QAAQ;AAElB;AACA;AAAA,eAEC;AAGD,gBAAI,CAAC;AACD,oBAAM,QAAQ;AAElB;AACA;AAAA,eAEC;AAED,wBAAY,KAAK;AACjB,iBAAK;AACL;AAAA;AAKA,gBAAI,YAAY,KAAK,QAAQ;AACzB,qBAAO;AACP;AAAA;AAIJ,kBAAM,QAAQ;AAAA;AAAA;AAI1B,YAAM,WAAW;AACjB,aAAO;AAAA,QACH,WAAgB;AAAA,QAChB,WAAgB;AAAA,QACf;AAAA,QACA;AAAA,QACA;AAAA;AAAA;AAAA;AAAA;;;ACryBT;AAAA;AAAA;AACA,YAAO,UAAU;AAEjB,QAAI,WAAW;AAsBf,oBAAgB,OAAM,MAAM;AACxB,UAAI,CAAC,SAAS,KAAK,QAAO;AACtB,gBAAO,qBAAqB,QAAO;AACnC,eAAO,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAE,UAAU,EAAE,QAAQ;AAAA;AAE/D,aAAO,SAAQ;AAAA;AAYnB,WAAO,OAAO;AAAA,MAUV,KAAK;AAAA,QACD,QAAQ;AAAA,UACJ,UAAU;AAAA,YACN,MAAM;AAAA,YACN,IAAI;AAAA;AAAA,UAER,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA;AAMpB,QAAI;AAEJ,WAAO,YAAY;AAAA,MAUf,UAAU,WAAW;AAAA,QACjB,QAAQ;AAAA,UACJ,SAAS;AAAA,YACL,MAAM;AAAA,YACN,IAAI;AAAA;AAAA,UAER,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA;AAMpB,WAAO,aAAa;AAAA,MAUhB,WAAW;AAAA;AAGf,WAAO,SAAS;AAAA,MAOZ,OAAO;AAAA,QACH,QAAQ;AAAA;AAAA;AAIhB,WAAO,UAAU;AAAA,MASb,QAAQ;AAAA,QACJ,QAAQ;AAAA,UACJ,QAAQ;AAAA,YACJ,SAAS;AAAA,YACT,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAkBhB,OAAO;AAAA,QACH,QAAQ;AAAA,UACJ,MAAM;AAAA,YACF,OAAO;AAAA,cACH;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA;AAAA;AAAA;AAAA,QAIZ,QAAQ;AAAA,UACJ,WAAW;AAAA,YACP,MAAM;AAAA,YACN,IAAI;AAAA;AAAA,UAER,aAAa;AAAA,YACT,MAAM;AAAA,YACN,IAAI;AAAA;AAAA,UAER,aAAa;AAAA,YACT,MAAM;AAAA,YACN,IAAI;AAAA;AAAA,UAER,WAAW;AAAA,YACP,MAAM;AAAA,YACN,IAAI;AAAA;AAAA,UAER,aAAa;AAAA,YACT,MAAM;AAAA,YACN,IAAI;AAAA;AAAA,UAER,WAAW;AAAA,YACP,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAKhB,WAAW;AAAA,QACP,QAAQ;AAAA,UACJ,YAAY;AAAA;AAAA;AAAA,MAWpB,WAAW;AAAA,QACP,QAAQ;AAAA,UACJ,QAAQ;AAAA,YACJ,MAAM;AAAA,YACN,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA;AAMpB,WAAO,YAAY;AAAA,MASf,aAAa;AAAA,QACT,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,YAAY;AAAA,QACR,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,YAAY;AAAA,QACR,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,aAAa;AAAA,QACT,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,YAAY;AAAA,QACR,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,aAAa;AAAA,QACT,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,WAAW;AAAA,QACP,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,aAAa;AAAA,QACT,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA,MAYhB,YAAY;AAAA,QACR,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA;AAMpB,WAAO,cAAc;AAAA,MASjB,WAAW;AAAA,QACP,QAAQ;AAAA,UACJ,OAAO;AAAA,YACH,MAAM;AAAA,YACN,MAAM;AAAA,YACN,IAAI;AAAA;AAAA;AAAA;AAAA;AAqBpB,WAAO,MAAM,aAAa,MAAM;AAC5B,aAAO,OAAO,SAAS;AAAA;AAAA;AAAA;;;AC7Y3B;AAAA;AAAA;AACA,QAAI,WAAW,QAAO,UAAU;AAEhC,aAAS,QAAQ;AAGjB,aAAS,WAAmB;AAC5B,aAAS,QAAmB;AAC5B,aAAS,SAAmB;AAG5B,aAAS,KAAK,WAAW,SAAS,MAAM,SAAS,OAAO,SAAS;AAAA;AAAA;;;ACXjE;AAAA;AAEA;AACA,YAAO,UAAU;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACHjB;AAAA;AAAA;AACA,QAAI,YAAY;AAChB,YAAO,UAAU,WAAU,UAAU,aAAa,UAAU,KAAK,SAAS,sBAAkD,OAAO;AAEnI,QAAI,YAAY,UAAU;AAA1B,QACI,OAAY,UAAU;AAD1B,QAEI,OAAY,UAAU;AAF1B,QAGI,OAAY,UAAU;AAH1B,QAII,QAAY,UAAU;AAJ1B,QAKI,WAAY,UAAU;AAL1B,QAMI,QAAY,UAAU;AAN1B,QAOI,UAAY,UAAU;AAP1B,QAQI,SAAY,UAAU;AA4D1B,SAAK,iBAAiB,wBAAwB,YAAY;AAGtD,UAAI,OAAO,WAAW,WAAW;AAC7B,qBAAa,SAAQ,kBAAkB,OAAO;AAElD,UAAI,OAAO,IAAI;AAEf,UAAI,WAAW,MAAM;AACjB,YAAI,gBACA;AACJ,iBAAS,IAAI,GAAG,GAAG,IAAI,WAAW,KAAK,QAAQ,EAAE,GAAG;AAChD,wBAAc;AACd,cAAK,kBAAiB,WAAW,KAAK,IAAI,cAAc,eAAe,WAAW;AAC9E,0BAAc,KAAK,OAAO,eAAe;AAC7C,cAAI,eAAe,QAAQ,eAAe,KAAK;AAC3C,iBAAK,MAAM,KAAK,YAAY,WAAW,eAAe;AAC1D,cAAI,eAAe;AACf,iBAAK,IAAI,GAAG,IAAI,eAAe,YAAY,QAAQ,EAAE;AACjD,0BAAY,IAAI,KAAK,eAAe,eAAe,YAAY,IAAI,eAAe;AAC1F,cAAI,eAAe;AACf,iBAAK,IAAI,GAAG,IAAI,eAAe,SAAS,QAAQ,EAAE;AAC9C,0BAAY,IAAI,KAAK,eAAe,eAAe,SAAS;AACpE,cAAI,eAAe;AACf,iBAAK,IAAI,GAAG,IAAI,eAAe,UAAU,QAAQ,EAAE;AAC/C,0BAAY,IAAI,MAAM,eAAe,eAAe,UAAU;AACtE,cAAI,eAAe;AACf,iBAAK,IAAI,GAAG,IAAI,eAAe,QAAQ,QAAQ,EAAE;AAC7C,0BAAY,IAAI,QAAQ,eAAe,eAAe,QAAQ;AACtE,cAAI,OAAO,sBAAsB,eAAe,SAAS,SAAQ;AACjE,cAAI,MAAM;AACN,gBAAI,KAAK,OAAO,KAAK;AACrB,iBAAK,IAAI,GAAG,IAAI,GAAG,QAAQ,EAAE;AACzB,0BAAY,UAAU,GAAG,IAAI,KAAK,GAAG;AAAA;AAAA;AAAA;AAKrD,aAAO;AAAA;AAQX,SAAK,UAAU,eAAe,sBAAsB,QAAQ;AACxD,UAAI,MAAM,SAAQ,kBAAkB;AACpC,iCAA2B,MAAM,IAAI,MAAM;AAC3C,aAAO;AAAA;AAIX,wCAAoC,IAAI,OAAO,QAAQ;AAGnD,UAAI,OAAO,SAAQ,oBAAoB,OAAO,EAAE,MAAM,GAAG,YAAa,IAAG,SAAS,UAAU,GAAG,QAAQ,OAAO,QAAQ,UAAU;AAChI,UAAI;AACA,aAAK,SAAS;AAClB,UAAI,CAAE,eAAc;AAChB,aAAK,aAAa,GAAG,SAAS,UAAU;AAG5C,eAAS,IAAI,GAAG,QAAQ,IAAI,GAAG,YAAY,QAAQ,EAAE;AACjD,YAAK,UAAS,GAAG,aAAa,eAAe;AACzC,eAAK,YAAY,KAAK,OAAO,aAAa;AAAA,iBACrC,kBAAkB;AACvB,eAAK,SAAS,KAAK,OAAO;AAAA,iBACrB,kBAAkB;AACvB,eAAK,UAAU,KAAK,OAAO,aAAa;AAAA,iBACnC,kBAAkB;AACvB,eAAK,QAAQ,KAAK,OAAO;AAAA,iBACpB,kBAA8B;AACnC,qCAA2B,QAAQ,OAAO;AAGlD,WAAK,UAAU,oBAAoB,GAAG,SAAS,SAAQ;AAGvD,UAAI,KAAK,YAAY,SAAS,KAAK,SAAS,SAAS,KAAK,UAAU,SAAS,KAAK,QAAQ;AACtF,cAAM,KAAK;AAAA;AAwCnB,QAAI,sBAAsB;AAQ1B,SAAK,iBAAiB,wBAAwB,YAAY,QAAQ;AAG9D,UAAI,OAAO,WAAW,WAAW;AAC7B,qBAAa,SAAQ,gBAAgB,OAAO;AAGhD,UAAI,OAAO,IAAI,KAAK,WAAW,KAAK,SAAS,WAAW,OAAO,SAAS,uBAAuB,sBAAsB,WAAW,SAAS,SAAQ,kBAC7I;AAES,UAAI,WAAW;AACxB,aAAK,IAAI,GAAG,IAAI,WAAW,UAAU,QAAQ,EAAE;AAC3C,eAAK,IAAI,MAAM,eAAe,WAAW,UAAU;AAC9C,UAAI,WAAW;AACxB,aAAK,IAAI,GAAG,IAAI,WAAW,MAAM,QAAQ,EAAE,GAAG;AAC1C,cAAI,QAAQ,MAAM,eAAe,WAAW,MAAM,IAAI;AACtD,eAAK,IAAI;AACT,cAAI,WAAW,MAAM,GAAG,eAAe;AACnC,iBAAK,YAAY,WAAW,MAAM,GAAG,YAAY,IAAI;AAAA;AAE1C,UAAI,WAAW;AAClC,aAAK,IAAI,GAAG,IAAI,WAAW,UAAU,QAAQ,EAAE;AAC3C,eAAK,IAAI,MAAM,eAAe,WAAW,UAAU,IAAI;AAC5C,UAAI,WAAW;AAC9B,aAAK,IAAI,GAAG,IAAI,WAAW,WAAW,QAAQ,EAAE,GAAG;AAC/C,eAAK,IAAI,KAAK,eAAe,WAAW,WAAW,IAAI;AACvD,cAAI,WAAW,WAAW,GAAG,WAAW,WAAW,WAAW,GAAG,QAAQ;AACrE,iBAAK,UAAU,aAAa;AAAA;AAErB,UAAI,WAAW;AAC9B,aAAK,IAAI,GAAG,IAAI,WAAW,SAAS,QAAQ,EAAE;AAC1C,eAAK,IAAI,KAAK,eAAe,WAAW,SAAS;AAClC,UAAI,WAAW,kBAAkB,WAAW,eAAe,QAAQ;AACtF,aAAK,aAAa;AAClB,aAAK,IAAI,GAAG,IAAI,WAAW,eAAe,QAAQ,EAAE;AAChD,eAAK,WAAW,KAAK,CAAE,WAAW,eAAe,GAAG,OAAO,WAAW,eAAe,GAAG;AAAA;AAE9E,UAAI,WAAW,iBAAiB,WAAW,cAAc,UAAU,WAAW,gBAAgB,WAAW,aAAa,QAAQ;AAC5I,aAAK,WAAW;AACH,YAAI,WAAW;AACxB,eAAK,IAAI,GAAG,IAAI,WAAW,cAAc,QAAQ,EAAE;AAC/C,iBAAK,SAAS,KAAK,CAAE,WAAW,cAAc,GAAG,OAAO,WAAW,cAAc,GAAG;AAChF,YAAI,WAAW;AACvB,eAAK,IAAI,GAAG,IAAI,WAAW,aAAa,QAAQ,EAAE;AAC9C,iBAAK,SAAS,KAAK,WAAW,aAAa;AAAA;AAGvD,aAAO;AAAA;AAQX,SAAK,UAAU,eAAe,sBAAsB,QAAQ;AACxD,UAAI,aAAa,SAAQ,gBAAgB,OAAO,EAAE,MAAM,KAAK,SACzD;AAES,WAAK,IAAI,GAAG,IAAI,KAAK,YAAY,QAAQ,EAAE,GAAG;AACvD,YAAI;AACJ,mBAAW,MAAM,KAAK,kBAAkB,KAAK,aAAa,GAAG,aAAa;AAC1E,YAAI,KAAK,aAAa,cAAc,UAAU;AAC1C,cAAI,UAAU,iBAAiB,KAAK,aAAa,GAAG,SAAS,KAAK,aAAa,GAAG,kBAC9E,YAAY,iBAAiB,KAAK,aAAa,GAAG,MAAM,KAAK,aAAa,GAAG,eAC7E,gBAAgB,cAAyB,MAAM,cAAyB,KAClE,KAAK,aAAa,GAAG,gBAAgB,UAAU,KAAK,QAAQ,KAAK,aAAa,GAAG,iBAAiB,KAAK,aAAa,GAAG,OACvH;AACV,qBAAW,WAAW,KAAK,SAAQ,gBAAgB,OAAO;AAAA,YACtD,MAAM,gBAAgB;AAAA,YACtB,OAAO;AAAA,cACH,SAAQ,qBAAqB,OAAO,EAAE,MAAM,OAAO,QAAQ,GAAG,OAAO,GAAG,MAAM;AAAA,cAC9E,SAAQ,qBAAqB,OAAO,EAAE,MAAM,SAAS,QAAQ,GAAG,OAAO,GAAG,MAAM,WAAW,UAAU;AAAA;AAAA,YAEzG,SAAS,SAAQ,eAAe,OAAO,EAAE,UAAU;AAAA;AAAA;AAAA;AAIlD,WAAK,IAAI,GAAG,IAAI,KAAK,YAAY,QAAQ,EAAE;AACpD,mBAAW,UAAU,KAAK,KAAK,aAAa,GAAG;AACnC,WAAK,IAAI,GAAG,IAAI,KAAK,YAAY,QAAQ,EAAE,GAAG;AACnC,YAAI,KAAK,aAAa,cAAc;AACvD,qBAAW,MAAM,KAAK,KAAK,aAAa,GAAG,aAAa;AAAA,iBACvC,KAAK,aAAa,cAAc;AACjD,qBAAW,WAAW,KAAK,KAAK,aAAa,GAAG,aAAa;AAAA,iBAC5C,KAAK,aAAa,cAAc;AACjD,qBAAW,SAAS,KAAK,KAAK,aAAa,GAAG;AAAA;AAG/B,UAAI,KAAK;AAC5B,aAAK,IAAI,GAAG,IAAI,KAAK,WAAW,QAAQ,EAAE;AACtC,qBAAW,eAAe,KAAK,SAAQ,gBAAgB,eAAe,OAAO,EAAE,OAAO,KAAK,WAAW,GAAG,IAAI,KAAK,KAAK,WAAW,GAAG;AAC3H,UAAI,KAAK;AACvB,aAAK,IAAI,GAAG,IAAI,KAAK,SAAS,QAAQ,EAAE;AACxB,cAAI,OAAO,KAAK,SAAS,OAAO;AACxC,uBAAW,aAAa,KAAK,KAAK,SAAS;AAAA;AAE3C,uBAAW,cAAc,KAAK,SAAQ,gBAAgB,cAAc,OAAO,EAAE,OAAO,KAAK,SAAS,GAAG,IAAI,KAAK,KAAK,SAAS,GAAG;AAE3I,iBAAW,UAAU,oBAAoB,KAAK,SAAS,SAAQ;AAE/D,aAAO;AAAA;AAsEX,QAAI,WAAW;AAQf,UAAM,iBAAiB,wBAAwB,YAAY,QAAQ;AAG/D,UAAI,OAAO,WAAW,WAAW;AAC7B,qBAAa,SAAQ,gBAAgB,OAAO;AAEhD,UAAI,OAAO,WAAW,WAAW;AAC7B,cAAM,MAAM;AAGhB,UAAI;AACJ,UAAI,WAAW,YAAY,WAAW,SAAS;AAC3C,oBAAY,WAAW;AAAA;AAEvB,oBAAY,mBAAmB,WAAW;AAG9C,UAAI;AACJ,cAAQ,WAAW;AAAA,aAEV;AAAG,sBAAY;AAAW;AAAA,aAC1B;AAAG,sBAAY;AAAY;AAAA,aAC3B;AAAG,sBAAY;AAAY;AAAA;AACvB,gBAAM,MAAM,oBAAoB,WAAW;AAAA;AAG3D,UAAI,WAAW,WAAW;AAC1B,UAAI,WAAW,aAAa,QAAW;AACtC,mBAAW,SAAS,SAAS,WAAW;AAAA;AAEtC,UAAI,QAAQ,IAAI,MACZ,WAAW,KAAK,SAAS,WAAW,OAAO,UAAU,WAAW,QAChE,WAAW,QACX,WACA,WACA;AAGJ,YAAM,UAAU,sBAAsB,WAAW,SAAS,SAAQ;AAElE,UAAI,WAAW,gBAAgB,WAAW,aAAa,QAAQ;AAC3D,YAAI,eAAe,WAAW;AAC9B,gBAAQ;AAAA,eACC;AAAA,eAAa;AACd,2BAAe;AACf;AAAA,eACC;AAAA,eAAc;AACf,2BAAe;AACf;AAAA;AAEA,gBAAI,QAAQ,SAAS,KAAK;AAC1B,gBAAI;AACA,6BAAe,SAAS;AAC5B;AAAA;AAER,cAAM,UAAU,WAAW;AAAA;AAG/B,UAAI,uBAAuB,WAAW,OAAO;AACzC,YAAI,WAAW,UAAU;AACrB,cAAI,WAAW,WAAW,CAAC,WAAW,QAAQ;AAC1C,kBAAM,UAAU,UAAU;AAAA,mBACvB,CAAE,YAAW,WAAW,WAAW,QAAQ;AAClD,gBAAM,UAAU,UAAU;AAAA;AAGlC,aAAO;AAAA;AAQX,UAAM,UAAU,eAAe,sBAAsB,QAAQ;AACzD,UAAI,aAAa,SAAQ,qBAAqB,OAAO,EAAE,MAAM,KAAK,MAAM,QAAQ,KAAK;AAErF,UAAI,KAAK,KAAK;AAEV,mBAAW,OAAO;AAClB,mBAAW,WAAW,UAAU,KAAK,QAAQ,KAAK;AAClD,mBAAW,QAAQ;AAAA,aAEhB;AAGH,gBAAQ,WAAW,OAAO,iBAAiB,KAAK,MAAM,KAAK,UAAU;AAAA,eAC5D;AAAA,eACA;AAAA,eACA;AACD,uBAAW,WAAW,KAAK,eAAe,UAAU,KAAK,QAAQ,KAAK,gBAAgB,KAAK;AAC3F;AAAA;AAIR,gBAAQ,KAAK;AAAA,eACJ;AAAY,uBAAW,QAAQ;AAAG;AAAA,eAClC;AAAY,uBAAW,QAAQ;AAAG;AAAA;AAC9B,uBAAW,QAAQ;AAAG;AAAA;AAAA;AAMvC,iBAAW,WAAW,KAAK,iBAAiB,KAAK,eAAe,OAAO,WAAW,KAAK;AAGvF,UAAI,KAAK;AACL,YAAK,YAAW,aAAa,KAAK,OAAO,YAAY,QAAQ,KAAK,WAAW;AACzE,gBAAM,MAAM;AAAA;AAEpB,UAAI,KAAK,SAAS;AACd,mBAAW,UAAU,oBAAoB,KAAK,SAAS,SAAQ;AAC/D,YAAI,KAAK,QAAQ,cAAc;AAC3B,qBAAW,eAAe,OAAO,KAAK,QAAQ;AAAA;AAGtD,UAAI,WAAW,UAAU;AACrB,YAAI,CAAC,KAAK;AACN,UAAC,YAAW,WAAY,YAAW,UAAU,SAAQ,aAAa,WAAW,SAAS;AAAA,iBACnF,KAAK;AACZ,QAAC,YAAW,WAAY,YAAW,UAAU,SAAQ,aAAa,WAAW,SAAS;AAE1F,aAAO;AAAA;AA4BX,QAAI,mBAAmB;AAOvB,SAAK,iBAAiB,wBAAwB,YAAY;AAGtD,UAAI,OAAO,WAAW,WAAW;AAC7B,qBAAa,SAAQ,oBAAoB,OAAO;AAGpD,UAAI,SAAS;AACb,UAAI,WAAW;AACX,iBAAS,IAAI,GAAG,IAAI,WAAW,MAAM,QAAQ,EAAE,GAAG;AAC9C,cAAI,QAAQ,WAAW,MAAM,GAAG,MAC5B,QAAQ,WAAW,MAAM,GAAG,UAAU;AAC1C,iBAAO,SAAQ,MAAK,SAAS,QAAO,SAAS,SAAS;AAAA;AAG9D,aAAO,IAAI,KACP,WAAW,QAAQ,WAAW,KAAK,SAAS,WAAW,OAAO,SAAS,oBACvE,QACA,sBAAsB,WAAW,SAAS,SAAQ;AAAA;AAQ1D,SAAK,UAAU,eAAe,wBAAwB;AAGlD,UAAI,SAAS;AACb,eAAS,IAAI,GAAG,KAAK,OAAO,KAAK,KAAK,SAAS,IAAI,GAAG,QAAQ,EAAE;AAC5D,eAAO,KAAK,SAAQ,yBAAyB,OAAO,EAAE,MAAM,GAAG,IAAI,QAAQ,KAAK,OAAO,GAAG;AAE9F,aAAO,SAAQ,oBAAoB,OAAO;AAAA,QACtC,MAAM,KAAK;AAAA,QACX,OAAO;AAAA,QACP,SAAS,oBAAoB,KAAK,SAAS,SAAQ;AAAA;AAAA;AAa3D,QAAI,oBAAoB;AAOxB,UAAM,iBAAiB,wBAAwB,YAAY;AAGvD,UAAI,OAAO,WAAW,WAAW;AAC7B,qBAAa,SAAQ,qBAAqB,OAAO;AAErD,aAAO,IAAI,MAEP,WAAW,QAAQ,WAAW,KAAK,SAAS,WAAW,OAAO,UAAU;AAAA;AAShF,UAAM,UAAU,eAAe,wBAAwB;AACnD,aAAO,SAAQ,qBAAqB,OAAO;AAAA,QACvC,MAAM,KAAK;AAAA;AAAA;AAqBnB,QAAI,sBAAsB;AAO1B,YAAQ,iBAAiB,wBAAwB,YAAY;AAGzD,UAAI,OAAO,WAAW,WAAW;AAC7B,qBAAa,SAAQ,uBAAuB,OAAO;AAEvD,UAAI,UAAU,IAAI,QAAQ,WAAW,QAAQ,WAAW,KAAK,SAAS,WAAW,OAAO,YAAY,uBAAuB,sBAAsB,WAAW,SAAS,SAAQ;AAC7K,UAAI,WAAW;AACX,iBAAS,IAAI,GAAG,IAAI,WAAW,OAAO,QAAQ,EAAE;AAC5C,kBAAQ,IAAI,OAAO,eAAe,WAAW,OAAO;AAE5D,aAAO;AAAA;AAOX,YAAQ,UAAU,eAAe,wBAAwB;AAGrD,UAAI,UAAU;AACd,eAAS,IAAI,GAAG,IAAI,KAAK,aAAa,QAAQ,EAAE;AAC5C,gBAAQ,KAAK,KAAK,cAAc,GAAG;AAEvC,aAAO,SAAQ,uBAAuB,OAAO;AAAA,QACzC,MAAM,KAAK;AAAA,QACX,QAAQ;AAAA,QACR,SAAS,oBAAoB,KAAK,SAAS,SAAQ;AAAA;AAAA;AAuB3D,QAAI,qBAAqB;AAOzB,WAAO,iBAAiB,wBAAwB,YAAY;AAGxD,UAAI,OAAO,WAAW,WAAW;AAC7B,qBAAa,SAAQ,sBAAsB,OAAO;AAEtD,aAAO,IAAI,OAEP,WAAW,QAAQ,WAAW,KAAK,SAAS,WAAW,OAAO,WAAW,sBACzE,OACA,WAAW,WACX,WAAW,YACX,QAAQ,WAAW,kBACnB,QAAQ,WAAW,kBACnB,sBAAsB,WAAW,SAAS,SAAQ;AAAA;AAQ1D,WAAO,UAAU,eAAe,wBAAwB;AACpD,aAAO,SAAQ,sBAAsB,OAAO;AAAA,QACxC,MAAM,KAAK;AAAA,QACX,WAAW,KAAK,sBAAsB,KAAK,oBAAoB,WAAW,KAAK;AAAA,QAC/E,YAAY,KAAK,uBAAuB,KAAK,qBAAqB,WAAW,KAAK;AAAA,QAClF,iBAAiB,KAAK;AAAA,QACtB,iBAAiB,KAAK;AAAA,QACtB,SAAS,oBAAoB,KAAK,SAAS,SAAQ;AAAA;AAAA;AAO3D,gCAA4B,MAAM;AAC9B,cAAQ;AAAA,aAEC;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAG,iBAAO;AAAA,aACV;AAAI,iBAAO;AAAA,aACX;AAAI,iBAAO;AAAA,aACX;AAAI,iBAAO;AAAA,aACX;AAAI,iBAAO;AAAA,aACX;AAAI,iBAAO;AAAA,aACX;AAAI,iBAAO;AAAA;AAEpB,YAAM,MAAM,mBAAmB;AAAA;AAInC,oCAAgC,MAAM;AAClC,cAAQ;AAAA,aACC;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AAAA,aACA;AACD,iBAAO;AAAA;AAEf,aAAO;AAAA;AAIX,8BAA0B,MAAM,cAAc;AAC1C,cAAQ;AAAA,aAEC;AAAU,iBAAO;AAAA,aACjB;AAAS,iBAAO;AAAA,aAChB;AAAS,iBAAO;AAAA,aAChB;AAAU,iBAAO;AAAA,aACjB;AAAS,iBAAO;AAAA,aAChB;AAAW,iBAAO;AAAA,aAClB;AAAW,iBAAO;AAAA,aAClB;AAAQ,iBAAO;AAAA,aACf;AAAU,iBAAO;AAAA,aACjB;AAAS,iBAAO;AAAA,aAChB;AAAU,iBAAO;AAAA,aACjB;AAAY,iBAAO;AAAA,aACnB;AAAY,iBAAO;AAAA,aACnB;AAAU,iBAAO;AAAA,aACjB;AAAU,iBAAO;AAAA;AAE1B,UAAI,wBAAwB;AACxB,eAAO;AACX,UAAI,wBAAwB;AACxB,eAAO,aAAa,QAAQ,KAAK;AACrC,YAAM,MAAM,mBAAmB;AAAA;AAInC,mCAA+B,SAAS,MAAM;AAC1C,UAAI,CAAC;AACD,eAAO;AACX,UAAI,MAAM;AACV,eAAS,IAAI,GAAG,OAAO,KAAK,KAAK,IAAI,KAAK,YAAY,QAAQ,EAAE;AAC5D,YAAK,OAAO,SAAQ,KAAK,aAAa,IAAI,UAAU;AAChD,cAAI,QAAQ,eAAe,MAAM;AAC7B,kBAAM,QAAQ;AACd,gBAAI,MAAM,wBAAwB,QAAQ,OAAO,QAAQ,YAAY,MAAM,aAAa,WAAW,SAAS;AACxG,oBAAM,MAAM,aAAa,WAAW;AACxC,gBAAI,KAAK,WAAW,MAAM;AAAA;AAAA;AAEtC,aAAO,IAAI,SAAS,UAAU,KAAK,SAAS,OAAO;AAAA;AAIvD,iCAA6B,SAAS,MAAM;AACxC,UAAI,CAAC;AACD,eAAO;AACX,UAAI,MAAM;AACV,eAAS,IAAI,GAAG,KAAK,OAAO,KAAK,UAAU,KAAK,KAAK,IAAI,GAAG,QAAQ,EAAE,GAAG;AACrE,cAAM,QAAQ,MAAM,GAAG;AACvB,YAAI,QAAQ;AACR;AACJ,YAAI,QAAQ,KAAK,OAAO;AACxB,YAAI,CAAC,SAAS,CAAE,SAAQ,KAAK,OAAO,MAAM,UAAU,KAAK,UAAU;AAC/D;AACJ,YAAI,KAAK,KAAK;AAAA;AAElB,aAAO,IAAI,SAAS,KAAK,WAAW,UAAU,KAAK,SAAS,QAAQ;AAAA;AAIxE,uBAAmB,MAAM,IAAI;AACzB,UAAI,WAAW,KAAK,SAAS,MAAM,MAC/B,SAAS,GAAG,SAAS,MAAM,MAC3B,IAAI,GACJ,IAAI,GACJ,IAAI,OAAO,SAAS;AACxB,UAAI,CAAE,iBAAgB,SAAS,cAAc;AACzC,eAAO,IAAI,SAAS,UAAU,IAAI,KAAK,SAAS,OAAO,OAAO,IAAI;AAC9D,cAAI,QAAQ,GAAG,OAAO,SAAS,MAAM;AACrC,cAAI,UAAU,QAAQ,UAAU;AAC5B;AACJ,YAAE;AAAA;AAAA;AAGN,eAAO,IAAI,SAAS,UAAU,IAAI,KAAK,SAAS,OAAO,OAAO,IAAI,EAAE,GAAG,EAAE;AAAE;AAC/E,aAAO,OAAO,MAAM,GAAG,KAAK;AAAA;AAIhC,wBAAoB,KAAK;AACrB,aAAO,IAAI,UAAU,GAAE,KAChB,IAAI,UAAU,GACT,QAAQ,uBAAuB,SAAS,IAAI,IAAI;AAAE,eAAO,MAAM,GAAG;AAAA;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC71BlF;AAAA;AAAA;AACA,AAiBA,WAAO,eAAe,UAAS,cAAc,EAAE,OAAO;AACtD,QAAM,KAAK,QAAQ;AACnB,QAAM,OAAO,QAAQ;AACrB,QAAM,WAAW;AACjB,oCAAgC,MAAM,cAAc;AAChD,YAAM,sBAAsB,KAAK;AACjC,WAAK,cAAc,CAAC,QAAQ,WAAW;AACnC,YAAI,KAAK,WAAW,SAAS;AACzB,iBAAO;AAAA;AAEX,mBAAW,aAAa,cAAc;AAClC,gBAAM,WAAW,KAAK,KAAK,WAAW;AACtC,cAAI;AACA,eAAG,WAAW,UAAU,GAAG,UAAU;AACrC,mBAAO;AAAA,mBAEJ,KAAP;AACI;AAAA;AAAA;AAGR,gBAAQ,YAAY,GAAG,gDAAgD;AACvE,eAAO,oBAAoB,QAAQ;AAAA;AAAA;AAG3C,yCAAqC,UAAU,SAAS;AACpD,YAAM,OAAO,IAAI,SAAS;AAC1B,gBAAU,WAAW;AACrB,UAAI,CAAC,CAAC,QAAQ,aAAa;AACvB,YAAI,CAAC,MAAM,QAAQ,QAAQ,cAAc;AACrC,iBAAO,QAAQ,OAAO,IAAI,MAAM;AAAA;AAEpC,+BAAuB,MAAM,QAAQ;AAAA;AAEzC,YAAM,aAAa,MAAM,KAAK,KAAK,UAAU;AAC7C,iBAAW;AACX,aAAO;AAAA;AAEX,aAAQ,wBAAwB;AAChC,uCAAmC,UAAU,SAAS;AAClD,YAAM,OAAO,IAAI,SAAS;AAC1B,gBAAU,WAAW;AACrB,UAAI,CAAC,CAAC,QAAQ,aAAa;AACvB,YAAI,CAAC,MAAM,QAAQ,QAAQ,cAAc;AACrC,gBAAM,IAAI,MAAM;AAAA;AAEpB,+BAAuB,MAAM,QAAQ;AAAA;AAEzC,YAAM,aAAa,KAAK,SAAS,UAAU;AAC3C,iBAAW;AACX,aAAO;AAAA;AAEX,aAAQ,4BAA4B;AAIpC,+BAA2B;AAIvB,YAAM,gBAAgB;AACtB,YAAM,uBAAuB;AAC7B,YAAM,0BAA0B;AAChC,YAAM,iBAAiB;AACvB,eAAS,OAAO,OAAO,cAAc,OAAO,OAAO,OAAO,SAAS;AACnE,eAAS,OAAO,cAAc,qBAAqB,OAAO,OAAO,OAAO,SAAS;AACjF,eAAS,OAAO,kBAAkB,wBAAwB,OAAO,OAAO,OAAO,SAAS;AACxF,eAAS,OAAO,QAAQ,eAAe,OAAO,OAAO,OAAO,SAAS;AAAA;AAEzE,aAAQ,kBAAkB;AAAA;AAAA;;;ACtF1B;AAAA;AAAA;AACA,AAiBA,WAAO,eAAe,UAAS,cAAc,EAAE,OAAO;AACtD,QAAM,YAAY;AAClB,QAAM,WAAW;AACjB,QAAM,aAAa;AACnB,QAAM,SAAS;AACf,4BAAwB,KAAK;AACzB,aAAQ,WAAW,OAAS,OAAO,IAAI,aAAa;AAAA;AAExD,aAAQ,iBAAiB;AACzB,QAAM,oBAAoB;AAAA,MACtB,OAAO;AAAA,MACP,OAAO;AAAA,MACP,OAAO;AAAA,MACP,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,MAAM;AAAA;AAEV,sBAAkB,UAAU,OAAM;AAC9B,UAAI,aAAa,IAAI;AACjB,eAAO;AAAA,aAEN;AACD,eAAO,WAAW,MAAM;AAAA;AAAA;AAGhC,uCAAmC,KAAK;AACpC,aAAQ,eAAe,SAAS,WAC5B,eAAe,SAAS,QACxB,eAAe,SAAS;AAAA;AAEhC,6BAAyB,KAAK;AAC1B,aAAO,eAAe,SAAS,aAAa,eAAe,SAAS;AAAA;AAExE,4CAAwC,KAAK,YAAY;AACrD,YAAM,UAAU,SAAS,YAAY,IAAI;AACzC,UAAI,0BAA0B,MAAM;AAChC,eAAO,CAAC,CAAC,SAAS;AAAA,aAEjB;AACD,YAAI,gBAAgB,QAAQ,OAAO,IAAI,WAAW,aAAa;AAC3D,iBAAO,OAAO,KAAK,IAAI,QAClB,IAAI,WAAQ;AACb,mBAAO,+BAA+B,IAAI,OAAO,QAAO;AAAA,aAEvD,OAAO,CAAC,aAAa,iBAAiB,YAAY,OAAO,eAAe;AAAA;AAAA;AAGrF,aAAO;AAAA;AAEX,gCAA4B,KAAK,SAAS;AACtC,aAAO,qBAAqB,QAAQ;AAChC,eAAO,IAAI,SAAS,IAAI,OAAO,SAAS;AAAA;AAAA;AAGhD,8BAA0B,KAAK;AAC3B,aAAO,mBAAmB,KAAK;AAC3B,YAAI,MAAM,QAAQ,MAAM;AACpB,gBAAM,IAAI,MAAM,qDAAqD,IAAI;AAAA;AAE7E,cAAM,UAAU,IAAI,WAAW;AAC/B,eAAO,IAAI,OAAO,SAAS;AAAA;AAAA;AAGnC,oCAAgC,QAAQ,aAAa,SAAS,iBAAiB;AAG3E,YAAM,cAAc,OAAO;AAC3B,YAAM,eAAe,OAAO;AAC5B,aAAO;AAAA,QACH,MAAM,MAAM,cAAc,MAAM,OAAO;AAAA,QACvC,eAAe,CAAC,CAAC,OAAO;AAAA,QACxB,gBAAgB,CAAC,CAAC,OAAO;AAAA,QACzB,kBAAkB,iBAAiB;AAAA,QACnC,oBAAoB,mBAAmB,aAAa;AAAA,QACpD,mBAAmB,iBAAiB;AAAA,QACpC,qBAAqB,mBAAmB,cAAc;AAAA,QAEtD,cAAc,UAAU,OAAO;AAAA,QAC/B,aAAa,wBAAwB,aAAa;AAAA,QAClD,cAAc,wBAAwB,cAAc;AAAA;AAAA;AAG5D,qCAAiC,SAAS,OAAM,SAAS,iBAAiB;AACtE,YAAM,MAAM;AACZ,iBAAW,UAAU,QAAQ,cAAc;AACvC,YAAI,OAAO,QAAQ,uBAAuB,QAAQ,OAAM,SAAS;AAAA;AAErE,aAAO;AAAA;AAEX,qCAAiC,SAAS,iBAAiB;AACvD,YAAM,oBAAoB,QAAQ,aAAa;AAC/C,aAAO;AAAA,QACH,QAAQ;AAAA,QACR,MAAM,kBAAkB,MAAM,SAAS,mBAAmB;AAAA,QAC1D,sBAAsB;AAAA;AAAA;AAG9B,kCAA8B,UAAU,iBAAiB;AACrD,YAAM,iBAAiB,SAAS,aAAa;AAC7C,aAAO;AAAA,QACH,QAAQ;AAAA,QACR,MAAM,eAAe,MAAM,SAAS,gBAAgB;AAAA,QACpD,sBAAsB;AAAA;AAAA;AAU9B,8BAA0B,KAAK,OAAM,SAAS,iBAAiB;AAC3D,UAAI,eAAe,SAAS,SAAS;AACjC,eAAO,wBAAwB,KAAK,OAAM,SAAS;AAAA,iBAE9C,eAAe,SAAS,MAAM;AACnC,eAAO,wBAAwB,KAAK;AAAA,iBAE/B,eAAe,SAAS,MAAM;AACnC,eAAO,qBAAqB,KAAK;AAAA,aAEhC;AACD,cAAM,IAAI,MAAM;AAAA;AAAA;AAGxB,qCAAiC,MAAM,SAAS;AAC5C,YAAM,MAAM;AACZ,WAAK;AACL,YAAM,iBAAiB,KAAK,aAAa,UAAU;AACnD,YAAM,aAAa,eAAe,IAAI,WAAS,OAAO,KAAK,WAAW,oBAAoB,OAAO,OAAO;AACxG,iBAAW,CAAC,OAAM,QAAQ,+BAA+B,MAAM,KAAK;AAChE,YAAI,SAAQ,iBAAiB,KAAK,OAAM,SAAS;AAAA;AAErD,aAAO;AAAA;AAEX,sDAAkD,sBAAsB,SAAS;AAC7E,gBAAU,WAAW;AACrB,YAAM,OAAO,SAAS,KAAK,eAAe;AAC1C,WAAK;AACL,aAAO,wBAAwB,MAAM;AAAA;AA4BzC,kBAAc,UAAU,SAAS;AAC7B,aAAO,OAAO,sBAAsB,UAAU,SAAS,KAAK,gBAAc;AACtE,eAAO,wBAAwB,YAAY;AAAA;AAAA;AAGnD,aAAQ,OAAO;AACf,uBAAkB,UAAU,SAAS;AACjC,YAAM,aAAa,OAAO,0BAA0B,UAAU;AAC9D,aAAO,wBAAwB,YAAY;AAAA;AAE/C,aAAQ,WAAW;AACnB,sBAAkB,MAAM,SAAS;AAC7B,gBAAU,WAAW;AACrB,YAAM,aAAa,SAAS,KAAK,SAAS;AAC1C,iBAAW;AACX,aAAO,wBAAwB,YAAY;AAAA;AAE/C,aAAQ,WAAW;AACnB,6CAAyC,eAAe,SAAS;AAC7D,YAAM,uBAAuB,WAAW,kBAAkB,OAAO;AACjE,aAAO,yCAAyC,sBAAsB;AAAA;AAE1E,aAAQ,kCAAkC;AAC1C,6CAAyC,eAAe,SAAS;AAC7D,YAAM,uBAAuB,WAAW,kBAAkB,WAAW;AACrE,aAAO,yCAAyC,sBAAsB;AAAA;AAE1E,aAAQ,kCAAkC;AAC1C,WAAO;AAAA;AAAA;;;;;;;;ACrMP,QAAA,QAAA,QAAA;AACA,QAAA,uBAAA;AACA,QAAA,cAAA;AAWA,QAAA,uBAAA;AAsBA,QAAA,UAAA;AACA,QAAA,gBAAA;AA2BA,iCAA6B,KAAe;AAC1C,aAAO;QACL,YAAY,IAAI;QAChB,MAAM,IAAI;;;AAId,oCAAgC,KAAkB;AAChD,aAAO;QACL,eAAe,IAAI;QACnB,MAAM,IAAI;;;AAId,gCAA4B,KAAc;AACxC,aAAO;QACL,WAAW,IAAI;;;AAInB,gCAA4B,KAAc;AACxC,aAAO;QACL,WAAW,IAAI;QACf,MAAM,IAAI;;;AAkBd,QAAM,yBAAyB;AAE/B,8BAA0B;MAKxB,cAAA;AAJA,aAAA,SAAuB;AAEvB,aAAA,eAAuB;AAGrB,aAAK,oBAAoB,IAAI;;MAG/B,SAAS,UAAyB,aAAqB,OAAkC;AACvF,cAAM,YAAY,IAAI;AACtB,aAAK,OAAO,KAAK;UACf;UACA;UACA;UACA,cAAc,WAAK,QAAL,UAAK,SAAA,SAAL,MAAO,UAAS,YAAY,QAAQ;UAClD,iBAAiB,WAAK,QAAL,UAAK,SAAA,SAAL,MAAO,UAAS,eAAe,QAAQ;;AAG1D,YAAI,KAAK,OAAO,UAAU,yBAAyB,GAAG;AACpD,eAAK,SAAS,KAAK,OAAO,MAAM;;AAElC,aAAK,gBAAgB;;MAGvB,kBAAe;AACb,eAAO;UACL,oBAAoB,qBAAqB,KAAK;UAC9C,mBAAmB,KAAK;UACxB,QAAQ,KAAK,OAAO,IAAI,WAAQ;AAC9B,mBAAO;cACL,aAAa,MAAM;cACnB,UAAU,MAAM;cAChB,WAAW,qBAAqB,MAAM;cACtC,aAAa,MAAM,eAAe,oBAAoB,MAAM,gBAAgB;cAC5E,gBAAgB,MAAM,kBAAkB,uBAAuB,MAAM,mBAAmB;;;;;;AAnClG,aAAA,gBAAA;AA0CA,wCAAoC;MAApC,cAAA;AACU,aAAA,kBAAiE,IAAI;AACrE,aAAA,qBAAuE,IAAI;AAC3E,aAAA,iBAA+D,IAAI;;MAE3E,SAAS,OAA6C;;AACpD,gBAAQ,MAAM;eACP,WAAW;AACd,gBAAI,eAAY,MAAG,KAAK,gBAAgB,IAAI,MAAM,SAAG,QAAA,OAAA,SAAA,KAAI,EAAC,KAAK,OAAO,OAAO;AAC7E,yBAAa,SAAS;AACtB,iBAAK,gBAAgB,IAAI,MAAM,IAAI;AACnC;;eAEG,cAAa;AAChB,gBAAI,eAAY,MAAG,KAAK,mBAAmB,IAAI,MAAM,SAAG,QAAA,OAAA,SAAA,KAAI,EAAC,KAAK,OAAO,OAAO;AAChF,yBAAa,SAAS;AACtB,iBAAK,mBAAmB,IAAI,MAAM,IAAI;AACtC;;eAEG,UAAS;AACZ,gBAAI,eAAY,MAAG,KAAK,eAAe,IAAI,MAAM,SAAG,QAAA,OAAA,SAAA,KAAI,EAAC,KAAK,OAAO,OAAO;AAC5E,yBAAa,SAAS;AACtB,iBAAK,eAAe,IAAI,MAAM,IAAI;AAClC;;;;MAKN,WAAW,OAA6C;AACtD,gBAAQ,MAAM;eACP,WAAW;AACd,gBAAI,eAAe,KAAK,gBAAgB,IAAI,MAAM;AAClD,gBAAI,iBAAiB,QAAW;AAC9B,2BAAa,SAAS;AACtB,kBAAI,aAAa,UAAU,GAAG;AAC5B,qBAAK,gBAAgB,OAAO,MAAM;qBAC7B;AACL,qBAAK,gBAAgB,IAAI,MAAM,IAAI;;;AAGvC;;eAEG,cAAc;AACjB,gBAAI,eAAe,KAAK,mBAAmB,IAAI,MAAM;AACrD,gBAAI,iBAAiB,QAAW;AAC9B,2BAAa,SAAS;AACtB,kBAAI,aAAa,UAAU,GAAG;AAC5B,qBAAK,mBAAmB,OAAO,MAAM;qBAChC;AACL,qBAAK,mBAAmB,IAAI,MAAM,IAAI;;;AAG1C;;eAEG,UAAU;AACb,gBAAI,eAAe,KAAK,eAAe,IAAI,MAAM;AACjD,gBAAI,iBAAiB,QAAW;AAC9B,2BAAa,SAAS;AACtB,kBAAI,aAAa,UAAU,GAAG;AAC5B,qBAAK,eAAe,OAAO,MAAM;qBAC5B;AACL,qBAAK,eAAe,IAAI,MAAM,IAAI;;;AAGtC;;;;MAKN,gBAAa;AACX,cAAM,YAAyB;AAC/B,mBAAW,EAAC,SAAQ,KAAK,gBAAgB,UAAU;AACjD,oBAAS,KAAK;;AAEhB,cAAM,eAA+B;AACrC,mBAAW,EAAC,SAAQ,KAAK,mBAAmB,UAAU;AACpD,uBAAY,KAAK;;AAEnB,cAAM,WAAuB;AAC7B,mBAAW,EAAC,SAAQ,KAAK,eAAe,UAAU;AAChD,mBAAQ,KAAK;;AAEf,eAAO,EAAC,qBAAU,2BAAa;;;AAlFnC,aAAA,0BAAA;AAsFA,oCAAgC;MAAhC,cAAA;AACE,aAAA,eAAuB;AACvB,aAAA,iBAAyB;AACzB,aAAA,cAAsB;AACtB,aAAA,2BAAwC;;MAExC,iBAAc;AACZ,aAAK,gBAAgB;AACrB,aAAK,2BAA2B,IAAI;;MAEtC,mBAAgB;AACd,aAAK,kBAAkB;;MAEzB,gBAAa;AACX,aAAK,eAAe;;;AAdxB,aAAA,sBAAA;AAuFA,QAAI,SAAS;AAEb,yBAAkB;AAChB,aAAO;;AAGT,QAAM,WAAyC;AAC/C,QAAM,cAA+C;AACrD,QAAM,UAAuC;AAC7C,QAAM,UAAuC;AAE7C,qCAAwC,OAAc,SAA0B;AAC9E,YAAM,KAAK;AACX,YAAM,MAAkB,EAAC,IAAI,aAAM,MAAM;AACzC,eAAS,MAAM,EAAE,KAAK;AACtB,aAAO;;AAJT,aAAA,0BAAA;AAOA,wCAA2C,OAAc,SAA4B;AACnF,YAAM,KAAK;AACX,YAAM,MAAqB,EAAC,IAAI,aAAM,MAAM;AAC5C,kBAAY,MAAM,EAAE,KAAK;AACzB,aAAO;;AAJT,aAAA,6BAAA;AAOA,oCAAuC,SAAyB;AAC9D,YAAM,KAAK;AACX,YAAM,MAAiB,EAAC,IAAI,MAAM;AAClC,cAAQ,MAAM,EAAE,KAAK;AACrB,aAAO;;AAJT,aAAA,yBAAA;AAOA,oCAAuC,OAAc,SAAyB;AAC5E,YAAM,KAAK;AACX,YAAM,MAAiB,EAAC,IAAI,aAAM,MAAM;AACxC,cAAQ,MAAM,EAAE,KAAK;AACrB,aAAO;;AAJT,aAAA,yBAAA;AAOA,mCAAsC,KAAuD;AAC3F,cAAQ,IAAI;aACL;AACH,iBAAO,SAAS,IAAI;AACpB;aACG;AACH,iBAAO,YAAY,IAAI;AACvB;aACG;AACH,iBAAO,QAAQ,IAAI;AACnB;aACG;AACH,iBAAO,QAAQ,IAAI;AACnB;;;AAbN,aAAA,wBAAA;AAsBA,8BAA0B,gBAAsB;AAC9C,YAAM,cAAc,OAAO,SAAS,gBAAgB;AACpD,aAAO,CAAC,cAAc,MAAM,GAAG,cAAc;;AAS/C,4BAAwB,cAAoB;AAC1C,UAAI,iBAAiB,IAAI;AACvB,eAAO;;AAET,YAAM,YAAY,aAAa,MAAM,KAAK,IAAI,aAAW,iBAAiB;AAC1E,YAAM,SAAmB;AACzB,aAAO,OAAO,OAAO,GAAG;;AAS1B,qCAAiC,WAAiB;AAChD,UAAI,MAAA,OAAO,YAAY;AACrB,eAAO,OAAO,KAAK,WAAW,KAAK,UAAU,MAAM,KAAK,IAAI,aAAW,OAAO,SAAS;iBAC9E,MAAA,OAAO,YAAY;AAC5B,YAAI;AACJ,YAAI;AACJ,cAAM,mBAAmB,UAAU,QAAQ;AAC3C,YAAI,qBAAqB,IAAI;AAC3B,wBAAc;AACd,yBAAe;eACV;AACL,wBAAc,UAAU,UAAU,GAAG;AACrC,yBAAe,UAAU,UAAU,mBAAmB;;AAExD,cAAM,aAAa,OAAO,KAAK,eAAe;AAC9C,cAAM,cAAc,OAAO,KAAK,eAAe;AAC/C,cAAM,eAAe,OAAO,MAAM,KAAK,WAAW,SAAS,YAAY,QAAQ;AAC/E,eAAO,OAAO,OAAO,CAAC,YAAY,cAAc;aAC3C;AACL,eAAO;;;AAIX,wCAAoC,OAAwB;AAC1D,cAAQ;aACD,qBAAA,kBAAkB;AACrB,iBAAO;YACL,OAAO;;aAEN,qBAAA,kBAAkB;AACrB,iBAAO;YACL,OAAO;;aAEN,qBAAA,kBAAkB;AACrB,iBAAO;YACL,OAAO;;aAEN,qBAAA,kBAAkB;AACrB,iBAAO;YACL,OAAO;;aAEN,qBAAA,kBAAkB;AACrB,iBAAO;YACL,OAAO;;;AAGT,iBAAO;YACL,OAAO;;;;AAKf,kCAA8B,MAAkB;AAC9C,UAAI,CAAC,MAAM;AACT,eAAO;;AAET,YAAM,mBAAmB,KAAK;AAC9B,aAAO;QACL,SAAU,mBAAmB,MAAQ;QACrC,OAAQ,mBAAmB,MAAQ;;;AAIvC,+BAA2B,cAA0B;AACnD,YAAM,eAAe,aAAa;AAClC,aAAO;QACL,KAAK,oBAAoB,aAAa;QACtC,MAAM;UACJ,QAAQ,aAAa;UACrB,OAAO,2BAA2B,aAAa;UAC/C,eAAe,aAAa,YAAY;UACxC,iBAAiB,aAAa,YAAY;UAC1C,cAAc,aAAa,YAAY;UACvC,6BAA6B,qBAAqB,aAAa,YAAY;UAC3E,OAAO,aAAa,MAAM;;QAE5B,aAAa,aAAa,SAAS,SAAS,IAAI,SAAO,oBAAoB;QAC3E,gBAAgB,aAAa,SAAS,YAAY,IAAI,SAAO,uBAAuB;;;AAIxF,wBAAoB,MAAsE,UAA2C;AACnI,YAAM,YAAY,OAAO,SAAS,KAAK,QAAQ;AAC/C,YAAM,eAAe,SAAS;AAC9B,UAAI,iBAAiB,QAAW;AAC9B,iBAAS;UACP,QAAQ,YAAA,OAAO;UACf,WAAW,kCAAkC;;AAE/C;;AAEF,eAAS,MAAM,EAAC,SAAS,kBAAkB;;AAG7C,4BAAwB,MAA8E,UAA+C;AACnJ,YAAM,aAAa,OAAO,SAAS,KAAK,QAAQ;AAChD,YAAM,aAA+B;AACrC,UAAI,IAAI,OAAO,SAAS,KAAK,QAAQ;AACrC,aAAO,IAAI,SAAS,QAAQ,KAAK;AAC/B,cAAM,eAAe,SAAS;AAC9B,YAAI,iBAAiB,QAAW;AAC9B;;AAEF,mBAAW,KAAK,kBAAkB;AAClC,YAAI,WAAW,UAAU,YAAY;AACnC;;;AAGJ,eAAS,MAAM;QACb,SAAS;QACT,KAAK,KAAK,QAAQ;;;AAItB,8BAA0B,aAAwB;AAChD,YAAM,eAAe,YAAY;AACjC,aAAO;QACL,KAAK,mBAAmB,YAAY;QACpC,MAAM;UACJ,eAAe,aAAa,YAAY;UACxC,iBAAiB,aAAa,YAAY;UAC1C,cAAc,aAAa,YAAY;UACvC,6BAA6B,qBAAqB,aAAa,YAAY;UAC3E,OAAO,aAAa,MAAM;;QAE5B,eAAe,aAAa,iBAAiB,QAAQ,IAAI,SAAO,mBAAmB;;;AAIvF,uBAAmB,MAAoE,UAA0C;AAC/H,YAAM,WAAW,OAAO,SAAS,KAAK,QAAQ;AAC9C,YAAM,cAAc,QAAQ;AAC5B,UAAI,gBAAgB,QAAW;AAC7B,iBAAS;UACP,QAAQ,YAAA,OAAO;UACf,WAAW,iCAAiC;;AAE9C;;AAEF,eAAS,MAAM,EAAC,QAAQ,iBAAiB;;AAG3C,wBAAoB,MAAsE,UAA2C;AACnI,YAAM,aAAa,OAAO,SAAS,KAAK,QAAQ;AAChD,YAAM,aAA8B;AACpC,UAAI,IAAI,OAAO,SAAS,KAAK,QAAQ;AACrC,aAAO,IAAI,QAAQ,QAAQ,KAAK;AAC9B,cAAM,cAAc,QAAQ;AAC5B,YAAI,gBAAgB,QAAW;AAC7B;;AAEF,mBAAW,KAAK,iBAAiB;AACjC,YAAI,WAAW,UAAU,YAAY;AACnC;;;AAGJ,eAAS,MAAM;QACb,QAAQ;QACR,KAAK,KAAK,QAAQ;;;AAItB,2BAAuB,MAA4E,UAA8C;AAC/I,YAAM,eAAe,OAAO,SAAS,KAAK,QAAQ;AAClD,YAAM,kBAAkB,YAAY;AACpC,UAAI,oBAAoB,QAAW;AACjC,iBAAS;UACP,QAAQ,YAAA,OAAO;UACf,WAAW,qCAAqC;;AAElD;;AAEF,YAAM,eAAe,gBAAgB;AACrC,YAAM,oBAAuC;QAC3C,KAAK,uBAAuB,gBAAgB;QAC5C,MAAM;UACJ,QAAQ,aAAa;UACrB,OAAO,2BAA2B,aAAa;UAC/C,eAAe,aAAa,YAAY;UACxC,iBAAiB,aAAa,YAAY;UAC1C,cAAc,aAAa,YAAY;UACvC,6BAA6B,qBAAqB,aAAa,YAAY;UAC3E,OAAO,aAAa,MAAM;;QAE5B,YAAY,aAAa,SAAS,QAAQ,IAAI,SAAO,mBAAmB;;AAE1E,eAAS,MAAM,EAAC,YAAY;;AAG9B,+CAA2C,mBAAoC;;AAC7E,UAAI,qBAAA,uBAAuB,oBAAoB;AAC7C,eAAO;UACL,SAAS;UACT,eAAe;YACb,YAAU,MAAE,wBAAwB,kBAAkB,WAAK,QAAA,OAAA,SAAA,KAAI;YAC/D,MAAM,kBAAkB;;;aAGvB;AACL,eAAO;UACL,SAAS;UACT,aAAa;YACX,UAAU,kBAAkB;;;;;AAMpC,uBAAmB,MAAoE,UAA0C;;AAC/H,YAAM,WAAW,OAAO,SAAS,KAAK,QAAQ;AAC9C,YAAM,cAAc,QAAQ;AAC5B,UAAI,gBAAgB,QAAW;AAC7B,iBAAS;UACP,QAAQ,YAAA,OAAO;UACf,WAAW,iCAAiC;;AAE9C;;AAEF,YAAM,eAAe,YAAY;AACjC,YAAM,kBAAmC,aAAa,WAAW;QAC/D,OAAO;QACP,KAAK;UACH,cAAc,aAAa,SAAS,0BAA0B,kBAAkB;UAChF,eAAa,MAAE,aAAa,SAAS,6BAAuB,QAAA,OAAA,SAAA,KAAI;UAChE,YAAU,MAAE,aAAa,SAAS,0BAAoB,QAAA,OAAA,SAAA,KAAI;UAC1D,mBAAiB,MAAE,aAAa,SAAS,sBAAgB,QAAA,OAAA,SAAA,KAAI;UAC7D,oBAAkB,MAAE,aAAa,SAAS,uBAAiB,QAAA,OAAA,SAAA,KAAI;;UAE/D;AACJ,YAAM,gBAA+B;QACnC,KAAK,mBAAmB,YAAY;QACpC,OAAO,aAAa,eAAe,kCAAkC,aAAa,gBAAgB;QAClG,QAAQ,aAAa,gBAAgB,kCAAkC,aAAa,iBAAiB;QACrG,aAAW,MAAE,aAAa,gBAAU,QAAA,OAAA,SAAA,KAAI;QACxC,UAAU;QACV,MAAM;UACJ,kBAAkB,aAAa;UAC/B,iBAAiB,aAAa;UAC9B,mBAAmB,aAAa;UAChC,gBAAgB,aAAa;UAC7B,qCAAqC,qBAAqB,aAAa;UACvE,sCAAsC,qBAAqB,aAAa;UACxE,mBAAmB,aAAa;UAChC,eAAe,aAAa;UAC5B,iCAAiC,qBAAqB,aAAa;UACnE,6BAA6B,qBAAqB,aAAa;UAC/D,2BAA2B,aAAa,yBAAyB,EAAE,OAAO,aAAa,2BAA2B;UAClH,4BAA4B,aAAa,0BAA0B,EAAE,OAAO,aAAa,4BAA4B;;;AAGzH,eAAS,MAAM,EAAC,QAAQ;;AAG1B,8BAA0B,MAAkF,UAAiD;AAC3J,YAAM,WAAW,OAAO,SAAS,KAAK,QAAQ;AAC9C,YAAM,cAAc,QAAQ;AAC5B,UAAI,gBAAgB,QAAW;AAC7B,iBAAS;UACP,QAAQ,YAAA,OAAO;UACf,WAAW,iCAAiC;;AAE9C;;AAEF,YAAM,UAAU,OAAO,SAAS,KAAK,QAAQ;AAC7C,YAAM,aAAa,OAAO,SAAS,KAAK,QAAQ;AAChD,YAAM,eAAe,YAAY;AAIjC,YAAM,aAAa,aAAa,gBAAgB,QAAQ,KAAK,CAAC,MAAM,SAAS,KAAK,KAAK,KAAK;AAC5F,YAAM,aAAiC;AACvC,UAAI,IAAI;AACR,aAAO,IAAI,WAAW,QAAQ,KAAK;AACjC,YAAI,WAAW,GAAG,MAAM,SAAS;AAC/B,qBAAW,KAAK,mBAAmB,WAAW;AAC9C,cAAI,WAAW,UAAU,YAAY;AACnC;;;;AAIN,eAAS,MAAM;QACb,YAAY;QACZ,KAAK,KAAK,WAAW;;;AAIzB,mCAAmC;AACjC,aAAO;QACL;QACA;QACA;QACA;QACA;QACA;QACA;;;AARJ,aAAA,sBAAA;AAYA,QAAI,2BAAsD;AAE1D,4CAA4C;AAC1C,UAAI,0BAA0B;AAC5B,eAAO;;AAIT,YAAM,iBAAiB,eAA8B;AACrD,YAAM,cAAc,eAAe,kBAAkB;QACnD,UAAU;QACV,OAAO;QACP,OAAO;QACP,UAAU;QACV,QAAQ;QACR,aAAa;UACX,GAAG;;;AAGP,YAAM,qBAAqB,cAAA,sBAAsB;AACjD,iCAA2B,mBAAmB,KAAK,SAAS,GAAG,SAAS;AACxE,aAAO;;AAnBT,aAAA,+BAAA;AAsBA,qBAAqB;AACnB,cAAA,qBAAqB,8BAA8B;;AADrD,aAAA,QAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1tBA,QAAA,QAAA,QAAA;AAKA,QAAA,QAAA,QAAA;AACA,QAAA,uBAAA;AACA,QAAA,oBAAA;AACA,QAAA,aAAA;AACA,QAAA,UAAA;AACA,QAAA,cAAA;AACA,QAAA,eAAA;AACA,QAAA,MAAA,QAAA;AACA,QAAA,eAAA;AAGA,QAAA,uBAAA;AAKA,QAAA,aAAA;AAEA,QAAM,gBAAgB,kBAA8B;AAEpD,QAAM,cAAc;AAWpB,QAAM,wBAAwB,CAAE,MAAK;AACrC,QAAM,uBAAuB;AAa7B,QAAM,EACJ,wBACA,2BACA,qBACA,mBACA,iBACA,4BACE,MAAM;AAWV,QAAM,mBAA2B,OAAO,KAAK,kBAAkB;AAE/D,2BAAuB;MAsGrB,YACU,eACA,mBACA,SACA,cAA+B;AAH/B,aAAA,gBAAA;AACA,aAAA,oBAAA;AACA,aAAA,UAAA;AACA,aAAA,cAAA;AArGF,aAAA,oBAAuC,qBAAA,kBAAkB;AAIzD,aAAA,UAA2C;AAK3C,aAAA,qBAAqB;AAMrB,aAAA,iBAA8C;AAO9C,aAAA,sBAAyC;AAYzC,aAAA,kBAA0B;AAI1B,aAAA,qBAA6B;AAY7B,aAAA,wBAAwB;AAKxB,aAAA,eAAe;AAIf,aAAA,WAAW;AAQF,aAAA,kBAA2B;AAGpC,aAAA,cAAc,IAAI,WAAA;AAClB,aAAA,kBAAkB,IAAI,WAAA;AAGtB,aAAA,oBAAsC;AAKtC,aAAA,aAA4B;AAC5B,aAAA,gBAAgB,IAAI,WAAA;AACpB,aAAA,iBAAiB;AACjB,aAAA,eAAe;AACf,aAAA,mBAAmB;AACnB,aAAA,2BAAwC;AACxC,aAAA,+BAA4C;AAmBlD,aAAK,YAAY;UACf,QAAQ;UACR,gBAAgB;UAChB,QAAQ;UAEP,OAAO,CAAC,MAAM,GACd,KAAK;AAER,YAAI,4BAA4B,SAAS;AACvC,eAAK,kBAAkB,QAAQ;;AAEjC,YAAI,+BAA+B,SAAS;AAC1C,eAAK,qBAAqB,QAAQ;;AAEpC,YAAI,yCAAyC,SAAS;AACpD,eAAK,wBACH,QAAQ,2CAA2C;eAChD;AACL,eAAK,wBAAwB;;AAE/B,aAAK,sBAAsB,WAAW,MAAK;WAAK;AAChD,qBAAa,KAAK;AAClB,aAAK,qBAAqB,WAAW,MAAK;WAAK;AAC/C,qBAAa,KAAK;AAClB,cAAM,iBAAiC;UACrC,cAAc,QAAQ;UACtB,UAAU,QAAQ;;AAEpB,aAAK,iBAAiB,IAAI,kBAAA,eAAe,MAAK;AAC5C,eAAK;WACJ;AACH,aAAK,0BAA0B,qBAAA,0BAA0B;AAEzD,YAAI,QAAQ,4BAA4B,GAAG;AACzC,eAAK,kBAAkB;;AAEzB,aAAK,gBAAgB,IAAI,WAAA;AACzB,YAAI,KAAK,iBAAiB;AACxB,eAAK,cAAc,WAAA,2BAA2B,KAAK,yBAAyB,MAAM,KAAK;AACvF,eAAK,cAAc,SAAS,WAAW;eAClC;AAEL,eAAK,cAAc;YACjB,MAAM;YACN,IAAI;YACJ,MAAM;;;AAGV,aAAK,MAAM,yCAAyC,KAAK,UAAU,SAAS,QAAW;;MAGjF,kBAAe;AACrB,eAAO;UACL,OAAO,KAAK;UACZ,OAAO,KAAK;UACZ,aAAa,KAAK;UAClB,UAAU,KAAK,gBAAgB;UAC/B,QAAQ,KAAK;;;MAIT,wBAAqB;;AAC3B,YAAI,KAAK,YAAY,MAAM;AACzB,iBAAO;;AAET,cAAM,gBAAgB,KAAK,QAAQ;AACnC,cAAM,gBAAgB,cAAc,gBAAgB,qBAAA,0BAA0B,cAAc,eAAe,cAAc,cAAc;AACvI,cAAM,eAAe,cAAc,eAAe,qBAAA,0BAA0B,cAAc,cAAc,cAAc,aAAa;AACnI,YAAI;AACJ,YAAI,KAAK,QAAQ,WAAW;AAC1B,gBAAM,YAAuB;AAC7B,gBAAM,aAA8D,UAAU;AAC9E,gBAAM,cAAc,UAAU;AAC9B,gBAAM,kBAAkB,UAAU;AAClC,oBAAU;YACR,yBAAuB,MAAE,WAAW,kBAAY,QAAA,OAAA,SAAA,KAAI;YACpD,sBAAsB,WAAW,eAAe,OAAO,WAAW;YAClE,kBAAmB,eAAe,SAAS,cAAe,YAAY,MAAM;YAC5E,mBAAoB,mBAAmB,SAAS,kBAAmB,gBAAgB,MAAM;;eAEtF;AACL,oBAAU;;AAEZ,cAAM,aAAyB;UAC7B;UACA;UACA,UAAU;UACV,YAAY,KAAK;UACjB,gBAAgB,KAAK,cAAc;UACnC,kBAAkB,KAAK,cAAc;UACrC,eAAe,KAAK,cAAc;UAClC,cAAc,KAAK;UACnB,kBAAkB,KAAK;UACvB,gBAAgB,KAAK;UACrB,iCAAiC,KAAK,cAAc;UACpD,kCAAkC;UAClC,0BAA0B,KAAK;UAC/B,8BAA8B,KAAK;UACnC,wBAAsB,MAAE,KAAK,QAAQ,MAAM,qBAAe,QAAA,OAAA,SAAA,KAAI;UAC9D,yBAAuB,MAAE,KAAK,QAAQ,MAAM,sBAAgB,QAAA,OAAA,SAAA,KAAI;;AAElE,eAAO;;MAGD,0BAAuB;AAC7B,YAAI,CAAC,KAAK,iBAAiB;AACzB;;AAEF,YAAI,KAAK,mBAAmB;AAC1B,qBAAA,sBAAsB,KAAK;AAC3B,eAAK,gBAAgB,WAAW,KAAK;AACrC,eAAK,oBAAoB;;AAE3B,aAAK,aAAa;AAClB,aAAK,gBAAgB,IAAI,WAAA;AACzB,aAAK,iBAAiB;AACtB,aAAK,eAAe;AACpB,aAAK,mBAAmB;AACxB,aAAK,2BAA2B;AAChC,aAAK,+BAA+B;;MAG9B,MAAM,MAAY;AACxB,gBAAQ,MAAM,YAAA,aAAa,OAAO,aAAa,MAAM,KAAK,YAAY,KAAK,OAAO,KAAK,0BAA0B,MAAM;;MAGjH,SAAS,MAAY;AAC3B,gBAAQ,MAAM,YAAA,aAAa,OAAO,uBAAuB,MAAM,KAAK,YAAY,KAAK,OAAO,KAAK,0BAA0B,MAAM;;MAG3H,qBAAkB;AACxB,YAAI,KAAK,oBAAoB;AAC3B,eAAK,kBACH,CAAC,qBAAA,kBAAkB,oBACnB,qBAAA,kBAAkB;eAEf;AACL,eAAK,kBACH,CAAC,qBAAA,kBAAkB,oBACnB,qBAAA,kBAAkB;;;MAQhB,eAAY;AAClB,aAAK,eAAe;;MAGd,cAAW;AACjB,aAAK,eAAe;AACpB,aAAK,eAAe;;MAGd,WAAQ;;AACd,YAAI,KAAK,iBAAiB;AACxB,eAAK,kBAAkB;;AAEzB,gBAAQ,MACN,YAAA,aAAa,OACb,aACA,MAAM,KAAK,YAAY,KAAK,OAAO,KAAK,0BAA0B;AAGpE,aAAK,qBAAqB,WAAW,MAAK;AACxC,eAAK,kBAAkB,CAAC,qBAAA,kBAAkB,QAAQ,qBAAA,kBAAkB;WACnE,KAAK;AACR,QAAA,MAAA,MAAA,KAAK,oBAAmB,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;AAC7B,aAAK,QAAS,KACZ,CAAC,KAAmB,UAAkB,YAAmB;AACvD,uBAAa,KAAK;;;MAKhB,sBAAmB;;AACzB,aAAK,sBAAsB,YAAY,MAAK;AAC1C,eAAK;WACJ,KAAK;AACR,QAAA,MAAA,MAAA,KAAK,qBAAoB,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;MAKxB,qBAAkB;AACxB,sBAAc,KAAK;AACnB,qBAAa,KAAK;;MAGZ,cAAc,uBAA4C;;AAChE,YAAI,sBAAsB,YAAY;AACpC,eAAK,aAAa,aAAA,YAAY,sBAAsB;AACpD,eAAK,MAAM,8CAA8C,sBAAsB;eAC1E;AACL,eAAK,aAAa;AAClB,eAAK,MAAM;;AAEb,cAAM,kBAAkB,WAAA,oBAAmB,MACzC,sBAAsB,gBAAU,QAAA,OAAA,SAAA,KAAI,KAAK;AAE3C,YAAI,oBACF,KAAK,YAAY,2BAA2B;AAC9C,0BAAkB,2BAA2B,OAAO;AACpD,YAAI,kCAAkC,KAAK,SAAS;AAClD,4BAAkB,mBAAmB,KAAK,QACxC;;AAGJ,YAAI,gBAAgB;AACpB,YAAI,mBAAmB,mBAAmB;AACxC,0BAAgB;AAIhB,cAAI,KAAK,QAAQ,kCAAkC;AACjD,kBAAM,wBAAwB,KAAK,QACjC;AAEF,8BAAkB,sBAAsB,CACtC,MACA,SACqB;AACrB,qBAAO,MAAA,oBAAoB,uBAAuB;;AAEpD,8BAAkB,aAAa;iBAC1B;AACL,kBAAM,oBAAiB,MAAA,MACrB,aAAA,cAAc,sBAAgB,QAAA,OAAA,SAAA,SAAA,GAAE,UAAI,QAAA,OAAA,SAAA,KAAI;AAE1C,8BAAkB,aAAa;;AAEjC,cAAI,sBAAsB,QAAQ;AAMhC,8BAAkB,mBAAmB,CAAC,WAAW,WAAU;AACzD,qBAAO,sBAAsB;;;eAG5B;AAIL,4BAAkB,mBAAmB,CAAC,WAAW,WAAU;AACzD,gBAAI,sBAAsB,QAAQ;AAChC,qBAAO,sBAAsB;mBACxB;AAIL,qBAAO,IAAI,QAAQ,KAAK;;;;AAK9B,4BAAiB,OAAA,OAAA,OAAA,OAAA,IACZ,oBACA,KAAK;AAoBV,cAAM,UAAU,MAAM,QACpB,gBAAgB,iBAChB;AAEF,aAAK,UAAU;AACf,YAAI,KAAK,iBAAiB;AACxB,eAAK,oBAAoB,WAAA,uBAAuB,KAAK,yBAAyB,MAAM,KAAK;AACzF,eAAK,gBAAgB,SAAS,KAAK;;AAErC,gBAAQ;AAKR,gBAAQ,KAAK,WAAW,MAAK;AAC3B,cAAI,KAAK,YAAY,SAAS;AAC5B,iBAAK,kBACH,CAAC,qBAAA,kBAAkB,aACnB,qBAAA,kBAAkB;;;AAIxB,gBAAQ,KAAK,SAAS,MAAK;AACzB,cAAI,KAAK,YAAY,SAAS;AAC5B,iBAAK,MAAM;AACX,iBAAK,kBACH,CAAC,qBAAA,kBAAkB,aACnB,qBAAA,kBAAkB;AAKpB,iBAAK,kBACH,CAAC,qBAAA,kBAAkB,QACnB,qBAAA,kBAAkB;;;AAIxB,gBAAQ,KACN,UACA,CAAC,WAAmB,cAAsB,eAAsB;AAC9D,cAAI,KAAK,YAAY,SAAS;AAG5B,gBACE,cAAc,MAAM,UAAU,6BAC9B,WAAW,OAAO,mBAClB;AACA,mBAAK,kBAAkB,KAAK,IAC1B,IAAI,KAAK,iBACT;AAEF,sBAAQ,IACN,YAAA,aAAa,OACb,iBAAiB,aAAA,YAAY,KAAK,qBAChC,KAAK,mGAEL,KAAK;;AAIX,iBAAK,MACH,2CACE;AAEJ,iBAAK,kBACH,CAAC,qBAAA,kBAAkB,YAAY,qBAAA,kBAAkB,QACjD,qBAAA,kBAAkB;;;AAK1B,gBAAQ,KAAK,SAAS,CAAC,UAAS;AAG9B,eAAK,MACH,kCACG,MAAgB;;;MAKjB,0BAAuB;;AAK7B,cAAM,oBACJ,KAAK,YAAY,2BAA2B;AAE9C,YAAI,mBAAmB,mBAAmB;AACxC,4BAAkB,gBAAgB,CAAC;AAInC,cAAI,KAAK,QAAQ,kCAAkC;AACjD,kBAAM,wBAAwB,KAAK,QACjC;AAEF,8BAAkB,sBAAsB,CACtC,MACA,SACqB;AACrB,qBAAO,MAAA,oBAAoB,uBAAuB;;AAEpD,8BAAkB,aAAa;iBAC1B;AACL,gBAAI,8BAA8B,KAAK,SAAS;AAK9C,oBAAM,aAAa,WAAA,oBAAmB,MACpC,aAAA,SAAS,KAAK,QAAQ,kCAAsC,QAAA,OAAA,SAAA,KAAI;gBAC9D,MAAM;;AAGV,oBAAM,WAAW,aAAA,cAAc;AAC/B,gCAAkB,aAAU,MAAG,aAAQ,QAAR,aAAQ,SAAA,SAAR,SAAU,UAAI,QAAA,OAAA,SAAA,KAAI;;;;AAKvD,qBAAA,qBACE,KAAK,mBACL,KAAK,SACL,mBACA,KACA,CAAC,WAAU;AACT,eAAK,cAAc;WAErB,CAAC,WAAU;AACT,eAAK,kBACH,CAAC,qBAAA,kBAAkB,aACnB,qBAAA,kBAAkB;;;MAalB,kBACN,WACA,UAA2B;AAE3B,YAAI,UAAU,QAAQ,KAAK,uBAAuB,IAAI;AACpD,iBAAO;;AAET,aAAK,MACH,qBAAA,kBAAkB,KAAK,qBACrB,SACA,qBAAA,kBAAkB;AAEtB,YAAI,KAAK,iBAAiB;AACxB,eAAK,cAAc,SAAS,WAAW,qBAAA,kBAAkB,KAAK,qBAAqB,SAAS,qBAAA,kBAAkB;;AAEhH,cAAM,gBAAgB,KAAK;AAC3B,aAAK,oBAAoB;AACzB,gBAAQ;eACD,qBAAA,kBAAkB;AACrB,iBAAK;AACL,iBAAK,QAAS,OAAO,KAAK,SAAS,MAAK;AACtC,yBAAW,YAAY,KAAK,qBAAqB;AAC/C;;;AAGJ,gBAAI,KAAK,uBAAuB;AAC9B,mBAAK;;AAEP;eACG,qBAAA,kBAAkB;AACrB,iBAAK;AACL,iBAAK;AACL,iBAAK,qBAAqB;AAC1B;eACG,qBAAA,kBAAkB;AACrB,gBAAI,KAAK,SAAS;AAChB,mBAAK,QAAQ;;AAEf,iBAAK,UAAU;AACf,iBAAK;AACL,iBAAK;AAIL,gBAAI,CAAC,KAAK,eAAe,aAAa;AACpC,sBAAQ,SAAS,MAAK;AACpB,qBAAK;;;AAGT;eACG,qBAAA,kBAAkB;AACrB,gBAAI,KAAK,SAAS;AAChB,mBAAK,QAAQ;;AAEf,iBAAK,UAAU;AACf,iBAAK;AACL,iBAAK;AACL;;AAEA,kBAAM,IAAI,MAAM,4CAA4C;;AAIhE,mBAAW,YAAY,CAAC,GAAG,KAAK,iBAAiB;AAC/C,mBAAS,MAAM,eAAe;;AAEhC,eAAO;;MAOD,qBAAkB;AAGxB,YAAI,KAAK,iBAAiB,KAAK,KAAK,aAAa,GAAG;AAClD,cAAI,KAAK,iBAAiB;AACxB,iBAAK,cAAc,SAAS,WAAW;;AAEzC,eAAK,kBACH,CAAC,qBAAA,kBAAkB,YAAY,qBAAA,kBAAkB,QACjD,qBAAA,kBAAkB;AAEpB,cAAI,KAAK,iBAAiB;AACxB,uBAAA,sBAAsB,KAAK;;;;MAKjC,UAAO;AACL,aAAK,SACH,kBACE,KAAK,eACL,SACC,MAAK,eAAe;AAEzB,YAAI,KAAK,iBAAiB,GAAG;AAC3B,cAAI,KAAK,SAAS;AAChB,iBAAK,QAAQ;;AAEf,eAAK,eAAe;AACpB,cAAI,CAAC,KAAK,uBAAuB;AAC/B,iBAAK;;;AAGT,aAAK,gBAAgB;;MAGvB,YAAS;AACP,aAAK,SACH,kBACE,KAAK,eACL,SACC,MAAK,eAAe;AAEzB,aAAK,gBAAgB;AACrB,YAAI,KAAK,iBAAiB,GAAG;AAC3B,cAAI,KAAK,SAAS;AAChB,iBAAK,QAAQ;;AAEf,eAAK,eAAe;AACpB,cAAI,CAAC,KAAK,uBAAuB;AAC/B,iBAAK;;AAEP,eAAK;;;MAIT,MAAG;AACD,aAAK,SACH,cACE,KAAK,WACL,SACC,MAAK,WAAW;AAErB,aAAK,YAAY;;MAGnB,QAAK;AACH,aAAK,SACH,cACE,KAAK,WACL,SACC,MAAK,WAAW;AAErB,aAAK,YAAY;AACjB,aAAK;;MAGP,gBAAa;AACX,YAAI,KAAK,aAAa,GAAG;AACvB,eAAK;AACL,iBAAO;;AAET,eAAO;;MAUT,gBACE,UACA,YACA,cAAsB;AAEtB,cAAM,UAAU,SAAS;AACzB,gBAAQ,0BAA0B,WAAW;AAC7C,gBAAQ,2BAA2B,KAAK;AACxC,gBAAQ,6BAA6B;AACrC,gBAAQ,uBAAuB;AAC/B,gBAAQ,qBAAqB,WAAW;AACxC,gBAAQ,mBAAmB;AAC3B,YAAI;AASJ,YAAI;AACF,wBAAc,KAAK,QAAS,QAAQ;iBAC7B,GAAP;AACA,eAAK,kBACH,CAAC,qBAAA,kBAAkB,QACnB,qBAAA,kBAAkB;AAEpB,gBAAM;;AAER,YAAI,gBAAgB;AACpB,mBAAW,UAAU,OAAO,KAAK,UAAU;AACzC,2BAAiB,OAAS,SAAS,OAAO,QAAQ,UAAU;;AAE9D,gBAAQ,MACN,YAAA,aAAa,OACb,eACA,oCACQ,KAAK,YAAY,KAAK,OAC5B,KAAK,0BACL,oBACA;AAEJ,cAAM,gBAAgB,KAAK;AAC3B,YAAI;AACJ,YAAI,KAAK,iBAAiB;AACxB,eAAK,YAAY;AACjB,qBAAW,iBAAiB,YAAS;AACnC,gBAAI,OAAO,SAAS,YAAA,OAAO,IAAI;AAC7B,mBAAK,YAAY;mBACZ;AACL,mBAAK,YAAY;;;AAGrB,eAAK,cAAc;AACnB,qBAAW,oBAAoB,aAAU;AACvC,gBAAI,kBAAkB,KAAK,SAAS;AAClC,kBAAI,SAAS;AACX,qBAAK,cAAc;qBACd;AACL,qBAAK,cAAc;;;;AAIzB,yBAAe;YACb,gBAAgB,MAAK;AACnB,mBAAK,gBAAgB;AACrB,mBAAK,2BAA2B,IAAI;;YAEtC,oBAAoB,MAAK;AACvB,mBAAK,oBAAoB;;;eAGxB;AACL,yBAAe;YACb,gBAAgB,MAAK;;YACrB,oBAAoB,MAAK;;;;AAG7B,mBAAW,kBAAkB,aAAa,MAAM,cAAc;;MAShE,kBAAe;AAKb,YACE,CAAC,KAAK,kBACJ,CAAC,qBAAA,kBAAkB,OACnB,qBAAA,kBAAkB,aAEpB;AACA,cAAI,KAAK,sBAAsB,qBAAA,kBAAkB,mBAAmB;AAClE,iBAAK,qBAAqB;;;;MAQhC,uBAAoB;AAClB,eAAO,KAAK;;MAQd,6BAA6B,UAAmC;AAC9D,aAAK,eAAe,KAAK;;MAQ3B,gCAAgC,UAAmC;AACjE,cAAM,gBAAgB,KAAK,eAAe,QAAQ;AAClD,YAAI,gBAAgB,IAAI;AACtB,eAAK,eAAe,OAAO,eAAe;;;MAI9C,sBAAsB,UAAoB;AACxC,aAAK,oBAAoB,KAAK;;MAGhC,yBAAyB,UAAoB;AAC3C,cAAM,gBAAgB,KAAK,oBAAoB,QAAQ;AACvD,YAAI,gBAAgB,IAAI;AACtB,eAAK,oBAAoB,OAAO,eAAe;;;MAOnD,eAAY;AACV,aAAK,eAAe;AACpB,aAAK,kBACH,CAAC,qBAAA,kBAAkB,oBACnB,qBAAA,kBAAkB;;MAItB,aAAU;AACR,eAAO,KAAK;;MAGd,iBAAc;AACZ,eAAO,KAAK;;;AA91BhB,aAAA,aAAA;;;;;;;;;;ACtEA,QAAA,oBAAA;AACA,QAAA,eAAA;AACA,QAAA,uBAAA;AAKA,QAAA,eAAA;AAOA,QAAM,qBAAqB;AAE3B,+BAA2B;MAqBzB,YAAoB,SAAe;AAAf,aAAA,SAAA;AApBZ,aAAA,OAOJ,OAAO,OAAO;AAKV,aAAA,eAAoC;;MAc5C,yBAAsB;AACpB,YAAI,wBAAwB;AAM5B,mBAAW,iBAAiB,KAAK,MAAM;AACrC,gBAAM,qBAAqB,KAAK,KAAK;AAErC,gBAAM,mBAAmB,mBAAmB,OAC1C,CAAC,UAAU,CAAC,MAAM,WAAW;AAG/B,cAAI,iBAAiB,SAAS,GAAG;AAC/B,oCAAwB;;AAM1B,eAAK,KAAK,iBAAiB;;AAM7B,YAAI,yBAAyB,KAAK,iBAAiB,MAAM;AACvD,wBAAc,KAAK;AACnB,eAAK,eAAe;;;MAOxB,oBAAiB;;AACf,YAAI,KAAK,UAAU,KAAK,iBAAiB,MAAM;AAC7C,eAAK,eAAe,YAAY,MAAK;AACnC,iBAAK;aACJ;AAIH,UAAA,MAAA,MAAA,KAAK,cAAa,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;;MAY3B,sBACE,kBACA,kBACA,kBACA,oBAAsC;AAEtC,aAAK;AACL,cAAM,gBAAgB,aAAA,YAAY;AAClC,YAAI,iBAAiB,KAAK,MAAM;AAC9B,gBAAM,qBAAqB,KAAK,KAAK;AACrC,qBAAW,iBAAiB,oBAAoB;AAC9C,gBACE,qBAAA,uBACE,kBACA,cAAc,sBAEhB,kBAAA,oBACE,kBACA,cAAc,qBAEhB,mBAAmB,QAAQ,cAAc,qBACzC;AACA,qBAAO,cAAc;;;;AAK3B,cAAM,aAAa,IAAI,aAAA,WACrB,kBACA,kBACA,kBACA;AAEF,YAAI,CAAE,kBAAiB,KAAK,OAAO;AACjC,eAAK,KAAK,iBAAiB;;AAE7B,aAAK,KAAK,eAAe,KAAK;UAC5B,mBAAmB;UACnB;UACA;UACA;;AAEF,YAAI,KAAK,QAAQ;AACf,qBAAW;;AAEb,eAAO;;;AAhIX,aAAA,iBAAA;AAoIA,QAAM,uBAAuB,IAAI,eAAe;AAMhD,+BAAkC,SAAe;AAC/C,UAAI,SAAQ;AACV,eAAO;aACF;AACL,eAAO,IAAI,eAAe;;;AAJ9B,aAAA,oBAAA;;;;;;;;;;ACtJA,4BAAwB;MACtB,YAA6B,SAAiB;AAAjB,aAAA,UAAA;;MAE7B,aAAa,UAA2B;AACtC,YAAI,SAA4B;AAEhC,iBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,QAAQ,KAAK;AAC5C,mBAAS,KAAK,QAAQ,GAAG,aAAa;;AAGxC,eAAO;;MAGT,gBAAgB,UAAkB;AAChC,YAAI,SAAmB;AAEvB,iBAAS,IAAI,KAAK,QAAQ,SAAS,GAAG,KAAK,GAAG,KAAK;AACjD,mBAAS,KAAK,QAAQ,GAAG,gBAAgB;;AAG3C,eAAO;;MAGT,YAAY,SAA6B;AACvC,YAAI,SAA+B;AAEnC,iBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,QAAQ,KAAK;AAC5C,mBAAS,KAAK,QAAQ,GAAG,YAAY;;AAGvC,eAAO;;MAGT,eAAe,SAAwB;AACrC,YAAI,SAA0B;AAE9B,iBAAS,IAAI,KAAK,QAAQ,SAAS,GAAG,KAAK,GAAG,KAAK;AACjD,mBAAS,KAAK,QAAQ,GAAG,eAAe;;AAG1C,eAAO;;MAGT,gBAAgB,QAAoB;AAClC,YAAI,SAAuB;AAE3B,iBAAS,IAAI,KAAK,QAAQ,SAAS,GAAG,KAAK,GAAG,KAAK;AACjD,mBAAS,KAAK,QAAQ,GAAG,gBAAgB;;AAG3C,eAAO;;MAGT,UAAO;AACL,mBAAW,UAAU,KAAK,SAAS;AACjC,iBAAO;;;MAIX,KAAK,SAAiB;AACpB,aAAK,QAAQ,QAAQ,GAAG;;MAG1B,aAAU;AACR,eAAO,KAAK;;;AAhEhB,aAAA,cAAA;AAoEA,mCAA+B;MAC7B,YAA6B,WAAuC;AAAvC,aAAA,YAAA;;MAE7B,KAAK,iBAAwC;AAC3C,aAAK,UAAU,QAAQ,GAAG;;MAG5B,aAAa,YAAgB;AAC3B,eAAO,IAAI,YACT,KAAK,UAAU,IAAI,CAAC,YAAY,QAAQ,aAAa;;;AAT3D,aAAA,qBAAA;;;;;;;;;;ACnDA,2BAAgC;YACxB,aAAa,UAA2B;AAC5C,eAAO;;MAGT,gBAAgB,UAAkB;AAChC,eAAO;;YAGH,YAAY,SAA6B;AAC7C,eAAO;;YAGH,eAAe,SAAwB;AAC3C,eAAO;;MAGT,gBAAgB,QAAoB;AAClC,eAAO;;MAGT,UAAO;;;AArBT,aAAA,aAAA;;;;;;;;;;ACnBA,QAAA,WAAA;AAEA,QAAA,cAAA;AACA,QAAA,eAAA;AAGA,8CAA2C,SAAA,WAAU;MAEnD,YACmB,SACA,QAAY;;AAE7B;AAHiB,aAAA,UAAA;AACA,aAAA,SAAA;AAGjB,aAAK,UAAU;AACf,aAAK,SAAS;AACd,cAAM,YAAsB,OAAO,YAAY,MAAM;AACrD,YAAI,cAAc;AAIlB,YAAI,UAAU,UAAU,GAAG;AACzB,wBAAc,UAAU;;AAE1B,cAAM,WAAQ,MAAA,MAAG,aAAA,cAAc,OAAO,gBAAU,QAAA,OAAA,SAAA,SAAA,GAAE,UAAI,QAAA,OAAA,SAAA,KAAI;AAG1D,aAAK,aAAa,WAAW,YAAY;;YAGrC,aAAa,UAA2B;AAC5C,cAAM,eAAc,KAAK,OAAO;AAChC,cAAM,gBAAgB,aAAY,iBAAiB;UACjD,aAAa,KAAK;;AAEpB,cAAM,iBAAiB,MAAM;AAC7B,YAAI;AACF,yBAAe,MAAM,MAAM;iBACpB,OAAP;AACA,eAAK,OAAO,iBACV,YAAA,OAAO,iBACP,gDAAgD,MAAM;AAExD,iBAAO,QAAQ,OAAiB;;AAElC,YAAI,eAAe,IAAI,iBAAiB,SAAS,GAAG;AAClD,eAAK,OAAO,iBACV,YAAA,OAAO,UACP;AAEF,iBAAO,QAAQ,OACb;;AAGJ,eAAO;;;AA/CX,aAAA,wBAAA;AAmDA,6CAAyC;MAEvC,YAA6B,SAAgB;AAAhB,aAAA,UAAA;AAC3B,aAAK,UAAU;;MAGjB,aAAa,YAAgB;AAC3B,eAAO,IAAI,sBAAsB,KAAK,SAAS;;;AAPnD,aAAA,+BAAA;;;;;;;;;;ACzDA,QAAA,cAAA;AACA,QAAA,WAAA;AAGA,QAAM,QAAiC;MACrC,CAAC,KAAK;MACN,CAAC,KAAK;MACN,CAAC,KAAK,KAAK;MACX,CAAC,KAAK,KAAK,KAAK;;AAGlB,yBAAqB,UAAgB;AACnC,YAAM,MAAM,IAAI,OAAO;AACvB,YAAM,YAAY,KAAK,IAAI,WAAW,KAAK;AAC3C,iBAAW,CAAC,MAAM,WAAW,OAAO;AAClC,cAAM,SAAS,YAAY;AAC3B,YAAI,SAAS,KAAK;AAChB,iBAAO,OAAO,KAAK,KAAK,WAAW;;;AAGvC,YAAM,IAAI,MAAM;;AAGlB,uCAAoC,SAAA,WAAU;MAG5C,YACmB,SACA,YAAgB;AAEjC;AAHiB,aAAA,UAAA;AACA,aAAA,aAAA;AAJX,aAAA,QAA6B;AAC7B,aAAA,WAAW;AAMjB,aAAK;AACL,aAAK;;MAGC,mBAAgB;AACtB,cAAM,eAAe,KAAK,WAAW;AACrC,YAAI,wBAAwB,MAAM;AAChC,eAAK,WAAW,aAAa;eACxB;AACL,eAAK,WAAW;;;MAIZ,WAAQ;;AACd,YAAI,KAAK,OAAO;AACd,uBAAa,KAAK;;AAEpB,cAAM,MAAc,IAAI,OAAO;AAC/B,cAAM,UAAU,KAAK,WAAW;AAChC,YAAI,WAAW,GAAG;AAChB,kBAAQ,SAAS,MAAK;AACpB,iBAAK,WAAW,iBACd,YAAA,OAAO,mBACP;;mBAGK,KAAK,aAAa,UAAU;AACrC,eAAK,QAAQ,WAAW,MAAK;AAC3B,iBAAK,WAAW,iBACd,YAAA,OAAO,mBACP;aAED;AACH,UAAA,MAAA,MAAA,KAAK,OAAM,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;;MAIpB,UAAO;AACL,aAAK;AACL,aAAK;;YAGD,aAAa,UAA2B;AAC5C,YAAI,KAAK,aAAa,UAAU;AAC9B,iBAAO;;AAKT,cAAM,gBAAgB,MAAM;AAC5B,cAAM,gBAAgB,YAAY,KAAK;AACvC,sBAAc,IAAI,gBAAgB;AAClC,eAAO;;MAGT,gBAAgB,QAAoB;AAClC,YAAI,KAAK,OAAO;AACd,uBAAa,KAAK;;AAEpB,eAAO;;;AAnEX,aAAA,iBAAA;AAuEA,sCAAkC;MAChC,YAA6B,SAAgB;AAAhB,aAAA,UAAA;;MAE7B,aAAa,YAAgB;AAC3B,eAAO,IAAI,eAAe,KAAK,SAAS;;;AAJ5C,aAAA,wBAAA;;;;;;;;;;AChGA,QAAA,OAAA,QAAA;AAIA,QAAA,WAAA;AAGA,mCAAiC;YAQzB,aAAa,SAAiB,UAAiB;AACnD,YAAI,gBAAgB;AACpB,YAAI,UAAU;AACZ,0BAAgB,MAAM,KAAK,gBAAgB;;AAE7C,cAAM,SAAS,OAAO,YAAY,cAAc,SAAS;AACzD,eAAO,WAAW,WAAW,IAAI,GAAG;AACpC,eAAO,cAAc,cAAc,QAAQ;AAC3C,sBAAc,KAAK,QAAQ;AAC3B,eAAO;;YAMH,YAAY,MAAY;AAC5B,cAAM,aAAa,KAAK,UAAU,OAAO;AACzC,YAAI,gBAAgB,KAAK,MAAM;AAC/B,YAAI,YAAY;AACd,0BAAgB,MAAM,KAAK,kBAAkB;;AAE/C,eAAO;;;AAIX,wCAA8B,mBAAkB;YACxC,gBAAgB,SAAe;AACnC,eAAO;;YAGH,aAAa,SAAiB,UAAiB;AACnD,cAAM,SAAS,OAAO,YAAY,QAAQ,SAAS;AAGnD,eAAO,WAAW,GAAG;AACrB,eAAO,cAAc,QAAQ,QAAQ;AACrC,gBAAQ,KAAK,QAAQ;AACrB,eAAO;;MAGT,kBAAkB,SAAe;AAC/B,eAAO,QAAQ,OACb,IAAI,MACF;;;AAMR,uCAA6B,mBAAkB;MAC7C,gBAAgB,SAAe;AAC7B,eAAO,IAAI,QAAgB,CAAC,UAAS,WAAU;AAC7C,eAAK,QAAQ,SAAS,CAAC,KAAK,WAAU;AACpC,gBAAI,KAAK;AACP,qBAAO;mBACF;AACL,uBAAQ;;;;;MAMhB,kBAAkB,SAAe;AAC/B,eAAO,IAAI,QAAgB,CAAC,UAAS,WAAU;AAC7C,eAAK,QAAQ,SAAS,CAAC,KAAK,WAAU;AACpC,gBAAI,KAAK;AACP,qBAAO;mBACF;AACL,uBAAQ;;;;;;AAOlB,oCAA0B,mBAAkB;MAC1C,gBAAgB,SAAe;AAC7B,eAAO,IAAI,QAAgB,CAAC,UAAS,WAAU;AAC7C,eAAK,KAAK,SAAS,CAAC,KAAK,WAAU;AACjC,gBAAI,KAAK;AACP,qBAAO;mBACF;AACL,uBAAQ;;;;;MAMhB,kBAAkB,SAAe;AAC/B,eAAO,IAAI,QAAgB,CAAC,UAAS,WAAU;AAC7C,eAAK,MAAM,SAAS,CAAC,KAAK,WAAU;AAClC,gBAAI,KAAK;AACP,qBAAO;mBACF;AACL,uBAAQ;;;;;;AAOlB,uCAA6B,mBAAkB;MAC7C,YAA6B,iBAAuB;AAClD;AAD2B,aAAA,kBAAA;;MAG7B,gBAAgB,SAAe;AAC7B,eAAO,QAAQ,OACb,IAAI,MACF,mEAAmE,KAAK;;MAK9E,kBAAkB,SAAe;AAE/B,eAAO,QAAQ,OACb,IAAI,MAAM,qCAAqC,KAAK;;;AAK1D,mCAA+B,iBAAuB;AACpD,cAAQ;aACD;AACH,iBAAO,IAAI;aACR;AACH,iBAAO,IAAI;aACR;AACH,iBAAO,IAAI;;AAEX,iBAAO,IAAI,eAAe;;;AAIhC,0CAAuC,SAAA,WAAU;MAAjD,cAAA;;AACU,aAAA,kBAAsC,IAAI;AAC1C,aAAA,qBAAyC,IAAI;;YAC/C,aAAa,UAA2B;AAC5C,cAAM,UAAoB,MAAM;AAChC,gBAAQ,IAAI,wBAAwB;AACpC,gBAAQ,IAAI,mBAAmB;AAC/B,eAAO;;MAGT,gBAAgB,UAAkB;AAChC,cAAM,kBAAmC,SAAS,IAAI;AACtD,YAAI,gBAAgB,SAAS,GAAG;AAC9B,gBAAM,WAA0B,gBAAgB;AAChD,cAAI,OAAO,aAAa,UAAU;AAChC,iBAAK,qBAAqB,sBAAsB;;;AAGpD,iBAAS,OAAO;AAChB,iBAAS,OAAO;AAChB,eAAO;;YAGH,YAAY,SAA6B;AAI7C,cAAM,kBAA+B,MAAM;AAC3C,cAAM,WACJ,gBAAgB,UAAU,SACtB,QACC,iBAAgB,QAAK,OAA8B;AAC1D,eAAO;UACL,SAAS,MAAM,KAAK,gBAAgB,aAClC,gBAAgB,SAChB;UAEF,OAAO,gBAAgB;;;YAIrB,eAAe,SAAwB;AAK3C,eAAO,KAAK,mBAAmB,YAAY,MAAM;;;AA9CrD,aAAA,oBAAA;AAkDA,yCAAqC;MAEnC,YAA6B,SAAgB;AAAhB,aAAA,UAAA;;MAC7B,aAAa,YAAgB;AAC3B,eAAO,IAAI;;;AAJf,aAAA,2BAAA;;;;;;;;;;ACvMA,QAAA,WAAA;AAEA,QAAA,cAAA;AAOA,6CAA0C,SAAA,WAAU;MAGlD,YACmB,SACA,YAAgB;AAEjC;AAHiB,aAAA,UAAA;AACA,aAAA,aAAA;AAJX,aAAA,qBAA6B,YAAA;AAC7B,aAAA,wBAAgC,YAAA;AAMtC,YAAI,kCAAkC,SAAS;AAC7C,eAAK,qBAAqB,QAAQ;;AAEpC,YAAI,qCAAqC,SAAS;AAChD,eAAK,wBAAwB,QAAQ;;;YAInC,YAAY,SAA6B;AAG7C,YAAI,KAAK,uBAAuB,IAAI;AAClC,iBAAO;eACF;AACL,gBAAM,kBAAkB,MAAM;AAC9B,cAAI,gBAAgB,QAAQ,SAAS,KAAK,oBAAoB;AAC5D,iBAAK,WAAW,iBACd,YAAA,OAAO,oBACP,iCAAiC,gBAAgB,QAAQ,cAAc,KAAK;AAE9E,mBAAO,QAAQ,OAAoB;iBAC9B;AACL,mBAAO;;;;YAKP,eAAe,SAAwB;AAG3C,YAAI,KAAK,0BAA0B,IAAI;AACrC,iBAAO;eACF;AACL,gBAAM,kBAAkB,MAAM;AAC9B,cAAI,gBAAgB,SAAS,KAAK,uBAAuB;AACvD,iBAAK,WAAW,iBACd,YAAA,OAAO,oBACP,qCAAqC,gBAAgB,cAAc,KAAK;AAE1E,mBAAO,QAAQ,OAAe;iBACzB;AACL,mBAAO;;;;;AAjDf,aAAA,uBAAA;AAuDA,4CAAwC;MAEtC,YAA6B,SAAuB;AAAvB,aAAA,UAAA;;MAE7B,aAAa,YAAgB;AAC3B,eAAO,IAAI,qBAAqB,KAAK,SAAS;;;AALlD,aAAA,8BAAA;;;;;;;;;;AChEA,QAAA,gBAAA;AAMA,QAAA,wBAAA;AAEA,QAAA,4BAAA;AACA,QAAA,oBAAA;AAEA,QAAA,WAAA;AAEA,QAAA,cAAA;AACA,QAAA,iBAAA;AACA,QAAA,4BAAA;AACA,QAAA,oBAAA;AACA,QAAA,uBAAA;AACA,QAAA,aAAA;AAMA,QAAA,YAAA;AAEA,QAAA,4BAAA;AACA,QAAA,eAAA;AACA,QAAA,eAAA;AAKA,QAAA,uBAAA;AACA,QAAA,aAAA;AAKA,QAAM,mBAAmB;AAEzB,QAAI,iBAAiB;AAErB,gCAAyB;AACvB,YAAM,aAAa;AACnB,wBAAkB;AAClB,UAAI,kBAAkB,OAAO,kBAAkB;AAC7C,yBAAiB;;AAEnB,aAAO;;AA0ET,sCAAkC;MAyChC,YACE,QACiB,cACA,SAAuB;;AADvB,aAAA,cAAA;AACA,aAAA,UAAA;AAzCX,aAAA,oBAAuC,qBAAA,kBAAkB;AACzD,aAAA,gBAAwB,IAAI,SAAA;AAK5B,aAAA,uBAGH;AACG,aAAA,YAKH;AACG,aAAA,4BAAwD;AAYxD,aAAA,iBAAwC;AAG/B,aAAA,kBAA2B;AAIpC,aAAA,cAAc,IAAI,WAAA;AAClB,aAAA,kBAAkB,IAAI,WAAA;AAO5B,YAAI,OAAO,WAAW,UAAU;AAC9B,gBAAM,IAAI,UAAU;;AAEtB,YAAI,CAAE,yBAAuB,sBAAA,qBAAqB;AAChD,gBAAM,IAAI,UACR;;AAGJ,YAAI,SAAS;AACX,cAAI,OAAO,YAAY,UAAU;AAC/B,kBAAM,IAAI,UAAU;;;AAGxB,aAAK,iBAAiB;AACtB,cAAM,oBAAoB,aAAA,SAAS;AACnC,YAAI,sBAAsB,MAAM;AAC9B,gBAAM,IAAI,MAAM,gCAAgC;;AAIlD,cAAM,yBAAyB,WAAA,oBAAoB;AACnD,YAAI,2BAA2B,MAAM;AACnC,gBAAM,IAAI,MACR,oDAAoD;;AAIxD,aAAK,eAAe,YAAY,MAAK;WAAK;AAC1C,QAAA,MAAA,MAAA,KAAK,cAAa,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;AAEvB,YAAI,KAAK,QAAQ,4BAA4B,GAAG;AAC9C,eAAK,kBAAkB;;AAGzB,aAAK,gBAAgB,IAAI,WAAA;AACzB,YAAI,KAAK,iBAAiB;AACxB,eAAK,cAAc,WAAA,wBAAwB,QAAQ,MAAM,KAAK;AAC9D,eAAK,cAAc,SAAS,WAAW;eAClC;AAEL,eAAK,cAAc;YACjB,MAAM;YACN,IAAI;YACJ,MAAM;;;AAIV,YAAI,KAAK,QAAQ,2BAA2B;AAC1C,eAAK,mBAAmB,KAAK,QAAQ;eAChC;AACL,eAAK,mBAAmB,WAAA,oBAAoB;;AAE9C,cAAM,iBAAiB,aAAA,aAAa,wBAAwB;AAC5D,aAAK,SAAS,eAAe;AAC7B,aAAK,UAAU,OAAO,OAAO,IAAI,KAAK,SAAS,eAAe;AAI9D,aAAK,iBAAiB,kBAAA,kBACpB,OAAC,QAAQ,uCAAiC,QAAA,OAAA,SAAA,KAAI,OAAO;AAEvD,cAAM,uBAA6C;UACjD,kBAAkB,CAChB,mBACA,mBACE;AACF,kBAAM,aAAa,KAAK,eAAe,sBACrC,KAAK,QACL,mBACA,OAAO,OAAO,IAAI,KAAK,SAAS,iBAChC,KAAK;AAEP,gBAAI,KAAK,iBAAiB;AACxB,mBAAK,cAAc,SAAS,WAAW,kDAAkD,WAAW;;AAEtG,mBAAO;;UAET,aAAa,CAAC,mBAAsC,WAAkB;AACpE,iBAAK,gBAAgB;AACrB,kBAAM,YAAY,KAAK,UAAU;AACjC,iBAAK,YAAY;AACjB,iBAAK;AACL,uBAAW,EAAE,YAAY,cAAc,YAAY,oBAAoB,WAAW;AAChF,mBAAK,QAAQ,YAAY,cAAc,YAAY;;AAErD,iBAAK,YAAY;;UAEnB,qBAAqB,MAAK;AAExB,kBAAM,IAAI,MACR;;UAGJ,kBAAkB,CAAC,UAAqC;AACtD,gBAAI,KAAK,iBAAiB;AACxB,mBAAK,gBAAgB,SAAS;;;UAGlC,qBAAqB,CAAC,UAAqC;AACzD,gBAAI,KAAK,iBAAiB;AACxB,mBAAK,gBAAgB,WAAW;;;;AAItC,aAAK,wBAAwB,IAAI,0BAAA,sBAC/B,KAAK,QACL,sBACA,SACA,CAAC,mBAAkB;AACjB,cAAI,KAAK,iBAAiB;AACxB,iBAAK,cAAc,SAAS,WAAW;;AAEzC,eAAK,iBAAiB;AAGtB,kBAAQ,SAAS,MAAK;AACpB,kBAAM,aAAa,KAAK;AACxB,iBAAK,uBAAuB;AAC5B,iBAAK;AACL,uBAAW,EAAE,YAAY,kBAAkB,YAAY;AACrD,mBAAK,aAAa,YAAY;;AAEhC,iBAAK,uBAAuB;;WAGhC,CAAC,WAAU;AACT,cAAI,KAAK,iBAAiB;AACxB,iBAAK,cAAc,SAAS,cAAc,yCAAyC,OAAO,OAAO,mBAAmB,OAAO,UAAU;;AAEvI,cAAI,KAAK,qBAAqB,SAAS,GAAG;AACxC,iBAAK,MAAM;;AAEb,gBAAM,aAAa,KAAK;AACxB,eAAK,uBAAuB;AAC5B,eAAK;AACL,qBAAW,EAAE,YAAY,kBAAkB,YAAY;AACrD,gBAAI,aAAa,aAAa,cAAc;AAC1C,mBAAK;AACL,mBAAK,qBAAqB,KAAK,EAAE,YAAY;mBACxC;AACL,yBAAW,iBAAiB,OAAO,MAAM,OAAO;;;;AAKxD,aAAK,qBAAqB,IAAI,eAAA,mBAAmB;UAC/C,IAAI,0BAAA,6BAA6B;UACjC,IAAI,kBAAA,sBAAsB;UAC1B,IAAI,0BAAA,4BAA4B,KAAK;UACrC,IAAI,qBAAA,yBAAyB;;AAE/B,aAAK,MAAM,sCAAsC,KAAK,UAAU,SAAS,QAAW;;MAG9E,kBAAe;AACrB,eAAO;UACL,QAAQ,KAAK;UACb,OAAO,KAAK;UACZ,OAAO,KAAK;UACZ,aAAa,KAAK;UAClB,UAAU,KAAK,gBAAgB;;;MAI3B,MAAM,MAAc,mBAAgC;AAC1D,kBAAA,MAAM,sBAAiB,QAAjB,sBAAiB,SAAjB,oBAAqB,YAAA,aAAa,OAAO,WAAW,MAAM,KAAK,YAAY,KAAK,OAAO,aAAA,YAAY,KAAK,UAAU,MAAM;;MAGxH,kBAAe;;AAErB,YAAI,CAAA,OAAC,MAAA,KAAK,cAAa,YAAM,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA,MAAM;AACjC,eAAK,MACH,oDACE,KAAK,qBAAqB,SAC1B,uBACA,KAAK,UAAU;AAEnB,UAAA,MAAA,MAAA,KAAK,cAAa,SAAG,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;;MAIjB,oBAAiB;;AAEvB,YAAI,CAAC,KAAK,aAAa,UAAU,KAAK,aAAa,UAAU;AAC3D,eAAK,MACH,sDACE,KAAK,qBAAqB,SAC1B,uBACA,KAAK,UAAU;AAEnB,UAAA,MAAA,MAAA,KAAK,cAAa,WAAK,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA;;;MAInB,SACN,YACA,cACA,YACA,gBAAwB;AAExB,aAAK,UAAU,KAAK,EAAE,YAAY,cAAc,YAAY;AAC5D,aAAK;;MAUC,QACN,YACA,cACA,YACA,gBAAwB;;AAExB,cAAM,aAAa,KAAK,cAAc,KAAK;UACzC,UAAU;UACV,eAAe,WAAW;;AAE5B,aAAK,MACH,kBACE,SAAA,eAAe,WAAW,kBAC1B,kBAAe,OACf,WAAW,gBAAU,QAAA,OAAA,SAAA,SAAA,GAAE,gBACvB,cAAW,OACX,WAAW,YAAM,QAAA,OAAA,SAAA,SAAA,GAAE,QACnB,MAAG,OACH,WAAW,YAAM,QAAA,OAAA,SAAA,SAAA,GAAE;AAEvB,gBAAQ,WAAW;eACZ,SAAA,eAAe;AAClB,gBAAI,WAAW,eAAe,MAAM;AAClC,yBAAW,iBACT,YAAA,OAAO,aACP;mBAGG;AAIL,kBACE,WAAW,WAAY,2BACvB,qBAAA,kBAAkB,OAClB;AACA,0BAAA,IACE,YAAA,aAAa,OACb,4CACE,WAAW,WAAY,eACvB,gBACA,qBAAA,kBAAkB,WAAW,WAAY;AAE7C,qBAAK,SAAS,YAAY,cAAc,YAAY;AACpD;;AAKF,yBAAW,YACR,aAAa,QAAQ,QAAQ,aAAa,UAC1C,KACC,CAAC,kBAAiB;;AAChB,sBAAM,kBAAqC,WAAW,WAAY;AAClE,oBAAI,oBAAoB,qBAAA,kBAAkB,OAAO;AAC/C,sBAAI;AACF,0BAAM,mBAAmB,WAAW,qBAAqB,IAAI,aAAW,QAAQ,aAAa;AAC7F,+BAAW,WAAY,gBACrB,eACA,YACA,CAAC,GAAG,gBAAgB,GAAG;AAIzB,oBAAA,OAAA,WAAW,iBAAW,QAAA,QAAA,SAAA,SAAA,IAAA,KAAtB;AACA,oBAAA,OAAA,WAAW,mBAAa,QAAA,QAAA,SAAA,SAAA,IAAA,KAAxB;2BACO,OAAP;AACA,wBACG,MAAgC,SACjC,4BACA;AAcA,2BAAK,MACH,+CACE,WAAW,WAAY,eACvB,iBACC,MAAgB,UACjB,mBACA,YAAA,aAAa;AAEjB,2BAAK,QAAQ,YAAY,cAAc,YAAY;2BAC9C;AACL,2BAAK,MACH,8CACE,WAAW,WAAY,eACvB,iBACC,MAAgB,UACjB,iBACA,YAAA,aAAa;AAEjB,iCAAW,iBACT,YAAA,OAAO,UACP,6CACG,MAAgB;;;uBAKpB;AAGL,uBAAK,MACH,uBACE,WAAW,WAAY,eACvB,gBACA,qBAAA,kBAAkB,mBAClB,0CACA,YAAA,aAAa;AAEjB,uBAAK,QAAQ,YAAY,cAAc,YAAY;;iBAGvD,CAAC,UAAmC;AAElC,2BAAW,iBACT,OAAO,MAAM,SAAS,WAAW,MAAM,OAAO,YAAA,OAAO,SACrD,mDAAmD,MAAM;;;AAKnE;eACG,SAAA,eAAe;AAClB,iBAAK,SAAS,YAAY,cAAc,YAAY;AACpD;eACG,SAAA,eAAe;AAClB,gBAAI,aAAa,aAAa,cAAc;AAC1C,mBAAK,SAAS,YAAY,cAAc,YAAY;mBAC/C;AACL,yBAAW,iBACT,WAAW,OAAQ,MACnB,WAAW,OAAQ;;AAGvB;eACG,SAAA,eAAe;AAClB,uBAAW,iBACT,WAAW,OAAQ,MACnB,WAAW,OAAQ;AAErB;;AAEA,kBAAM,IAAI,MACR,yCAAyC,WAAW;;;MAKpD,+BACN,eAAuC;AAEvC,cAAM,eAAe,KAAK,0BAA0B,UAClD,CAAC,UAAU,UAAU;AAEvB,YAAI,gBAAgB,GAAG;AACrB,eAAK,0BAA0B,OAAO,cAAc;;;MAIhD,YAAY,UAA2B;AAC7C,kBAAA,MACE,YAAA,aAAa,OACb,sBACA,MAAM,KAAK,YAAY,KAAK,OAC1B,aAAA,YAAY,KAAK,UACjB,MACA,qBAAA,kBAAkB,KAAK,qBACvB,SACA,qBAAA,kBAAkB;AAEtB,YAAI,KAAK,iBAAiB;AACxB,eAAK,cAAc,SAAS,WAAW,qBAAA,kBAAkB,KAAK,qBAAqB,SAAS,qBAAA,kBAAkB;;AAEhH,aAAK,oBAAoB;AACzB,cAAM,eAAe,KAAK,0BAA0B;AACpD,mBAAW,iBAAiB,cAAc;AACxC,cAAI,aAAa,cAAc,cAAc;AAC3C,gBAAI,cAAc,OAAO;AACvB,2BAAa,cAAc;;AAE7B,iBAAK,+BAA+B;AACpC,0BAAc;;;;MAKZ,aAAa,QAAyB,UAAkB;AAC9D,YAAI,OAAO,gBAAgB,MAAM;AAG/B;;AAEF,YAAI,KAAK,mBAAmB,MAAM;AAKhC,eAAK,sBAAsB;AAC3B,eAAK,qBAAqB,KAAK;YAC7B,YAAY;YACZ,cAAc;;AAEhB,eAAK;eACA;AACL,gBAAM,aAAa,KAAK,eAAe,OAAO,aAAa;AAC3D,cAAI,WAAW,WAAW,YAAA,OAAO,IAAI;AACnC,gBAAI,WAAW,aAAa,SAAS;AACnC,oBAAM,WAAW,IAAI;AACrB,uBAAS,WACP,SAAS,eAAe,WAAW,aAAa,QAAQ;AAE1D,uBAAS,gBACP,SAAS,oBACP,WAAW,aAAa,QAAQ,QAAQ;AAE5C,qBAAO,kBAAkB;AAEzB,qBAAO,YAAY;;AAErB,gBAAI,WAAW,uBAAuB,SAAS,GAAG;AAahD,oBAAM,4BAA4B,IAAI,eAAA,mBAAmB,WAAW;AACpE,oBAAM,qBAAqB,0BAA0B,aAAa;AAClE,iCAAmB,aAAa,QAAQ,QAAQ,WAAW,KAAK,sBAAmB;AACjF,qBAAK,QAAQ,QAAQ,kBAAkB,YAAY,mBAAmB;;mBAEnE;AACL,mBAAK,QAAQ,QAAQ,UAAU,YAAY;;iBAExC;AACL,mBAAO,iBACL,WAAW,QACX,oCAAoC,OAAO;;;;MAMnD,iBAAiB,QAAyB,UAAkB;AAC1D,aAAK,aAAa,QAAQ,SAAS;;MAGrC,QAAK;AACH,aAAK,sBAAsB;AAC3B,aAAK,YAAY,qBAAA,kBAAkB;AACnC,sBAAc,KAAK;AACnB,YAAI,KAAK,iBAAiB;AACxB,qBAAA,sBAAsB,KAAK;;AAG7B,aAAK,eAAe;;MAGtB,YAAS;AACP,eAAO,aAAA,YAAY,KAAK;;MAG1B,qBAAqB,cAAqB;AACxC,cAAM,oBAAoB,KAAK;AAC/B,YAAI,cAAc;AAChB,eAAK,sBAAsB;;AAE7B,eAAO;;MAGT,uBACE,cACA,UACA,UAAiC;AAEjC,YAAI,KAAK,sBAAsB,qBAAA,kBAAkB,UAAU;AACzD,gBAAM,IAAI,MAAM;;AAElB,YAAI,QAAQ;AACZ,YAAI,aAAa,UAAU;AACzB,gBAAM,eACJ,oBAAoB,OAAO,WAAW,IAAI,KAAK;AACjD,gBAAM,MAAM,IAAI;AAChB,cAAI,aAAa,aAAa,gBAAgB,KAAK;AACjD,oBAAQ,SACN,UACA,IAAI,MAAM;AAEZ;;AAEF,kBAAQ,WAAW,MAAK;AACtB,iBAAK,+BAA+B;AACpC,qBACE,IAAI,MAAM;aAEX,aAAa,YAAY,IAAI;;AAElC,cAAM,gBAAgB;UACpB;UACA;UACA;;AAEF,aAAK,0BAA0B,KAAK;;MAQtC,iBAAc;AACZ,eAAO,KAAK;;MAGd,WACE,QACA,UACA,MACA,YACA,gBAAyC;AAEzC,YAAI,OAAO,WAAW,UAAU;AAC9B,gBAAM,IAAI,UAAU;;AAEtB,YAAI,CAAE,QAAO,aAAa,YAAY,oBAAoB,OAAO;AAC/D,gBAAM,IAAI,UACR;;AAGJ,YAAI,KAAK,sBAAsB,qBAAA,kBAAkB,UAAU;AACzD,gBAAM,IAAI,MAAM;;AAElB,cAAM,aAAa;AACnB,aAAK,MACH,iBACE,aACA,eACA,SACA,iBACA;AAEJ,cAAM,eAAkC;UACtC;UACA,OAAO,mBAAc,QAAd,mBAAc,SAAd,iBAAkB,YAAA,UAAU;UACnC,MAAM,SAAI,QAAJ,SAAI,SAAJ,OAAQ,KAAK;UACnB;;AAEF,cAAM,SAA0B,IAAI,cAAA,gBAClC,QACA,MACA,cACA,KAAK,oBACL,KAAK,YAAY,uBACjB;AAEF,YAAI,KAAK,iBAAiB;AACxB,eAAK,YAAY;AACjB,iBAAO,iBAAiB,YAAS;AAC/B,gBAAI,OAAO,SAAS,YAAA,OAAO,IAAI;AAC7B,mBAAK,YAAY;mBACZ;AACL,mBAAK,YAAY;;;;AAIvB,eAAO;;;AAhoBX,aAAA,wBAAA;;;;;;;;;;AC3HA,QAAA,WAAA,QAAA;AACA,QAAA,QAAA,QAAA;AACA,QAAA,WAAA,QAAA;AAGA,QAAA,cAAA;AAOA,QAAA,aAAA;AACA,QAAA,mBAAA;AAGA,QAAA,UAAA;AAEA,QAAM,cAAc;AAEpB,mBAAe,MAAY;AACzB,cAAQ,MAAM,YAAA,aAAa,OAAO,aAAa;;AAOjD,QAAM,8BAA8B;AACpC,QAAM,uBAAuB;AAC7B,QAAM,sBAAsB;AAC5B,QAAM,qBAAqB;AAC3B,QAAM,sBAAsB;AAC5B,QAAM,iBAAiB;AACvB,QAAM,oBAAgD;MACpD,GAAG;MACH,GAAG;MACH,GAAG;MACH,GAAG;MACH,GAAG;MACH,GAAG;;AAEL,QAAM,yBAAyB;OAG5B,8BAA8B;OAC9B,uBAAuB;OACvB,MAAM,UAAU,sBAAsB,MAAM,UAAU;OACtD,MAAM,UAAU,4BAA4B;;AAE/C,QAAM,yBAAyB;MAC7B,iBAAiB;;AAkCnB,4CACU,SAAA,aAAY;MAIpB,YACU,MACD,UACA,SAAoB;AAE3B;AAJQ,aAAA,OAAA;AACD,aAAA,WAAA;AACA,aAAA,UAAA;AAGP,aAAK,YAAY;AACjB,aAAK,KAAK,iBAAiB;;MAG7B,UAAO;AACL,eAAO,KAAK,KAAK;;MAGnB,aAAa,kBAA0B;AACrC,aAAK,KAAK,aAAa;;MAGzB,cAAW;AACT,eAAO,KAAK,KAAK;;;AAxBrB,aAAA,sBAAA;AA4BA,iDACU,SAAA,SAAQ;MAIhB,YACU,MACD,UACA,aAAqC;AAE5C,cAAM,EAAE,YAAY;AAJZ,aAAA,OAAA;AACD,aAAA,WAAA;AACA,aAAA,cAAA;AAGP,aAAK,YAAY;AACjB,aAAK,KAAK,iBAAiB;AAC3B,aAAK,KAAK,cAAc;;MAG1B,MAAM,MAAY;AAChB,YAAI,CAAC,KAAK,KAAK,wBAAwB,OAAO;AAC5C;;AAGF,aAAK,KAAK;;MAGZ,UAAO;AACL,eAAO,KAAK,KAAK;;MAGnB,aAAa,kBAA0B;AACrC,aAAK,KAAK,aAAa;;MAGzB,cAAW;AACT,eAAO,KAAK,KAAK;;;AAjCrB,aAAA,2BAAA;AAqCA,iDACU,SAAA,SAAQ;MAKhB,YACU,MACD,UACA,WACA,SAAoB;AAE3B,cAAM,EAAE,YAAY;AALZ,aAAA,OAAA;AACD,aAAA,WAAA;AACA,aAAA,YAAA;AACA,aAAA,UAAA;AAGP,aAAK,YAAY;AACjB,aAAK,mBAAmB,IAAI,WAAA;AAC5B,aAAK,KAAK,iBAAiB;AAE3B,aAAK,GAAG,SAAS,CAAC,QAAO;AACvB,eAAK,KAAK,UAAU;AACpB,eAAK;;;MAIT,UAAO;AACL,eAAO,KAAK,KAAK;;MAGnB,aAAa,kBAA0B;AACrC,aAAK,KAAK,aAAa;;MAGzB,cAAW;AACT,eAAO,KAAK,KAAK;;MAGnB,OACE,OACA,UAEA,UAAkC;AAElC,YAAI;AACF,gBAAM,WAAW,KAAK,KAAK,iBAAiB;AAE5C,cAAI,CAAC,KAAK,KAAK,MAAM,WAAW;AAC9B,iBAAK,KAAK,KAAK,SAAS;AACxB;;iBAEK,KAAP;AACA,cAAI,OAAO,YAAA,OAAO;AAClB,eAAK,KAAK,SAAS;;AAGrB;;MAGF,OAAO,UAAkB;AACvB,aAAK,KAAK,WAAW;UACnB,MAAM,YAAA,OAAO;UACb,SAAS;UACT,UAAU,KAAK;;AAEjB,iBAAS;;MAIX,IAAI,UAAc;AAChB,YAAI,UAAU;AACZ,eAAK,mBAAmB;;AAG1B,cAAM;;;AAvEV,aAAA,2BAAA;AA2EA,+CACU,SAAA,OAAM;MAKd,YACU,MACD,UACA,WACA,aAAqC;AAE5C,cAAM,EAAE,YAAY;AALZ,aAAA,OAAA;AACD,aAAA,WAAA;AACA,aAAA,YAAA;AACA,aAAA,cAAA;AAGP,aAAK,YAAY;AACjB,aAAK,mBAAmB,IAAI,WAAA;AAC5B,aAAK,KAAK,iBAAiB;AAC3B,aAAK,KAAK,cAAc;AAExB,aAAK,GAAG,SAAS,CAAC,QAAO;AACvB,eAAK,KAAK,UAAU;AACpB,eAAK;;;MAIT,UAAO;AACL,eAAO,KAAK,KAAK;;MAGnB,aAAa,kBAA0B;AACrC,aAAK,KAAK,aAAa;;MAGzB,cAAW;AACT,eAAO,KAAK,KAAK;;MAInB,IAAI,UAAc;AAChB,YAAI,UAAU;AACZ,eAAK,mBAAmB;;AAG1B,cAAM;;;AA1CV,aAAA,yBAAA;AA8CA,2BAAuB,UAAU,QAC/B,yBAAyB,UAAU;AACrC,2BAAuB,UAAU,SAC/B,yBAAyB,UAAU;AACrC,2BAAuB,UAAU,SAC/B,yBAAyB,UAAU;AACrC,2BAAuB,UAAU,MAAM,yBAAyB,UAAU;AA+E1E,8CAGU,SAAA,aAAY;MAapB,YACU,QACA,SACA,SAAuB;AAE/B;AAJQ,aAAA,SAAA;AACA,aAAA,UAAA;AACA,aAAA,UAAA;AAfV,aAAA,YAAY;AACZ,aAAA,gBAA8B,WAAW,MAAK;WAAK;AAC3C,aAAA,WAAqB;AACrB,aAAA,eAAe;AACf,aAAA,eAAe;AACf,aAAA,UAAU;AACV,aAAA,gBAAgB;AAChB,aAAA,mBAAyC;AACzC,aAAA,iBAA4C;AAC5C,aAAA,qBAA6B,YAAA;AAC7B,aAAA,wBAAgC,YAAA;AAStC,aAAK,OAAO,KAAK,SAAS,CAAC,QAA4B;;AAQvD,aAAK,OAAO,KAAK,SAAS,MAAK;;AAC7B,gBACE,uBAAoB,OAClB,KAAK,aAAO,QAAA,OAAA,SAAA,SAAA,GAAE,QACd,iCACA,KAAK,OAAO;AAEhB,eAAK,YAAY;AACjB,eAAK,KAAK,aAAa;AACvB,eAAK,KAAK,aAAa;AACvB,eAAK,WAAW,EAAC,MAAM,YAAA,OAAO,WAAW,SAAS,uBAAuB,UAAU,IAAI,WAAA;;AAGzF,aAAK,OAAO,GAAG,SAAS,MAAK;AAC3B,eAAK,KAAK;;AAGZ,YAAI,kCAAkC,SAAS;AAC7C,eAAK,qBAAqB,QAAQ;;AAEpC,YAAI,qCAAqC,SAAS;AAChD,eAAK,wBAAwB,QAAQ;;AAIvC,qBAAa,KAAK;;MAGZ,iBAAc;AAGpB,YAAI,KAAK,OAAO,aAAa,KAAK,OAAO,QAAQ;AAC/C,eAAK,YAAY;;AAEnB,eAAO,KAAK;;MAGd,aAAa,gBAAyB;AACpC,YAAI,KAAK,kBAAkB;AACzB;;AAGF,YAAI,KAAK,cAAc;AACrB;;AAGF,aAAK,eAAe;AACpB,cAAM,SAAS,iBAAiB,eAAe,mBAAmB;AAElE,cAAM,UAAU,OAAO,OAAO,IAAI,wBAAwB;AAC1D,aAAK,OAAO,QAAQ,SAAS;;MAG/B,gBAAgB,SAAkC;AAChD,cAAM,WAAW,WAAA,SAAS,iBAAiB;AAI3C,cAAM,gBAAgB,SAAS,IAAI;AAEnC,YAAI,cAAc,SAAS,GAAG;AAC5B,gBAAM,QAAQ,cAAc,GAAG,WAAW,MAAM;AAEhD,cAAI,UAAU,MAAM;AAClB,kBAAM,MAAM,IAAI,MAAM;AACtB,gBAAI,OAAO,YAAA,OAAO;AAClB,iBAAK,UAAU;AACf;;AAGF,gBAAM,UAAW,CAAC,MAAM,KAAK,kBAAkB,MAAM,MAAO;AAE5D,gBAAM,MAAM,IAAI;AAChB,eAAK,WAAW,IAAI,gBAAgB,IAAI,oBAAoB;AAC5D,eAAK,gBAAgB,WAAW,uBAAuB,SAAS;AAChE,mBAAS,OAAO;;AAIlB,iBAAS,OAAO,MAAM,UAAU;AAChC,iBAAS,OAAO,MAAM,UAAU;AAChC,iBAAS,OAAO,MAAM,UAAU;AAChC,iBAAS,OAAO;AAChB,iBAAS,OAAO;AAEhB,eAAO;;MAGT,sBAAmB;AACjB,eAAO,IAAI,QAAQ,CAAC,UAAS,WAAU;AACrC,gBAAM,SAAS,KAAK;AACpB,gBAAM,SAAmB;AACzB,cAAI,cAAc;AAElB,iBAAO,GAAG,QAAQ,CAAC,SAAgB;AACjC,mBAAO,KAAK;AACZ,2BAAe,KAAK;;AAGtB,iBAAO,KAAK,OAAO,YAAW;AAC5B,gBAAI;AACF,oBAAM,eAAe,OAAO,OAAO,QAAQ;AAC3C,kBACE,KAAK,0BAA0B,MAC/B,aAAa,SAAS,KAAK,uBAC3B;AACA,qBAAK,UAAU;kBACb,MAAM,YAAA,OAAO;kBACb,SAAS,qCAAqC,aAAa,cAAc,KAAK;;AAEhF;;AAGF,mBAAK,KAAK;AACV,uBAAQ,KAAK,mBAAmB;qBACzB,KAAP;AACA,kBAAI,OAAO,YAAA,OAAO;AAClB,mBAAK,UAAU;AACf;;;;;MAMR,iBAAiB,OAAmB;AAClC,cAAM,gBAAgB,KAAK,QAAQ,UAAU;AAG7C,cAAM,aAAa,cAAc;AACjC,cAAM,SAAS,OAAO,YAAY,aAAa;AAC/C,eAAO,WAAW,GAAG;AACrB,eAAO,cAAc,YAAY;AACjC,sBAAc,KAAK,QAAQ;AAC3B,eAAO;;MAGT,mBAAmB,OAAa;AAE9B,cAAM,kBAAkB,MAAM,MAAM;AAEpC,eAAO,KAAK,QAAQ,YAAY;;YAG5B,iBACJ,KACA,OACA,UACA,OAAc;AAEd,YAAI,KAAK,kBAAkB;AACzB;;AAEF,YAAI,CAAC,UAAU;AACb,qBAAW,IAAI,WAAA;;AAGjB,YAAI,KAAK;AACP,cAAI,CAAC,OAAO,UAAU,eAAe,KAAK,KAAK,aAAa;AAC1D,gBAAI,WAAW;;AAEjB,eAAK,UAAU;AACf;;AAGF,YAAI;AACF,gBAAM,WAAW,KAAK,iBAAiB;AAEvC,eAAK,MAAM;AACX,eAAK,WAAW,EAAE,MAAM,YAAA,OAAO,IAAI,SAAS,MAAM;iBAC3C,MAAP;AACA,eAAI,OAAO,YAAA,OAAO;AAClB,eAAK,UAAU;;;MAInB,WAAW,WAAuB;;AAChC,aAAK,KAAK,WAAW,UAAU;AAC/B,aAAK,KAAK,aAAa,UAAU,SAAS,YAAA,OAAO;AACjD,YAAI,KAAK,kBAAkB;AACzB;;AAGF,cACE,uBAAoB,OAClB,KAAK,aAAO,QAAA,OAAA,SAAA,SAAA,GAAE,QACd,8BACA,YAAA,OAAO,UAAU,QACjB,eACA,UAAU;AAGd,qBAAa,KAAK;AAElB,YAAI,CAAC,KAAK,cAAc;AACtB,eAAK,eAAe;AACpB,eAAK,OAAO,KAAK,gBAAgB,MAAK;AACpC,kBAAM,iBAAiB,OAAO,OAC5B;eACG,qBAAqB,UAAU;eAC/B,sBAAsB,UAAU,UAAU;eAE7C,UAAU,SAAS;AAGrB,iBAAK,OAAO,aAAa;;AAE3B,eAAK;AACL,eAAK,OAAO;;;MAIhB,UAAU,OAAiD;AACzD,cAAM,SAAuB;UAC3B,MAAM,YAAA,OAAO;UACb,SAAS,aAAa,QAAQ,MAAM,UAAU;UAC9C,UACE,cAAc,SAAS,MAAM,aAAa,SACtC,MAAM,WACN,IAAI,WAAA;;AAGZ,YACE,UAAU,SACV,OAAO,MAAM,SAAS,YACtB,OAAO,UAAU,MAAM,OACvB;AACA,iBAAO,OAAO,MAAM;AAEpB,cAAI,aAAa,SAAS,OAAO,MAAM,YAAY,UAAU;AAC3D,mBAAO,UAAU,MAAM;;;AAI3B,aAAK,WAAW;;MAGlB,MAAM,OAAa;AACjB,YAAI,KAAK,kBAAkB;AACzB;;AAGF,YACE,KAAK,uBAAuB,MAC5B,MAAM,SAAS,KAAK,oBACpB;AACA,eAAK,UAAU;YACb,MAAM,YAAA,OAAO;YACb,SAAS,iCAAiC,MAAM,cAAc,KAAK;;AAErE;;AAGF,aAAK;AACL,aAAK,KAAK;AACV,eAAO,KAAK,OAAO,MAAM;;MAG3B,SAAM;AACJ,aAAK,OAAO;;MAGd,iBAAiB,MAAuB;AACtC,aAAK,KAAK,aAAa,CAAC,WAAU;AAChC,eAAK,YAAY;AACjB,eAAK,KAAK,aAAa;;;MAI3B,cACE,UAEiD;AAEjD,cAAM,UAAU,IAAI,iBAAA;AAEpB,aAAK,OAAO,GAAG,QAAQ,OAAO,SAAgB;AAC5C,gBAAM,WAAW,QAAQ,MAAM;AAE/B,qBAAW,WAAW,UAAU;AAC9B,gBACE,KAAK,0BAA0B,MAC/B,QAAQ,SAAS,KAAK,uBACtB;AACA,mBAAK,UAAU;gBACb,MAAM,YAAA,OAAO;gBACb,SAAS,qCAAqC,QAAQ,cAAc,KAAK;;AAE3E;;AAEF,iBAAK,KAAK;AACV,iBAAK,oBAAoB,UAAU;;;AAIvC,aAAK,OAAO,KAAK,OAAO,MAAK;AAC3B,eAAK,oBAAoB,UAAU;;;MAIvC,wBACE,UAEiD;AAEjD,aAAK,UAAU;AAEf,eAAO,KAAK,eAAe,SAAS,GAAG;AACrC,gBAAM,cAAc,KAAK,eAAe;AACxC,gBAAM,UAAU,SAAS,KAAK;AAE9B,cAAI,gBAAgB,QAAQ,YAAY,OAAO;AAC7C,iBAAK,UAAU;AACf;;;AAIJ,eAAO,KAAK;;MAGN,oBACN,UAGA,cAA2B;AAE3B,YAAI,KAAK,eAAe;AACtB,eAAK,iBAAiB,KAAK;eACtB;AACL,eAAK,YAAY,UAAU;;;YAIjB,YACZ,UAGA,cAA2B;AAE3B,YAAI,iBAAiB,MAAM;AACzB,cAAI,KAAK,SAAS;AAChB,qBAAS,KAAK;iBACT;AACL,iBAAK,eAAe,KAAK;;AAG3B;;AAGF,aAAK,gBAAgB;AAErB,YAAI;AACF,gBAAM,eAAe,MAAM,KAAK,mBAAmB;AAEnD,cAAI,KAAK,SAAS;AAChB,gBAAI,CAAC,SAAS,KAAK,eAAe;AAChC,mBAAK,UAAU;AACf,mBAAK,OAAO;;iBAET;AACL,iBAAK,eAAe,KAAK;;iBAEpB,OAAP;AAEA,eAAK,iBAAiB,SAAS;AAE/B,cACE,CACE,WAAU,SACV,OAAO,MAAM,SAAS,YACtB,OAAO,UAAU,MAAM,SACvB,MAAM,QAAQ,YAAA,OAAO,MACrB,MAAM,QAAQ,YAAA,OAAO,kBAEvB;AAEA,kBAAM,OAAO,YAAA,OAAO;;AAGtB,mBAAS,KAAK,SAAS;;AAGzB,aAAK,gBAAgB;AAErB,YAAI,KAAK,iBAAiB,SAAS,GAAG;AACpC,eAAK,YACH,UACA,KAAK,iBAAiB;;;MAK5B,UAAO;AACL,cAAM,SAAS,KAAK,OAAO,QAAQ;AACnC,YAAI,OAAO,eAAe;AACxB,cAAI,OAAO,YAAY;AACrB,mBAAO,GAAG,OAAO,iBAAiB,OAAO;iBACpC;AACL,mBAAO,OAAO;;eAEX;AACL,iBAAO;;;MAIX,cAAW;AACT,eAAO,KAAK;;;AApbhB,aAAA,wBAAA;AA2bA,mCAA+B,MAAuB;AACpD,YAAM,MAAM,IAAI,MAAM;AACtB,UAAI,OAAO,YAAA,OAAO;AAElB,WAAK,UAAU;AACf,WAAK,YAAY;AACjB,WAAK,KAAK,aAAa;;;;;;;;;;;ACpyBzB,QAAA,gBAAA;AAOA,kCAAuC;aAI9B,iBAAc;AACnB,eAAO,IAAI;;aAGN,UACL,WACA,cACA,yBAAyB,OAAK;AAE9B,YAAI,cAAc,QAAQ,CAAC,OAAO,SAAS,YAAY;AACrD,gBAAM,IAAI,UAAU;;AAGtB,YAAI,CAAC,MAAM,QAAQ,eAAe;AAChC,gBAAM,IAAI,UAAU;;AAGtB,YAAI,OAAO,2BAA2B,WAAW;AAC/C,gBAAM,IAAI,UAAU;;AAGtB,cAAM,OAAO;AACb,cAAM,MAAM;AAEZ,iBAAS,IAAI,GAAG,IAAI,aAAa,QAAQ,KAAK;AAC5C,gBAAM,OAAO,aAAa;AAE1B,cAAI,SAAS,QAAQ,OAAO,SAAS,UAAU;AAC7C,kBAAM,IAAI,UAAU,eAAe;;AAGrC,cAAI,CAAC,OAAO,SAAS,KAAK,cAAc;AACtC,kBAAM,IAAI,UAAU,eAAe;;AAGrC,cAAI,CAAC,OAAO,SAAS,KAAK,aAAa;AACrC,kBAAM,IAAI,UAAU,eAAe;;AAGrC,eAAK,KAAK,KAAK;AACf,cAAI,KAAK,KAAK;;AAGhB,eAAO,IAAI,wBAAwB;UACjC,IAAI,aAAa,cAAA,yBAAyB;UAC1C;UACA;UACA,aAAa;UACb,SAAS,cAAA;;;;AApDf,aAAA,oBAAA;AAyDA,kDAAwC,kBAAiB;MACvD,YAAS;AACP,eAAO;;MAGT,eAAY;AACV,eAAO;;;AAIX,gDAAsC,kBAAiB;MAGrD,YAAY,SAA4B;AACtC;AACA,aAAK,UAAU;;MAGjB,YAAS;AACP,eAAO;;MAGT,eAAY;AACV,eAAO,KAAK;;;;;;;;;;;;ACxFhB,QAAA,QAAA,QAAA;AAIA,QAAA,cAAA;AAEA,QAAA,aAAA;AACA,QAAA,gBAAA;AAqBA,QAAA,uBAAA;AAEA,QAAA,aAAA;AAKA,QAAA,UAAA;AACA,QAAA,uBAAA;AAOA,QAAA,eAAA;AACA,QAAA,aAAA;AAGA,QAAM,cAAc;AAOpB,oBAAa;;AAEb,4CACE,YAAkB;AAElB,aAAO;QACL,MAAM,YAAA,OAAO;QACb,SAAS,4CAA4C;QACrD,UAAU,IAAI,WAAA;;;AAelB,+BAA2B,aAA0B,YAAkB;AACrE,YAAM,8BAA8B,+BAClC;AAEF,cAAQ;aACD;AACH,iBAAO,CACL,MACA,aACE;AACF,qBAAS,6BAA6C;;aAErD;AACH,iBAAO,CACL,MACA,aACE;AACF,qBAAS,6BAA6C;;aAErD;AACH,iBAAO,CAAC,SAAwC;AAC9C,iBAAK,KAAK,SAAS;;aAElB;AACH,iBAAO,CAAC,SAAsC;AAC5C,iBAAK,KAAK,SAAS;;;AAGrB,gBAAM,IAAI,MAAM,uBAAuB;;;AAiB7C,uBAAmB;MAmBjB,YAAY,SAAwB;AAlB5B,aAAA,kBAAuG;AAEvG,aAAA,WAAwC,IAAI;AAI5C,aAAA,WAAW,IAAI;AACf,aAAA,UAAU;AAID,aAAA,kBAA2B;AAEpC,aAAA,gBAAgB,IAAI,WAAA;AACpB,aAAA,cAAc,IAAI,WAAA;AAClB,aAAA,0BAA0B,IAAI,WAAA;AAC9B,aAAA,yBAAyB,IAAI,WAAA;AAGnC,aAAK,UAAU,YAAO,QAAP,YAAO,SAAP,UAAW;AAC1B,YAAI,KAAK,QAAQ,4BAA4B,GAAG;AAC9C,eAAK,kBAAkB;;AAEzB,YAAI,KAAK,iBAAiB;AACxB,eAAK,cAAc,WAAA,uBAAuB,MAAM,KAAK;AACrD,eAAK,cAAc,SAAS,WAAW;AACvC,eAAK,MAAM;eACN;AAEL,eAAK,cAAc;YACjB,MAAM;YACN,IAAI;;;;MAKF,kBAAe;AACrB,eAAO;UACL,OAAO,KAAK;UACZ,aAAa,KAAK;UAClB,kBAAkB,KAAK,wBAAwB;UAC/C,iBAAiB,KAAK,uBAAuB;;;MAIzC,6BAA6B,SAAiC;AACpE,eAAO,MAAK;;AACV,gBAAM,cAAc,KAAK,SAAS,IAAI;AACtC,gBAAM,gBAAgB,QAAQ;AAC9B,gBAAM,gBAAgB,cAAc,gBAAgB,qBAAA,0BAA0B,cAAc,eAAe,cAAc,cAAc;AACvI,gBAAM,eAAe,cAAc,eAAe,qBAAA,0BAA0B,cAAc,cAAe,cAAc,aAAa;AACpI,cAAI;AACJ,cAAI,QAAQ,WAAW;AACrB,kBAAM,YAAuB;AAC7B,kBAAM,aAA8D,UAAU;AAC9E,kBAAM,cAAc,UAAU;AAC9B,kBAAM,kBAAkB,UAAU;AAClC,sBAAU;cACR,yBAAuB,MAAE,WAAW,kBAAY,QAAA,OAAA,SAAA,KAAI;cACpD,sBAAsB,WAAW,eAAe,OAAO,WAAW;cAClE,kBAAmB,eAAe,SAAS,cAAe,YAAY,MAAM;cAC5E,mBAAoB,mBAAmB,SAAS,kBAAmB,gBAAgB,MAAM;;iBAEtF;AACL,sBAAU;;AAEZ,gBAAM,aAAyB;YAC7B;YACA;YACA,UAAU;YACV,YAAY;YACZ,gBAAgB,YAAY,cAAc;YAC1C,kBAAkB,YAAY,cAAc;YAC5C,eAAe,YAAY,cAAc;YACzC,cAAc,YAAY;YAC1B,kBAAkB,YAAY;YAC9B,gBAAgB;YAChB,iCAAiC;YACjC,kCAAkC,YAAY,cAAc;YAC5D,0BAA0B,YAAY;YACtC,8BAA8B,YAAY;YAC1C,wBAAsB,MAAE,QAAQ,MAAM,qBAAe,QAAA,OAAA,SAAA,KAAI;YACzD,yBAAuB,MAAE,QAAQ,MAAM,sBAAgB,QAAA,OAAA,SAAA,KAAI;;AAE7D,iBAAO;;;MAIH,MAAM,MAAY;AACxB,gBAAQ,MAAM,YAAA,aAAa,OAAO,aAAa,MAAM,KAAK,YAAY,KAAK,OAAO;;MAIpF,kBAAe;AACb,cAAM,IAAI,MAAM;;MAGlB,WACE,SACA,gBAA4C;AAE5C,YACE,YAAY,QACZ,OAAO,YAAY,YACnB,mBAAmB,QACnB,OAAO,mBAAmB,UAC1B;AACA,gBAAM,IAAI,MAAM;;AAGlB,cAAM,cAAc,OAAO,KAAK;AAEhC,YAAI,YAAY,WAAW,GAAG;AAC5B,gBAAM,IAAI,MAAM;;AAGlB,oBAAY,QAAQ,CAAC,UAAQ;AAC3B,gBAAM,QAAQ,QAAQ;AACtB,cAAI;AAEJ,cAAI,MAAM,eAAe;AACvB,gBAAI,MAAM,gBAAgB;AACxB,2BAAa;mBACR;AACL,2BAAa;;iBAEV;AACL,gBAAI,MAAM,gBAAgB;AACxB,2BAAa;mBACR;AACL,2BAAa;;;AAIjB,cAAI,SAAS,eAAe;AAC5B,cAAI;AAEJ,cAAI,WAAW,UAAa,OAAO,MAAM,iBAAiB,UAAU;AAClE,qBAAS,eAAe,MAAM;;AAGhC,cAAI,WAAW,QAAW;AACxB,mBAAO,OAAO,KAAK;iBACd;AACL,mBAAO,kBAAkB,YAAY;;AAGvC,gBAAM,UAAU,KAAK,SACnB,MAAM,MACN,MACA,MAAM,mBACN,MAAM,oBACN;AAGF,cAAI,YAAY,OAAO;AACrB,kBAAM,IAAI,MAAM,sBAAsB,MAAM;;;;MAKlD,cAAc,SAA0B;AACtC,YAAI,YAAY,QAAQ,OAAO,YAAY,UAAU;AACnD,gBAAM,IAAI,MAAM;;AAGlB,cAAM,cAAc,OAAO,KAAK;AAChC,oBAAY,QAAQ,CAAC,UAAQ;AAC3B,gBAAM,QAAQ,QAAQ;AACtB,eAAK,WAAW,MAAM;;;MAI1B,KAAK,MAAc,OAAwB;AACzC,cAAM,IAAI,MAAM;;MAGlB,UACE,MACA,OACA,UAAqD;AAErD,YAAI,KAAK,YAAY,MAAM;AACzB,gBAAM,IAAI,MAAM;;AAGlB,YAAI,OAAO,SAAS,UAAU;AAC5B,gBAAM,IAAI,UAAU;;AAGtB,YAAI,UAAU,QAAQ,CAAE,kBAAiB,qBAAA,oBAAoB;AAC3D,gBAAM,IAAI,UAAU;;AAGtB,YAAI,OAAO,aAAa,YAAY;AAClC,gBAAM,IAAI,UAAU;;AAGtB,cAAM,iBAAiB,aAAA,SAAS;AAChC,YAAI,mBAAmB,MAAM;AAC3B,gBAAM,IAAI,MAAM,yBAAyB;;AAE3C,cAAM,UAAU,WAAA,oBAAoB;AACpC,YAAI,YAAY,MAAM;AACpB,gBAAM,IAAI,MAAM,4CAA4C;;AAG9D,cAAM,gBAAqC;UACzC,0BAA0B,OAAO;;AAEnC,YAAI,kCAAkC,KAAK,SAAS;AAClD,wBAAc,mBAAmB,KAAK,QACpC;;AAGJ,YAAI,iCAAiC,KAAK,SAAS;AACjD,wBAAc,WAAW;YACvB,sBAAsB,KAAK,QAAQ;;;AAIvC,cAAM,mBAAmB,CAAC,OAAqB,UAAgB;AAC7D,kBAAQ,SAAS,MAAM,SAAS,OAAO;;AAGzC,cAAM,cAAc,MAAkD;AACpE,cAAI;AACJ,cAAI,MAAM,aAAa;AACrB,kBAAM,sBAAsB,OAAO,OACjC,eACA,MAAM;AAER,0BAAc,MAAM,mBAAmB;iBAClC;AACL,0BAAc,MAAM,aAAa;;AAGnC,sBAAY,WAAW,GAAG;AAC1B,eAAK,eAAe;AACpB,iBAAO;;AAGT,cAAM,mBAAmB,CACvB,aACA,SACA,kBACuB;AACvB,cAAI,YAAY,WAAW,GAAG;AAC5B,mBAAO,QAAQ,QAAQ,EAAE,MAAM,SAAS,OAAO;;AAEjD,iBAAO,QAAQ,IACb,YAAY,IAAI,CAAC,YAAW;AAC1B,iBAAK,MAAM,wBAAwB,qBAAA,0BAA0B;AAC7D,gBAAI;AACJ,gBAAI,qBAAA,uBAAuB,UAAU;AACnC,qBAAO;gBACL,MAAO,QAAiC;gBACxC,MAAM;;mBAEH;AACL,qBAAO;;AAGT,kBAAM,cAAc;AACpB,mBAAO,IAAI,QAAwB,CAAC,UAAS,WAAU;AACrD,oBAAM,UAAU,CAAC,QAAc;AAC7B,qBAAK,MAAM,oBAAoB,qBAAA,0BAA0B,WAAW,iBAAiB,IAAI;AACzF,yBAAQ;;AAGV,0BAAY,KAAK,SAAS;AAE1B,0BAAY,OAAO,MAAM,MAAK;AAC5B,sBAAM,eAAe,YAAY;AACjC,oBAAI;AACJ,oBAAI,OAAO,iBAAiB,UAAU;AACpC,2CAAyB;oBACvB,MAAM;;uBAEH;AACL,2CAAyB;oBACvB,MAAM,aAAa;oBACnB,MAAM,aAAa;;;AAGvB,sBAAM,cAAc,WAAA,uBAAuB,qBAAA,0BAA0B,yBAAyB,MAAK;AACjG,yBAAO;oBACL,cAAc;oBACd,eAAe;oBACf,UAAU;oBACV,YAAY;oBACZ,gBAAgB;oBAChB,kBAAkB;oBAClB,eAAe;oBACf,cAAc;oBACd,kBAAkB;oBAClB,gBAAgB;oBAChB,iCAAiC;oBACjC,kCAAkC;oBAClC,0BAA0B;oBAC1B,8BAA8B;oBAC9B,wBAAwB;oBACxB,yBAAyB;;;AAG7B,qBAAK,wBAAwB,SAAS;AACtC,qBAAK,gBAAgB,KAAK,EAAC,QAAQ,aAAa;AAChD,qBAAK,MAAM,wBAAwB,qBAAA,0BAA0B;AAC7D,yBAAQ,UAAU,yBAAyB,uBAAuB,OAAO;AACzE,4BAAY,eAAe,SAAS;;;cAI1C,KAAK,CAAC,YAAW;AACjB,gBAAI,QAAQ;AACZ,uBAAW,UAAU,SAAS;AAC5B,kBAAI,OAAO,WAAW,UAAU;AAC9B,yBAAS;AACT,oBAAI,WAAW,SAAS;AACtB,wBAAM,IAAI,MACR;;;;AAKR,mBAAO;cACL,MAAM;cACN,OAAO,QAAQ;;;;AAKrB,cAAM,mBAAmB,CACvB,gBACuB;AACvB,cAAI,YAAY,WAAW,GAAG;AAC5B,mBAAO,QAAQ,QAAoB,EAAE,MAAM,GAAG,OAAO;;AAEvD,gBAAM,UAAU,YAAY;AAC5B,gBAAM,cAAc;AACpB,iBAAO,IAAI,QAAoB,CAAC,UAAS,WAAU;AACjD,kBAAM,UAAU,CAAC,QAAc;AAC7B,mBAAK,MAAM,oBAAoB,qBAAA,0BAA0B,WAAW,iBAAiB,IAAI;AACzF,uBAAQ,iBAAiB,YAAY,MAAM;;AAG7C,wBAAY,KAAK,SAAS;AAE1B,wBAAY,OAAO,SAAS,MAAK;AAC/B,oBAAM,eAAe,YAAY;AACjC,oBAAM,yBAA4C;gBAChD,MAAM,aAAa;gBACnB,MAAM,aAAa;;AAErB,oBAAM,cAAc,WAAA,uBAAuB,qBAAA,0BAA0B,yBAAyB,MAAK;AACjG,uBAAO;kBACL,cAAc;kBACd,eAAe;kBACf,UAAU;kBACV,YAAY;kBACZ,gBAAgB;kBAChB,kBAAkB;kBAClB,eAAe;kBACf,cAAc;kBACd,kBAAkB;kBAClB,gBAAgB;kBAChB,iCAAiC;kBACjC,kCAAkC;kBAClC,0BAA0B;kBAC1B,8BAA8B;kBAC9B,wBAAwB;kBACxB,yBAAyB;;;AAG7B,mBAAK,wBAAwB,SAAS;AACtC,mBAAK,gBAAgB,KAAK,EAAC,QAAQ,aAAa;AAChD,mBAAK,MAAM,wBAAwB,qBAAA,0BAA0B;AAC7D,uBACE,iBACE,YAAY,MAAM,IAClB,aAAa,MACb;AAGJ,0BAAY,eAAe,SAAS;;;;AAK1C,cAAM,mBAAqC;UACzC,wBAAwB,CACtB,aACA,eACA,uBACE;AAEF,6BAAiB,yBAAyB,MAAK;;AAC/C,gBAAI,YAAY,WAAW,GAAG;AAC5B,+BAAiB,IAAI,MAAM,kCAAkC,SAAS;AACtE;;AAEF,gBAAI;AACJ,gBAAI,qBAAA,uBAAuB,YAAY,KAAK;AAC1C,kBAAI,YAAY,GAAG,SAAS,GAAG;AAC7B,oCAAoB,iBAAiB;qBAChC;AACL,oCAAoB,iBAClB,aACA,YAAY,GAAG,MACf;;mBAGC;AAEL,kCAAoB,iBAAiB,aAAa,GAAG;;AAEvD,8BAAkB,KAChB,CAAC,eAAc;AACb,kBAAI,WAAW,UAAU,GAAG;AAC1B,sBAAM,cAAc,iCAAiC,YAAY;AACjE,wBAAQ,IAAI,YAAA,aAAa,OAAO;AAChC,iCAAiB,IAAI,MAAM,cAAc;qBACpC;AACL,oBAAI,WAAW,QAAQ,YAAY,QAAQ;AACzC,0BAAQ,IACN,YAAA,aAAa,MACb,gBAAgB,WAAW,sCAAsC,YAAY;;AAGjF,iCAAiB,MAAM,WAAW;;eAGtC,CAAC,UAAS;AACR,oBAAM,cAAc,iCAAiC,YAAY;AACjE,sBAAQ,IAAI,YAAA,aAAa,OAAO;AAChC,+BAAiB,IAAI,MAAM,cAAc;;;UAI/C,SAAS,CAAC,UAAS;AACjB,6BAAiB,IAAI,MAAM,MAAM,UAAU;;;AAI/C,cAAM,WAAW,WAAA,eAAe,SAAS,kBAAkB,KAAK;AAChE,iBAAS;;MAGX,gBAAa;AAGX,mBAAW,EAAC,QAAQ,aAAa,aAAa,SAAQ,KAAK,iBAAiB;AAC1E,cAAI,YAAY,WAAW;AACzB,wBAAY,MAAM,MAAK;AACrB,mBAAK,wBAAwB,WAAW;AACxC,yBAAA,sBAAsB;;;;AAK5B,aAAK,UAAU;AAIf,aAAK,SAAS,QAAQ,CAAC,cAAc,YAAW;AAI9C,kBAAQ,QAAQ,MAAM,UAAU;;AAElC,aAAK,SAAS;AACd,mBAAA,sBAAsB,KAAK;;MAG7B,SACE,OACA,SACA,WACA,aACA,MAAY;AAEZ,YAAI,KAAK,SAAS,IAAI,QAAO;AAC3B,iBAAO;;AAGT,aAAK,SAAS,IAAI,OAAM;UACtB,MAAM;UACN;UACA;UACA;UACA,MAAM;;AAER,eAAO;;MAGT,WAAW,OAAY;AACrB,eAAO,KAAK,SAAS,OAAO;;MAG9B,QAAK;AACH,YACE,KAAK,gBAAgB,WAAW,KAChC,KAAK,gBAAgB,MACnB,CAAC,EAAC,QAAQ,kBAAiB,YAAY,cAAc,OAEvD;AACA,gBAAM,IAAI,MAAM;;AAGlB,YAAI,KAAK,YAAY,MAAM;AACzB,gBAAM,IAAI,MAAM;;AAElB,YAAI,KAAK,iBAAiB;AACxB,eAAK,cAAc,SAAS,WAAW;;AAEzC,aAAK,UAAU;;MAGjB,YAAY,UAAiC;AAC3C,cAAM,kBAAkB,CAAC,UAAiB;AACxC,qBAAA,sBAAsB,KAAK;AAC3B,mBAAS;;AAEX,YAAI,gBAAgB;AAEpB,iCAAsB;AACpB;AAEA,cAAI,kBAAkB,GAAG;AACvB;;;AAKJ,aAAK,UAAU;AAEf,mBAAW,EAAC,QAAQ,aAAa,aAAa,SAAQ,KAAK,iBAAiB;AAC1E,cAAI,YAAY,WAAW;AACzB;AACA,wBAAY,MAAM,MAAK;AACrB,mBAAK,wBAAwB,WAAW;AACxC,yBAAA,sBAAsB;AACtB;;;;AAKN,aAAK,SAAS,QAAQ,CAAC,cAAc,YAAW;AAC9C,cAAI,CAAC,QAAQ,QAAQ;AACnB,6BAAiB;AACjB,oBAAQ,MAAM;;;AAGlB,YAAI,kBAAkB,GAAG;AACvB;;;MAIJ,eAAY;AACV,cAAM,IAAI,MAAM;;MAQlB,iBAAc;AACZ,eAAO,KAAK;;MAGN,eACN,aAAwD;AAExD,YAAI,gBAAgB,MAAM;AACxB;;AAGF,oBAAY,GACV,UACA,CAAC,QAAiC,YAAsC;AACtE,gBAAM,sBAAsB,KAAK,SAAS,IAAI,OAAO;AACrD,eAAK,YAAY;AACjB,kCAAmB,QAAnB,wBAAmB,SAAA,SAAnB,oBAAqB,cAAc;AACnC,gBAAM,cAAc,QAAQ,MAAM,UAAU;AAE5C,cACE,OAAO,gBAAgB,YACvB,CAAC,YAAY,WAAW,qBACxB;AACA,mBAAO,QACL;eACG,MAAM,UAAU,sBACf,MAAM,UAAU;eAEpB,EAAE,WAAW;AAEf,iBAAK,YAAY;AACjB,oCAAmB,QAAnB,wBAAmB,SAAA,SAAnB,oBAAqB,cAAc;AACnC;;AAGF,cAAI,OAA+C;AAEnD,cAAI;AACF,kBAAM,OAAO,QAAQ,MAAM,UAAU;AACrC,kBAAM,gBAAgB,YAAY;AAClC,gBAAI,sBAAsB;AAC1B,gBAAI,eAAe;AACjB,kBAAI,OAAO,kBAAkB,UAAU;AACrC,sCAAsB;qBACjB;AACL,sCACE,cAAc,UAAU,MAAM,cAAc;;;AAGlD,iBAAK,MACH,6BACE,OACA,iBACA;AAEJ,kBAAM,UAAU,KAAK,SAAS,IAAI;AAElC,gBAAI,YAAY,QAAW;AACzB,mBAAK,MACH,sCACE,OACA;AAEJ,oBAAM,+BAA+B;;AAGvC,mBAAO,IAAI,cAAA,sBAAsB,QAAQ,SAAS,KAAK;AACvD,iBAAK,KAAK,WAAW,CAAC,SAAgB;AACpC,kBAAI,SAAS,YAAA,OAAO,IAAI;AACtB,qBAAK,YAAY;qBACZ;AACL,qBAAK,YAAY;;;AAGrB,gBAAI,qBAAqB;AACvB,mBAAK,KAAK,aAAa,CAAC,YAAoB;AAC1C,oBAAI,SAAS;AACX,sCAAoB,cAAc;uBAC7B;AACL,sCAAoB,cAAc;;;AAGtC,mBAAK,GAAG,eAAe,MAAK;AAC1B,oCAAoB,gBAAgB;AACpC,oCAAoB,2BAA2B,IAAI;;AAErD,mBAAK,GAAG,kBAAkB,MAAK;AAC7B,oCAAoB,oBAAoB;AACxC,oCAAoB,+BAA+B,IAAI;;;AAG3D,kBAAM,WAAqB,KAAK,gBAAgB;AAChD,oBAAQ,QAAQ;mBACT;AACH,4BAAY,MAAM,SAAgC;AAClD;mBACG;AACH,sCACE,MACA,SACA;AAEF;mBACG;AACH,sCACE,MACA,SACA;AAEF;mBACG;AACH,oCACE,MACA,SACA;AAEF;;AAEA,sBAAM,IAAI,MAAM,yBAAyB,QAAQ;;mBAE9C,KAAP;AACA,gBAAI,CAAC,MAAM;AACT,qBAAO,IAAI,cAAA,sBAAsB,QAAQ,MAAO,KAAK;AACrD,mBAAK,YAAY;AACjB,sCAAmB,QAAnB,wBAAmB,SAAA,SAAnB,oBAAqB,cAAc;;AAGrC,gBAAI,IAAI,SAAS,QAAW;AAC1B,kBAAI,OAAO,YAAA,OAAO;;AAGpB,iBAAK,UAAU;;;AAKrB,oBAAY,GAAG,WAAW,CAAC,YAAW;;AACpC,cAAI,CAAC,KAAK,SAAS;AACjB,oBAAQ;AACR;;AAGF,gBAAM,cAAc,WAAA,uBAAsB,MAAC,QAAQ,OAAO,mBAAa,QAAA,OAAA,SAAA,KAAI,WAAW,KAAK,6BAA6B;AAExH,gBAAM,sBAA2C;YAC/C,KAAK;YACL,eAAe,IAAI,WAAA;YACnB,cAAc;YACd,kBAAkB;YAClB,0BAA0B;YAC1B,8BAA8B;;AAGhC,eAAK,SAAS,IAAI,SAAS;AAC3B,gBAAM,gBAAgB,QAAQ,OAAO;AACrC,cAAI,KAAK,iBAAiB;AACxB,iBAAK,cAAc,SAAS,WAAW,sCAAsC;AAC7E,iBAAK,uBAAuB,SAAS;;AAEvC,kBAAQ,GAAG,SAAS,MAAK;AACvB,gBAAI,KAAK,iBAAiB;AACxB,mBAAK,cAAc,SAAS,WAAW,kCAAkC;AACzE,mBAAK,uBAAuB,WAAW;AACvC,yBAAA,sBAAsB;;AAExB,iBAAK,SAAS,OAAO;;;;;AA7tB7B,aAAA,SAAA;AAmuBA,+BACE,MACA,SACA,UAAkB;AAElB,YAAM,UAAU,MAAM,KAAK;AAE3B,UAAI,YAAY,UAAa,KAAK,WAAW;AAC3C;;AAGF,YAAM,UAAU,IAAI,cAAA,oBAClB,MACA,UACA;AAGF,cAAQ,KACN,SACA,CACE,KACA,OACA,SACA,UACE;AACF,aAAK,iBAAiB,KAAK,OAAO,SAAS;;;AAKjD,mCACE,MACA,SACA,UAAkB;AAElB,YAAM,SAAS,IAAI,cAAA,yBACjB,MACA,UACA,QAAQ;AAGV,uBACE,KACA,OACA,SACA,OAAc;AAEd,eAAO;AACP,aAAK,iBAAiB,KAAK,OAAO,SAAS;;AAG7C,UAAI,KAAK,WAAW;AAClB;;AAGF,aAAO,GAAG,SAAS;AACnB,cAAQ,KAAK,QAAQ;;AAGvB,yCACE,MACA,SACA,UAAkB;AAElB,YAAM,UAAU,MAAM,KAAK;AAE3B,UAAI,YAAY,UAAa,KAAK,WAAW;AAC3C;;AAGF,YAAM,SAAS,IAAI,cAAA,yBACjB,MACA,UACA,QAAQ,WACR;AAGF,cAAQ,KAAK;;AAGf,iCACE,MACA,SACA,UAAkB;AAElB,YAAM,SAAS,IAAI,cAAA,uBACjB,MACA,UACA,QAAQ,WACR,QAAQ;AAGV,UAAI,KAAK,WAAW;AAClB;;AAGF,cAAQ,KAAK;;;;;;;;;;;ACt7Bf,8BAA0B;MAKxB,cAAA;AACE,aAAK,OAAO;AACZ,aAAK,UAAU;AACf,aAAK,WAAW;;MAMlB,SAAS,MAAY;AACnB,aAAK,OAAO;AACZ,eAAO;;MAMT,YAAY,SAAe;AACzB,aAAK,UAAU;AACf,eAAO;;MAMT,aAAa,UAAkB;AAC7B,aAAK,WAAW;AAChB,eAAO;;MAMT,QAAK;AACH,cAAM,SAAgC;AAEtC,YAAI,KAAK,SAAS,MAAM;AACtB,iBAAO,OAAO,KAAK;;AAGrB,YAAI,KAAK,YAAY,MAAM;AACzB,iBAAO,UAAU,KAAK;;AAGxB,YAAI,KAAK,aAAa,MAAM;AAC1B,iBAAO,WAAW,KAAK;;AAGzB,eAAO;;;AArDX,aAAA,gBAAA;;;;;;;;;ACxBA,QAAA,YAAA;AAAS,WAAA,eAAA,UAAA,SAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,UAAA;;AACT,QAAA,aAAA;AAGE,WAAA,eAAA,UAAA,oBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,WAAA;;AAGF,QAAA,eAAA;AAAkB,WAAA,eAAA,UAAA,eAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,aAAA;;AAElB,QAAA,oBAAA;AAAS,WAAA,eAAA,UAAA,kBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,kBAAA;;AACT,QAAA,kBAAA;AAIE,WAAA,eAAA,UAAA,mCAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,gBAAA;;AACA,WAAA,eAAA,UAAA,4BAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,gBAAA;;AACA,WAAA,eAAA,UAAA,wBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,gBAAA;;AACA,WAAA,eAAA,UAAA,+BAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,gBAAA;;AAEF,QAAA,uBAAA;AAEE,WAAA,eAAA,UAAA,6BAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,qBAAA;;AAEF,QAAA,gCAAA;AAAS,WAAA,eAAA,UAAA,4BAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,8BAAA;;AACT,QAAA,WAAA;AAEE,WAAA,eAAA,UAAA,qBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,SAAA;;AACA,WAAA,eAAA,UAAA,eAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,SAAA;;AAGA,WAAA,eAAA,UAAA,kBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,SAAA;;AAGF,QAAA,WAAA;AAAiB,WAAA,eAAA,UAAA,cAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,SAAA;;AACjB,QAAA,iBAAA;AAAS,WAAA,eAAA,UAAA,sBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,eAAA;;AACT,QAAA,UAAA;AAAS,WAAA,eAAA,UAAA,wBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,QAAA;;;;;;;;;;;ACnBT,QAAA,aAAA;AAMA,QAAA,MAAA,QAAA;AACA,QAAA,OAAA,QAAA;AACA,QAAA,mBAAA;AACA,QAAA,cAAA;AAEA,QAAA,aAAA;AACA,QAAA,UAAA;AACA,QAAA,cAAA;AAEA,QAAA,eAAA;AACA,QAAA,QAAA,QAAA;AAGA,QAAM,cAAc;AAEpB,mBAAe,MAAY;AACzB,cAAQ,MAAM,YAAA,aAAa,OAAO,aAAa;;AAMjD,QAAM,eAAe;AAErB,QAAM,oBAAoB,KAAK,UAAU,IAAI;AAC7C,QAAM,mBAAmB,KAAK,UAAU,IAAI;AAM5C,4BAA2B,QAAa;AACtC,YAAM,SAAc;AACpB,eACM,IAAI,GACR,IACA,KAAK,IAAI,MACP,MACA,OAAO,IAAI,CAAC,UAAU,MAAM,UAE9B,KACA;AACA,mBAAW,SAAS,QAAQ;AAC1B,cAAI,IAAI,MAAM,QAAQ;AACpB,mBAAO,KAAK,MAAM;;;;AAIxB,aAAO;;AAMT,4BAAiB;MAWf,YACU,QACA,UACR,gBAA8B;;AAFtB,aAAA,SAAA;AACA,aAAA,WAAA;AATF,aAAA,uBAA4D;AAC5D,aAAA,oBAAgD;AAChD,aAAA,qBAAoD;AACpD,aAAA,sBAA4C;AAC5C,aAAA,2BAAgD;AAQtD,cAAM,qCAAqC,aAAA,YAAY;AACvD,cAAM,WAAW,aAAA,cAAc,OAAO;AACtC,YAAI,aAAa,MAAM;AACrB,eAAK,WAAW;AAChB,eAAK,cAAc;AACnB,eAAK,OAAO;eACP;AACL,cAAI,MAAA,OAAO,SAAS,SAAS,MAAA,OAAO,SAAS,OAAO;AAClD,iBAAK,WAAW;cACd;gBACE,MAAM,SAAS;gBACf,MAAI,MAAE,SAAS,UAAI,QAAA,OAAA,SAAA,KAAI;;;AAG3B,iBAAK,cAAc;AACnB,iBAAK,OAAO;iBACP;AACL,iBAAK,WAAW;AAChB,iBAAK,cAAc,SAAS;AAC5B,iBAAK,OAAI,MAAG,SAAS,UAAI,QAAA,OAAA,SAAA,KAAI;;;AAGjC,aAAK,aAAa,KAAK,WAAW;AAElC,aAAK,yBAAyB;UAC5B,MAAM,YAAA,OAAO;UACb,SAAS,qCAAqC,aAAA,YAAY,KAAK;UAC/D,UAAU,IAAI,WAAA;;;MAQV,kBAAe;AACrB,YAAI,KAAK,aAAa,MAAM;AAC1B,gBAAM,qCAAqC,aAAA,YAAY,KAAK;AAC5D,uBAAa,MAAK;AAChB,iBAAK,SAAS,uBACZ,KAAK,UACL,MACA,MACA,MACA;;AAGJ;;AAEF,YAAI,KAAK,gBAAgB,MAAM;AAC7B,uBAAa,MAAK;AAChB,iBAAK,SAAS,QAAQ;cACpB,MAAM,YAAA,OAAO;cACb,SAAS,+BAA+B,aAAA,YAAY,KAAK;cACzD,UAAU,IAAI,WAAA;;;eAGb;AAOL,eAAK,qBAAqB;AAC1B,gBAAM,WAAmB,KAAK;AAK9B,eAAK,uBAAuB,iBAAiB,UAAU,EAAE,KAAK;AAC9D,eAAK,qBAAqB,KACxB,CAAC,gBAAe;AACd,iBAAK,uBAAuB;AAC5B,kBAAM,eAAoC,YAAY,OACpD,CAAC,SAAS,KAAK,WAAW;AAE5B,kBAAM,eAAoC,YAAY,OACpD,CAAC,SAAS,KAAK,WAAW;AAE5B,iBAAK,qBAAqB,YACxB,cACA,cACA,IAAI,CAAC,SAAU,GAAE,MAAM,KAAK,SAAS,MAAM,CAAC,KAAK;AACnD,kBAAM,qBACJ,MACA,KAAK,mBACF,IAAI,CAAC,SAAS,KAAK,OAAO,MAAM,KAAK,MACrC,KAAK,OACR;AACF,kBACE,mCACE,aAAA,YAAY,KAAK,UACjB,OACA;AAEJ,gBAAI,KAAK,mBAAmB,WAAW,GAAG;AACxC,mBAAK,SAAS,QAAQ,KAAK;AAC3B;;AAMF,iBAAK,SAAS,uBACZ,KAAK,oBACL,KAAK,qBACL,KAAK,0BACL,MACA;aAGJ,CAAC,QAAO;AACN,kBACE,iCACE,aAAA,YAAY,KAAK,UACjB,OACC,IAAc;AAEnB,iBAAK,uBAAuB;AAC5B,iBAAK,SAAS,QAAQ,KAAK;;AAK/B,cAAI,KAAK,sBAAsB,MAAM;AAInC,iBAAK,oBAAoB,kBAAkB;AAC3C,iBAAK,kBAAkB,KACrB,CAAC,cAAa;AACZ,mBAAK,oBAAoB;AACzB,kBAAI;AACF,qBAAK,sBAAsB,iBAAA,8BACzB,WACA,KAAK;uBAEA,KAAP;AACA,qBAAK,2BAA2B;kBAC9B,MAAM,YAAA,OAAO;kBACb,SAAS;kBACT,UAAU,IAAI,WAAA;;;AAGlB,kBAAI,KAAK,uBAAuB,MAAM;AAKpC,qBAAK,SAAS,uBACZ,KAAK,oBACL,KAAK,qBACL,KAAK,0BACL,MACA;;eAIN,CAAC,QAAO;;;;;MAchB,mBAAgB;AACd,cAAM,4CAA4C,aAAA,YAAY,KAAK;AACnE,YAAI,KAAK,yBAAyB,MAAM;AACtC,eAAK;;;MAIT,UAAO;;aAWA,oBAAoB,QAAe;AACxC,eAAO,OAAO;;;AAQlB,qBAAqB;AACnB,iBAAA,iBAAiB,OAAO;AACxB,iBAAA,sBAAsB;;AAFxB,aAAA,QAAA;;;;;;;;;;ACpRA,QAAA,aAAA;AAKA,4BAAiB;MAEf,YACE,QACQ,UACR,gBAA8B;AADtB,aAAA,WAAA;AAHF,aAAA,YAAiC;AAMvC,YAAI;AACJ,YAAI,OAAO,cAAc,IAAI;AAC3B,iBAAO,MAAM,OAAO;eACf;AACL,iBAAO,OAAO;;AAEhB,aAAK,YAAY,CAAC,EAAE;;MAEtB,mBAAgB;AACd,gBAAQ,SACN,KAAK,SAAS,wBACd,KAAK,WACL,MACA,MACA,MACA;;MAIJ,UAAO;;aAIA,oBAAoB,QAAe;AACxC,eAAO;;;AAIX,qBAAqB;AACnB,iBAAA,iBAAiB,QAAQ;;AAD3B,aAAA,QAAA;;;;;;;;;;ACxCA,QAAA,QAAA,QAAA;AAGA,QAAA,cAAA;AACA,QAAA,aAAA;AACA,QAAA,aAAA;AAEA,QAAA,eAAA;AACA,QAAA,UAAA;AAEA,QAAM,cAAc;AAEpB,mBAAe,MAAY;AACzB,cAAQ,MAAM,YAAA,aAAa,OAAO,aAAa;;AAGjD,QAAM,cAAc;AACpB,QAAM,cAAc;AAKpB,QAAM,eAAe;AAErB,2BAAgB;MAGd,YACU,QACA,UACR,gBAA8B;;AAFtB,aAAA,SAAA;AACA,aAAA,WAAA;AAJF,aAAA,YAAiC;AACjC,aAAA,QAA6B;AAMnC,cAAM,qCAAqC,aAAA,YAAY;AACvD,cAAM,YAAiC;AACvC,YAAI,CAAE,QAAO,WAAW,eAAe,OAAO,WAAW,cAAc;AACrE,eAAK,QAAQ;YACX,MAAM,YAAA,OAAO;YACb,SAAS,uBAAuB,OAAO;YACvC,UAAU,IAAI,WAAA;;AAEhB;;AAEF,cAAM,WAAW,OAAO,KAAK,MAAM;AACnC,mBAAW,QAAQ,UAAU;AAC3B,gBAAM,WAAW,aAAA,cAAc;AAC/B,cAAI,aAAa,MAAM;AACrB,iBAAK,QAAQ;cACX,MAAM,YAAA,OAAO;cACb,SAAS,mBAAmB,OAAO,kBAAkB;cACrD,UAAU,IAAI,WAAA;;AAEhB;;AAEF,cACG,OAAO,WAAW,eAAe,CAAC,MAAA,OAAO,SAAS,SAClD,OAAO,WAAW,eAAe,CAAC,MAAA,OAAO,SAAS,OACnD;AACA,iBAAK,QAAQ;cACX,MAAM,YAAA,OAAO;cACb,SAAS,mBAAmB,OAAO,kBAAkB;cACrD,UAAU,IAAI,WAAA;;AAEhB;;AAEF,oBAAU,KAAK;YACb,MAAM,SAAS;YACf,MAAI,MAAE,SAAS,UAAI,QAAA,OAAA,SAAA,KAAI;;;AAG3B,aAAK,YAAY;AACjB,cAAM,YAAY,OAAO,SAAS,mBAAmB,KAAK;;MAE5D,mBAAgB;AACd,gBAAQ,SAAS,MAAK;AACpB,cAAI,KAAK,OAAO;AACd,iBAAK,SAAS,QAAQ,KAAK;iBACtB;AACL,iBAAK,SAAS,uBACZ,KAAK,WACL,MACA,MACA,MACA;;;;MAKR,UAAO;;aAIA,oBAAoB,QAAe;AACxC,eAAO,OAAO,KAAK,MAAM,KAAK;;;AAIlC,qBAAqB;AACnB,iBAAA,iBAAiB,aAAa;AAC9B,iBAAA,iBAAiB,aAAa;;AAFhC,aAAA,QAAA;;;;;;;;;;AC/FA,QAAA,kBAAA;AAOA,QAAA,uBAAA;AACA,QAAA,WAAA;AASA,QAAA,uBAAA;AAIA,QAAA,UAAA;AACA,QAAA,cAAA;AAEA,QAAM,cAAc;AAEpB,mBAAe,MAAY;AACzB,cAAQ,MAAM,YAAA,aAAa,OAAO,aAAa;;AAGjD,QAAM,YAAY;AAMlB,QAAM,+BAA+B;AAErC,6CAAyC;MACvC,sBAAmB;AACjB,eAAO;;MAGT,cAAA;;MAEA,eAAY;AACV,eAAO;WACJ,YAAY;;;aAKV,eAAe,KAAQ;AAC5B,eAAO,IAAI;;;AAff,aAAA,+BAAA;AAuBA,gCAAqB;MACnB,YAAoB,YAAsB;AAAtB,aAAA,aAAA;;MAEpB,KAAK,UAAkB;AACrB,eAAO;UACL,gBAAgB,SAAA,eAAe;UAC/B,YAAY,KAAK;UACjB,QAAQ;UACR,sBAAsB;UACtB,eAAe;;;;AAarB,sCAAkC;MAkDhC,YAA6B,sBAA0C;AAA1C,aAAA,uBAAA;AA9CrB,aAAA,oBAAyC;AAKzC,aAAA,cAA4B;AAI5B,aAAA,eAAkC,qBAAA,kBAAkB;AAKpD,aAAA,yBAAyB;AAQzB,aAAA,cAAiC;AAejC,aAAA,sBAAsB;AAU5B,aAAK,wBAAwB;WAC1B,qBAAA,kBAAkB,aAAa;WAC/B,qBAAA,kBAAkB,OAAO;WACzB,qBAAA,kBAAkB,QAAQ;WAC1B,qBAAA,kBAAkB,WAAW;WAC7B,qBAAA,kBAAkB,oBAAoB;;AAEzC,aAAK,0BAA0B,CAC7B,YACA,eACA,aACE;AACF,eAAK,sBAAsB,kBAAkB;AAC7C,eAAK,sBAAsB,aAAa;AAKxC,cACE,eAAe,KAAK,YAAY,KAAK,2BACrC,aAAa,qBAAA,kBAAkB,mBAC/B;AACA,iBAAK;;AAEP,cAAI,aAAa,qBAAA,kBAAkB,OAAO;AACxC,iBAAK,eAAe;AACpB;iBACK;AACL,gBACE,KAAK,uBACL,KAAK,sBAAsB,qBAAA,kBAAkB,UAC3C,KAAK,YAAY,QACnB;AAIA,mBAAK;AACL,mBAAK,YAAY,qBAAA,kBAAkB,MAAM,IAAI,SAAA,YAAY;AACzD;;AAEF,gBAAI,KAAK,gBAAgB,MAAM;AAC7B,kBAAI,KAAK,qBAAqB;AAC5B,oBAAI;AACJ,oBAAI,KAAK,sBAAsB,qBAAA,kBAAkB,cAAc,GAAG;AAChE,+BAAa,qBAAA,kBAAkB;2BAE/B,KAAK,sBAAsB,qBAAA,kBAAkB,qBAC7C,GACA;AACA,+BAAa,qBAAA,kBAAkB;uBAC1B;AACL,+BAAa,qBAAA,kBAAkB;;AAEjC,oBAAI,eAAe,KAAK,cAAc;AACpC,sBAAI,eAAe,qBAAA,kBAAkB,mBAAmB;AACtD,yBAAK,YAAY,YAAY,IAAI,SAAA;yBAC5B;AACL,yBAAK,YAAY,YAAY,IAAI,SAAA,YAAY;;;qBAG5C;AACL,qBAAK,YACH,qBAAA,kBAAkB,YAClB,IAAI,SAAA,YAAY;;;;;AAM1B,aAAK,gCAAgC,CACnC,YACA,eACA,aACE;AACF,cAAI,aAAa,qBAAA,kBAAkB,OAAO;AACxC,iBAAK,cAAc;AACnB,uBAAW;AACX,uBAAW,gCACT,KAAK;AAEP,iBAAK,qBAAqB,oBAAoB,WAAW;AACzD,gBAAI,KAAK,YAAY,SAAS,GAAG;AAC/B,kBAAI,KAAK,qBAAqB;AAC5B,oBAAI;AACJ,oBAAI,KAAK,sBAAsB,qBAAA,kBAAkB,cAAc,GAAG;AAChE,+BAAa,qBAAA,kBAAkB;2BAE/B,KAAK,sBAAsB,qBAAA,kBAAkB,qBAC7C,GACA;AACA,+BAAa,qBAAA,kBAAkB;uBAC1B;AACL,+BAAa,qBAAA,kBAAkB;;AAEjC,oBAAI,eAAe,qBAAA,kBAAkB,mBAAmB;AACtD,uBAAK,YAAY,YAAY,IAAI,SAAA;uBAC5B;AACL,uBAAK,YAAY,YAAY,IAAI,SAAA,YAAY;;qBAE1C;AACL,qBAAK,YACH,qBAAA,kBAAkB,YAClB,IAAI,SAAA,YAAY;;mBAGf;AAKL,mBAAK,YAAY,qBAAA,kBAAkB,MAAM,IAAI,SAAA,YAAY;;;;AAI/D,aAAK,yBAAyB,WAAW,MAAK;WAAK;AACnD,qBAAa,KAAK;;MAGZ,gCAA6B;AACnC,YAAI,KAAK,qBAAqB;AAC5B;;AAEF,mBAAW,CAAC,OAAO,eAAe,KAAK,YAAY,WAAW;AAC5D,cAAI,QAAQ,KAAK,wBAAwB;AACvC,kBAAM,kBAAkB,WAAW;AACnC,gBACE,oBAAoB,qBAAA,kBAAkB,QACtC,oBAAoB,qBAAA,kBAAkB,YACtC;AACA,mBAAK,gBAAgB;AACrB;;;;AAIN,aAAK,sBAAsB;;MAOrB,gBAAgB,iBAAuB;AAC7C,qBAAa,KAAK;AAClB,aAAK,yBAAyB;AAC9B,YACE,KAAK,YAAY,iBAAiB,2BAClC,qBAAA,kBAAkB,MAClB;AACA,gBACE,iDACE,KAAK,YAAY,iBAAiB;AAEtC,kBAAQ,SAAS,MAAK;AACpB,iBAAK,YAAY,iBAAiB;;;AAGtC,aAAK,yBAAyB,WAAW,MAAK;AAC5C,eAAK;WACJ;;MAGG,eAAe,YAAsB;AAC3C,cAAM,kCAAkC,WAAW;AACnD,YAAI,KAAK,gBAAgB,MAAM;AAC7B,eAAK,YAAY;AACjB,eAAK,YAAY,gCACf,KAAK;;AAGT,aAAK,cAAc;AACnB,aAAK,YAAY,qBAAA,kBAAkB,OAAO,IAAI,gBAAgB;AAC9D,mBAAW,6BAA6B,KAAK;AAC7C,mBAAW;AACX,aAAK,qBAAqB,iBAAiB,WAAW;AACtD,aAAK;AACL,qBAAa,KAAK;;MAGZ,YAAY,UAA6B,QAAc;AAC7D,cACE,qBAAA,kBAAkB,KAAK,gBACrB,SACA,qBAAA,kBAAkB;AAEtB,aAAK,eAAe;AACpB,aAAK,qBAAqB,YAAY,UAAU;;MAG1C,sBAAmB;AACzB,mBAAW,cAAc,KAAK,aAAa;AACzC,qBAAW,gCAAgC,KAAK;AAChD,qBAAW;AACX,eAAK,qBAAqB,oBAAoB,WAAW;;AAE3D,aAAK,yBAAyB;AAC9B,aAAK,wBAAwB;WAC1B,qBAAA,kBAAkB,aAAa;WAC/B,qBAAA,kBAAkB,OAAO;WACzB,qBAAA,kBAAkB,QAAQ;WAC1B,qBAAA,kBAAkB,WAAW;WAC7B,qBAAA,kBAAkB,oBAAoB;;AAEzC,aAAK,cAAc;AACnB,aAAK,sBAAsB;;MAOrB,uBAAoB;AAC1B,aAAK;AACL,cACE,6BACE,KAAK,kBAAkB,IAAI,CAAC,YAC1B,qBAAA,0BAA0B;AAGhC,aAAK,cAAc,KAAK,kBAAkB,IAAI,CAAC,YAC7C,KAAK,qBAAqB,iBAAiB,SAAS;AAEtD,mBAAW,cAAc,KAAK,aAAa;AACzC,qBAAW;AACX,eAAK,qBAAqB,iBAAiB,WAAW;;AAExD,mBAAW,cAAc,KAAK,aAAa;AACzC,qBAAW,6BAA6B,KAAK;AAC7C,eAAK,sBAAsB,WAAW,2BAA2B;AACjE,cAAI,WAAW,2BAA2B,qBAAA,kBAAkB,OAAO;AACjE,iBAAK,eAAe;AACpB,iBAAK;AACL;;;AAGJ,mBAAW,CAAC,OAAO,eAAe,KAAK,YAAY,WAAW;AAC5D,gBAAM,kBAAkB,WAAW;AACnC,cACE,oBAAoB,qBAAA,kBAAkB,QACtC,oBAAoB,qBAAA,kBAAkB,YACtC;AACA,iBAAK,gBAAgB;AACrB,gBAAI,KAAK,gBAAgB,MAAM;AAC7B,mBAAK,YAAY,qBAAA,kBAAkB,YAAY,IAAI,SAAA,YAAY;;AAEjE;;;AAIJ,YAAI,KAAK,gBAAgB,MAAM;AAC7B,eAAK,YACH,qBAAA,kBAAkB,mBAClB,IAAI,SAAA;;;MAKV,kBACE,aACA,UAA6B;AAM7B,YACE,KAAK,YAAY,WAAW,KAC5B,CAAC,KAAK,kBAAkB,MACtB,CAAC,OAAO,UAAU,YAAY,WAAW,QAE3C;AACA,eAAK,oBAAoB;AACzB,eAAK;;;MAIT,WAAQ;AACN,mBAAW,cAAc,KAAK,aAAa;AACzC,qBAAW;;AAEb,YAAI,KAAK,iBAAiB,qBAAA,kBAAkB,MAAM;AAChD,cAAI,KAAK,kBAAkB,SAAS,GAAG;AACrC,iBAAK;;;AAGT,YACE,KAAK,iBAAiB,qBAAA,kBAAkB,QACxC,KAAK,qBACL;AACA,eAAK,qBAAqB;;;MAI9B,eAAY;;MAKZ,UAAO;AACL,aAAK;AACL,YAAI,KAAK,gBAAgB,MAAM;AAC7B,eAAK,YAAY;AACjB,eAAK,YAAY,gCACf,KAAK;AAEP,eAAK,qBAAqB,oBAAoB,KAAK,YAAY;;;MAInE,cAAW;AACT,eAAO;;;AAxWX,aAAA,wBAAA;AA4WA,qBAAqB;AACnB,sBAAA,yBACE,WACA,uBACA;AAEF,sBAAA,gCAAgC;;AANlC,aAAA,QAAA;;;;;;;;;;AC/bA,QAAA,kBAAA;AAMA,QAAA,uBAAA;AACA,QAAA,WAAA;AASA,QAAA,uBAAA;AAIA,QAAA,UAAA;AACA,QAAA,cAAA;AAEA,QAAM,cAAc;AAEpB,mBAAe,MAAY;AACzB,cAAQ,MAAM,YAAA,aAAa,OAAO,aAAa;;AAGjD,QAAM,YAAY;AAElB,8CAAmC;MACjC,sBAAmB;AACjB,eAAO;;MAGT,cAAA;;MAEA,eAAY;AACV,eAAO;WACJ,YAAY;;;aAKV,eAAe,KAAQ;AAC5B,eAAO,IAAI;;;AAIf,iCAAsB;MACpB,YACmB,gBACT,YAAY,GAAC;AADJ,aAAA,iBAAA;AACT,aAAA,YAAA;;MAGV,KAAK,UAAkB;AACrB,cAAM,mBAAmB,KAAK,eAAe,KAAK;AAClD,aAAK,YAAa,MAAK,YAAY,KAAK,KAAK,eAAe;AAC5D,eAAO;UACL,gBAAgB,SAAA,eAAe;UAC/B,YAAY;UACZ,QAAQ;UACR,sBAAsB;UACtB,eAAe;;;MASnB,qBAAkB;AAChB,eAAO,KAAK,eAAe,KAAK;;;AAYpC,uCAAmC;MAWjC,YAA6B,sBAA0C;AAA1C,aAAA,uBAAA;AAVrB,aAAA,cAA4B;AAE5B,aAAA,eAAkC,qBAAA,kBAAkB;AAMpD,aAAA,qBAA8C;AAGpD,aAAK,wBAAwB;WAC1B,qBAAA,kBAAkB,aAAa;WAC/B,qBAAA,kBAAkB,OAAO;WACzB,qBAAA,kBAAkB,QAAQ;WAC1B,qBAAA,kBAAkB,WAAW;WAC7B,qBAAA,kBAAkB,oBAAoB;;AAEzC,aAAK,0BAA0B,CAC7B,YACA,eACA,aACE;AACF,eAAK,sBAAsB,kBAAkB;AAC7C,eAAK,sBAAsB,aAAa;AACxC,eAAK;AAEL,cACE,aAAa,qBAAA,kBAAkB,qBAC/B,aAAa,qBAAA,kBAAkB,MAC/B;AACA,iBAAK,qBAAqB;AAC1B,uBAAW;;;;MAKT,0BAAuB;AAC7B,YAAI,KAAK,sBAAsB,qBAAA,kBAAkB,SAAS,GAAG;AAC3D,gBAAM,mBAAmB,KAAK,YAAY,OACxC,CAAC,eACC,WAAW,2BAA2B,qBAAA,kBAAkB;AAE5D,cAAI,QAAQ;AACZ,cAAI,KAAK,uBAAuB,MAAM;AACpC,oBAAQ,iBAAiB,QACvB,KAAK,mBAAmB;AAE1B,gBAAI,QAAQ,GAAG;AACb,sBAAQ;;;AAGZ,eAAK,YACH,qBAAA,kBAAkB,OAClB,IAAI,iBAAiB,kBAAkB;mBAEhC,KAAK,sBAAsB,qBAAA,kBAAkB,cAAc,GAAG;AACvE,eAAK,YAAY,qBAAA,kBAAkB,YAAY,IAAI,SAAA,YAAY;mBAE/D,KAAK,sBAAsB,qBAAA,kBAAkB,qBAAqB,GAClE;AACA,eAAK,YACH,qBAAA,kBAAkB,mBAClB,IAAI,SAAA;eAED;AACL,eAAK,YAAY,qBAAA,kBAAkB,MAAM,IAAI,SAAA,YAAY;;;MAIrD,YAAY,UAA6B,QAAc;AAC7D,cACE,qBAAA,kBAAkB,KAAK,gBACrB,SACA,qBAAA,kBAAkB;AAEtB,YAAI,aAAa,qBAAA,kBAAkB,OAAO;AACxC,eAAK,qBAAqB;eACrB;AACL,eAAK,qBAAqB;;AAE5B,aAAK,eAAe;AACpB,aAAK,qBAAqB,YAAY,UAAU;;MAG1C,sBAAmB;AACzB,mBAAW,cAAc,KAAK,aAAa;AACzC,qBAAW,gCAAgC,KAAK;AAChD,qBAAW;AACX,eAAK,qBAAqB,oBAAoB,WAAW;;AAE3D,aAAK,wBAAwB;WAC1B,qBAAA,kBAAkB,aAAa;WAC/B,qBAAA,kBAAkB,OAAO;WACzB,qBAAA,kBAAkB,QAAQ;WAC1B,qBAAA,kBAAkB,WAAW;WAC7B,qBAAA,kBAAkB,oBAAoB;;AAEzC,aAAK,cAAc;;MAGrB,kBACE,aACA,UAA6B;AAE7B,aAAK;AACL,cACE,6BACE,YAAY,IAAI,CAAC,YAAY,qBAAA,0BAA0B;AAE3D,aAAK,cAAc,YAAY,IAAI,CAAC,YAClC,KAAK,qBAAqB,iBAAiB,SAAS;AAEtD,mBAAW,cAAc,KAAK,aAAa;AACzC,qBAAW;AACX,qBAAW,6BAA6B,KAAK;AAC7C,eAAK,qBAAqB,iBAAiB,WAAW;AACtD,gBAAM,kBAAkB,WAAW;AACnC,eAAK,sBAAsB,oBAAoB;AAC/C,cACE,oBAAoB,qBAAA,kBAAkB,QACtC,oBAAoB,qBAAA,kBAAkB,mBACtC;AACA,uBAAW;;;AAGf,aAAK;;MAGP,WAAQ;AACN,mBAAW,cAAc,KAAK,aAAa;AACzC,qBAAW;;;MAGf,eAAY;;MAIZ,UAAO;AACL,aAAK;;MAEP,cAAW;AACT,eAAO;;;AA/IX,aAAA,yBAAA;AAmJA,qBAAqB;AACnB,sBAAA,yBACE,WACA,wBACA;;AAJJ,aAAA,QAAA;;;;;;;;;;AClOA,QAAA,qBAAA;AAyIE,WAAA,eAAA,UAAA,mBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAzIO,mBAAA;;AAET,QAAA,YAAA;AAiH2B,WAAA,eAAA,UAAA,WAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAjHT,UAAA;;AAClB,QAAA,uBAAA;AAiGuB,WAAA,eAAA,UAAA,qBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAjGd,qBAAA;;AACT,QAAA,wBAAA;AAoIE,WAAA,eAAA,UAAA,sBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aApIO,sBAAA;;AACT,QAAA,WAAA;AAuGE,WAAA,eAAA,UAAA,UAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aArGA,SAAA;;AAMF,QAAA,cAAA;AAqFkB,WAAA,eAAA,UAAA,gBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aArFT,YAAA;;AAsFG,WAAA,eAAA,UAAA,UAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAtFW,YAAA;;AAwFR,WAAA,eAAA,UAAA,aAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAxFgB,YAAA;;AAC/B,QAAA,UAAA;AACA,QAAA,gBAAA;AA+FE,WAAA,eAAA,UAAA,yBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aA7FA,cAAA;;AA8FA,WAAA,eAAA,UAAA,yBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aA7FA,cAAA;;AA8FyB,WAAA,eAAA,UAAA,gCAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aA9FzB,cAAA;;AAKF,QAAA,aAAA;AAsES,WAAA,eAAA,UAAA,YAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAtEA,WAAA;;AACT,QAAA,WAAA;AAgLS,WAAA,eAAA,UAAA,UAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aA/KP,SAAA;;AAIF,QAAA,uBAAA;AA4KS,WAAA,eAAA,UAAA,qBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aA5Ka,qBAAA;;AACtB,QAAA,mBAAA;AAkLS,WAAA,eAAA,UAAA,iBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAlLA,iBAAA;;AAmBI,aAAA,cAAc;MAQzB,2BAA2B,CACzB,uBACG,oBACmB;AACtB,eAAO,gBAAgB,OACrB,CAAC,KAAK,UAAU,IAAI,QAAQ,QAC5B;;MAWJ,wBAAwB,CACtB,UACG,eACgB;AACnB,eAAO,WAAW,OAAO,CAAC,KAAK,UAAU,IAAI,QAAQ,QAAQ;;MAI/D,gBAAgB,sBAAA,mBAAmB;MACnC,WAAW,sBAAA,mBAAmB;MAG9B,6BAA6B,mBAAA,gBAAgB;MAC7C,4BAA4B,mBAAA,gBAAgB;MAC5C,aAAa,mBAAA,gBAAgB;;AAoClB,aAAA,cAAc,CAAC,WAAmB,OAAO;AAEzC,aAAA,qBAAqB,CAChC,QACA,UACA,aACG,OAAO,aAAa,UAAU;AAkDtB,aAAA,aAAa,CAAC,OAAY,YAAgB;AACrD,YAAM,IAAI,MACR;;AAIS,aAAA,OAAO,CAAC,UAAe,QAAa,YAAgB;AAC/D,YAAM,IAAI,MACR;;AAIS,aAAA,YAAY,CAAC,YAAkC;AAC1D,cAAQ,UAAU;;AAGP,aAAA,kBAAkB,CAAC,cAAiC;AAC/D,cAAQ,mBAAmB;;AAOhB,aAAA,mBAAmB,CAAC,WAAkB;AACjD,aAAO,SAAA,OAAO,UAAU,WAAW,KAAK;;AAO1C,QAAA,wBAAA;AAEE,WAAA,eAAA,UAAA,mBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,sBAAA;;AACA,WAAA,eAAA,UAAA,oBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,sBAAA;;AAIA,WAAA,eAAA,UAAA,oBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,sBAAA;;AACA,WAAA,eAAA,UAAA,iCAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,sBAAA;;AAOF,QAAA,aAAA;AACE,WAAA,eAAA,UAAA,gCAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,WAAA;;AACA,WAAA,eAAA,UAAA,uBAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,WAAA;;AAGF,QAAA,UAAA;AAAS,WAAA,eAAA,UAAA,4BAAA,EAAA,YAAA,MAAA,KAAA,WAAA;AAAA,aAAA,QAAA;;AAET,QAAA,eAAA;AACS,aAAA,eAAA;AAET,QAAA,eAAA;AACA,QAAA,eAAA;AACA,QAAA,cAAA;AACA,QAAA,2BAAA;AACA,QAAA,4BAAA;AACA,QAAA,WAAA;AAEA,QAAM,gBAAgB,kBAA8B;AAEpD,IAAC,OAAK;AACJ,cAAQ,MAAM,YAAA,aAAa,OAAO,SAAS,mCAAmC;AAC9E,mBAAa;AACb,mBAAa;AACb,kBAAY;AACZ,+BAAyB;AACzB,gCAA0B;AAC1B,eAAS;;;;;;ACrRX,IAqBa,YAAY;EAIvB,aAAa;EAIb,YAAY;EAKZ,aAAa;;AClCf,ACAA,ACAA,ACAA,qBAiBqB;EAInB,cAAA;AAFA,SAAA,SAAoC,MAAA;;AACpC,SAAA,UAAqC,MAAA;;AAEnC,SAAK,UAAU,IAAI,QAAQ,CAAC,UAAS,WAAM;AACzC,WAAK,UAAU;AACf,WAAK,SAAS;;;EASlB,aACE,UAAqD;AAErD,WAAO,CAAC,OAAO,UAAM;AACnB,UAAI,OAAO;AACT,aAAK,OAAO;aACP;AACL,aAAK,QAAQ;;AAEf,UAAI,OAAO,aAAa,YAAY;AAGlC,aAAK,QAAQ,MAAM,MAAA;;AAInB,YAAI,SAAS,WAAW,GAAG;AACzB,mBAAS;eACJ;AACL,mBAAS,OAAO;;;;;;ACpD1B,ACAA,ACAA,AA6DA,IAAM,aAAa;kCAYgB,MAAK;EAGtC,YACW,MACT,SACO,YAAoC;AAE3C,UAAM;AAJG,SAAA,OAAA;AAEF,SAAA,aAAA;AALA,SAAA,OAAO;AAWd,WAAO,eAAe,MAAM,cAAc;AAI1C,QAAI,MAAM,mBAAmB;AAC3B,YAAM,kBAAkB,MAAM,aAAa,UAAU;;;;yBAKlC;EAIvB,YACmB,SACA,aACA,QAA2B;AAF3B,SAAA,UAAA;AACA,SAAA,cAAA;AACA,SAAA,SAAA;;EAGnB,OACE,SACG,MAAyD;AAE5D,UAAM,aAAc,KAAK,MAAoB;AAC7C,UAAM,WAAW,GAAG,KAAK,WAAW;AACpC,UAAM,WAAW,KAAK,OAAO;AAE7B,UAAM,UAAU,WAAW,gBAAgB,UAAU,cAAc;AAEnE,UAAM,cAAc,GAAG,KAAK,gBAAgB,YAAY;AAExD,UAAM,QAAQ,IAAI,cAAc,UAAU,aAAa;AAEvD,WAAO;;;AAIX,yBAAyB,UAAkB,MAAe;AACxD,SAAO,SAAS,QAAQ,SAAS,CAAC,GAAG,QAAG;AACtC,UAAM,QAAQ,KAAK;AACnB,WAAO,SAAS,OAAO,OAAO,SAAS,IAAI;;;AAI/C,IAAM,UAAU;AClIhB,ACAA,ACAA,mBA0D0B,GAAW,GAAS;AAC5C,MAAI,MAAM,GAAG;AACX,WAAO;;AAGT,QAAM,QAAQ,OAAO,KAAK;AAC1B,QAAM,QAAQ,OAAO,KAAK;AAC1B,aAAW,KAAK,OAAO;AACrB,QAAI,CAAC,MAAM,SAAS,IAAI;AACtB,aAAO;;AAGT,UAAM,QAAS,EAA8B;AAC7C,UAAM,QAAS,EAA8B;AAC7C,QAAI,SAAS,UAAU,SAAS,QAAQ;AACtC,UAAI,CAAC,UAAU,OAAO,QAAQ;AAC5B,eAAO;;eAEA,UAAU,OAAO;AAC1B,aAAO;;;AAIX,aAAW,KAAK,OAAO;AACrB,QAAI,CAAC,MAAM,SAAS,IAAI;AACtB,aAAO;;;AAGX,SAAO;;AAGT,kBAAkB,OAAc;AAC9B,SAAO,UAAU,QAAQ,OAAO,UAAU;;AC1F5C,ACAA,AEAA,ACAA,ACAA,IAiCa,mBAAmB,IAAI,KAAK,KAAK;ACjC9C,ACAA,ACAA,AAoBA,UAAU,cAAc;;;sBCQF;EAiBpB,YACW,OACA,iBACA,MAAmB;AAFnB,SAAA,OAAA;AACA,SAAA,kBAAA;AACA,SAAA,OAAA;AAnBX,SAAA,oBAAoB;AAIpB,SAAA,eAA2B;AAE3B,SAAA,oBAAiB;AAEjB,SAAA,oBAAyD;;EAczD,qBAAqB,MAAuB;AAC1C,SAAK,oBAAoB;AACzB,WAAO;;EAGT,qBAAqB,mBAA0B;AAC7C,SAAK,oBAAoB;AACzB,WAAO;;EAGT,gBAAgB,OAAiB;AAC/B,SAAK,eAAe;AACpB,WAAO;;EAGT,2BAA2B,UAAsC;AAC/D,SAAK,oBAAoB;AACzB,WAAO;;;ACpEX,AAiBO,IAAM,qBAAqB;ACjBlC,qBAiCqB;EAWnB,YACmB,OACA,WAA6B;AAD7B,SAAA,OAAA;AACA,SAAA,YAAA;AAZX,SAAA,YAAiC;AACxB,SAAA,YAAgD,IAAI;AACpD,SAAA,oBAGb,IAAI;AACS,SAAA,mBACf,IAAI;AACE,SAAA,kBAAuD,IAAI;;EAWnE,IAAI,YAAmB;AAErB,UAAM,uBAAuB,KAAK,4BAA4B;AAE9D,QAAI,CAAC,KAAK,kBAAkB,IAAI,uBAAuB;AACrD,YAAM,WAAW,IAAI;AACrB,WAAK,kBAAkB,IAAI,sBAAsB;AAEjD,UACE,KAAK,cAAc,yBACnB,KAAK,wBACL;AAEA,YAAI;AACF,gBAAM,WAAW,KAAK,uBAAuB;YAC3C,oBAAoB;;AAEtB,cAAI,UAAU;AACZ,qBAAS,QAAQ;;iBAEZ,GAAP;;;;AAON,WAAO,KAAK,kBAAkB,IAAI,sBAAuB;;EAmB3D,aAAa,SAGZ;;AAEC,UAAM,uBAAuB,KAAK,4BAChC,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS;AAEX,UAAM,WAAW,MAAA,YAAO,QAAP,YAAO,SAAA,SAAP,QAAS,cAAQ,QAAA,OAAA,SAAA,KAAI;AAEtC,QACE,KAAK,cAAc,yBACnB,KAAK,wBACL;AACA,UAAI;AACF,eAAO,KAAK,uBAAuB;UACjC,oBAAoB;;eAEf,GAAP;AACA,YAAI,UAAU;AACZ,iBAAO;eACF;AACL,gBAAM;;;WAGL;AAEL,UAAI,UAAU;AACZ,eAAO;aACF;AACL,cAAM,MAAM,WAAW,KAAK;;;;EAKlC,eAAY;AACV,WAAO,KAAK;;EAGd,aAAa,WAAuB;AAClC,QAAI,UAAU,SAAS,KAAK,MAAM;AAChC,YAAM,MACJ,yBAAyB,UAAU,qBAAqB,KAAK;;AAIjE,QAAI,KAAK,WAAW;AAClB,YAAM,MAAM,iBAAiB,KAAK;;AAGpC,SAAK,YAAY;AAGjB,QAAI,CAAC,KAAK,wBAAwB;AAChC;;AAIF,QAAI,iBAAiB,YAAY;AAC/B,UAAI;AACF,aAAK,uBAAuB,EAAE,oBAAoB;eAC3C,GAAP;;;AAWJ,eAAW,CACT,oBACA,qBACG,KAAK,kBAAkB,WAAW;AACrC,YAAM,uBACJ,KAAK,4BAA4B;AAEnC,UAAI;AAEF,cAAM,WAAW,KAAK,uBAAuB;UAC3C,oBAAoB;;AAEtB,yBAAiB,QAAQ;eAClB,GAAP;;;;EAON,cAAc,aAAqB,oBAAkB;AACnD,SAAK,kBAAkB,OAAO;AAC9B,SAAK,iBAAiB,OAAO;AAC7B,SAAK,UAAU,OAAO;;QAKlB,SAAM;AACV,UAAM,WAAW,MAAM,KAAK,KAAK,UAAU;AAE3C,UAAM,QAAQ,IAAI;MAChB,GAAG,SACA,OAAO,aAAW,cAAc,SAEhC,IAAI,aAAY,QAAgB,SAAU;MAC7C,GAAG,SACA,OAAO,aAAW,aAAa,SAE/B,IAAI,aAAY,QAAgB;;;EAIvC,iBAAc;AACZ,WAAO,KAAK,aAAa;;EAG3B,cAAc,aAAqB,oBAAkB;AACnD,WAAO,KAAK,UAAU,IAAI;;EAG5B,WAAW,aAAqB,oBAAkB;AAChD,WAAO,KAAK,iBAAiB,IAAI,eAAe;;EAGlD,WAAW,OAA0B,IAAE;AACrC,UAAM,EAAE,UAAU,OAAO;AACzB,UAAM,uBAAuB,KAAK,4BAChC,KAAK;AAEP,QAAI,KAAK,cAAc,uBAAuB;AAC5C,YAAM,MACJ,GAAG,KAAK,QAAQ;;AAIpB,QAAI,CAAC,KAAK,kBAAkB;AAC1B,YAAM,MAAM,aAAa,KAAK;;AAGhC,UAAM,WAAW,KAAK,uBAAuB;MAC3C,oBAAoB;MACpB;;AAIF,eAAW,CACT,oBACA,qBACG,KAAK,kBAAkB,WAAW;AACrC,YAAM,+BACJ,KAAK,4BAA4B;AACnC,UAAI,yBAAyB,8BAA8B;AACzD,yBAAiB,QAAQ;;;AAI7B,WAAO;;EAWT,OAAO,UAA6B,YAAmB;;AACrD,UAAM,uBAAuB,KAAK,4BAA4B;AAC9D,UAAM,oBACJ,MAAA,KAAK,gBAAgB,IAAI,2BAAqB,QAAA,OAAA,SAAA,KAC9C,IAAI;AACN,sBAAkB,IAAI;AACtB,SAAK,gBAAgB,IAAI,sBAAsB;AAE/C,UAAM,mBAAmB,KAAK,UAAU,IAAI;AAC5C,QAAI,kBAAkB;AACpB,eAAS,kBAAkB;;AAG7B,WAAO,MAAA;AACL,wBAAkB,OAAO;;;EAQrB,sBACN,UACA,YAAkB;AAElB,UAAM,YAAY,KAAK,gBAAgB,IAAI;AAC3C,QAAI,CAAC,WAAW;AACd;;AAEF,eAAW,YAAY,WAAW;AAChC,UAAI;AACF,iBAAS,UAAU;eACnB,IAAA;;;;EAME,uBAAuB,EAC7B,oBACA,UAAU,MAIX;AACC,QAAI,WAAW,KAAK,UAAU,IAAI;AAClC,QAAI,CAAC,YAAY,KAAK,WAAW;AAC/B,iBAAW,KAAK,UAAU,gBAAgB,KAAK,WAAW;QACxD,oBAAoB,8BAA8B;QAClD;;AAEF,WAAK,UAAU,IAAI,oBAAoB;AACvC,WAAK,iBAAiB,IAAI,oBAAoB;AAO9C,WAAK,sBAAsB,UAAU;AAOrC,UAAI,KAAK,UAAU,mBAAmB;AACpC,YAAI;AACF,eAAK,UAAU,kBACb,KAAK,WACL,oBACA;iBAEF,IAAA;;;;AAMN,WAAO,YAAY;;EAGb,4BACN,aAAqB,oBAAkB;AAEvC,QAAI,KAAK,WAAW;AAClB,aAAO,KAAK,UAAU,oBAAoB,aAAa;WAClD;AACL,aAAO;;;EAIH,uBAAoB;AAC1B,WACE,CAAC,CAAC,KAAK,aACP,KAAK,UAAU,sBAAiB;;;AAMtC,uCAAuC,YAAkB;AACvD,SAAO,eAAe,qBAAqB,SAAY;;AAGzD,0BAA0C,WAAuB;AAC/D,SAAO,UAAU,sBAAiB;;ACxXpC,+BAwB+B;EAG7B,YAA6B,OAAY;AAAZ,SAAA,OAAA;AAFZ,SAAA,YAAY,IAAI;;EAajC,aAA6B,WAAuB;AAClD,UAAM,WAAW,KAAK,YAAY,UAAU;AAC5C,QAAI,SAAS,kBAAkB;AAC7B,YAAM,IAAI,MACR,aAAa,UAAU,yCAAyC,KAAK;;AAIzE,aAAS,aAAa;;EAGxB,wBAAwC,WAAuB;AAC7D,UAAM,WAAW,KAAK,YAAY,UAAU;AAC5C,QAAI,SAAS,kBAAkB;AAE7B,WAAK,UAAU,OAAO,UAAU;;AAGlC,SAAK,aAAa;;EAUpB,YAA4B,OAAO;AACjC,QAAI,KAAK,UAAU,IAAI,QAAO;AAC5B,aAAO,KAAK,UAAU,IAAI;;AAI5B,UAAM,WAAW,IAAI,SAAY,OAAM;AACvC,SAAK,UAAU,IAAI,OAAM;AAEzB,WAAO;;EAGT,eAAY;AACV,WAAO,MAAM,KAAK,KAAK,UAAU;;;;;AC/ErC,AAyCO,IAAM,YAAsB;IAavB;AAAZ,AAAA,UAAY,WAAQ;AAClB,YAAA,UAAA,WAAA,KAAA;AACA,YAAA,UAAA,aAAA,KAAA;AACA,YAAA,UAAA,UAAA,KAAA;AACA,YAAA,UAAA,UAAA,KAAA;AACA,YAAA,UAAA,WAAA,KAAA;AACA,YAAA,UAAA,YAAA,KAAA;GANU,YAAA,YAAQ;AASpB,IAAM,oBAA2D;EAC/D,SAAS,SAAS;EAClB,WAAW,SAAS;EACpB,QAAQ,SAAS;EACjB,QAAQ,SAAS;EACjB,SAAS,SAAS;EAClB,UAAU,SAAS;;AAMrB,IAAM,kBAA4B,SAAS;AAmB3C,IAAM,gBAAgB;GACnB,SAAS,QAAQ;GACjB,SAAS,UAAU;GACnB,SAAS,OAAO;GAChB,SAAS,OAAO;GAChB,SAAS,QAAQ;;AAQpB,IAAM,oBAAgC,CAAC,UAAU,YAAY,SAAI;AAC/D,MAAI,UAAU,SAAS,UAAU;AAC/B;;AAEF,QAAM,MAAM,IAAI,OAAO;AACvB,QAAM,SAAS,cAAc;AAC7B,MAAI,QAAQ;AACV,YAAQ,QACN,IAAI,SAAS,SAAS,SACtB,GAAG;SAEA;AACL,UAAM,IAAI,MACR,8DAA8D;;;mBAKjD;EAOjB,YAAmB,OAAY;AAAZ,SAAA,OAAA;AAUX,SAAA,YAAY;AAsBZ,SAAA,cAA0B;AAc1B,SAAA,kBAAqC;AA1C3C,cAAU,KAAK;;MAQb,WAAQ;AACV,WAAO,KAAK;;MAGV,SAAS,KAAa;AACxB,QAAI,CAAE,QAAO,WAAW;AACtB,YAAM,IAAI,UAAU,kBAAkB;;AAExC,SAAK,YAAY;;EAInB,YAAY,KAA8B;AACxC,SAAK,YAAY,OAAO,QAAQ,WAAW,kBAAkB,OAAO;;MAQlE,aAAU;AACZ,WAAO,KAAK;;MAEV,WAAW,KAAe;AAC5B,QAAI,OAAO,QAAQ,YAAY;AAC7B,YAAM,IAAI,UAAU;;AAEtB,SAAK,cAAc;;MAOjB,iBAAc;AAChB,WAAO,KAAK;;MAEV,eAAe,KAAsB;AACvC,SAAK,kBAAkB;;EAOzB,SAAS,MAAe;AACtB,SAAK,mBAAmB,KAAK,gBAAgB,MAAM,SAAS,OAAO,GAAG;AACtE,SAAK,YAAY,MAAM,SAAS,OAAO,GAAG;;EAE5C,OAAO,MAAe;AACpB,SAAK,mBACH,KAAK,gBAAgB,MAAM,SAAS,SAAS,GAAG;AAClD,SAAK,YAAY,MAAM,SAAS,SAAS,GAAG;;EAE9C,QAAQ,MAAe;AACrB,SAAK,mBAAmB,KAAK,gBAAgB,MAAM,SAAS,MAAM,GAAG;AACrE,SAAK,YAAY,MAAM,SAAS,MAAM,GAAG;;EAE3C,QAAQ,MAAe;AACrB,SAAK,mBAAmB,KAAK,gBAAgB,MAAM,SAAS,MAAM,GAAG;AACrE,SAAK,YAAY,MAAM,SAAS,MAAM,GAAG;;EAE3C,SAAS,MAAe;AACtB,SAAK,mBAAmB,KAAK,gBAAgB,MAAM,SAAS,OAAO,GAAG;AACtE,SAAK,YAAY,MAAM,SAAS,OAAO,GAAG;;;;;ACjN9C,sCAyBsC;EACpC,YAA6B,WAA6B;AAA7B,SAAA,YAAA;;EAG7B,wBAAqB;AACnB,UAAM,YAAY,KAAK,UAAU;AAGjC,WAAO,UACJ,IAAI,cAAQ;AACX,UAAI,yBAAyB,WAAW;AACtC,cAAM,UAAU,SAAS;AACzB,eAAO,GAAG,QAAQ,WAAW,QAAQ;aAChC;AACL,eAAO;;OAGV,OAAO,eAAa,WACpB,KAAK;;;AAWZ,kCAAkC,UAAwB;AACxD,QAAM,YAAY,SAAS;AAC3B,SAAO,eAAS,QAAT,cAAS,SAAA,SAAT,UAAW,UAAI;;;;ACxDxB,AAmBO,IAAM,SAAS,IAAI,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;ACnBjC,IAgDa,sBAAqB;AAE3B,IAAM,sBAAsB;GAChC,SAAU;GACV,SAAgB;GAChB,SAAgB;GAChB,SAAsB;GACtB,SAAe;GACf,SAAqB;GACrB,SAAW;GACX,SAAiB;GACjB,SAAe;GACf,SAAqB;GACrB,SAAgB;GAChB,SAAsB;GACtB,SAAoB;GACpB,SAA0B;GAC1B,SAAgB;GAChB,SAAsB;GACtB,SAAkB;GAClB,SAAwB;GACxB,SAAmB;GACnB,SAAyB;GACzB,SAAc;GACd,SAAoB;GACpB,SAAgB;GAChB,SAAsB;EACvB,WAAW;GACV,OAAc;;AC5EjB,IA0Ba,QAAQ,IAAI;IAQZ,cAAc,IAAI;uBAQ7B,MACA,WAAuB;AAEvB,MAAI;AACD,SAAwB,UAAU,aAAa;WACzC,GAAP;AACA,WAAO,MACL,aAAa,UAAU,4CAA4C,KAAI,QACvE;;;4BAwBJ,WAAuB;AAEvB,QAAM,gBAAgB,UAAU;AAChC,MAAI,YAAY,IAAI,gBAAgB;AAClC,WAAO,MACL,sDAAsD;AAGxD,WAAO;;AAGT,cAAY,IAAI,eAAe;AAG/B,aAAW,QAAO,MAAM,UAAU;AAChC,kBAAc,MAAwB;;AAGxC,SAAO;;sBAaP,MACA,OAAO;AAEP,SAAQ,KAAwB,UAAU,YAAY;;AC5GxD,AA4BA,IAAM,SAA6B;GACjC,WACE;GAEF,iBAAyB;GACzB,kBACE;GACF,gBAAwB;GACxB,yBACE;GAEF,yBACE;;AAWG,IAAM,gBAAgB,IAAI,aAC/B,OACA,YACA;ACtDF,4BA6B4B;EAc1B,YACE,SACA,QACA,WAA6B;AANvB,SAAA,aAAa;AAQnB,SAAK,WAAQ,OAAA,OAAA,IAAQ;AACrB,SAAK,UAAO,OAAA,OAAA,IAAQ;AACpB,SAAK,QAAQ,OAAO;AACpB,SAAK,kCACH,OAAO;AACT,SAAK,aAAa;AAClB,SAAK,UAAU,aACb,IAAI,UAAU,OAAO,MAAM,MAAI;;MAI/B,iCAA8B;AAChC,SAAK;AACL,WAAO,KAAK;;MAGV,+BAA+B,KAAY;AAC7C,SAAK;AACL,SAAK,kCAAkC;;MAGrC,OAAI;AACN,SAAK;AACL,WAAO,KAAK;;MAGV,UAAO;AACT,SAAK;AACL,WAAO,KAAK;;MAGV,SAAM;AACR,SAAK;AACL,WAAO,KAAK;;MAGV,YAAS;AACX,WAAO,KAAK;;MAGV,YAAS;AACX,WAAO,KAAK;;MAGV,UAAU,KAAY;AACxB,SAAK,aAAa;;EAOZ,iBAAc;AACpB,QAAI,KAAK,WAAW;AAClB,YAAM,cAAc,OAAM,eAAuB,EAAE,SAAS,KAAK;;;;ACtGvE,IAkDa,cAAc;uBA+DzB,SACA,YAAY,IAAE;AAEd,MAAI,OAAO,cAAc,UAAU;AACjC,UAAM,QAAO;AACb,gBAAY,EAAE;;AAGhB,QAAM,SAAM,OAAA,OAAA,EACV,MAAM,qBACN,gCAAgC,SAC7B;AAEL,QAAM,QAAO,OAAO;AAEpB,MAAI,OAAO,UAAS,YAAY,CAAC,OAAM;AACrC,UAAM,cAAc,OAAM,gBAAwB;MAChD,SAAS,OAAO;;;AAIpB,QAAM,cAAc,MAAM,IAAI;AAC9B,MAAI,aAAa;AAEf,QACE,UAAU,SAAS,YAAY,YAC/B,UAAU,QAAQ,YAAY,SAC9B;AACA,aAAO;WACF;AACL,YAAM,cAAc,OAAM,iBAAyB,EAAE,SAAS;;;AAIlE,QAAM,YAAY,IAAI,mBAAmB;AACzC,aAAW,aAAa,YAAY,UAAU;AAC5C,cAAU,aAAa;;AAGzB,QAAM,SAAS,IAAI,gBAAgB,SAAS,QAAQ;AAEpD,QAAM,IAAI,OAAM;AAEhB,SAAO;;gBAgCc,QAAe,qBAAkB;AACtD,QAAM,OAAM,MAAM,IAAI;AACtB,MAAI,CAAC,MAAK;AACR,UAAM,cAAc,OAAM,UAAkB,EAAE,SAAS;;AAGzD,SAAO;;yBAkDP,kBACA,UACA,SAAgB;;AAIhB,MAAI,UAAU,MAAA,oBAAoB,uBAAiB,QAAA,OAAA,SAAA,KAAI;AACvD,MAAI,SAAS;AACX,eAAW,IAAI;;AAEjB,QAAM,kBAAkB,QAAQ,MAAM;AACtC,QAAM,kBAAkB,SAAQ,MAAM;AACtC,MAAI,mBAAmB,iBAAiB;AACtC,UAAM,UAAU;MACd,+BAA+B,0BAA0B;;AAE3D,QAAI,iBAAiB;AACnB,cAAQ,KACN,iBAAiB;;AAGrB,QAAI,mBAAmB,iBAAiB;AACtC,cAAQ,KAAK;;AAEf,QAAI,iBAAiB;AACnB,cAAQ,KACN,iBAAiB;;AAGrB,WAAO,KAAK,QAAQ,KAAK;AACzB;;AAEF,qBACE,IAAI,UACF,GAAG,mBACH,MAAO,GAAE,SAAS,sBAAU;;ACvRlC,gCAuBuC,SAAgB;AACrD,qBACE,IAAI,UACF,mBACA,eAAa,IAAI,0BAA0B,YAAU;AAMzD,kBAAgB,QAAM,WAAS;AAE/B,kBAAgB,QAAM,WAAS;AAE/B,kBAAgB,WAAW;;ACP7B,uBAAuB;;;;;AC9BvB,AAmBA,gBAAgB,OAAM,UAAS;;;;;;;;;;;ACP/B,IAAM,QAAO;AACb,IAAM,aAAY;AAElB,AAoBA,iBAAW;EACP,YAAY,KAAK;AACb,SAAK,MAAM;;EAEf,kBAAkB;AACd,WAAO,KAAK,OAAO;;EAMvB,QAAQ;AACJ,QAAI,KAAK,mBAAmB;AACxB,aAAO,SAAS,KAAK;WAEpB;AACD,aAAO;;;EAGf,QAAQ,WAAW;AACf,WAAO,UAAU,QAAQ,KAAK;;;AAItC,KAAK,kBAAkB,IAAI,KAAK;AAGhC,KAAK,qBAAqB,IAAI,KAAK;AACnC,KAAK,cAAc,IAAI,KAAK;AAC5B,KAAK,YAAY,IAAI,KAAK;AAE1B,IAAM,WAAU;AAEhB,AAgBA,IAAI,eAAc;AAClB,uBAAuB,UAAS;AAC5B,iBAAc;;AAGlB,AAiBA,oBAAoB,OAAO;AAEvB,SAAO,0BAAQ,OAAO,EAAE,OAAO;;AAGnC,AAgBA,IAAM,YAAY,IAAI,OAAO;AAqB7B,kBAAkB,QAAQ,KAAK;AAC3B,MAAI,UAAU,YAAY,SAAS,OAAO;AACtC,UAAM,OAAO,IAAI,IAAI;AACrB,cAAU,MAAM,cAAc,kBAAiB,OAAO,GAAG;;;AAGjE,kBAAkB,QAAQ,KAAK;AAC3B,MAAI,UAAU,YAAY,SAAS,OAAO;AACtC,UAAM,OAAO,IAAI,IAAI;AACrB,cAAU,MAAM,cAAc,kBAAiB,OAAO,GAAG;;;AAejE,qBAAqB,KAAK;AACtB,MAAI,OAAO,QAAQ,UAAU;AACzB,WAAO;SAEN;AACD,QAAI;AACA,aAAO,WAAW;aAEf,GAAP;AAEI,aAAO;;;;AAKnB,AAwBA,cAAc,UAAU,oBAAoB;AAGxC,QAAM,UAAU,cAAc,8CAA6C;AAC3E,WAAS;AAIT,QAAM,IAAI,MAAM;;AAQpB,oBAAoB,WAAW,SAAS;AACpC,MAAI,CAAC,WAAW;AACZ;;;AA4BR,AAgBA,IAAM,OAAO;EAIT,IAAI;EAEJ,WAAW;EAEX,SAAS;EAOT,kBAAkB;EAQlB,mBAAmB;EAEnB,WAAW;EAKX,gBAAgB;EAQhB,mBAAmB;EAKnB,iBAAiB;EAKjB,oBAAoB;EAqBpB,qBAAqB;EAQrB,SAAS;EAgBT,cAAc;EAEd,eAAe;EAKf,UAAU;EAQV,aAAa;EAEb,WAAW;;AAGf,mCAA6B,MAAM;EAE/B,YAIA,MAIA,SAAS;AACL,UAAM;AACN,SAAK,OAAO;AACZ,SAAK,UAAU;AAEf,SAAK,OAAO;AAIZ,SAAK,WAAW,MAAM,GAAG,KAAK,eAAe,KAAK,UAAU,KAAK;;;AAIzE,AAgBA,sBAAe;EACX,cAAc;AACV,SAAK,UAAU,IAAI,QAAQ,CAAC,UAAS,WAAW;AAC5C,WAAK,UAAU;AACf,WAAK,SAAS;;;;AAK1B,AAgBA,uBAAiB;EACb,YAAY,OAAO,MAAM;AACrB,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,SAAK,cAAc;AAEnB,SAAK,YAAY,mBAAmB,UAAU;;;AAOtD,qCAA+B;EAC3B,WAAW;AACP,WAAO,QAAQ,QAAQ;;EAE3B,kBAAkB;;EAClB,MAAM,YAAY,gBAAgB;AAE9B,eAAW,iBAAiB,MAAM,eAAe,KAAK;;EAE1D,WAAW;;;AA6Bf,wCAAkC;EAC9B,YAAY,cAAc;AACtB,SAAK,eAAe;AAEpB,SAAK,cAAc,KAAK;AAKxB,SAAK,eAAe;AACpB,SAAK,eAAe;AACpB,SAAK,OAAO;;EAEhB,MAAM,YAAY,gBAAgB;AAC9B,QAAI,cAAc,KAAK;AAEvB,UAAM,wBAAwB,UAAQ;AAClC,UAAI,KAAK,iBAAiB,aAAa;AACnC,sBAAc,KAAK;AACnB,eAAO,eAAe;aAErB;AACD,eAAO,QAAQ;;;AAKvB,QAAI,YAAY,IAAI;AACpB,SAAK,gBAAgB,MAAM;AACvB,WAAK;AACL,WAAK,cAAc,KAAK;AACxB,gBAAU;AACV,kBAAY,IAAI;AAChB,iBAAW,iBAAiB,MAAM,sBAAsB,KAAK;;AAEjE,UAAM,iBAAiB,MAAM;AACzB,YAAM,sBAAsB;AAC5B,iBAAW,iBAAiB,YAAY;AACpC,cAAM,oBAAoB;AAC1B,cAAM,sBAAsB,KAAK;;;AAGzC,UAAM,eAAe,CAAC,SAAS;AAC3B,eAAS,+BAA+B;AACxC,WAAK,OAAO;AACZ,WAAK,KAAK,qBAAqB,KAAK;AACpC;;AAEJ,SAAK,aAAa,OAAO,UAAQ,aAAa;AAI9C,eAAW,MAAM;AACb,UAAI,CAAC,KAAK,MAAM;AACZ,cAAM,OAAO,KAAK,aAAa,aAAa,EAAE,UAAU;AACxD,YAAI,MAAM;AACN,uBAAa;eAEZ;AAED,mBAAS,+BAA+B;AACxC,oBAAU;AACV,sBAAY,IAAI;;;OAGzB;AACH;;EAEJ,WAAW;AAIP,UAAM,sBAAsB,KAAK;AACjC,UAAM,eAAe,KAAK;AAC1B,SAAK,eAAe;AACpB,QAAI,CAAC,KAAK,MAAM;AACZ,aAAO,QAAQ,QAAQ;;AAE3B,WAAO,KAAK,KAAK,SAAS,cAAc,KAAK,eAAa;AAItD,UAAI,KAAK,iBAAiB,qBAAqB;AAC3C,iBAAS,+BAA+B;AACxC,eAAO,KAAK;aAEX;AACD,YAAI,WAAW;AACX,qBAAW,OAAO,UAAU,gBAAgB;AAC5C,iBAAO,IAAI,WAAW,UAAU,aAAa,KAAK;eAEjD;AACD,iBAAO;;;;;EAKvB,kBAAkB;AACd,SAAK,eAAe;;EAExB,WAAW;AACP,QAAI,KAAK,MAAM;AACX,WAAK,KAAK,wBAAwB,KAAK;;;EAO/C,UAAU;AACN,UAAM,aAAa,KAAK,QAAQ,KAAK,KAAK;AAC1C,eAAW,eAAe,QAAQ,OAAO,eAAe;AACxD,WAAO,IAAI,KAAK;;;AAUxB,4BAAsB;EAClB,YAAY,MAAM,cAAc,UAAU;AACtC,SAAK,OAAO;AACZ,SAAK,eAAe;AACpB,SAAK,WAAW;AAChB,SAAK,OAAO;AACZ,SAAK,OAAO,KAAK;;MAEjB,cAAc;AACd,UAAM,UAAU;MACZ,mBAAmB,KAAK;;AAG5B,UAAM,aAAa,KAAK,KAAK,QAAQ,mCAAmC;AACxE,QAAI,YAAY;AACZ,cAAQ,mBAAmB;;AAE/B,QAAI,KAAK,UAAU;AACf,cAAQ,oCAAoC,KAAK;;AAErD,WAAO;;;AAQf,0CAAoC;EAChC,YAAY,MAAM,cAAc,UAAU;AACtC,SAAK,OAAO;AACZ,SAAK,eAAe;AACpB,SAAK,WAAW;;EAEpB,WAAW;AACP,WAAO,QAAQ,QAAQ,IAAI,gBAAgB,KAAK,MAAM,KAAK,cAAc,KAAK;;EAElF,MAAM,YAAY,gBAAgB;AAE9B,eAAW,iBAAiB,MAAM,eAAe,KAAK;;EAE1D,WAAW;;EACX,kBAAkB;;;AAMtB,iCAAiC,cAAa;AAC1C,MAAI,CAAC,cAAa;AACd,WAAO,IAAI;;AAEf,UAAQ,aAAY;SACX;AACD,YAAM,SAAS,aAAY;AAE3B,iBAAW,CAAC,CAAE,QAAO,WAAW,YAC5B,WAAW,QACX,OAAO,WACP,OAAO,QAAQ;AACnB,aAAO,IAAI,8BAA8B,QAAQ,aAAY,mBAAmB,KAAK,aAAY,eAAe;SAC/G;AACD,aAAO,aAAY;;AAEnB,YAAM,IAAI,eAAe,KAAK,kBAAkB;;;AAI5D,AAsBA,2BAAqB;EACjB,YAAY,eAAe,sBAAsB;AAC7C,SAAK,gBAAgB;AACrB,QAAI,sBAAsB;AACtB,2BAAqB,wBAAwB,oBAAkB,KAAK,iBAAiB;AACrF,WAAK,yBAAyB,oBAAkB,qBAAqB,oBAAoB;;;EAGjG,iBAAiB,uBAAuB;AACpC,SAAK,gBAAgB,KAAK,IAAI,uBAAuB,KAAK;AAC1D,WAAO,KAAK;;EAEhB,OAAO;AACH,UAAM,YAAY,EAAE,KAAK;AACzB,QAAI,KAAK,wBAAwB;AAC7B,WAAK,uBAAuB;;AAEhC,WAAO;;;AAGf,eAAe,UAAU;AAEzB,AAoBA,qBAAe;EACX,YAAY,UAAU,QAAQ,QAAQ;AAClC,QAAI,WAAW,QAAW;AACtB,eAAS;eAEJ,SAAS,SAAS,QAAQ;AAC/B;;AAEJ,QAAI,WAAW,QAAW;AACtB,eAAS,SAAS,SAAS;eAEtB,SAAS,SAAS,SAAS,QAAQ;AACxC;;AAEJ,SAAK,WAAW;AAChB,SAAK,SAAS;AACd,SAAK,MAAM;;MAEX,SAAS;AACT,WAAO,KAAK;;EAEhB,QAAQ,OAAO;AACX,WAAO,SAAS,WAAW,MAAM,WAAW;;EAEhD,MAAM,YAAY;AACd,UAAM,WAAW,KAAK,SAAS,MAAM,KAAK,QAAQ,KAAK;AACvD,QAAI,sBAAsB,UAAU;AAChC,iBAAW,QAAQ,aAAW;AAC1B,iBAAS,KAAK;;WAGjB;AACD,eAAS,KAAK;;AAElB,WAAO,KAAK,UAAU;;EAG1B,QAAQ;AACJ,WAAO,KAAK,SAAS,KAAK;;EAE9B,SAAS,MAAM;AACX,WAAO,SAAS,SAAY,IAAI;AAChC,WAAO,KAAK,UAAU,KAAK,UAAU,KAAK,SAAS,MAAM,KAAK,SAAS;;EAE3E,UAAU;AACN,WAAO,KAAK,UAAU,KAAK,UAAU,KAAK,QAAQ,KAAK,SAAS;;EAEpE,eAAe;AACX,WAAO,KAAK,SAAS,KAAK;;EAE9B,cAAc;AACV,WAAO,KAAK,IAAI,KAAK,SAAS;;EAElC,IAAI,OAAO;AACP,WAAO,KAAK,SAAS,KAAK,SAAS;;EAEvC,UAAU;AACN,WAAO,KAAK,WAAW;;EAE3B,WAAW,OAAO;AACd,QAAI,MAAM,SAAS,KAAK,QAAQ;AAC5B,aAAO;;AAEX,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AAClC,UAAI,KAAK,IAAI,OAAO,MAAM,IAAI,IAAI;AAC9B,eAAO;;;AAGf,WAAO;;EAEX,oBAAoB,gBAAgB;AAChC,QAAI,KAAK,SAAS,MAAM,eAAe,QAAQ;AAC3C,aAAO;;AAEX,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AAClC,UAAI,KAAK,IAAI,OAAO,eAAe,IAAI,IAAI;AACvC,eAAO;;;AAGf,WAAO;;EAEX,QAAQ,IAAI;AACR,aAAS,IAAI,KAAK,QAAQ,MAAM,KAAK,SAAS,IAAI,KAAK,KAAK;AACxD,SAAG,KAAK,SAAS;;;EAGzB,UAAU;AACN,WAAO,KAAK,SAAS,MAAM,KAAK,QAAQ,KAAK;;SAE1C,WAAW,IAAI,IAAI;AACtB,UAAM,MAAM,KAAK,IAAI,GAAG,QAAQ,GAAG;AACnC,aAAS,IAAI,GAAG,IAAI,KAAK,KAAK;AAC1B,YAAM,OAAO,GAAG,IAAI;AACpB,YAAM,QAAQ,GAAG,IAAI;AACrB,UAAI,OAAO,OAAO;AACd,eAAO;;AAEX,UAAI,OAAO,OAAO;AACd,eAAO;;;AAGf,QAAI,GAAG,SAAS,GAAG,QAAQ;AACvB,aAAO;;AAEX,QAAI,GAAG,SAAS,GAAG,QAAQ;AACvB,aAAO;;AAEX,WAAO;;;AASf,iCAA2B,SAAS;EAChC,UAAU,UAAU,QAAQ,QAAQ;AAChC,WAAO,IAAI,aAAa,UAAU,QAAQ;;EAE9C,kBAAkB;AAId,WAAO,KAAK,UAAU,KAAK;;EAE/B,WAAW;AACP,WAAO,KAAK;;SAOT,cAAc,gBAAgB;AAIjC,UAAM,WAAW;AACjB,eAAW,QAAQ,gBAAgB;AAC/B,UAAI,KAAK,QAAQ,SAAS,GAAG;AACzB,cAAM,IAAI,eAAe,KAAK,kBAAkB,oBAAoB;;AAGxE,eAAS,KAAK,GAAG,KAAK,MAAM,KAAK,OAAO,aAAW,QAAQ,SAAS;;AAExE,WAAO,IAAI,aAAa;;SAErB,YAAY;AACf,WAAO,IAAI,aAAa;;;AAyGhC,AAgBA,IAAM,aAAa;AACnB,IAAM,uBAAuB;AAC7B,IAAM,aAAa;AACnB,IAAM,gBAAgB;AAItB,4BAA4B,MAAM;AAC9B,MAAI,SAAS;AACb,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AAClC,QAAI,OAAO,SAAS,GAAG;AACnB,eAAS,gBAAgB;;AAE7B,aAAS,cAAc,KAAK,IAAI,IAAI;;AAExC,SAAO,gBAAgB;;AAG3B,uBAAuB,SAAS,WAAW;AACvC,MAAI,SAAS;AACb,QAAM,SAAS,QAAQ;AACvB,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC7B,UAAM,IAAI,QAAQ,OAAO;AACzB,YAAQ;WACC;AACD,kBAAU,aAAa;AACvB;WACC;AACD,kBAAU,aAAa;AACvB;;AAEA,kBAAU;;;AAGtB,SAAO;;AAGX,yBAAyB,QAAQ;AAC7B,SAAO,SAAS,aAAa;;AA8DjC,AAsDA,4BAAsB;EAClB,YAAY,SAEZ,yBAAyB,kBAAkB;AACvC,SAAK,UAAU;AACf,SAAK,0BAA0B;AAC/B,SAAK,mBAAmB;;;AAUhC,gBAAgB,QAAQ;AAKxB,gBAAgB,MAAM;AAOtB,4BAAsB;EAClB,YAIA,QASA,yBAYA,iBAAiB;AACb,SAAK,SAAS;AACd,SAAK,0BAA0B;AAC/B,SAAK,kBAAkB;;;AAI/B,gBAAgB,QAAQ;AAExB,gBAAgB,UAAU;AAQ1B,4BAAsB;EAClB,YAIA,QAIA,SAKA,kBAaA,eAMA,WAAW;AACP,SAAK,SAAS;AACd,SAAK,UAAU;AACf,SAAK,mBAAmB;AACxB,SAAK,gBAAgB;AACrB,SAAK,YAAY;;;AAIzB,gBAAgB,QAAQ;AAExB,gBAAgB,UAAU;AAE1B,gBAAgB,qBAAqB;AAErC,gBAAgB,uBAAuB,CAAC,UAAU;AAQlD,+BAAyB;EACrB,cAAc;;SAKP,cAAc,QAAQ;AACzB,WAAO,CAAC;;SAML,cAAc,QAAQ,MAAM;AAC/B,WAAO,CAAC,QAAQ,mBAAmB;;SAMhC,IAAI,QAAQ,MAAM,SAAS;AAC9B,WAAO,CAAC,QAAQ,mBAAmB,OAAO;;;AAGlD,mBAAmB,QAAQ;AAO3B,mBAAmB,cAAc,IAAI;AAkCrC,6BAAuB;EAMnB,YAMA,iBAKA,YAKA,UAOA,uBAKA,UAKA,YAAY;AACR,SAAK,kBAAkB;AACvB,SAAK,aAAa;AAClB,SAAK,WAAW;AAChB,SAAK,wBAAwB;AAC7B,SAAK,WAAW;AAChB,SAAK,aAAa;;;AAG1B,iBAAiB,QAAQ;AAOzB,iBAAiB,gBAAgB;AACjC,iBAAiB,oBAAoB;AAQrC,iBAAiB,0BAA0B;AAC3C,iBAAiB,8BAA8B,CAAC,cAAc;AAI9D,mCAA6B;EAKzB,YAAY,UAAU;AAClB,SAAK,WAAW;;;AAGxB,uBAAuB,QAAQ;AAC/B,uBAAuB,MAAM;AAU7B,qBAAe;EACX,YASA,UAIA,aAMA,UAkBA,aAeA,0BAMA,8BAQA,OAAO;AACH,SAAK,WAAW;AAChB,SAAK,cAAc;AACnB,SAAK,WAAW;AAChB,SAAK,cAAc;AACnB,SAAK,2BAA2B;AAChC,SAAK,+BAA+B;AACpC,SAAK,QAAQ;;;AAGrB,SAAS,QAAQ;AAEjB,SAAS,UAAU;AAEnB,SAAS,wBAAwB;AAMjC,SAAS,sBAAsB,CAAC,eAAe;AAW/C,6BAAuB;EACnB,YAIA,UAIA,MAMA,gBAAgB;AACZ,SAAK,WAAW;AAChB,SAAK,OAAO;AACZ,SAAK,iBAAiB;;;AAI9B,iBAAiB,QAAQ;AAEzB,iBAAiB,UAAU,CAAC,YAAY;AAExC,iBAAiB,uBAAuB;AAExC,iBAAiB,yBAAyB,CAAC,QAAQ;AAOnD,2BAAqB;EACjB,YAMA,iBAMA,6BASA,2BAIA,aAAa;AACT,SAAK,kBAAkB;AACvB,SAAK,8BAA8B;AACnC,SAAK,4BAA4B;AACjC,SAAK,cAAc;;;AAO3B,eAAe,MAAM;AACrB,eAAe,QAAQ;AAOvB,+BAAyB;EACrB,YAIA,cAKA,QAAQ;AACJ,SAAK,eAAe;AACpB,SAAK,SAAS;;;AAItB,mBAAmB,QAAQ;AAE3B,mBAAmB,UAAU,CAAC,gBAAgB;AAO9C,6BAAuB;EACnB,YAIA,UAEA,cAEA,gBAEA,cAAc;AACV,SAAK,WAAW;AAChB,SAAK,eAAe;AACpB,SAAK,iBAAiB;AACtB,SAAK,eAAe;;;AAI5B,iBAAiB,QAAQ;AAEzB,iBAAiB,UAAU;AAI3B,qBAAe;EACX,YAEA,UAEA,YAEA,UAAS;AACL,SAAK,WAAW;AAChB,SAAK,aAAa;AAClB,SAAK,UAAU;;;AAIvB,SAAS,QAAQ;AACjB,SAAS,UAAU;AAInB,yBAAmB;EACf,YAEA,OAEA,UAEA,cAAc;AACV,SAAK,OAAO;AACZ,SAAK,WAAW;AAChB,SAAK,eAAe;;;AAI5B,aAAa,QAAQ;AACrB,aAAa,UAAU;AAEvB,IAAM,YAAY;EACd,gBAAgB;EAChB,gBAAgB;EAChB,mBAAmB;EACnB,iBAAiB;EACjB,SAAS;EACT,gBAAgB;EAChB,eAAe;EACf,iBAAiB;;AAIrB,IAAM,YAAY;AAGlB,IAAM,YAAY,CAAC,GAAG,WAAW,iBAAiB;AAElD,IAAM,YAAY,CAAC,GAAG,WAAW,uBAAuB;AAExD,IAAM,YAAY,CAAC,GAAG,WAAW,mBAAmB;AAGpD,IAAM,aAAa,CAAC,GAAG,WAAW,SAAS,OAAO,aAAa;AAQ/D,AAsCA,AAuLA,AA0WA,qCAAqC,GAAG;AAGpC,SAAO,EAAE,SAAS;;AA2PtB,AA4BA,AAqBA,qBAAqB,QAAQ;AACzB,SAAO,+BAAc;;AAGzB,AAgBA,mBAAa;SACF,QAAQ;AAEX,UAAM,QAAQ;AAEd,UAAM,cAAc,KAAK,MAAM,MAAM,MAAM,UAAU,MAAM;AAC3D,QAAI,SAAS;AACb,UAAM,eAAe;AACrB,WAAO,OAAO,SAAS,cAAc;AACjC,YAAM,QAAQ,YAAY;AAC1B,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE,GAAG;AAGnC,YAAI,OAAO,SAAS,gBAAgB,MAAM,KAAK,aAAa;AACxD,oBAAU,MAAM,OAAO,MAAM,KAAK,MAAM;;;;AAIpD,WAAO;;;AAGf,6BAA6B,MAAM,OAAO;AACtC,MAAI,OAAO,OAAO;AACd,WAAO;;AAEX,MAAI,OAAO,OAAO;AACd,WAAO;;AAEX,SAAO;;AAkBX,AA2KA,AAiDA,AAyCA,AAoDA,AAgBA,sBAAsB,SAAS;AAG3B,MAAI,mBAAmB,KAAK,UAAU;AAClC,UAAM,IAAI,eAAe,KAAK,kBAAkB,gCAAgC;;AAEpF,SAAO,IAAI,OAAO,SAAS,UAAU,SAAS;;AAGlD,sBAAsB,KAAK;AACvB,SAAO,IAAI,OAAO,KAAK,UAAU,SAAS;;AAO9C,AAyBA,uBAAiB;EACb,YAAY,cAAc;AACtB,SAAK,eAAe;;SAEjB,iBAAiB,QAAQ;AAC5B,UAAM,eAAe,aAAa;AAClC,WAAO,IAAI,WAAW;;SAEnB,eAAe,OAAO;AACzB,UAAM,eAAe,2BAA2B;AAChD,WAAO,IAAI,WAAW;;EAE1B,WAAW;AACP,WAAO,aAAa,KAAK;;EAE7B,eAAe;AACX,WAAO,2BAA2B,KAAK;;EAE3C,sBAAsB;AAClB,WAAO,KAAK,aAAa,SAAS;;EAEtC,UAAU,OAAO;AACb,WAAO,oBAAoB,KAAK,cAAc,MAAM;;EAExD,QAAQ,OAAO;AACX,WAAO,KAAK,iBAAiB,MAAM;;;AAG3C,WAAW,oBAAoB,IAAI,WAAW;AAI9C,oCAAoC,OAAO;AACvC,MAAI,eAAe;AACnB,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE,GAAG;AACnC,oBAAgB,OAAO,aAAa,MAAM;;AAE9C,SAAO;;AAKX,oCAAoC,cAAc;AAC9C,QAAM,SAAS,IAAI,WAAW,aAAa;AAC3C,WAAS,IAAI,GAAG,IAAI,aAAa,QAAQ,KAAK;AAC1C,WAAO,KAAK,aAAa,WAAW;;AAExC,SAAO;;AAGX,AAiBA,IAAM,wBAAwB,IAAI,OAAO;AA+DzC,AAsFA,AA0CA,AAmBA,wBAAkB;EACd,YAAY,MAAM;AACd,SAAK,OAAO;;SAET,SAAS,MAAM;AAClB,WAAO,IAAI,YAAY,aAAa,WAAW;;SAE5C,SAAS,OAAM;AAClB,WAAO,IAAI,YAAY,aAAa,WAAW,OAAM,SAAS;;EAGlE,gBAAgB,cAAc;AAC1B,WAAQ,KAAK,KAAK,UAAU,KACxB,KAAK,KAAK,IAAI,KAAK,KAAK,SAAS,OAAO;;EAEhD,QAAQ,OAAO;AACX,WAAQ,UAAU,QAAQ,aAAa,WAAW,KAAK,MAAM,MAAM,UAAU;;EAEjF,WAAW;AACP,WAAO,KAAK,KAAK;;SAEd,WAAW,IAAI,IAAI;AACtB,WAAO,aAAa,WAAW,GAAG,MAAM,GAAG;;SAExC,cAAc,MAAM;AACvB,WAAO,KAAK,SAAS,MAAM;;SAQxB,aAAa,UAAU;AAC1B,WAAO,IAAI,YAAY,IAAI,aAAa,SAAS;;;AAIzD,AAqaA,AAsKA,AA2JA,AAmZA,AAiUA,AAkBA,sBAAgB;EACZ,YAAY,YAAY,MAAM;AAC1B,SAAK,aAAa;AAClB,SAAK,OAAO,OAAO,OAAO,SAAS;;EAGvC,OAAO,KAAK,OAAO;AACf,WAAO,IAAI,UAAU,KAAK,YAAY,KAAK,KACtC,OAAO,KAAK,OAAO,KAAK,YACxB,KAAK,MAAM,MAAM,SAAS,OAAO,MAAM;;EAGhD,OAAO,KAAK;AACR,WAAO,IAAI,UAAU,KAAK,YAAY,KAAK,KACtC,OAAO,KAAK,KAAK,YACjB,KAAK,MAAM,MAAM,SAAS,OAAO,MAAM;;EAGhD,IAAI,KAAK;AACL,QAAI,OAAO,KAAK;AAChB,WAAO,CAAC,KAAK,WAAW;AACpB,YAAM,MAAM,KAAK,WAAW,KAAK,KAAK;AACtC,UAAI,QAAQ,GAAG;AACX,eAAO,KAAK;iBAEP,MAAM,GAAG;AACd,eAAO,KAAK;iBAEP,MAAM,GAAG;AACd,eAAO,KAAK;;;AAGpB,WAAO;;EAIX,QAAQ,KAAK;AAET,QAAI,cAAc;AAClB,QAAI,OAAO,KAAK;AAChB,WAAO,CAAC,KAAK,WAAW;AACpB,YAAM,MAAM,KAAK,WAAW,KAAK,KAAK;AACtC,UAAI,QAAQ,GAAG;AACX,eAAO,cAAc,KAAK,KAAK;iBAE1B,MAAM,GAAG;AACd,eAAO,KAAK;aAEX;AAED,uBAAe,KAAK,KAAK,OAAO;AAChC,eAAO,KAAK;;;AAIpB,WAAO;;EAEX,UAAU;AACN,WAAO,KAAK,KAAK;;MAGjB,OAAO;AACP,WAAO,KAAK,KAAK;;EAGrB,SAAS;AACL,WAAO,KAAK,KAAK;;EAGrB,SAAS;AACL,WAAO,KAAK,KAAK;;EAMrB,iBAAiB,QAAQ;AACrB,WAAO,KAAK,KAAK,iBAAiB;;EAEtC,QAAQ,IAAI;AACR,SAAK,iBAAiB,CAAC,GAAG,MAAM;AAC5B,SAAG,GAAG;AACN,aAAO;;;EAGf,WAAW;AACP,UAAM,eAAe;AACrB,SAAK,iBAAiB,CAAC,GAAG,MAAM;AAC5B,mBAAa,KAAK,GAAG,KAAK;AAC1B,aAAO;;AAEX,WAAO,IAAI,aAAa,KAAK;;EAOjC,iBAAiB,QAAQ;AACrB,WAAO,KAAK,KAAK,iBAAiB;;EAGtC,cAAc;AACV,WAAO,IAAI,kBAAkB,KAAK,MAAM,MAAM,KAAK,YAAY;;EAEnE,gBAAgB,KAAK;AACjB,WAAO,IAAI,kBAAkB,KAAK,MAAM,KAAK,KAAK,YAAY;;EAElE,qBAAqB;AACjB,WAAO,IAAI,kBAAkB,KAAK,MAAM,MAAM,KAAK,YAAY;;EAEnE,uBAAuB,KAAK;AACxB,WAAO,IAAI,kBAAkB,KAAK,MAAM,KAAK,KAAK,YAAY;;;AAItE,8BAAwB;EACpB,YAAY,MAAM,UAAU,YAAY,WAAW;AAC/C,SAAK,YAAY;AACjB,SAAK,YAAY;AACjB,QAAI,MAAM;AACV,WAAO,CAAC,KAAK,WAAW;AACpB,YAAM,WAAW,WAAW,KAAK,KAAK,YAAY;AAElD,UAAI,WAAW;AACX,eAAO;;AAEX,UAAI,MAAM,GAAG;AAET,YAAI,KAAK,WAAW;AAChB,iBAAO,KAAK;eAEX;AACD,iBAAO,KAAK;;iBAGX,QAAQ,GAAG;AAGhB,aAAK,UAAU,KAAK;AACpB;aAEC;AAGD,aAAK,UAAU,KAAK;AACpB,YAAI,KAAK,WAAW;AAChB,iBAAO,KAAK;eAEX;AACD,iBAAO,KAAK;;;;;EAK5B,UAAU;AACN,QAAI,OAAO,KAAK,UAAU;AAC1B,UAAM,SAAS,EAAE,KAAK,KAAK,KAAK,OAAO,KAAK;AAC5C,QAAI,KAAK,WAAW;AAChB,aAAO,KAAK;AACZ,aAAO,CAAC,KAAK,WAAW;AACpB,aAAK,UAAU,KAAK;AACpB,eAAO,KAAK;;WAGf;AACD,aAAO,KAAK;AACZ,aAAO,CAAC,KAAK,WAAW;AACpB,aAAK,UAAU,KAAK;AACpB,eAAO,KAAK;;;AAGpB,WAAO;;EAEX,UAAU;AACN,WAAO,KAAK,UAAU,SAAS;;EAEnC,OAAO;AACH,QAAI,KAAK,UAAU,WAAW,GAAG;AAC7B,aAAO;;AAEX,UAAM,OAAO,KAAK,UAAU,KAAK,UAAU,SAAS;AACpD,WAAO,EAAE,KAAK,KAAK,KAAK,OAAO,KAAK;;;AAI5C,qBAAe;EACX,YAAY,KAAK,OAAO,OAAO,MAAM,OAAO;AACxC,SAAK,MAAM;AACX,SAAK,QAAQ;AACb,SAAK,QAAQ,SAAS,OAAO,QAAQ,SAAS;AAC9C,SAAK,OAAO,QAAQ,OAAO,OAAO,SAAS;AAC3C,SAAK,QAAQ,SAAS,OAAO,QAAQ,SAAS;AAC9C,SAAK,OAAO,KAAK,KAAK,OAAO,IAAI,KAAK,MAAM;;EAGhD,KAAK,KAAK,OAAO,OAAO,MAAM,OAAO;AACjC,WAAO,IAAI,SAAS,OAAO,OAAO,MAAM,KAAK,KAAK,SAAS,OAAO,QAAQ,KAAK,OAAO,SAAS,OAAO,QAAQ,KAAK,OAAO,QAAQ,OAAO,OAAO,KAAK,MAAM,SAAS,OAAO,QAAQ,KAAK;;EAE5L,UAAU;AACN,WAAO;;EAMX,iBAAiB,QAAQ;AACrB,WAAQ,KAAK,KAAK,iBAAiB,WAC/B,OAAO,KAAK,KAAK,KAAK,UACtB,KAAK,MAAM,iBAAiB;;EAMpC,iBAAiB,QAAQ;AACrB,WAAQ,KAAK,MAAM,iBAAiB,WAChC,OAAO,KAAK,KAAK,KAAK,UACtB,KAAK,KAAK,iBAAiB;;EAGnC,MAAM;AACF,QAAI,KAAK,KAAK,WAAW;AACrB,aAAO;WAEN;AACD,aAAO,KAAK,KAAK;;;EAIzB,SAAS;AACL,WAAO,KAAK,MAAM;;EAGtB,SAAS;AACL,QAAI,KAAK,MAAM,WAAW;AACtB,aAAO,KAAK;WAEX;AACD,aAAO,KAAK,MAAM;;;EAI1B,OAAO,KAAK,OAAO,YAAY;AAC3B,QAAI,IAAI;AACR,UAAM,MAAM,WAAW,KAAK,EAAE;AAC9B,QAAI,MAAM,GAAG;AACT,UAAI,EAAE,KAAK,MAAM,MAAM,MAAM,EAAE,KAAK,OAAO,KAAK,OAAO,aAAa;eAE/D,QAAQ,GAAG;AAChB,UAAI,EAAE,KAAK,MAAM,OAAO,MAAM,MAAM;WAEnC;AACD,UAAI,EAAE,KAAK,MAAM,MAAM,MAAM,MAAM,EAAE,MAAM,OAAO,KAAK,OAAO;;AAElE,WAAO,EAAE;;EAEb,YAAY;AACR,QAAI,KAAK,KAAK,WAAW;AACrB,aAAO,SAAS;;AAEpB,QAAI,IAAI;AACR,QAAI,CAAC,EAAE,KAAK,WAAW,CAAC,EAAE,KAAK,KAAK,SAAS;AACzC,UAAI,EAAE;;AAEV,QAAI,EAAE,KAAK,MAAM,MAAM,MAAM,EAAE,KAAK,aAAa;AACjD,WAAO,EAAE;;EAGb,OAAO,KAAK,YAAY;AACpB,QAAI;AACJ,QAAI,IAAI;AACR,QAAI,WAAW,KAAK,EAAE,OAAO,GAAG;AAC5B,UAAI,CAAC,EAAE,KAAK,aAAa,CAAC,EAAE,KAAK,WAAW,CAAC,EAAE,KAAK,KAAK,SAAS;AAC9D,YAAI,EAAE;;AAEV,UAAI,EAAE,KAAK,MAAM,MAAM,MAAM,EAAE,KAAK,OAAO,KAAK,aAAa;WAE5D;AACD,UAAI,EAAE,KAAK,SAAS;AAChB,YAAI,EAAE;;AAEV,UAAI,CAAC,EAAE,MAAM,aAAa,CAAC,EAAE,MAAM,WAAW,CAAC,EAAE,MAAM,KAAK,SAAS;AACjE,YAAI,EAAE;;AAEV,UAAI,WAAW,KAAK,EAAE,SAAS,GAAG;AAC9B,YAAI,EAAE,MAAM,WAAW;AACnB,iBAAO,SAAS;eAEf;AACD,qBAAW,EAAE,MAAM;AACnB,cAAI,EAAE,KAAK,SAAS,KAAK,SAAS,OAAO,MAAM,MAAM,EAAE,MAAM;;;AAGrE,UAAI,EAAE,KAAK,MAAM,MAAM,MAAM,MAAM,EAAE,MAAM,OAAO,KAAK;;AAE3D,WAAO,EAAE;;EAEb,QAAQ;AACJ,WAAO,KAAK;;EAGhB,QAAQ;AACJ,QAAI,IAAI;AACR,QAAI,EAAE,MAAM,WAAW,CAAC,EAAE,KAAK,SAAS;AACpC,UAAI,EAAE;;AAEV,QAAI,EAAE,KAAK,WAAW,EAAE,KAAK,KAAK,SAAS;AACvC,UAAI,EAAE;;AAEV,QAAI,EAAE,KAAK,WAAW,EAAE,MAAM,SAAS;AACnC,UAAI,EAAE;;AAEV,WAAO;;EAEX,cAAc;AACV,QAAI,IAAI,KAAK;AACb,QAAI,EAAE,MAAM,KAAK,SAAS;AACtB,UAAI,EAAE,KAAK,MAAM,MAAM,MAAM,MAAM,EAAE,MAAM;AAC3C,UAAI,EAAE;AACN,UAAI,EAAE;;AAEV,WAAO;;EAEX,eAAe;AACX,QAAI,IAAI,KAAK;AACb,QAAI,EAAE,KAAK,KAAK,SAAS;AACrB,UAAI,EAAE;AACN,UAAI,EAAE;;AAEV,WAAO;;EAEX,aAAa;AACT,UAAM,KAAK,KAAK,KAAK,MAAM,MAAM,SAAS,KAAK,MAAM,KAAK,MAAM;AAChE,WAAO,KAAK,MAAM,KAAK,MAAM,MAAM,KAAK,OAAO,IAAI;;EAEvD,cAAc;AACV,UAAM,KAAK,KAAK,KAAK,MAAM,MAAM,SAAS,KAAK,KAAK,KAAK,OAAO;AAChE,WAAO,KAAK,KAAK,KAAK,MAAM,MAAM,KAAK,OAAO,MAAM;;EAExD,YAAY;AACR,UAAM,OAAO,KAAK,KAAK,KAAK,MAAM,MAAM,CAAC,KAAK,KAAK,OAAO,MAAM;AAChE,UAAM,QAAQ,KAAK,MAAM,KAAK,MAAM,MAAM,CAAC,KAAK,MAAM,OAAO,MAAM;AACnE,WAAO,KAAK,KAAK,MAAM,MAAM,CAAC,KAAK,OAAO,MAAM;;EAGpD,gBAAgB;AACZ,UAAM,aAAa,KAAK;AACxB,QAAI,KAAK,IAAI,GAAK,eAAe,KAAK,OAAO,GAAG;AAC5C,aAAO;WAEN;AACD,aAAO;;;EAKf,QAAQ;AACJ,QAAI,KAAK,WAAW,KAAK,KAAK,SAAS;AACnC,YAAM;;AAEV,QAAI,KAAK,MAAM,SAAS;AACpB,YAAM;;AAEV,UAAM,aAAa,KAAK,KAAK;AAC7B,QAAI,eAAe,KAAK,MAAM,SAAS;AACnC,YAAM;WAEL;AACD,aAAO,aAAc,MAAK,UAAU,IAAI;;;;AAMpD,SAAS,QAAQ;AACjB,SAAS,MAAM;AACf,SAAS,QAAQ;AAEjB,0BAAoB;EAChB,cAAc;AACV,SAAK,OAAO;;MAEZ,MAAM;AACN,UAAM;;MAEN,QAAQ;AACR,UAAM;;MAEN,QAAQ;AACR,UAAM;;MAEN,OAAO;AACP,UAAM;;MAEN,QAAQ;AACR,UAAM;;EAGV,KAAK,KAAK,OAAO,OAAO,MAAM,OAAO;AACjC,WAAO;;EAGX,OAAO,KAAK,OAAO,YAAY;AAC3B,WAAO,IAAI,SAAS,KAAK;;EAG7B,OAAO,KAAK,YAAY;AACpB,WAAO;;EAEX,UAAU;AACN,WAAO;;EAEX,iBAAiB,QAAQ;AACrB,WAAO;;EAEX,iBAAiB,QAAQ;AACrB,WAAO;;EAEX,SAAS;AACL,WAAO;;EAEX,SAAS;AACL,WAAO;;EAEX,QAAQ;AACJ,WAAO;;EAGX,gBAAgB;AACZ,WAAO;;EAEX,QAAQ;AACJ,WAAO;;;AAGf,SAAS,QAAQ,IAAI;AAErB,AAuBA,sBAAgB;EACZ,YAAY,YAAY;AACpB,SAAK,aAAa;AAClB,SAAK,OAAO,IAAI,UAAU,KAAK;;EAEnC,IAAI,MAAM;AACN,WAAO,KAAK,KAAK,IAAI,UAAU;;EAEnC,QAAQ;AACJ,WAAO,KAAK,KAAK;;EAErB,OAAO;AACH,WAAO,KAAK,KAAK;;MAEjB,OAAO;AACP,WAAO,KAAK,KAAK;;EAErB,QAAQ,MAAM;AACV,WAAO,KAAK,KAAK,QAAQ;;EAG7B,QAAQ,IAAI;AACR,SAAK,KAAK,iBAAiB,CAAC,GAAG,MAAM;AACjC,SAAG;AACH,aAAO;;;EAIf,eAAe,OAAO,IAAI;AACtB,UAAM,OAAO,KAAK,KAAK,gBAAgB,MAAM;AAC7C,WAAO,KAAK,WAAW;AACnB,YAAM,OAAO,KAAK;AAClB,UAAI,KAAK,WAAW,KAAK,KAAK,MAAM,OAAO,GAAG;AAC1C;;AAEJ,SAAG,KAAK;;;EAMhB,aAAa,IAAI,OAAO;AACpB,QAAI;AACJ,QAAI,UAAU,QAAW;AACrB,aAAO,KAAK,KAAK,gBAAgB;WAEhC;AACD,aAAO,KAAK,KAAK;;AAErB,WAAO,KAAK,WAAW;AACnB,YAAM,OAAO,KAAK;AAClB,YAAM,SAAS,GAAG,KAAK;AACvB,UAAI,CAAC,QAAQ;AACT;;;;EAKZ,kBAAkB,MAAM;AACpB,UAAM,OAAO,KAAK,KAAK,gBAAgB;AACvC,WAAO,KAAK,YAAY,KAAK,UAAU,MAAM;;EAEjD,cAAc;AACV,WAAO,IAAI,kBAAkB,KAAK,KAAK;;EAE3C,gBAAgB,KAAK;AACjB,WAAO,IAAI,kBAAkB,KAAK,KAAK,gBAAgB;;EAG3D,IAAI,MAAM;AACN,WAAO,KAAK,KAAK,KAAK,KAAK,OAAO,MAAM,OAAO,MAAM;;EAGzD,OAAO,MAAM;AACT,QAAI,CAAC,KAAK,IAAI,OAAO;AACjB,aAAO;;AAEX,WAAO,KAAK,KAAK,KAAK,KAAK,OAAO;;EAEtC,UAAU;AACN,WAAO,KAAK,KAAK;;EAErB,UAAU,OAAO;AACb,QAAI,SAAS;AAEb,QAAI,OAAO,OAAO,MAAM,MAAM;AAC1B,eAAS;AACT,cAAQ;;AAEZ,UAAM,QAAQ,UAAQ;AAClB,eAAS,OAAO,IAAI;;AAExB,WAAO;;EAEX,QAAQ,OAAO;AACX,QAAI,CAAE,kBAAiB,YAAY;AAC/B,aAAO;;AAEX,QAAI,KAAK,SAAS,MAAM,MAAM;AAC1B,aAAO;;AAEX,UAAM,SAAS,KAAK,KAAK;AACzB,UAAM,UAAU,MAAM,KAAK;AAC3B,WAAO,OAAO,WAAW;AACrB,YAAM,WAAW,OAAO,UAAU;AAClC,YAAM,YAAY,QAAQ,UAAU;AACpC,UAAI,KAAK,WAAW,UAAU,eAAe,GAAG;AAC5C,eAAO;;;AAGf,WAAO;;EAEX,UAAU;AACN,UAAM,MAAM;AACZ,SAAK,QAAQ,cAAY;AACrB,UAAI,KAAK;;AAEb,WAAO;;EAEX,WAAW;AACP,UAAM,SAAS;AACf,SAAK,QAAQ,UAAQ,OAAO,KAAK;AACjC,WAAO,eAAe,OAAO,aAAa;;EAE9C,KAAK,MAAM;AACP,UAAM,SAAS,IAAI,UAAU,KAAK;AAClC,WAAO,OAAO;AACd,WAAO;;;AAGf,8BAAwB;EACpB,YAAY,MAAM;AACd,SAAK,OAAO;;EAEhB,UAAU;AACN,WAAO,KAAK,KAAK,UAAU;;EAE/B,UAAU;AACN,WAAO,KAAK,KAAK;;;AAIzB,AAgBA,IAAM,6BAA6B,IAAI,UAAU,YAAY;AAI7D,IAAM,qBAAqB,IAAI,UAAU,YAAY;AAIrD,IAAM,6BAA6B,IAAI,UAAU,YAAY;AAI7D,IAAM,yBAAyB,IAAI,UAAU,YAAY;AAQzD,IAAM,sBAAsB,IAAI,UAAU;AAK1C,AAiDA,AAmKA,AAkcA,AAqIA,AAuBA,AA0BA,IAAI;AACJ,AAAC,UAAU,UAAS;AAChB,WAAQ,SAAQ,QAAQ,KAAK;AAC7B,WAAQ,SAAQ,eAAe,KAAK;AACpC,WAAQ,SAAQ,aAAa,KAAK;AAClC,WAAQ,SAAQ,sBAAsB,KAAK;AAC3C,WAAQ,SAAQ,uBAAuB,KAAK;AAC5C,WAAQ,SAAQ,eAAe,KAAK;AACpC,WAAQ,SAAQ,oBAAoB,KAAK;AACzC,WAAQ,SAAQ,uBAAuB,KAAK;AAC5C,WAAQ,SAAQ,qBAAqB,MAAM;AAC3C,WAAQ,SAAQ,wBAAwB,KAAK;AAC7C,WAAQ,SAAQ,yBAAyB,KAAK;AAC9C,WAAQ,SAAQ,aAAa,MAAM;AACnC,WAAQ,SAAQ,kBAAkB,MAAM;AACxC,WAAQ,SAAQ,mBAAmB,MAAM;AACzC,WAAQ,SAAQ,cAAc,MAAM;AACpC,WAAQ,SAAQ,iBAAiB,MAAM;AACvC,WAAQ,SAAQ,eAAe,MAAM;GACtC,WAAY,WAAU;AA2GzB,AAsHA,AAsgBA,AAgBA,IAAM,aAAc,OAAM;AACtB,QAAM,OAAO;AACb,OAAK,SAAyB;AAC9B,OAAK,UAA2B;AAChC,SAAO;;AAEX,IAAM,YAAa,OAAM;AACrB,QAAM,MAAM;AACZ,MAAI,OAAuB;AAC3B,MAAI,QAAiC;AACrC,MAAI,OAA0B;AAC9B,MAAI,QAAoC;AACxC,MAAI,QAAoB;AACxB,MAAI,QAAwB;AAC5B,MAAI,oBAAyC;AAC7C,MAAI,QAAiB;AACrB,MAAI,YAAyB;AAC7B,MAAI,wBAAiD;AACrD,SAAO;;AAw0BX,AA6EA,AAgOA,AAyDA,AA+DA,AAoFA,AAgEA,AA+YA,AAqDA,AA0QA,AAoCA,AAsBA,IAAM,0BAA0B;AAChC,IAAM,+BAA+B,KAAK,OAAO;AACjD,sBAAgB;EACZ,YAGA,8BAEA,qBAGA,iCAAiC;AAC7B,SAAK,+BAA+B;AACpC,SAAK,sBAAsB;AAC3B,SAAK,kCAAkC;;SAEpC,cAAc,WAAW;AAC5B,WAAO,IAAI,UAAU,WAAW,UAAU,+BAA+B,UAAU;;;AAG3F,UAAU,gCAAgC;AAC1C,UAAU,0CAA0C;AACpD,UAAU,UAAU,IAAI,UAAU,8BAA8B,UAAU,+BAA+B,UAAU;AACnH,UAAU,WAAW,IAAI,UAAU,yBAAyB,GAAG;AAE/D,AAiBA,IAAM,+BAA+B,IAAI,OAAO;AAEhD,IAAM,sBAAsB,IAAI,KAAK;AAErC,IAAM,sBAAsB,IAAI,KAAK;AA0MrC,AAyJA,AAqGA,AAmHA,AA+WA,AAkTA,AAqBA,IAAM,oBAAoB,KAAK,KAAK;AAotBpC,AAqMA,AAwBA,IAAM,8BAA8B,IAAI,KAAK;AA+wB7C,AAsCA,AAqHA,AA+MA,AA6JA,AAsIA,AAkMA,AAiIA,AAsEA,AAyoBA,AAyBA,AAoDA,AAmEA,AAkBA,IAAM,WAAU,sBAAO,cAAc,YAAY;AAEjD,IAAM,EAAE,SAAS,gBAAgB,SAAQ;AAEzC,IAAM,0BAA0B,WAAW,QAAQ,SAAS,aAAa,qBAAoB;AAoJ7F,AAkBA,IAAM,aAAa,8BAAc,YAAY;AAC7C,IAAM,aAAY,yBAAQ;AAoB1B,AA0BA,AA6BA,AAgCA,AAgBA,IAAM,YAAY;AAKlB,IAAM,mCAAmC;AACzC,IAAM,yBAAyB;AAE/B,IAAM,+BAA+B,KAAK;AAU1C,+BAAyB;EACrB,YAIA,OAIA,SAMA,iBAAiB,kCAKjB,gBAAgB,wBAMhB,aAAa,8BAA8B;AACvC,SAAK,QAAQ;AACb,SAAK,UAAU;AACf,SAAK,iBAAiB;AACtB,SAAK,gBAAgB;AACrB,SAAK,aAAa;AAClB,SAAK,gBAAgB;AACrB,SAAK,eAAe;AAEpB,SAAK,kBAAkB,KAAK;AAC5B,SAAK;;EAST,QAAQ;AACJ,SAAK,gBAAgB;;EAMzB,aAAa;AACT,SAAK,gBAAgB,KAAK;;EAO9B,cAAc,IAAI;AAEd,SAAK;AAGL,UAAM,2BAA2B,KAAK,MAAM,KAAK,gBAAgB,KAAK;AAEtE,UAAM,eAAe,KAAK,IAAI,GAAG,KAAK,QAAQ,KAAK;AAEnD,UAAM,mBAAmB,KAAK,IAAI,GAAG,2BAA2B;AAChE,QAAI,mBAAmB,GAAG;AACtB,eAAS,WAAW,mBAAmB,oCACnB,KAAK,wCACC,8CACL;;AAEzB,SAAK,eAAe,KAAK,MAAM,kBAAkB,KAAK,SAAS,kBAAkB,MAAM;AACnF,WAAK,kBAAkB,KAAK;AAC5B,aAAO;;AAIX,SAAK,iBAAiB,KAAK;AAC3B,QAAI,KAAK,gBAAgB,KAAK,gBAAgB;AAC1C,WAAK,gBAAgB,KAAK;;AAE9B,QAAI,KAAK,gBAAgB,KAAK,YAAY;AACtC,WAAK,gBAAgB,KAAK;;;EAGlC,cAAc;AACV,QAAI,KAAK,iBAAiB,MAAM;AAC5B,WAAK,aAAa;AAClB,WAAK,eAAe;;;EAG5B,SAAS;AACL,QAAI,KAAK,iBAAiB,MAAM;AAC5B,WAAK,aAAa;AAClB,WAAK,eAAe;;;EAI5B,gBAAgB;AACZ,WAAQ,MAAK,WAAW,OAAO,KAAK;;;AAI5C,AAkBA,IAAM,kBAAkB,KAAK;AAE7B,IAAM,qBAAqB,KAAK;AAkbhC,AAgIA,AA2BA,IAAM,0BAA0B,KAAK;AA2HrC,AA2kBA,AAgBA,IAAM,YAAY;AAYlB,6BAAuB;EACnB,YAAY,YAAY,SAAS,cAAc,IAAI,iBAAiB;AAChE,SAAK,aAAa;AAClB,SAAK,UAAU;AACf,SAAK,eAAe;AACpB,SAAK,KAAK;AACV,SAAK,kBAAkB;AACvB,SAAK,WAAW,IAAI;AACpB,SAAK,OAAO,KAAK,SAAS,QAAQ,KAAK,KAAK,KAAK,SAAS;AAI1D,SAAK,SAAS,QAAQ,MAAM,SAAO;;;SAgBhC,kBAAkB,YAAY,SAAS,SAAS,IAAI,iBAAiB;AACxE,UAAM,aAAa,KAAK,QAAQ;AAChC,UAAM,YAAY,IAAI,iBAAiB,YAAY,SAAS,YAAY,IAAI;AAC5E,cAAU,MAAM;AAChB,WAAO;;EAMX,MAAM,SAAS;AACX,SAAK,cAAc,WAAW,MAAM,KAAK,sBAAsB;;EAMnE,YAAY;AACR,WAAO,KAAK;;EAShB,OAAO,QAAQ;AACX,QAAI,KAAK,gBAAgB,MAAM;AAC3B,WAAK;AACL,WAAK,SAAS,OAAO,IAAI,eAAe,KAAK,WAAW,wBAAyB,UAAS,OAAO,SAAS;;;EAGlH,qBAAqB;AACjB,SAAK,WAAW,iBAAiB,MAAM;AACnC,UAAI,KAAK,gBAAgB,MAAM;AAC3B,aAAK;AACL,eAAO,KAAK,KAAK,KAAK,YAAU;AAC5B,iBAAO,KAAK,SAAS,QAAQ;;aAGhC;AACD,eAAO,QAAQ;;;;EAI3B,eAAe;AACX,QAAI,KAAK,gBAAgB,MAAM;AAC3B,WAAK,gBAAgB;AACrB,mBAAa,KAAK;AAClB,WAAK,cAAc;;;;AAQ/B,sCAAsC,GAAG,KAAK;AAC1C,WAAS,WAAW,GAAG,QAAQ;AAC/B,MAAI,4BAA4B,IAAI;AAChC,WAAO,IAAI,eAAe,KAAK,aAAa,GAAG,QAAQ;SAEtD;AACD,UAAM;;;AAId,AAiIA,AA8IA,AA6PA,AA8CA,AAuBA,AA2IA,AA6XA,AA+7BA,AA8LA,AAsDA,AAyBA,mCAAmC,aAAa,WAAW,aAAa,WAAW;AAC/E,MAAI,cAAc,QAAQ,cAAc,MAAM;AAC1C,UAAM,IAAI,eAAe,KAAK,kBAAkB,GAAG,mBAAmB;;;AA8G9E,AA0BA,AAyDA,AAgCA,AA4JA,AA8JA,AAqGA,AAgBA,IAAM,YAAY;AAClB,IAAM,mCAAmC;AAMzC,4BAAsB;EAClB,YAAY,cASZ,YAAY,cAAc;AACtB,SAAK,cAAc;AACnB,SAAK,aAAa;AAClB,SAAK,eAAe;AACpB,SAAK,OAAO,KAAK;AACjB,SAAK,WAAW,OAAO;AACvB,SAAK,qBAAqB,MAAM,QAAQ;AACxC,SAAK,YAAY,MAAM,YAAY,OAAO,SAAS;AAC/C,eAAS,WAAW,kBAAkB,KAAK;AAC3C,YAAM,KAAK,mBAAmB;AAC9B,WAAK,OAAO;;;QAGd,mBAAmB;AACrB,WAAO;MACH,YAAY,KAAK;MACjB,cAAc,KAAK;MACnB,UAAU,KAAK;MACf,aAAa,KAAK;MAClB,aAAa,KAAK;MAClB,+BAA+B;;;EAGvC,4BAA4B,UAAU;AAClC,SAAK,qBAAqB;;EAM9B,sBAAsB;AAClB,QAAI,KAAK,WAAW,gBAAgB;AAChC,YAAM,IAAI,eAAe,KAAK,qBAAqB;;;EAG3D,YAAY;AACR,SAAK,WAAW;AAChB,UAAM,WAAW,IAAI;AACrB,SAAK,WAAW,oCAAoC,YAAY;AAC5D,UAAI;AACA,YAAI,KAAK,kBAAkB;AACvB,gBAAM,KAAK,iBAAiB;;AAEhC,YAAI,KAAK,mBAAmB;AACxB,gBAAM,KAAK,kBAAkB;;AAKjC,aAAK,YAAY;AACjB,iBAAS;eAEN,GAAP;AACI,cAAM,iBAAiB,6BAA6B,GAAG;AACvD,iBAAS,OAAO;;;AAGxB,WAAO,SAAS;;;AA4TxB,AAgBA,yBAAmB;EAkBf,YAAY,YAAY,OAAO,gBAAgB,MAAM,KAAK,kBAAkB,uBAAuB,iBAAiB;AAChH,SAAK,aAAa;AAClB,SAAK,QAAQ;AACb,SAAK,iBAAiB;AACtB,SAAK,OAAO;AACZ,SAAK,MAAM;AACX,SAAK,mBAAmB;AACxB,SAAK,wBAAwB;AAC7B,SAAK,kBAAkB;;;AAI/B,IAAM,wBAAwB;AAK9B,uBAAiB;EACb,YAAY,WAAW,UAAU;AAC7B,SAAK,YAAY;AACjB,SAAK,WAAW,WAAW,WAAW;;MAEtC,oBAAoB;AACpB,WAAO,KAAK,aAAa;;EAE7B,QAAQ,OAAO;AACX,WAAQ,iBAAiB,cACrB,MAAM,cAAc,KAAK,aACzB,MAAM,aAAa,KAAK;;;AAIpC,AAgBA,IAAM,YAAY;AAKlB,IAAM,qBAAqB,IAAI;AAK/B,0BAA0B,WAAW;AACjC,QAAM,YAAY,mBAAmB,IAAI;AACzC,MAAI,WAAW;AACX,aAAS,WAAW;AACpB,uBAAmB,OAAO;AAC1B,cAAU;;;AAGlB,0BAA0B,YAAY,OAAO,gBAAgB,UAAU;AACnE,SAAO,IAAI,aAAa,YAAY,OAAO,gBAAgB,SAAS,MAAM,SAAS,KAAK,SAAS,8BAA8B,SAAS,mCAAmC,SAAS;;AAGxL,AAiBA,IAAM,eAAe;AACrB,IAAM,cAAc;AAMpB,kCAA4B;EACxB,YAAY,UAAU;AAClB,QAAI;AACJ,QAAI,SAAS,SAAS,QAAW;AAC7B,UAAI,SAAS,QAAQ,QAAW;AAC5B,cAAM,IAAI,eAAe,KAAK,kBAAkB;;AAEpD,WAAK,OAAO;AACZ,WAAK,MAAM;WAEV;AACD,WAAK,OAAO,SAAS;AACrB,WAAK,MAAO,MAAK,SAAS,SAAS,QAAQ,OAAO,SAAS,KAAK;;AAEpE,SAAK,cAAc,SAAS;AAC5B,SAAK,4BAA4B,CAAC,CAAC,SAAS;AAC5C,QAAI,SAAS,mBAAmB,QAAW;AACvC,WAAK,iBAAiB;WAErB;AACD,UAAI,SAAS,mBAAmB,2BAC5B,SAAS,iBAAiB,8BAA8B;AACxD,cAAM,IAAI,eAAe,KAAK,kBAAkB,mCAAmC;aAElF;AACD,aAAK,iBAAiB,SAAS;;;AAGvC,SAAK,+BAA+B,CAAC,CAAC,SAAS;AAC/C,SAAK,oCACD,CAAC,CAAC,SAAS;AACf,SAAK,kBAAkB,CAAC,CAAC,SAAS;AAClC,8BAA0B,gCAAgC,SAAS,8BAA8B,qCAAqC,SAAS;;EAEnJ,QAAQ,OAAO;AACX,WAAQ,KAAK,SAAS,MAAM,QACxB,KAAK,QAAQ,MAAM,OACnB,KAAK,gBAAgB,MAAM,eAC3B,KAAK,mBAAmB,MAAM,kBAC9B,KAAK,iCACD,MAAM,gCACV,KAAK,sCACD,MAAM,qCACV,KAAK,8BAA8B,MAAM,6BACzC,KAAK,oBAAoB,MAAM;;;AAI3C,AAqBA,wBAAkB;EAEd,YAAY,iBAAiB,cAAc;AACvC,SAAK,eAAe;AAIpB,SAAK,OAAO;AACZ,SAAK,kBAAkB;AACvB,SAAK,YAAY,IAAI,sBAAsB;AAC3C,SAAK,kBAAkB;AACvB,QAAI,2BAA2B,YAAY;AACvC,WAAK,cAAc;WAElB;AACD,WAAK,OAAO;AACZ,WAAK,cAAc,kBAAkB;;;MAOzC,MAAM;AACN,QAAI,CAAC,KAAK,MAAM;AACZ,YAAM,IAAI,eAAe,KAAK,qBAAqB;;AAGvD,WAAO,KAAK;;MAEZ,eAAe;AACf,WAAO,KAAK;;MAEZ,cAAc;AACd,WAAO,KAAK,mBAAmB;;EAEnC,aAAa,UAAU;AACnB,QAAI,KAAK,iBAAiB;AACtB,YAAM,IAAI,eAAe,KAAK,qBAAqB;;AAIvD,SAAK,YAAY,IAAI,sBAAsB;AAC3C,QAAI,SAAS,gBAAgB,QAAW;AACpC,WAAK,eAAe,wBAAwB,SAAS;;;EAG7D,eAAe;AACX,WAAO,KAAK;;EAEhB,kBAAkB;AACd,SAAK,kBAAkB;AACvB,WAAO,KAAK;;EAEhB,UAAU;AACN,QAAI,CAAC,KAAK,gBAAgB;AACtB,WAAK,iBAAiB,KAAK;;AAE/B,WAAO,KAAK;;EAGhB,SAAS;AACL,WAAO;MACH,KAAK,KAAK;MACV,YAAY,KAAK;MACjB,UAAU,KAAK;;;EAUvB,aAAa;AACT,qBAAiB;AACjB,WAAO,QAAQ;;;AAGvB,2BAA2B,MAAK;AAC5B,MAAI,CAAC,OAAO,UAAU,eAAe,MAAM,KAAI,SAAS,CAAC,eAAe;AACpE,UAAM,IAAI,eAAe,KAAK,kBAAkB;;AAEpD,SAAO,IAAI,WAAW,KAAI,QAAQ;;AA6CtC,AAuOA,AAgBA,IAAM,UAAU;AAChB,2BAAqB;EACjB,cAAc;AAEV,SAAK,OAAO,QAAQ;AAGpB,SAAK,eAAe;AAGpB,SAAK,kBAAkB;AAGvB,SAAK,oBAAoB;AAEzB,SAAK,UAAU;AAGf,SAAK,sBAAsB;AAE3B,SAAK,yBAAyB;AAE9B,SAAK,iBAAiB;AAEtB,SAAK,UAAU,IAAI,mBAAmB,MAAM;AAI5C,SAAK,oBAAoB,MAAM;AAC3B,WAAK,QAAQ;;;MAGjB,iBAAiB;AACjB,WAAO,KAAK;;EAMhB,iBAAiB,IAAI;AAEjB,SAAK,QAAQ;;EAEjB,oCAAoC,IAAI;AACpC,SAAK;AAEL,SAAK,gBAAgB;;EAEzB,oBAAoB,oBAAoB;AACpC,QAAI,CAAC,KAAK,iBAAiB;AACvB,WAAK,kBAAkB;AACvB,WAAK,yBAAyB,sBAAsB;;;EAG5D,QAAQ,IAAI;AACR,SAAK;AACL,QAAI,KAAK,iBAAiB;AAEtB,aAAO,IAAI,QAAQ,MAAM;;;AAK7B,UAAM,OAAO,IAAI;AACjB,WAAO,KAAK,gBAAgB,MAAM;AAC9B,UAAI,KAAK,mBAAmB,KAAK,wBAAwB;AAErD,eAAO,QAAQ;;AAEnB,WAAK,KAAK,KAAK,SAAS,KAAK;AAC7B,aAAO,KAAK;OACb,KAAK,MAAM,KAAK;;EAEvB,iBAAiB,IAAI;AACjB,SAAK,iBAAiB,MAAM;AACxB,WAAK,aAAa,KAAK;AACvB,aAAO,KAAK;;;QAOd,cAAc;AAChB,QAAI,KAAK,aAAa,WAAW,GAAG;AAChC;;AAEJ,QAAI;AACA,YAAM,KAAK,aAAa;AACxB,WAAK,aAAa;AAClB,WAAK,QAAQ;aAEV,GAAP;AACI,UAAI,4BAA4B,IAAI;AAChC,iBAAS,SAAS,4CAA4C;aAE7D;AACD,cAAM;;;AAGd,QAAI,KAAK,aAAa,SAAS,GAAG;AAW9B,WAAK,QAAQ,cAAc,MAAM,KAAK;;;EAG9C,gBAAgB,IAAI;AAChB,UAAM,UAAU,KAAK,KAAK,KAAK,MAAM;AACjC,WAAK,sBAAsB;AAC3B,aAAO,KACF,MAAM,CAAC,UAAU;AAClB,aAAK,UAAU;AACf,aAAK,sBAAsB;AAC3B,cAAM,UAAU,kBAAkB;AAClC,iBAAS,8BAA8B;AAIvC,cAAM;SAEL,KAAK,YAAU;AAChB,aAAK,sBAAsB;AAC3B,eAAO;;;AAGf,SAAK,OAAO;AACZ,WAAO;;EAEX,kBAAkB,SAAS,SAAS,IAAI;AACpC,SAAK;AAEL,QAAI,KAAK,eAAe,QAAQ,WAAW,IAAI;AAC3C,gBAAU;;AAEd,UAAM,YAAY,iBAAiB,kBAAkB,MAAM,SAAS,SAAS,IAAI,eAAa,KAAK,uBAAuB;AAC1H,SAAK,kBAAkB,KAAK;AAC5B,WAAO;;EAEX,kBAAkB;AACd,QAAI,KAAK,SAAS;AACd;;;EAGR,4BAA4B;;QAMtB,QAAQ;AAKV,QAAI;AACJ,OAAG;AACC,oBAAc,KAAK;AACnB,YAAM;aACD,gBAAgB,KAAK;;EAMlC,yBAAyB,SAAS;AAC9B,eAAW,MAAM,KAAK,mBAAmB;AACrC,UAAI,GAAG,YAAY,SAAS;AACxB,eAAO;;;AAGf,WAAO;;EASX,6BAA6B,aAAa;AAEtC,WAAO,KAAK,QAAQ,KAAK,MAAM;AAE3B,WAAK,kBAAkB,KAAK,CAAC,GAAG,MAAM,EAAE,eAAe,EAAE;AACzD,iBAAW,MAAM,KAAK,mBAAmB;AACrC,WAAG;AACH,YAAI,gBAAgB,SAAmB,GAAG,YAAY,aAAa;AAC/D;;;AAGR,aAAO,KAAK;;;EAMpB,qBAAqB,SAAS;AAC1B,SAAK,eAAe,KAAK;;EAG7B,uBAAuB,IAAI;AAEvB,UAAM,QAAQ,KAAK,kBAAkB,QAAQ;AAC7C,SAAK,kBAAkB,OAAO,OAAO;;;AAG7C,yBAAyB;AACrB,SAAO,IAAI;;AAOf,2BAA2B,OAAO;AAC9B,MAAI,UAAU,MAAM,WAAW;AAC/B,MAAI,MAAM,OAAO;AACb,QAAI,MAAM,MAAM,SAAS,MAAM,UAAU;AACrC,gBAAU,MAAM;WAEf;AACD,gBAAU,MAAM,UAAU,OAAO,MAAM;;;AAG/C,SAAO;;AAGX,AA8GA,AA+BA,8BAAwB,YAAY;EAEhC,YAAY,iBAAiB,qBAAqB;AAC9C,UAAM,iBAAiB;AAIvB,SAAK,OAAO;AACZ,SAAK,SAAS;AACd,SAAK,kBACD,UAAU,kBAAkB,gBAAgB,OAAO;;EAE3D,aAAa;AACT,QAAI,CAAC,KAAK,kBAAkB;AAGxB,yBAAmB;;AAEvB,WAAO,KAAK,iBAAiB;;;AA6CrC,sBAAsB,OAAM,UAAU;AAClC,SAAO,aAAa,MAAK,aAAa;;AAY1C,4BAA4B,WAAW;AACnC,MAAI;AACJ,QAAM,WAAW,UAAU;AAC3B,QAAM,eAAe,iBAAiB,UAAU,aAAe,OAAK,UAAU,UAAU,QAAQ,OAAO,SAAS,SAAS,GAAG,QAAQ,UAAU,IAAI,UAAU,iBAAiB;AAC7K,YAAU,mBAAmB,IAAI,gBAAgB,UAAU,cAAc,UAAU,QAAQ;;AAmR/F,AAgBA,2BAA2B,SAAS,kBAAkB,MAAM;AACxD,gBAAc;AACd,qBAAmB,IAAI,UAAU,aAAa,CAAC,WAAW,EAAE,SAAS,eAAe;AAChF,UAAM,OAAM,UAAU,YAAY,OAAO;AACzC,UAAM,oBAAoB,IAAI,UAAU,MAAK,IAAI,4BAA4B,UAAU,YAAY;AACnG,eAAW,OAAO,OAAO,EAAE,mBAAmB;AAC9C,sBAAkB,aAAa;AAC/B,WAAO;KACR;AACH,kBAAgB,OAAM,YAAW;AAEjC,kBAAgB,OAAM,YAAW;;AAGrC,AA0DA,AAiFA,AA8BA,AA2EA,AAmmBA,IAAM,sBAAsB,IAAI,OAAO;AAsDvC,AAwIA,AAoSA,AA0cA,AAoGA,AAyDA,AA2GA,AA6FA,AAoCA,AAwQA,AAsEA,AAsFA,AAiCA,AAgBA,kBAAkB;;;ACp7tBlB,IAAM,iBAAiB;AAAA,EACrB,QAAQ;AAAA,EACR,YAAY;AAAA,EACZ,WAAW;AAAA,EACX,eAAe;AAAA,EACf,mBAAmB;AAAA,EACnB,OAAO;AAAA;AAIT,IAAM,MAAM,cAAc;AAC1B,IAAM,KAAK;AAEX,IAAM,UAAU,MAAM,QAAQ;;;ACnB9B,QAAQ,UAAU,YAAY;AAC5B,QAAM,MAAM;AACZ,SAAO;AAAA,IACL,YAAY;AAAA,IACZ,MAAM,KAAK,UAAU;AAAA,IACrB,MAAM;AAAA;AAAA;",
  "names": []
}
